{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This module handles training and evaluation of a neural network model.\n",
    "\n",
    "Invoke the following command to train the model:\n",
    "python -m trainer --model=cnn --dataset=mnist\n",
    "\n",
    "You can then monitor the logs on Tensorboard:\n",
    "tensorboard --logdir=output\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "tf.flags.DEFINE_string(\"model\", \"\", \"Model name.\")\n",
    "tf.flags.DEFINE_string(\"dataset\", \"\", \"Dataset name.\")\n",
    "tf.flags.DEFINE_string(\"output_dir\", \"\", \"Optional output dir.\")\n",
    "tf.flags.DEFINE_string(\"schedule\", \"train_and_evaluate\", \"Schedule.\")\n",
    "tf.flags.DEFINE_string(\"hparams\", \"\", \"Hyper parameters.\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 100000, \"Number of training epochs.\")\n",
    "tf.flags.DEFINE_integer(\"save_summary_steps\", 10, \"Summary steps.\")\n",
    "tf.flags.DEFINE_integer(\"save_checkpoints_steps\", 10, \"Checkpoint steps.\")\n",
    "tf.flags.DEFINE_integer(\"eval_steps\", None, \"Number of eval steps.\")\n",
    "tf.flags.DEFINE_integer(\"eval_frequency\", 10, \"Eval frequency.\")\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "MODELS = {\n",
    "    # This is a dictionary of models, the keys are model names, and the values\n",
    "    # are the module containing get_params, model, and eval_metrics.\n",
    "    # Example: \"cnn\": cnn\n",
    "}\n",
    "\n",
    "DATASETS = {\n",
    "    # This is a dictionary of datasets, the keys are dataset names, and the\n",
    "    # values are the module containing get_params, prepare, read, and parse.\n",
    "    # Example: \"mnist\": mnist\n",
    "}\n",
    "\n",
    "HPARAMS = {\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"decay_steps\": 10000,\n",
    "    \"batch_size\": 128\n",
    "}\n",
    "\n",
    "def get_params():\n",
    "    \"\"\"Aggregates and returns hyper parameters.\"\"\"\n",
    "    hparams = HPARAMS\n",
    "    hparams.update(DATASETS[FLAGS.dataset].get_params())\n",
    "    hparams.update(MODELS[FLAGS.model].get_params())\n",
    "\n",
    "    hparams = tf.contrib.training.HParams(**hparams)\n",
    "    hparams.parse(FLAGS.hparams)\n",
    "\n",
    "    return hparams\n",
    "\n",
    "def make_input_fn(mode, params):\n",
    "    \"\"\"Returns an input function to read the dataset.\"\"\"\n",
    "    def _input_fn():\n",
    "        dataset = DATASETS[FLAGS.dataset].read(mode)\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            dataset = dataset.repeat(FLAGS.num_epochs)\n",
    "            dataset = dataset.shuffle(params.batch_size * 5)\n",
    "        dataset = dataset.map(\n",
    "            DATASETS[FLAGS.dataset].parse, num_threads=8)\n",
    "        dataset = dataset.batch(params.batch_size)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        features, labels = iterator.get_next()\n",
    "        return features, labels\n",
    "    return _input_fn\n",
    "\n",
    "def make_model_fn():\n",
    "    \"\"\"Returns a model function.\"\"\"\n",
    "    def _model_fn(features, labels, mode, params):\n",
    "        model_fn = MODELS[FLAGS.model].model\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "        predictions, loss = model_fn(features, labels, mode, params)\n",
    "\n",
    "        train_op = None\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            def _decay(learning_rate, global_step):\n",
    "                learning_rate = tf.train.exponential_decay(\n",
    "                    learning_rate, global_step, params.decay_steps, 0.5,\n",
    "                    staircase=True)\n",
    "                return learning_rate\n",
    "\n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "                loss=loss,\n",
    "                global_step=global_step,\n",
    "                learning_rate=params.learning_rate,\n",
    "                optimizer=params.optimizer,\n",
    "                learning_rate_decay_fn=_decay)\n",
    "\n",
    "        return tf.contrib.learn.ModelFnOps(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "            loss=loss,\n",
    "            train_op=train_op)\n",
    "\n",
    "    return _model_fn\n",
    "\n",
    "def experiment_fn(run_config, hparams):\n",
    "    \"\"\"Constructs an experiment object.\"\"\"\n",
    "    estimator = tf.contrib.learn.Estimator(\n",
    "        model_fn=make_model_fn(), config=run_config, params=hparams)\n",
    "    return tf.contrib.learn.Experiment(\n",
    "        estimator=estimator,\n",
    "        train_input_fn=make_input_fn(tf.estimator.ModeKeys.TRAIN, hparams),\n",
    "        eval_input_fn=make_input_fn(tf.estimator.ModeKeys.EVAL, hparams),\n",
    "        eval_metrics=MODELS[FLAGS.model].eval_metrics(hparams),\n",
    "        eval_steps=FLAGS.eval_steps,\n",
    "        min_eval_frequency=FLAGS.eval_frequency)\n",
    "\n",
    "def main(unused_argv):\n",
    "    \"\"\"Main entry point.\"\"\"\n",
    "    if FLAGS.output_dir:\n",
    "        model_dir = FLAGS.output_dir\n",
    "    else:\n",
    "        model_dir = \"output/%s_%s\" % (FLAGS.model, FLAGS.dataset)\n",
    "\n",
    "    DATASETS[FLAGS.dataset].prepare()\n",
    "\n",
    "    session_config = tf.ConfigProto()\n",
    "    session_config.allow_soft_placement = True\n",
    "    session_config.gpu_options.allow_growth = True\n",
    "    run_config = tf.contrib.learn.RunConfig(\n",
    "        model_dir=model_dir,\n",
    "        save_summary_steps=FLAGS.save_summary_steps,\n",
    "        save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
    "        save_checkpoints_secs=None,\n",
    "        session_config=session_config)\n",
    "\n",
    "    tf.contrib.learn.learn_runner.run(\n",
    "        experiment_fn=experiment_fn,\n",
    "        run_config=run_config,\n",
    "        schedule=FLAGS.schedule,\n",
    "        hparams=get_params())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
