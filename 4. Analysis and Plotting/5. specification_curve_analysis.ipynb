{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "import sys  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from pathlib import Path  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "sys.path.append(code_dir)\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_module.imports import *  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module import researchpy_fork as rp # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module import specification_curve_fork as specy # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}df_manual_len.txt', 'r') as f:\n",
    "    df_manual_len = int(f.read())\n",
    "\n",
    "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_training.pkl')\n",
    "assert len(df_manual) == df_manual_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_manual_len} BUT IS OF LENGTH {len(df_manual)}'\n",
    "print(f'Dataframe loaded with shape: {df_manual.shape}')\n",
    "df_manual = categorize_df_gender_age(df_manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'r') as f:\n",
    "    df_jobs_len = int(f.read())\n",
    "\n",
    "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
    "assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_jobs)}'\n",
    "print(f'Dataframe loaded with shape: {df_jobs.shape}')\n",
    "df_jobs = categorize_df_gender_age(df_jobs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis plan:\n",
    "\n",
    "1. ## [Descriptives, visualizations, and tables](./1.%20descriptives_visualization_and_tables.ipynb)\n",
    "2. ## [Frequencies and Normality tests](./2.%20frequencies_and_normality_test.ipynb)\n",
    "   1. ### Frequencies, histograms, and QQ plots\n",
    "      * Normal test\n",
    "      * Kurtosis test\n",
    "      * Shapiro\n",
    "      * Anderson\n",
    "      * Bartlett\n",
    "   2. ### Correlation between independent variables (IVs) and control variables and Multicolinarity test\n",
    "      * Pearson's R\n",
    "      * VIF\n",
    "     - ***ivs_dummy*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "     - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "     - ***% Sector per Workforce*** (continous ratio) = Sector percentage per worksforce (0-100)\n",
    "     - ***num_words*** (continous ratio) = Number of words in job description\n",
    "     - ***English Requirement in Job Ad*** (binary nominal) = English requirement in job description (0 vs. 1)\n",
    "     - ***Dutch Requirement in Job Ad*** (binary nominal) = Dutch requirement in job description (0 vs. 1)\n",
    "     - ***Platform*** (binary dummy) = LinkedIn (0 vs. 1), Indeed (0 vs. 1), Glassdoor (0 vs. 1)\n",
    "\n",
    "3. ## [ANOVA and Chi-square (Pearson's R)](./3.%20chisqt_and_anova.ipynb)\n",
    "\n",
    "   1. ### Chi-square\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "\n",
    "   2. ### One-way ANOVA, interactions, and post-hoc test\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "          - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "          - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "      * **df_jobs:**\n",
    "         - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "         - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "           - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "           - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "\n",
    "4. ## [Regression Analysis](./3.%20regression_analysis.ipynb)\n",
    "   1. ### Logistic Regression  with all interaction (smf):\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   3. ### Multilevel OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "\n",
    "5. ## [Specification Curve Analysis](./4.%20specification_curve_analysis.ipynb)\n",
    "\n",
    "   1. ### Logistic Specification Curve Analysis:\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Specification Curve Analysis:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframes dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'df_manual': df_manual,\n",
    "    'df_jobs': df_jobs,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specification Curve Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models, IVs, and controls dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models dict\n",
    "sm_models = {\n",
    "    'logistic': sm.Logit,\n",
    "    'OLS': sm.OLS,\n",
    "}\n",
    "\n",
    "# IVs dict\n",
    "ivs_for_spec = {\n",
    "    'dummy': ivs_dummy,\n",
    "    'percentages': ivs_perc,\n",
    "    'all': ivs_dummy_and_perc,\n",
    "}\n",
    "\n",
    "# Controls dict\n",
    "controls_for_spec_dict = {\n",
    "    'perc_words': controls[:2],\n",
    "    'perc_words_lang': controls[:4],\n",
    "    'perc_words_lang_platform': controls[:6],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset font size to 8 for readability\n",
    "mpl.rcParams['font.size'] = 8\n",
    "plt.rcParams['font.size'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for (df_name, df), (model_name, model), (ivs_type, ivs_), (controls_name, controls_) in tqdm_product(dataframes.items(), sm_models.items(), ivs_for_spec.items(), controls_for_spec_dict.items()):\n",
    "\n",
    "    # Set DV and plot title suffix\n",
    "    if df_name == 'df_manual':\n",
    "        dvs_ = dvs\n",
    "        dvs_type = 'binary'\n",
    "        plot_title_prefix = 'Binary Coding of Warmth and Competence x '\n",
    "    elif df_name == 'df_jobs':\n",
    "        dvs_ = dvs_all\n",
    "        dvs_type = 'binary and probability'\n",
    "        plot_title_prefix = 'Binary Coding and Probability of Warmth and Competence x '\n",
    "\n",
    "    # Set IV and plot title prefix\n",
    "    if ivs_type == 'dummy':\n",
    "        plot_title_suffix = 'Categorical Dominant Social Category of Sector'\n",
    "    elif ivs_type == 'percentages':\n",
    "        plot_title_suffix = 'Percentages of Social Category per Sector'\n",
    "    elif ivs_type == 'all':\n",
    "        plot_title_suffix = 'Categorical Dominant Social Category of Sector and Percentages of Social Category per Sector'\n",
    "\n",
    "    # Set controls\n",
    "    if controls_name == 'perc_words':\n",
    "        plot_title_suffix += ' + % Sector per Workforce + Job Description num_words'\n",
    "    elif controls_name == 'perc_words_lang':\n",
    "        plot_title_suffix += ' + % Sector per Workforce + Job Description num_words + Language Requirements'\n",
    "    elif controls_name == 'perc_words_lang_platform':\n",
    "        plot_title_suffix += ' + % Sector per Workforce + Job Description num_words + Language Requirements + Platform'\n",
    "\n",
    "    # Run specification curve analysis\n",
    "    print(f'{\"=\"*5} {model_name.upper()} REGRESSION SPECIFICATION MODE RESULTS FOR {df_name} USING {dvs_type.upper()} x {ivs_type.upper()} + {controls_name.upper()} {\"=\"*5}')\n",
    "    print(f'Running specification curve analysis with:\\nDEPENDENT VARIABLES = {dvs_}\\nINDEPENDENT VARIABLES = {ivs_}\\nCONTROLS = {controls}')\n",
    "\n",
    "    try:\n",
    "        sc = specy.SpecificationCurve(df=df, y_endog=dvs_, x_exog=ivs_, controls=controls_)\n",
    "        sc.fit(estimator=model)\n",
    "        df_results = sc.df_r\n",
    "\n",
    "        # Plot and save\n",
    "        plot_title = f'{plot_title_prefix}{plot_title_suffix}'\n",
    "        print('~'*80)\n",
    "        print(f'\\n{\"=\"*5} RESULTS FOR {plot_title} {\"=\"*5}\\n')\n",
    "        print('~'*80)\n",
    "\n",
    "        for image_save_format in tqdm.tqdm(['eps', 'png', 'svg']):\n",
    "            # Use following if not using forked specification_curve\n",
    "            # sc.plot(preferred_spec=[iv, dv], save_path=save_path,)\n",
    "            save_path = f'{plot_save_path}{df_name} - Specification Curve - {dvs_type} Warmth and Competence x {ivs_type} Gender and Age + {controls_name}.{image_save_format}'\n",
    "            sc_fig = sc.plot(\n",
    "                save_path=save_path,\n",
    "                show_plot=False,\n",
    "                return_fig=True,\n",
    "                plot_title=plot_title\n",
    "            )\n",
    "\n",
    "        # Get statsmodels results and save\n",
    "        ## Get controls mask\n",
    "        controls_mask = df_results['Specification'].apply(lambda x: all(control in x for control in controls_))\n",
    "        ## Get gender only results\n",
    "        gender_mask = df_results['Specification'].apply(lambda x: any(item for item in ivs_[:-len(ivs_)//2] if item in x and len(x) == 2))\n",
    "        df_results_gender = df_results[gender_mask]\n",
    "        if df_results_gender[controls_mask].empty:\n",
    "            print('No specification with Gender and all controls.')\n",
    "        else:\n",
    "            df_results_gender = df_results_gender[controls_mask]\n",
    "        # Get age only results\n",
    "        age_mask = df_results['Specification'].apply(lambda x: any(item for item in ivs_[len(ivs_)//2:] if item in x and len(x) == 2))\n",
    "        df_results_age = df_results[age_mask]\n",
    "        if df_results_age[controls_mask].empty:\n",
    "            print('No specification with Age and all controls.')\n",
    "        else:\n",
    "            df_results_age = df_results_age[controls_mask]\n",
    "\n",
    "        for df in [df_results_gender, df_results_age]:\n",
    "            for idx, row in df.iterrows():\n",
    "                for dv_iv in row['Specification']:\n",
    "                    if dv_iv in ivs_dummy_and_perc:\n",
    "                        iv_name = dv_iv\n",
    "                    elif dv_iv in dvs_:\n",
    "                        dv_name = dv_iv\n",
    "                print('\\n')\n",
    "                print('+'*20)\n",
    "                print(f'{dv_name} x {iv_name}\\n')\n",
    "                print('+'*20)\n",
    "                print(f'{row[\"Results\"].summary()}')\n",
    "                print('-'*20)\n",
    "\n",
    "                # Save results to file\n",
    "                df_to_save = pd.DataFrame(csv.reader(row['Results'].summary().as_csv().split('\\n'), delimiter=','))\n",
    "                df_to_save.to_csv(f'{table_save_path}{model_name} specification curve {df_name} - {dvs_type} Warmth and Competence x {ivs_type} Gender and Age + {controls_name}.csv', index=False)\n",
    "\n",
    "        # Top 10 significant highest coefficients\n",
    "        df_coeff_p = df_results.loc[sc.df_r['coeff_pvals'] < 0.05].sort_values(by=['Coefficient'], ascending=False)\n",
    "        print(f\"Top 10 significant coefficients:\\n{df_coeff_p[['x_exog', 'y_endog', 'coeff_pvals', 'Coefficient', 'conf_int', 'pvalues']].head(10)}\")\n",
    "\n",
    "    except(np.linalg.LinAlgError):\n",
    "        print(f'Singular matrix when using {model_name} with {controls_name} + {dvs_type} x {ivs_type}')\n",
    "\n",
    "    print(f'{\"=\"*5} END OF RESULTS FOR {dvs_type.upper()} x {ivs_type.upper()} + {controls_name.upper()} {\"=\"*5}')\n",
    "    print('~'*80, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
