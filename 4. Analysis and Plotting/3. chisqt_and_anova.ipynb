{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "if code_dir_name not in str(Path.cwd()).split('/')[-1]:\n",
    "    for _ in range(5):\n",
    "\n",
    "        parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "        if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "            code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "            if code_dir is not None:\n",
    "                break\n",
    "else:\n",
    "    code_dir = str(Path.cwd())\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8638e902f9457cb6fc2a4a449191df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from setup_module.imports import *  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module import researchpy_fork as rp # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module import specification_curve_fork as specy # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded with shape: (5947, 68)\n"
     ]
    }
   ],
   "source": [
    "with open(f'{data_dir}df_manual_len.txt', 'r') as f:\n",
    "    df_manual_len = int(f.read())\n",
    "\n",
    "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_training.pkl')\n",
    "assert len(df_manual) == df_manual_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_manual_len} BUT IS OF LENGTH {len(df_manual)}'\n",
    "print(f'Dataframe loaded with shape: {df_manual.shape}')\n",
    "df_manual = categorize_df_gender_age(df_manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded with shape: (307154, 83)\n"
     ]
    }
   ],
   "source": [
    "with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'r') as f:\n",
    "    df_jobs_len = int(f.read())\n",
    "\n",
    "# df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
    "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
    "assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_jobs)}'\n",
    "print(f'Dataframe loaded with shape: {df_jobs.shape}')\n",
    "df_jobs = categorize_df_gender_age(df_jobs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis plan:\n",
    "\n",
    "1. ## [Descriptives, visualizations, and tables](./1.%20descriptives_visualization_and_tables.ipynb)\n",
    "2. ## [Frequencies and Normality tests](./2.%20frequencies_and_normality_test.ipynb)\n",
    "   1. ### Frequencies, histograms, and QQ plots\n",
    "      * Normal test\n",
    "      * Kurtosis test\n",
    "      * Shapiro\n",
    "      * Anderson\n",
    "      * Bartlett\n",
    "   2. ### Correlation between independent variables (IVs) and control variables and Multicolinarity test\n",
    "      * Pearson's R\n",
    "      * VIF\n",
    "     - ***ivs_dummy*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "     - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "     - ***% Sector per Workforce*** (continous ratio) = Sector percentage per worksforce (0-100)\n",
    "     - ***num_words*** (continous ratio) = Number of words in job description\n",
    "     - ***English Requirement in Job Ad*** (binary nominal) = English requirement in job description (0 vs. 1)\n",
    "     - ***Dutch Requirement in Job Ad*** (binary nominal) = Dutch requirement in job description (0 vs. 1)\n",
    "     - ***Platform*** (binary dummy) = LinkedIn (0 vs. 1), Indeed (0 vs. 1), Glassdoor (0 vs. 1)\n",
    "\n",
    "3. ## [ANOVA and Chi-square (Pearson's R)](./3.%20chisqt_and_anova.ipynb)\n",
    "\n",
    "   1. ### Chi-square\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "\n",
    "   2. ### One-way ANOVA, interactions, and post-hoc test\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "          - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "          - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "      * **df_jobs:**\n",
    "         - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "         - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "           - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "           - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "\n",
    "4. ## [Regression Analysis](./3.%20regression_analysis.ipynb)\n",
    "   1. ### Logistic Regression  with all interaction (smf):\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   3. ### Multilevel OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "\n",
    "5. ## [Specification Curve Analysis](./4.%20specification_curve_analysis.ipynb)\n",
    "\n",
    "   1. ### Logistic Specification Curve Analysis:\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Specification Curve Analysis:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframes dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'df_jobs': df_jobs,\n",
    "    'df_manual': df_manual,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chisqt(df_name, df):\n",
    "    print('\\n')\n",
    "    print('+'*120)\n",
    "    print(f'{\"=\"*50} RESULTS FOR {df_name} {\"=\"*50}')\n",
    "\n",
    "    for dv, iv in tqdm_product(dvs, ivs_dummy):\n",
    "\n",
    "        # Full chi-square\n",
    "        expected, observed, full_chisqt = pg.chi2_independence(data=df, x=iv, y=dv)\n",
    "        print('\\n')\n",
    "        print('+'*120)\n",
    "        print(f'Dependent Variable: {dv}\\nIndependent Variable: {iv}')\n",
    "        print('\\n')\n",
    "        print('~' * 20)\n",
    "        print('FULL CHI-SQUARE TEST:')\n",
    "        print('-'*20)\n",
    "        print(f'Observed Count:\\n{observed}\\n')\n",
    "        print('-'*20)\n",
    "        print(f'Expected Count:\\n{expected}\\n')\n",
    "        print('-'*20)\n",
    "        print(f'Chi-square:\\n{full_chisqt.round(2)}\\n')\n",
    "        print('~' * 20)\n",
    "        chi_to_save = pd.concat([pd.concat([observed, pd.DataFrame(expected)], axis='index'), full_chisqt], axis='index')\n",
    "        chi_to_save.to_csv(f'{table_save_path}chi-square {df_name} - {dv} x {iv}.csv')\n",
    "        chi_to_save.style.to_latex(f'{table_save_path}chi-square {df_name} - {dv} x {iv}.tex', hrules=True)\n",
    "\n",
    "        # Chi-square\n",
    "        chisqt = pd.crosstab(df[iv], df[dv])\n",
    "        pearson_r, p_value, dof, expected = scipy.stats.chi2_contingency(chisqt)\n",
    "        reject_H0 = p_value > alpha\n",
    "        reject_H = p_value < alpha\n",
    "\n",
    "        # if not reject_H0 and reject_H:\n",
    "        #     print('\\n')\n",
    "        #     print('+'*120)\n",
    "        #     print(f'Dependent Variable: {dv}\\nIndependent Variable: {iv}\\nNOT SIGNIFICANT at p-value: {p_value:.3f}!')\n",
    "        #     print('\\n')\n",
    "        #     print('~' * 20)\n",
    "        #     print(f\"Pearsons's R: {pearson_r}.\\np-value: {p_value:.3f}.\\nDegree of freedom: {dof}.\\nH0 Rejected: {reject_H0}\\nH Rejected: {reject_H}\")\n",
    "        #     print('\\n')\n",
    "        # elif reject_H0 and not reject_H:\n",
    "        print('\\n')\n",
    "        print('+'*120)\n",
    "        print(f'Dependent Variable: {dv}\\nIndependent Variable: {iv}')\n",
    "        print('\\n')\n",
    "        print('~' * 20)\n",
    "        print(f\"Pearsons's R: {pearson_r}.\\np-value: {p_value:.3f}.\\nDegree of freedom: {dof}.\\nH0 Rejected: {reject_H0}\\nH Rejected: {reject_H}\")\n",
    "        print('-'*20)\n",
    "        print(f'Observed Count:\\n{chisqt}\\n')\n",
    "        print('-'*20)\n",
    "        print(f'Expected Count:\\n{expected}\\n')\n",
    "        print('~' * 20)\n",
    "\n",
    "        # # Plot acceptance region distribution\n",
    "        # x = np.linspace(0, 10, 100)\n",
    "        # fig,ax = plt.subplots(1,1, figsize=(15,10))\n",
    "        # #plotting vertical line for critical value\n",
    "        # plt.axvline(x=scipy.stats.chi2.isf(0.05,dof), ymin=0, ymax= 0.3,label='X-Critical',color='black')\n",
    "        # #plotting vertical line for calculated value.\n",
    "        # plt.axvline(x=stat, ymin=0, ymax= 0.3,label='X-calculated',color='blue')\n",
    "        # #plotting distribution graph for our calculated degrees of freedom\n",
    "        # ax.plot(x, scipy.stats.chi2.pdf(x, dof), label=f'df = {str(dof)}', color='red')\n",
    "        # ax.set_xlabel('Value',fontsize=12, fontweight='bold')\n",
    "        # ax.set_ylabel('Probability Distribution',fontsize=12,fontweight='bold')\n",
    "        # ax.set_title(f'Chi-Square Distribution for {dv} x {iv}',fontsize=16,fontweight='bold')\n",
    "        # plt.xlim(0, 10)\n",
    "        # plt.ylim(0, 0.6)\n",
    "        # plt.legend()\n",
    "        # plt.show()\n",
    "    return chi_to_save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fe9d5e838c4fdcb1b7db660e92b224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='df_name', options=('df_jobs', 'df_manual'), value='df_jobs'), Outp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 561 ms, sys: 148 ms, total: 708 ms\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "@interact(df_name=dataframes.keys())\n",
    "def run_chisqt_interactive(df_name):\n",
    "    chi_to_save = run_chisqt(df_name, df=dataframes[df_name])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_anova(df_name, df, anovas_dict=None):\n",
    "    if anovas_dict is None:\n",
    "        anovas_dict = defaultdict(dict)\n",
    "\n",
    "    print('\\n')\n",
    "    print('+'*120)\n",
    "    print(f'{\"=\"*50} RESULTS FOR {df_name} {\"=\"*50}')\n",
    "\n",
    "    # MANOVA\n",
    "    print('MANOVA')\n",
    "    print('\\n')\n",
    "    print('~' * 20)\n",
    "    print(f'{ivs} x {dvs if df_name == \"df_manual\" else dvs_prob}')\n",
    "    dvs_for_formula = ' + '.join(dvs if df_name == 'df_manual' else dvs_prob)\n",
    "    ivs_for_formula = ' + '.join(f'C({iv})' for iv in ivs)\n",
    "    controls_for_formula = ' + '.join('_'.join(control.split()) for control in controls[:2])\n",
    "    # manova = sm.multivariate.MANOVA(endog=np.asarray(df[dvs].values, dtype=int), exog=sm.add_constant(np.asarray(df[ivs_num[:]], dtype=int))).mv_test().summary()\n",
    "    manova = sm.multivariate.MANOVA.from_formula(formula=f'{dvs_for_formula} ~ {ivs_for_formula}', data=df).mv_test()\n",
    "    print(f'{ivs} x {dvs if df_name == \"df_manual\" else dvs_prob} MANOVA:\\n{manova.summary()}')\n",
    "    df_to_save = pd.concat(pd.read_html(manova.summary().as_html()), axis='index', ignore_index=True)\n",
    "    df_to_save.to_csv(f'{table_save_path}manova {df_name} - {ivs} x {dvs if df_name == \"df_manual\" else dvs_prob}.csv')\n",
    "    df_to_save.style.to_latex(f'{table_save_path}manova {df_name} - {ivs} x {dvs if df_name == \"df_manual\" else dvs_prob}.tex', hrules=True)\n",
    "    print('~' * 20)\n",
    "    anovas_dict[df_name] |= {'MANOVA': manova}\n",
    "\n",
    "    # MANCOVA\n",
    "    print('MANCOVA')\n",
    "    print('\\n')\n",
    "    print('~' * 20)\n",
    "    print(f'{ivs} x {dvs}')\n",
    "    endog=np.asarray(df[dvs].values, dtype=int)\n",
    "    exog=np.asarray(df[ivs_num[:] + controls[:2]], dtype=int)\n",
    "    constant = sm.add_constant(exog)\n",
    "    mancova = sm.multivariate.MANOVA(endog=endog, exog=exog).mv_test()\n",
    "    print(f'{ivs} x {dvs} MANOVA:\\n{mancova.summary()}')\n",
    "    df_to_save = pd.concat(pd.read_html(mancova.summary().as_html()), axis='index', ignore_index=True)\n",
    "    df_to_save.to_csv(f'{table_save_path}mancova {df_name} - {ivs} x {dvs}.csv')\n",
    "    df_to_save.style.to_latex(f'{table_save_path}mancova {df_name} - {ivs} x {dvs}.tex', hrules=True)\n",
    "    print('~' * 20)\n",
    "    anovas_dict[df_name] |= {'MANCOVA': mancova}\n",
    "\n",
    "    if df_name == 'df_manual':\n",
    "        dvs_ = dvs\n",
    "    elif df_name == 'df_jobs':\n",
    "        dvs_ = dvs_all\n",
    "\n",
    "    for dv, iv in tqdm_product(dvs_, ivs):\n",
    "        print('+'*120)\n",
    "        print(f'Dependent Variable: {dv}\\nIndependent Variable: {iv}')\n",
    "        print('+'*120)\n",
    "\n",
    "        # LEVENE'S TESTS\n",
    "        print(\"LEVENE'S TEST\")\n",
    "        print('\\n')\n",
    "        print('~' * 20)\n",
    "        print(f'{iv} x {dv}')\n",
    "        levene = pg.homoscedasticity(data=df, dv=dv, group=iv, method='levene').round(2) #dv\n",
    "        equal_var_levene = eval(levene.equal_var.to_string(index=False))\n",
    "        print(f\"{iv} x {dv} Levene's test:\\n{levene}\")\n",
    "        levene.to_csv(f\"{table_save_path}levene's {df_name} - {iv} x {dv}.csv\")\n",
    "        levene.style.to_latex(f\"{table_save_path}levene's {df_name} - {iv} x {dv}.tex\")\n",
    "        print('~' * 20)\n",
    "        print('\\n')\n",
    "\n",
    "        # SCIPY ANOVAS\n",
    "        print('ANOVA SIGNIFICANCE')\n",
    "        print('\\n')\n",
    "        print('~' * 20)\n",
    "        print(f'{iv} x {dv}')\n",
    "        f_statistic, p_value = f_oneway(\n",
    "            df[dv][df[iv] == ivs_dict[iv][0]],\n",
    "            df[dv][df[iv] == ivs_dict[iv][1]],\n",
    "            df[dv][df[iv] == ivs_dict[iv][2]]\n",
    "        )\n",
    "        reject_H0 = p_value > alpha\n",
    "        reject_H = p_value < alpha\n",
    "\n",
    "        # if not reject_H0 and reject_H:\n",
    "        #     print('\\n')\n",
    "        #     print('+'*120)\n",
    "        #     print(f'Dependent Variable: {dv}\\nIndependent Variable: {iv}\\nNOT SIGNIFICANT at p-value: {p_value:.3f}!')\n",
    "        #     print('\\n')\n",
    "        #     print('~' * 20)\n",
    "        #     print(f'One-way ANOVA F-statistic: {f_statistic}\\np-value: {p_value}.\\nH0 Rejected: {reject_H0}\\nH Rejected: {reject_H}')\n",
    "        #     print('\\n')\n",
    "        # elif reject_H0 and not reject_H:\n",
    "        print('\\n')\n",
    "        print('+'*120)\n",
    "        print(f'Dependent Variable: {dv}\\nIndependent Variable: {iv}')\n",
    "        print('\\n')\n",
    "        print('~' * 20)\n",
    "        print(f'One-way ANOVA F-statistic: {f_statistic}\\np-value: {p_value}.\\nH0 Rejected: {reject_H0}\\nH Rejected: {reject_H}')\n",
    "        print('\\n')\n",
    "\n",
    "        # INTERACTION MODEL\n",
    "        print(f'INTEACTION ANOVA {dv}')\n",
    "        print('\\n')\n",
    "        print('~' * 20)\n",
    "        print(f'{iv} x {dv}')\n",
    "        formula = f'{dv} ~ C({ivs[0]})*C({ivs[1]})'\n",
    "        model = smf.ols(data = df, formula = formula).fit()\n",
    "        anova_interaction = sm.stats.anova_lm(model, typ=2).round(2)\n",
    "        print(f'{iv} x {dv} ANOVA INTERACTION:\\n{anova_interaction}')\n",
    "        print('~' * 20)\n",
    "        print('\\n')\n",
    "        anovas_dict[df_name] |= {f'ANOVA INTERACTION {dv}': anova_interaction}\n",
    "\n",
    "        if equal_var_levene == True:\n",
    "            # ONE-WAY ANOVA\n",
    "            print('ONE-WAY ANOVA')\n",
    "            print('\\n')\n",
    "            print('~' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            anova1 = pg.anova(data=df, dv=dv, between=iv, detailed=True, effsize='np2').round(2)\n",
    "            print(f'{iv} x {dv} ONE-WAY ANOVA:\\n{anova1}')\n",
    "            anova1.to_csv(f'{table_save_path}one-way anova {df_name} - {iv} x {dv}.csv')\n",
    "            anova1.style.to_latex(f'{table_save_path}one-way anova {df_name} - {iv} x {dv}.tex', hrules=True)\n",
    "            print('~' * 20)\n",
    "            print('\\n')\n",
    "            anovas_dict[df_name] |= {f'ONE-WAY ANOVA {dv}': anova1}\n",
    "\n",
    "            # ONE-WAY ANCOVA\n",
    "            print('ANCOVA')\n",
    "            print('\\n')\n",
    "            print('~' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            ancova = pg.ancova(data=df, dv=dv, between=iv, covar=controls[:2], effsize='np2').round(2)\n",
    "            print(f'{iv} x {dv} ANCOVA:\\n{ancova}')\n",
    "            ancova.to_csv(f'{table_save_path}ancova {df_name} - {iv} x {dv}.csv')\n",
    "            ancova.style.to_latex(f'{table_save_path}ancova {df_name} - {iv} x {dv}.tex', hrules=True)\n",
    "            print('~' * 20)\n",
    "            print('\\n')\n",
    "            anovas_dict[df_name] |= {f'ANCOVA {dv}': ancova}\n",
    "\n",
    "            # TWO-WAY ANOVA\n",
    "            print('TWO-WAY ANOVA')\n",
    "            print('\\n')\n",
    "            print('~' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            anova2 = pg.anova(data=df, dv=dv, between=ivs, detailed=True, effsize='np2').round(2)\n",
    "            print(f'{iv} x {dv} TWO-WAY ANOVA:\\n{anova2}')\n",
    "            anova2.to_csv(f'{table_save_path}two-way anova {df_name} - {ivs[0]} and {ivs[1]} x {dv}.csv')\n",
    "            anova2.style.to_latex(f'{table_save_path}two-way anova {df_name} - {ivs[0]} and {ivs[1]} x {dv}.tex', hrules=True)\n",
    "            print('~' * 20)\n",
    "            print('\\n')\n",
    "            anovas_dict[df_name] |= {f'TWO-WAY ANOVA {dv}': anova2}\n",
    "\n",
    "            # TUKEY POST HOC\n",
    "            print(\"POST HOC TUKEY'S ANOVA\")\n",
    "            print('\\n')\n",
    "            print('~' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            anova_pairwise_tukey = pg.pairwise_tukey(\n",
    "                data=df, dv=dv, between=iv, effsize='eta-square'\n",
    "            ).round(2)\n",
    "            pg.print_table(anova_pairwise_tukey)\n",
    "            anova_pairwise_tukey.to_csv(f'{table_save_path}post hoc tukey {df_name} - {iv} x {dv}.csv')\n",
    "            anova_pairwise_tukey.style.to_latex(f'{table_save_path}post hoc tukey {df_name} - {iv} x {dv}.tex', hrules=True)\n",
    "            print('~' * 20)\n",
    "            print('\\n')\n",
    "            anovas_dict[df_name] |= {f'TUKEY POST HOC {dv}': anova_pairwise_tukey}\n",
    "\n",
    "        elif equal_var_levene == False:\n",
    "            # WELCH ANOVA\n",
    "            print('WELCH ANOVA')\n",
    "            print('\\n')\n",
    "            print('~' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            anova_welch = pg.welch_anova(data=df, dv=dv, between=iv).round(2)\n",
    "            pg.print_table(anova_welch)\n",
    "            anova_welch.to_csv(f'{table_save_path}welch anova {df_name} - {iv} x {dv}.csv')\n",
    "            anova_welch.style.to_latex(f'{table_save_path}welch anova {df_name} - {iv} x {dv}.tex', hrules=True)\n",
    "            print('~' * 20)\n",
    "            print('\\n')\n",
    "            anovas_dict[df_name] |= {f'WELCH ANOVA {dv}': anova_welch}\n",
    "\n",
    "            # KRUSKAL-WALLIS ANOVA\n",
    "            print('KRUSKAL-WALLIS ANOVA')\n",
    "            print('\\n')\n",
    "            print('~' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            anova_kruskal = pg.kruskal(data=df, dv=dv, between=iv).round(2)\n",
    "            pg.print_table(anova_kruskal)\n",
    "            anova_kruskal.to_csv(f'{table_save_path}kruskal-wallis anova {df_name} - {iv} x {dv}.csv')\n",
    "            anova_kruskal.style.to_latex(f'{table_save_path}kruskal-wallis anova {df_name} - {iv} x {dv}.tex', hrules=True)\n",
    "            print('~' * 20)\n",
    "            print('\\n')\n",
    "            anovas_dict[df_name] |= {f'KRUSKAL-WALLIS ANOVA {dv}': anova_kruskal}\n",
    "\n",
    "            # GAMES HOWELL POST HOC\n",
    "            print('POST HOC GAMES HOWELL ANOVA')\n",
    "            print('\\n')\n",
    "            print('~' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            anova_games_posthoc = pg.pairwise_gameshowell(\n",
    "                data=df, dv=dv, between=iv, effsize='eta-square'\n",
    "            ).round(2)\n",
    "            pg.print_table(anova_games_posthoc)\n",
    "            anova_games_posthoc.to_csv(f'{table_save_path}post hoc gameshowell {df_name} - {iv} x {dv}.csv')\n",
    "            anova_games_posthoc.style.to_latex(f'{table_save_path}post hoc gameshowell {df_name} - {iv} x {dv}.tex', hrules=True)\n",
    "            print('~' * 20)\n",
    "            print('\\n')\n",
    "            print('+'*120)\n",
    "            print('\\n')\n",
    "            anovas_dict[df_name] |= {f'GAMES HOWELL POST HOC {dv}': anova_games_posthoc}\n",
    "\n",
    "    return anovas_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcf7d6d97b94bcc97a2a59d3ef24bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='df_name', options=('df_jobs', 'df_manual'), value='df_jobs'), Outp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(df_name=dataframes.keys())\n",
    "def run_anova_interactive(df_name):\n",
    "    anovas_dict = run_anova(df_name, df=dataframes[df_name])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Automating_Equity1_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
