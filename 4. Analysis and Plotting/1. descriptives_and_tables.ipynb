{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1795b68f",
   "metadata": {},
   "source": [
    "### START HERE IF SOURCING FROM df_manual_FOR_training\n",
    "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79862f16",
   "metadata": {},
   "source": [
    "# Descriptives and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245d864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "if code_dir_name not in str(Path.cwd()).split('/')[-1]:\n",
    "    for _ in range(5):\n",
    "\n",
    "        parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "        if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "            code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "            if code_dir is not None:\n",
    "                break\n",
    "else:\n",
    "    code_dir = str(Path.cwd())\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bee517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module import researchpy_fork as rp # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module.statannotations_fork.Annotator import Annotator # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ed134",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_sectors_all = pd.read_pickle(f'{table_save_path}Sectors Output from script.pkl')\n",
    "except FileNotFoundError:\n",
    "    cbs_notebook = '\\\\'.join(f'{scraped_data}CBS/CBS.ipynb')\n",
    "    %run $cbs_notebook import df_sectors_all # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea14dd7e",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_and_close_plots():\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f085a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_plots():\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92627846",
   "metadata": {},
   "source": [
    "# Analysis plan:\n",
    "\n",
    "1. ## [Descriptives and tables](./1.%20descriptives_and_tables.ipynb)\n",
    "2. ## [Visualization](./2.%20visualization.ipynb)\n",
    "3. ## [Frequencies and Normality tests](./2.%20frequencies_and_normality_test.ipynb)\n",
    "   1. ### Frequencies, histograms, and QQ plots\n",
    "      * Normal test\n",
    "      * Kurtosis test\n",
    "      * Shapiro\n",
    "      * Anderson\n",
    "      * Bartlett\n",
    "   2. ### Correlation between independent variables (IVs) and control variables and Multicolinarity test\n",
    "      * Pearson's R\n",
    "      * VIF\n",
    "     - ***ivs_dummy*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "     - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "     - ***% Sector per Workforce*** (continous ratio) = Sector percentage per worksforce (0-100)\n",
    "     - ***num_words*** (continous ratio) = Number of words in job description\n",
    "     - ***English Requirement in Job Ad*** (binary nominal) = English requirement in job description (0 vs. 1)\n",
    "     - ***Dutch Requirement in Job Ad*** (binary nominal) = Dutch requirement in job description (0 vs. 1)\n",
    "     - ***Platform*** (binary dummy) = LinkedIn (0 vs. 1), Indeed (0 vs. 1), Glassdoor (0 vs. 1)\n",
    "\n",
    "4. ## [ANOVA and Chi-square (Pearson's R)](./3.%20chisqt_and_anova.ipynb)\n",
    "\n",
    "   1. ### Chi-square\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "\n",
    "   2. ### One-way ANOVA, interactions, and post-hoc test\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "          - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "          - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "      * **df_jobs:**\n",
    "         - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "         - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "           - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "           - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "\n",
    "5. ## [Regression Analysis](./3.%20regression_analysis.ipynb)\n",
    "   1. ### Logistic Regression  with all interaction (smf):\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   3. ### Multilevel OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "\n",
    "6. ## [Specification Curve Analysis](./4.%20specification_curve_analysis.ipynb)\n",
    "\n",
    "   1. ### Logistic Specification Curve Analysis:\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Specification Curve Analysis:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86ff5654",
   "metadata": {},
   "source": [
    "# Descriptives"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62585cb0",
   "metadata": {},
   "source": [
    "### READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff3d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}df_manual_len.txt', 'r') as f:\n",
    "    df_manual_len = int(f.read())\n",
    "\n",
    "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_analysis.pkl')\n",
    "assert len(df_manual) == df_manual_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_manual_len} BUT IS OF LENGTH {len(df_manual)}'\n",
    "print(f'Dataframe loaded with shape: {df_manual.shape}')\n",
    "df_manual = categorize_df_gender_age(df_manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67446cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'r') as f:\n",
    "    df_jobs_len = int(f.read())\n",
    "\n",
    "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
    "assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_manual)}'\n",
    "print(f'Dataframe loaded with shape: {df_jobs.shape}')\n",
    "df_jobs = categorize_df_gender_age(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8165e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'df_jobs': df_jobs,\n",
    "    # 'df_manual': df_manual,\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63338bc0",
   "metadata": {},
   "source": [
    "### All info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681db815-a531-4ace-a8a3-cb957945bde1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All info\n",
    "analysis_columns = [\n",
    "    'Warmth',\n",
    "    'Competence'\n",
    "]\n",
    "\n",
    "for df_name, df in dataframes.items():\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    df = categorize_df_gender_age(df)\n",
    "\n",
    "    df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_list_columns = [c for c in df_jobs.columns if not df_jobs[c].apply(lambda x: isinstance(x, list)).any()]\n",
    "non_list_columns = df_jobs.columns.get_indexer(non_list_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92eb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary(df_jobs.iloc[:, non_list_columns], is_collapsible = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329fa54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in dataframes.items():\n",
    "    skim(df_jobs.iloc[:, non_list_columns])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abbaaca7",
   "metadata": {},
   "source": [
    "## Sentence Level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2f09fa9",
   "metadata": {},
   "source": [
    "### All Gender and Age info at Sentence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7461f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender and Age info by sentence\n",
    "def run_descriptives_ivs_all_sent(df_name, df, ivs_all=ivs_all):\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    print('='*30)\n",
    "    print('Gender and Age info at Sentence Level')\n",
    "    print('-'*30)\n",
    "    get_df_info(df, ivs_all=ivs_all)\n",
    "    print('-'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_descriptives_ivs_all_sent_interact(df_name):\n",
    "        run_descriptives_ivs_all_sent(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_descriptives_ivs_all_sent(list(dataframes.keys())[0], dataframes[list(dataframes.keys())[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd1ba797",
   "metadata": {},
   "source": [
    "### % Gender and Age info at Sentence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6200fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_descriptives_iv_percs_sent(df_name, df):\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    for iv_perc in ivs_perc:\n",
    "        min_sector = df['Sector'].loc[df[iv_perc] == df[iv_perc].min()].values[0]\n",
    "        max_sector = df['Sector'].loc[df[iv_perc] == df[iv_perc].max()].values[0]\n",
    "        mean = df[iv_perc].mean().round(2).astype(float)\n",
    "        std = df[iv_perc].std().round(2).astype(float)\n",
    "        print(f'{iv_perc}:\\nMin Sector: {df[iv_perc].min():.1f}% in {min_sector}\\nMax Sector: {df[iv_perc].max():.1f}% in {max_sector}\\nMean: {mean}\\nStandard Deviation: {std}\\n')\n",
    "        print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6273b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_descriptives_iv_percs_sent_interact(df_name):\n",
    "        run_descriptives_iv_percs_sent(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_descriptives_iv_percs_sent(list(dataframes.keys())[0], dataframes[list(dataframes.keys())[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2c5b22d",
   "metadata": {},
   "source": [
    "### All Warmth and Competence info at Sentence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42786842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmth and Competence percentages info by sentence\n",
    "def run_descriptives_dvs_sent(df_name, df):\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    print('='*30)\n",
    "    print('Warmth and Competence info at Sentence Level')\n",
    "    print('-'*30)\n",
    "    get_df_info(df, ivs_all=dvs_all)\n",
    "    print('-'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a0dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_descriptives_dvs_sent_interact(df_name):\n",
    "        run_descriptives_dvs_sent(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_descriptives_dvs_sent(list(dataframes.keys())[0], dataframes[list(dataframes.keys())[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "678e7193",
   "metadata": {},
   "source": [
    "## Job Ad Level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7dd10b00",
   "metadata": {},
   "source": [
    "### All Gender and Age info at Job Ad Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5471abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender and Age info by job ad\n",
    "def run_descriptives_ivs_all_job(df_name, df, ivs_all=ivs_all):\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    print('='*30)\n",
    "    print('Gender and Age info at Job Advertisement Level')\n",
    "    print('-'*30)\n",
    "    get_df_info(df.groupby(['Job ID']).first(), ivs_all=ivs_all)\n",
    "    print('-'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12648399",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_descriptives_ivs_all_job_interact(df_name):\n",
    "        run_descriptives_ivs_all_job(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_descriptives_ivs_all_job(list(dataframes.keys())[0], list(dataframes.values())[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4239621f",
   "metadata": {},
   "source": [
    "### % Gender and Age info at Job Ad Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b1c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_descriptives_iv_percs_job(df_name, df):\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "    df = df.groupby(['Job ID']).first()\n",
    "\n",
    "    for iv_perc in ivs_perc:\n",
    "        min_sector = df['Sector'].loc[df[iv_perc] == df[iv_perc].min()].values[0]\n",
    "        max_sector = df['Sector'].loc[df[iv_perc] == df[iv_perc].max()].values[0]\n",
    "        mean = df[iv_perc].mean().round(2).astype(float)\n",
    "        std = df[iv_perc].std().round(2).astype(float)\n",
    "        print(f'{iv_perc}:\\nMin Sector: {df[iv_perc].min():.1f}% in {min_sector}\\nMax Sector: {df[iv_perc].max():.1f}% in {max_sector}\\nMean: {mean}\\nStandard Deviation: {std}\\n')\n",
    "        print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2096d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_descriptives_iv_percs_job_interact(df_name):\n",
    "        run_descriptives_iv_percs_job(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_descriptives_iv_percs_job(list(dataframes.keys())[0], dataframes[list(dataframes.keys())[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dcd67de",
   "metadata": {},
   "source": [
    "### All Warmth and Competence info at Job Ad Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6480b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmth and Competence info by job ad\n",
    "def run_descriptives_dvs_job(df_name, df):\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    print('='*30)\n",
    "    print('Warmth and Competence info at Job Advertisement Level')\n",
    "    print('-'*30)\n",
    "    get_df_info(df.groupby(['Job ID']).first(), ivs_all=dvs_all)\n",
    "    print('-'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_descriptives_dvs_job_interact(df_name):\n",
    "        run_descriptives_dvs_job(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_descriptives_dvs_job(list(dataframes.keys())[0], dataframes[list(dataframes.keys())[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9cef5",
   "metadata": {},
   "source": [
    "### All Job Ad string info at Job Ad Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ebf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get longest and shortest sentence\n",
    "def run_job_desc_lengths(df_name, df, text_col=None, num_words_col=None):\n",
    "    if text_col is None:\n",
    "        text_col = 'Job Description spacy_sentencized'\n",
    "    if num_words_col is None:\n",
    "        num_words_col = 'Job Description_num_words'\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    print('='*30)\n",
    "    print('Job Description Length at Sentence Level')\n",
    "    print('-'*30)\n",
    "    len_average_char = df[text_col].apply(len).mean()\n",
    "    average_char = df[text_col].loc[(df[text_col].apply(len) - len_average_char).abs().idxmin()]\n",
    "    len_longest_char = df[text_col].apply(len).max()\n",
    "    longest_char = df[text_col].loc[df[text_col].apply(len).idxmax()]\n",
    "    len_shortest_char = df[text_col].apply(len).min()\n",
    "    shortest_char = df[text_col].loc[df[text_col].apply(len).idxmin()]\n",
    "\n",
    "    len_average = df[num_words_col].mean()\n",
    "    len_longest = df[num_words_col].max()\n",
    "    len_shortest = df[num_words_col].min()\n",
    "\n",
    "    print(f'Average Sentence length: {len_average}')\n",
    "    print('-'*30)\n",
    "    print(f'Longest Sentence length: {len_longest}')\n",
    "    print('-'*30)\n",
    "    print(f'Shortest Sentence length: {len_shortest}')\n",
    "    print('-'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea435ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_job_desc_lengths_interact(df_name):\n",
    "        run_job_desc_lengths(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_job_desc_lengths(list(dataframes.keys())[0], dataframes[list(dataframes.keys())[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb2a0569",
   "metadata": {},
   "source": [
    "# Controls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c94b5afb",
   "metadata": {},
   "source": [
    "## Sentence Level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47d98af6",
   "metadata": {},
   "source": [
    "### Controls all info at Sentence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881bbfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control variables info by sentence\n",
    "def run_descriptives_controls_sent(df_name, df, controls_=None):\n",
    "    if controls_ is None:\n",
    "        controls_ = controls\n",
    "\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    print('='*30)\n",
    "    print(f'Control varibales info at Sentence Level: {controls_}')\n",
    "    print('-'*30)\n",
    "    get_df_info(df, ivs_all = controls_)\n",
    "    print('-'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_descriptives_controls_sent_interact(df_name):\n",
    "        run_descriptives_controls_sent(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_descriptives_controls_sent(list(dataframes.keys())[0], dataframes[list(dataframes.keys())[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "119c7445",
   "metadata": {},
   "source": [
    "### All info % Sector per Workforce at Sentence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b49d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_descriptives_sectors_all_job(df_name, df, controls_=None):\n",
    "    if controls_ is None:\n",
    "        controls_ = controls\n",
    "\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    print('='*30)\n",
    "    print('Sector info at Sentence Level')\n",
    "    print('-'*30)\n",
    "    get_df_info(df, ivs_all=['% Sector per Workforce'])\n",
    "    print('-'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_descriptives_sectors_all_job_interact(df_name):\n",
    "        run_descriptives_sectors_all_job(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_descriptives_sectors_all_job(list(dataframes.keys())[0], dataframes[list(dataframes.keys())[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc5d908b",
   "metadata": {},
   "source": [
    "### % Sector per Workforce at Sentence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46843565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_descriptives_sectors_job(df_name, df, controls_=None):\n",
    "    if controls_ is None:\n",
    "        controls_ = controls\n",
    "\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    min_sector = df['Sector'].loc[df['% Sector per Workforce'] == df['% Sector per Workforce'].min()].values[0]\n",
    "    max_sector = df['Sector'].loc[df['% Sector per Workforce'] == df['% Sector per Workforce'].max()].values[0]\n",
    "    mean = df['% Sector per Workforce'].mean().round(2).astype(float)\n",
    "    std = df['% Sector per Workforce'].std().round(2).astype(float)\n",
    "    print(f'\"% Sector per Workforce\":\\nMin Sector: {df[\"% Sector per Workforce\"].min():.1f}% in {min_sector}\\nMax Sector: {df[\"% Sector per Workforce\"].max():.1f}% in {max_sector}\\nMean: {mean}\\nStandard Deviation: {std}\\n')\n",
    "    print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_descriptives_sectors_job_interact(df_name):\n",
    "        run_descriptives_sectors_job(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_descriptives_sectors_job(list(dataframes.keys())[0], dataframes[list(dataframes.keys())[0]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c00a4d1",
   "metadata": {},
   "source": [
    "### IVs and Controls Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a62b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_corr_ivs_controls_sent(df_name, df, ivs_=None, controls_=None):\n",
    "    if ivs_ is None:\n",
    "        ivs_ = ivs_dummy_perc_and_perc_interactions\n",
    "    if controls_ is None:\n",
    "        controls_ = controls\n",
    "\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    considered_features = controls_[:2] + ivs_[:]\n",
    "    corr_df = df[considered_features].corr()\n",
    "    print('-'*20)\n",
    "    # print(f'Correlation Matrix for {df_name}')\n",
    "    # print(corr_df)\n",
    "    print('-'*20)\n",
    "    print('Highly correlated variables:\\n')\n",
    "    print('-'*20)\n",
    "    print(corr_df[(corr_df > 0.5) & (corr_df != 1)].stack().sort_values(ascending=False).drop_duplicates())\n",
    "    print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_corr_ivs_controls_sent_interact(df_name):\n",
    "        run_corr_ivs_controls_sent(df_name, dataframes[df_name], ivs_=ivs_dummy_perc_and_perc_interactions)\n",
    "else:\n",
    "    run_corr_ivs_controls_sent(list(dataframes.keys())[0], list(dataframes.values())[0], ivs_=ivs_dummy_perc_and_perc_interactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b8865",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_corr_ivs_controls_sent_interact(df_name):\n",
    "        run_corr_ivs_controls_sent(df_name, dataframes[df_name], ivs_=ivs_dummy_and_perc)\n",
    "else:\n",
    "    run_corr_ivs_controls_sent(list(dataframes.keys())[0], list(dataframes.values())[0], ivs_=ivs_dummy_and_perc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb989ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_corr_ivs_controls_sent_interact(df_name):\n",
    "        run_corr_ivs_controls_sent(df_name, dataframes[df_name], ivs_=ivs_perc_and_perc_interactions)\n",
    "else:\n",
    "    run_corr_ivs_controls_sent(list(dataframes.keys())[0], list(dataframes.values())[0], ivs_=ivs_perc_and_perc_interactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_corr_ivs_controls_sent_interact(df_name):\n",
    "        run_corr_ivs_controls_sent(df_name, dataframes[df_name], ivs_=ivs_perc_interactions)\n",
    "else:\n",
    "    run_corr_ivs_controls_sent(list(dataframes.keys())[0], list(dataframes.values())[0], ivs_=ivs_perc_interactions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19f47dbf",
   "metadata": {},
   "source": [
    "## Job Ad Level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59ddf058",
   "metadata": {},
   "source": [
    "### All Controls info at Job Ad Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control variables info by job ad\n",
    "def run_descriptives_controls_job(df_name, df, controls_=None):\n",
    "    if controls_ is None:\n",
    "        controls_ = controls\n",
    "\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    print('='*30)\n",
    "    print('Control varibales info at Job Advertisement Level')\n",
    "    print('-'*30)\n",
    "    get_df_info(df.groupby(['Job ID']).first(), ivs_all = controls_)\n",
    "    print('-'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edeb558",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_descriptives_controls_job_interact(df_name):\n",
    "        run_descriptives_controls_job(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_descriptives_controls_job(list(dataframes.keys())[0], dataframes[list(dataframes.keys())[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_corr_ivs_controls_job(df_name, df, ivs_=None, controls_=None):\n",
    "    if ivs_ is None:\n",
    "        ivs_ = ivs_dummy_perc_and_perc_interactions\n",
    "    if controls_ is None:\n",
    "        controls_ = controls\n",
    "\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    df = df.groupby(['Job ID']).first()\n",
    "\n",
    "    considered_features = controls_[:2] + ivs_[:]\n",
    "    corr_df = df[considered_features].corr()\n",
    "    print('-'*20)\n",
    "    # print(f'Correlation Matrix for {df_name}')\n",
    "    # print(corr_df)\n",
    "    print('-'*20)\n",
    "    print('Highly correlated variables:\\n')\n",
    "    print('-'*20)\n",
    "    print(corr_df[(corr_df > 0.5) & (corr_df != 1)].stack().sort_values(ascending=False).drop_duplicates())\n",
    "    print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a826e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_corr_ivs_controls_job_interact(df_name):\n",
    "        run_corr_ivs_controls_job(df_name, dataframes[df_name], ivs_=ivs_dummy_perc_and_perc_interactions)\n",
    "else:\n",
    "    run_corr_ivs_controls_job(df_name, dataframes[df_name], ivs_=ivs_dummy_perc_and_perc_interactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c3141",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_corr_ivs_controls_job_interact(df_name):\n",
    "        run_corr_ivs_controls_job(df_name, dataframes[df_name], ivs_=ivs_dummy_and_perc)\n",
    "else:\n",
    "    run_corr_ivs_controls_job(df_name, dataframes[df_name], ivs_=ivs_dummy_and_perc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8bcc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_corr_ivs_controls_job_interact(df_name):\n",
    "        run_corr_ivs_controls_job(df_name, dataframes[df_name], ivs_=ivs_perc_and_perc_interactions)\n",
    "else:\n",
    "    run_corr_ivs_controls_job(df_name, dataframes[df_name], ivs_=ivs_perc_and_perc_interactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bebf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_corr_ivs_controls_job_interact(df_name):\n",
    "        run_corr_ivs_controls_job(df_name, dataframes[df_name], ivs_=ivs_perc_interactions)\n",
    "else:\n",
    "    run_corr_ivs_controls_job(df_name, dataframes[df_name], ivs_=ivs_perc_interactions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67331972",
   "metadata": {},
   "source": [
    "## Imbalance Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcfd6de-970d-43c0-b29f-5e61cae2bdb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imbalance Ratio\n",
    "all_imbalance_ratio_dict = {}\n",
    "def run_imbalance_ratio(df_name, df):\n",
    "    print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "\n",
    "    warmth_imbalance_ratio = df['Warmth'].loc[\n",
    "        df['Warmth'] == 1].count()/df['Warmth'].loc[df['Warmth'] == 0\n",
    "    ].count()\n",
    "    competence_imbalance_ratio = df['Competence'].loc[\n",
    "        df['Competence'] == 1].count()/df['Competence'].loc[df['Competence'] == 0\n",
    "    ].count()\n",
    "\n",
    "    all_imbalance_ratio_dict[f'{df_name} Warmth'] = warmth_imbalance_ratio\n",
    "    all_imbalance_ratio_dict[f'{df_name} Competence'] = competence_imbalance_ratio\n",
    "\n",
    "    print('='*20)\n",
    "    print('Imabalance Ratios')\n",
    "    print('-'*10)\n",
    "    print(f'Warmth IR: {warmth_imbalance_ratio:.2f}')\n",
    "    print(f'Competence IR: {competence_imbalance_ratio:.2f}')\n",
    "    print('='*20)\n",
    "\n",
    "    with open(f'{data_dir}{df_name}_all_imbalance_ratio_dict.json', 'w') as f:\n",
    "        json.dump(all_imbalance_ratio_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys())\n",
    "    def run_imbalance_ratio_interact(df_name):\n",
    "        run_imbalance_ratio(df_name, dataframes[df_name])\n",
    "else:\n",
    "    run_imbalance_ratio(list(dataframes.keys())[0], list(dataframes.values())[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91bd4cfb",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc427c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_desc_excel(\n",
    "    df_desc,\n",
    "    index_var,\n",
    "    title_prefix,\n",
    "    file_save_path,\n",
    "    sheet_name=None,\n",
    "    startrow=None,\n",
    "    startcol=None,\n",
    "):\n",
    "    if sheet_name is None:\n",
    "        sheet_name = 'All'\n",
    "    if startrow is None:\n",
    "        startrow = 1\n",
    "    if startcol is None:\n",
    "        startcol = 1\n",
    "\n",
    "    # index = df_desc.index.to_frame().reset_index(drop=True)\n",
    "    df_desc = df_desc.reset_index(drop=False, col_level=1, col_fill=f'{title_prefix} Job Advertisements')\n",
    "\n",
    "    # Define last rows and cols locs\n",
    "    header_range = len(df_desc.columns.levels)\n",
    "    endrow = startrow + header_range + df_desc.shape[0]\n",
    "    endcol = startcol + df_desc.shape[1]\n",
    "\n",
    "    # Write\n",
    "    writer = pd.ExcelWriter(f'{file_save_path}.xlsx')\n",
    "    df_desc.to_excel(writer, sheet_name=sheet_name, merge_cells=True, startrow=startrow, startcol=startcol)\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    worksheet.set_row(startrow + header_range, None, None, {'hidden': True}) # hide the empty row that appears after the headers\n",
    "    worksheet.set_column(startrow, 1, None, None, {'hidden': True}) # hide the index column\n",
    "\n",
    "    # MAIN BODY\n",
    "    # Format column headers\n",
    "    for i, (col_num, col_value) in tqdm_product(range(header_range), (enumerate(df_desc.columns.values))):\n",
    "        row_to_write = startrow + i\n",
    "        col_to_write = startcol + 1 + col_num # 1 is for index\n",
    "        header_formats = {'bold': False, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'top': True, 'bottom': True, 'left': False, 'right': False}\n",
    "\n",
    "        if col_value[i] in ['n', 'M', 'SD']:\n",
    "            header_formats |= {'italic': True}\n",
    "\n",
    "        if col_value[i] == '95% Conf.':\n",
    "            worksheet.set_column(col_to_write, col_to_write, 8.5)\n",
    "\n",
    "        if col_value[i] == index_var:\n",
    "            worksheet.set_column(col_to_write, col_to_write, 10)\n",
    "            header_formats['align'] = 'left'\n",
    "            header_formats |= {'text_wrap': True}\n",
    "            worksheet.merge_range(row_to_write, col_to_write, header_range, col_to_write, index_var, workbook.add_format(header_formats))\n",
    "        else:\n",
    "            worksheet.write(row_to_write, col_to_write, col_value[i], workbook.add_format(header_formats))\n",
    "\n",
    "    # Format body columns\n",
    "    num = [col_num for col_num, value in enumerate(df_desc.columns.values) if value[-1] == 'n']\n",
    "    perc = [col_num for col_num, value in enumerate(df_desc.columns.values) if value[-1] == '%']\n",
    "    body_max_row_idx, body_max_col_idx = df_desc.shape\n",
    "\n",
    "    for c, r in tqdm_product(range(body_max_col_idx), range(body_max_row_idx)):\n",
    "        row_to_write = startrow + header_range + 1 + r # 1 is for the hidden empty column under the header\n",
    "        col_to_write = startcol + 1 + c # 1 is for index\n",
    "        body_formats = {'num_format': '0.00', 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'text_wrap': True, 'left': False, 'right': False}\n",
    "\n",
    "        if r == body_max_row_idx-1:\n",
    "            body_formats |= {'bottom': True}\n",
    "\n",
    "        if c == 0:\n",
    "            body_formats |= {'align': 'left'}\n",
    "\n",
    "        if c in num:\n",
    "            body_formats |= {'num_format': '0'}\n",
    "\n",
    "        if c in perc:\n",
    "            body_formats |= {'num_format': '0.0'}\n",
    "\n",
    "        worksheet.write(row_to_write, col_to_write, df_desc.iloc[r, c], workbook.add_format(body_formats))\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9698910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_desc(df, df_name, vars_list, var_name, index_var, sentence_level=False, continous_var_names_list=None):\n",
    "\n",
    "    if continous_var_names_list is None:\n",
    "        continous_var_names_list = ['Probabilities', 'Percentages']\n",
    "\n",
    "    if df_name == 'df_manual':\n",
    "        title_prefix = 'Manually Annotated Dataset'\n",
    "    elif df_name == 'df_jobs':\n",
    "        title_prefix = 'Classifier Labeled'\n",
    "\n",
    "    if sentence_level == False:\n",
    "        level = 'Job Advertisement'\n",
    "        df = df.groupby('Job ID').first()\n",
    "    if sentence_level == True:\n",
    "        level = 'Sentence'\n",
    "\n",
    "    # Warmth and Competence Categorical df\n",
    "    if len(set(var_name.split()).intersection(continous_var_names_list)) == 0:\n",
    "        df_cat = rp.summary_cat(df[vars_list], ascending= True).round(2)\n",
    "        df_cat['Variable'] = df_cat['Variable'].replace('', np.nan).fillna(method='ffill')\n",
    "        df_cat = df_cat.loc[df_cat['Outcome'] == 1].drop(columns=['Outcome'])\n",
    "        totals = pd.DataFrame(df_cat.sum(numeric_only=True)).transpose()\n",
    "        totals.insert(0, 'Variable', 'Total')\n",
    "        df_cat = df_cat.fillna('')\n",
    "        df_cat = pd.concat([df_cat, totals], axis='index', ignore_index=True)\n",
    "\n",
    "    # Warmth and Competence Continuous df\n",
    "    df_cont = rp.summary_cont(df[vars_list], conf = 0.95, decimals = 2)\n",
    "\n",
    "    # Merged df\n",
    "    if len(set(var_name.split()).intersection(continous_var_names_list)) == 0:\n",
    "        df_desc = df_cat.merge(df_cont, on='Variable', how='outer')\n",
    "        df_desc = df_desc.fillna('')\n",
    "    else:\n",
    "        df_desc = df_cont\n",
    "\n",
    "    # Rename variable columns\n",
    "    df_desc['Variable'] = df_desc['Variable'].apply(\n",
    "        lambda var_name: f'{var_name.split(\"_\")[1]}-dominated'.replace('_', ' ').strip()\n",
    "        if '_' in var_name and 'Mixed' not in var_name and '%' not in var_name and 'Probability' not in var_name\n",
    "        else f'{var_name.split(\"_\")[1]} Gender'.replace('_', ' ')\n",
    "        if '_' in var_name and 'Mixed' in var_name and '%' not in var_name and 'Probability' not in var_name\n",
    "        else \" \".join(var_name.split(\"_\")[1:]).split()[0]\n",
    "        if '_' in var_name and 'Mixed' not in var_name and '%' in var_name and 'Probability' not in var_name\n",
    "        else f'{var_name.split(\"_\")[0]} Probability'.replace('_', ' ')\n",
    "        if '_' in var_name and 'Mixed' not in var_name and '%' not in var_name and 'Probability' in var_name\n",
    "        else var_name\n",
    "    )\n",
    "\n",
    "    # Clean up df and set index\n",
    "    if len(set(var_name.split()).intersection(continous_var_names_list)) == 0:\n",
    "        drop_columns = ['N', 'SE', '95% Conf.', 'Interval']\n",
    "        rename_dict = {'Variable': index_var, 'Count': 'n', 'Percent': '%', 'Mean': 'M'}\n",
    "    else:\n",
    "        drop_columns = ['N', 'SE']\n",
    "        rename_dict = {'Variable': index_var, 'Mean': 'M', 'SD': 'SD', '95% Conf. Int.': '95% CI'}\n",
    "\n",
    "    df_desc = df_desc.drop(columns=drop_columns)\n",
    "    df_desc = df_desc.rename(columns=rename_dict)\n",
    "    df_desc = df_desc.set_index(keys=[index_var], drop=True)\n",
    "\n",
    "    # Make into MultiIndex\n",
    "    df_desc.columns = pd.MultiIndex.from_product([[level], df_desc.columns])\n",
    "\n",
    "    return df_desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d753448",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_dict = {\n",
    "    'Gender Categorical Designation of Sector': ivs_gender_dummy,\n",
    "    'Age Categorical Designation of Sector': ivs_age_dummy,\n",
    "    'Gender Percentages per Sector (%)': ivs_gender_perc,\n",
    "    'Age Percentages per Sector (%)': ivs_age_perc,\n",
    "    'Warmth and Competence Categorical Coding': dvs,\n",
    "    'Warmth and Competence Probabilities': dvs_prob,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46076356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_desc_tables(df_name, df, var_name, vars_list):\n",
    "    if df_name == 'df_manual':\n",
    "        title_prefix = 'Manually Annotated Dataset'\n",
    "    elif df_name == 'df_jobs' and 'Warmth and Competence' not in var_name:\n",
    "        title_prefix = 'Collected Dataset'\n",
    "    elif df_name == 'df_jobs':\n",
    "        title_prefix = 'Classifier Labeled'\n",
    "\n",
    "    # Set index varaible name\n",
    "    if 'Warmth and Competence' in var_name:\n",
    "        index_var = 'Stereotype-related frames'\n",
    "    elif 'Percentages' in var_name:\n",
    "        index_var = 'Percentages per Sector (PPS)'\n",
    "    else:\n",
    "        index_var = 'Sectors'\n",
    "\n",
    "    with contextlib.suppress(KeyError):\n",
    "        # Categorical DF on job ad level\n",
    "        df_desc_cat_jobad = make_df_desc(df, df_name, vars_list=vars_list, var_name=var_name, index_var=index_var, sentence_level=False)\n",
    "\n",
    "        # Categorical DF on sentence level\n",
    "        df_desc_cat_sent = make_df_desc(df, df_name, vars_list=vars_list, var_name=var_name, index_var=index_var, sentence_level=True)\n",
    "\n",
    "        # Merge Categorical dfs\n",
    "        df_desc_cat = df_desc_cat_jobad.merge(df_desc_cat_sent, on=index_var)\n",
    "\n",
    "        # Continuous DF on job ad level\n",
    "        df_desc_cont_jobad = make_df_desc(df, df_name, vars_list=vars_list, var_name=var_name, index_var=index_var, sentence_level=False)\n",
    "\n",
    "        # Continuous DF on sentence level\n",
    "        df_desc_cont_sent = make_df_desc(df, df_name, vars_list=vars_list, var_name=var_name, index_var=index_var, sentence_level=True)\n",
    "\n",
    "        # Merge Continuous dfs\n",
    "        df_desc_cont = df_desc_cont_jobad.merge(df_desc_cont_sent, on=index_var)\n",
    "\n",
    "        # Collect dfs in list\n",
    "        df_desc_list = [df_desc_cat, df_desc_cont]\n",
    "\n",
    "        for df_desc in df_desc_list:\n",
    "            levels_with_title = [[f'{title_prefix} Job Advertisements']]\n",
    "            # Add title prefix\n",
    "            levels_with_title.extend(\n",
    "                list(df_desc.columns.get_level_values(i).unique())\n",
    "                    for i in range(len(df_desc.columns.levels))\n",
    "            )\n",
    "            # levels_with_title.insert(0, )\n",
    "            if 'Warmth and Competence' not in var_name:\n",
    "                levels_with_title.insert(1, [var_name])\n",
    "\n",
    "            # Make into MultiIndex\n",
    "            df_desc.columns = pd.MultiIndex.from_product(levels_with_title)\n",
    "\n",
    "            # Save Tables\n",
    "            # File save path\n",
    "            file_save_path = f'{table_save_path}descriptives {df_name} {title_prefix} {var_name} - Job Advertisement'\n",
    "            # CSV\n",
    "            df_desc.to_csv(f'{file_save_path}.csv', index=True)\n",
    "            # PKL\n",
    "            df_desc.to_pickle(f'{file_save_path}.pkl')\n",
    "            # TEX\n",
    "            with pd.option_context('max_colwidth', 10000000000):\n",
    "                df_desc.style.to_latex(\n",
    "                    f'{file_save_path}.tex',\n",
    "                    convert_css=True,\n",
    "                    environment='longtable',\n",
    "                    hrules=True,\n",
    "                    # escape=True,\n",
    "                    # multicolumn=True,\n",
    "                    multicol_align='c',\n",
    "                    position='H',\n",
    "                    caption=f'{var_name} Descriptives', label='Descriptives'\n",
    "                )\n",
    "            # MD\n",
    "            df_desc.to_markdown(f'{file_save_path}.md', index=True)\n",
    "            # EXCEL\n",
    "            save_desc_excel(df_desc, index_var, title_prefix, file_save_path)\n",
    "\n",
    "        print('\\n')\n",
    "        print(f'{\"+\"*20} {df_name.upper()} {\"+\"*20}\\n')\n",
    "        print(f'{var_name} Descriptives')\n",
    "        if df_desc_list[0].equals(df_desc_list[1]):\n",
    "            print(df_desc_list[0])\n",
    "        else:\n",
    "            print(df_desc_list[0])\n",
    "            print(df_desc_list[1])\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f31a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys(), var_name=vars_dict.keys())\n",
    "    def make_desc_tables_interact(df_name, var_name):\n",
    "        make_desc_tables(df_name, dataframes[df_name], var_name, vars_dict[var_name])\n",
    "else:\n",
    "    for (df_name, df), (var_name, vars_list) in tqdm_product(dataframes.items(), vars_dict.items()):\n",
    "        make_desc_tables(df_name, df, var_name, vars_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7274b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Automating_Equity1_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
