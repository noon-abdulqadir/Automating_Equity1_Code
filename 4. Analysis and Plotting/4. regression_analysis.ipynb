{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "if code_dir_name not in str(Path.cwd()).split('/')[-1]:\n",
    "    for _ in range(5):\n",
    "\n",
    "        parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "        if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "            code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "            if code_dir is not None:\n",
    "                break\n",
    "else:\n",
    "    code_dir = Path.cwd()\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_module.imports import *  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module import researchpy_fork as rp # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module import specification_curve_fork as specy # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}df_manual_len.txt', 'r') as f:\n",
    "    df_manual_len = int(f.read())\n",
    "\n",
    "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_training.pkl')\n",
    "assert len(df_manual) == df_manual_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_manual_len} BUT IS OF LENGTH {len(df_manual)}'\n",
    "print(f'Dataframe loaded with shape: {df_manual.shape}')\n",
    "df_manual = categorize_df_gender_age(df_manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'r') as f:\n",
    "    df_jobs_len = int(f.read())\n",
    "\n",
    "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
    "assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_jobs)}'\n",
    "print(f'Dataframe loaded with shape: {df_jobs.shape}')\n",
    "df_jobs = categorize_df_gender_age(df_jobs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis plan:\n",
    "\n",
    "1. ## [Descriptives, visualizations, and tables](./1.%20descriptives_visualization_and_tables.ipynb)\n",
    "2. ## [Frequencies and Normality tests](./2.%20frequencies_and_normality_test.ipynb)\n",
    "   1. ### Frequencies, histograms, and QQ plots\n",
    "      * Normal test\n",
    "      * Kurtosis test\n",
    "      * Shapiro\n",
    "      * Anderson\n",
    "      * Bartlett\n",
    "   2. ### Correlation between independent variables (IVs) and control variables and Multicolinarity test\n",
    "      * Pearson's R\n",
    "      * VIF\n",
    "     - ***ivs_dummy*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "     - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "     - ***% Sector per Workforce*** (continous ratio) = Sector percentage per worksforce (0-100)\n",
    "     - ***num_words*** (continous ratio) = Number of words in job description\n",
    "     - ***English Requirement in Job Ad*** (binary nominal) = English requirement in job description (0 vs. 1)\n",
    "     - ***Dutch Requirement in Job Ad*** (binary nominal) = Dutch requirement in job description (0 vs. 1)\n",
    "     - ***Platform*** (binary dummy) = LinkedIn (0 vs. 1), Indeed (0 vs. 1), Glassdoor (0 vs. 1)\n",
    "\n",
    "3. ## [ANOVA and Chi-square (Pearson's R)](./3.%20chisqt_and_anova.ipynb)\n",
    "\n",
    "   1. ### Chi-square\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "\n",
    "   2. ### One-way ANOVA, interactions, and post-hoc test\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "          - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "          - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "      * **df_jobs:**\n",
    "         - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "         - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "           - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "           - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "\n",
    "4. ## [Regression Analysis](./3.%20regression_analysis.ipynb)\n",
    "   1. ### Logistic Regression  with all interaction (smf):\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   3. ### Multilevel OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "\n",
    "5. ## [Specification Curve Analysis](./4.%20specification_curve_analysis.ipynb)\n",
    "\n",
    "   1. ### Logistic Specification Curve Analysis:\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Specification Curve Analysis:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes dict\n",
    "dataframes = {\n",
    "    # 'df_manual': df_manual,\n",
    "    'df_jobs': df_jobs,\n",
    "}\n",
    "\n",
    "# Models dict\n",
    "sm_models = {\n",
    "    # 'Logistic': sm.Logit,\n",
    "    'OLS': sm.OLS,\n",
    "}\n",
    "\n",
    "# DVs dict\n",
    "dvs_for_analysis = {\n",
    "    # 'binary': ['Categorical Warmth and Competence', dvs],\n",
    "    'probability': ['Probability Warmth and Competence', dvs_prob],\n",
    "    # 'binary and probability': ['Categorical and Probability Warmth and Competence', dvs_all],\n",
    "}\n",
    "\n",
    "# IVs dict\n",
    "ivs_dummy_for_analysis = [iv for iv in ivs_dummy if 'Mixed' not in iv]\n",
    "ivs_dummy_and_perc_for_analysis = [iv for iv in ivs_dummy_and_perc if 'Mixed' not in iv]\n",
    "ivs_for_analysis = {\n",
    "    # 'categories': ['Categorical Gender and Age', ivs_dummy_for_analysis],\n",
    "    # 'percentages': ['PPS Gender and Age', ivs_perc],\n",
    "    'categories and percentages': ['Categorical and PPS Gender and Age', ivs_dummy_and_perc_for_analysis],\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula dfs and varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes with '%' and spaces removed and replaced with '_'\n",
    "dataframes_ = {\n",
    "    # 'df_manual_': df_manual.copy().rename(columns={x: x.replace('%', 'percentage').replace(' ', '_') for x in df_manual.columns}),\n",
    "    'df_jobs_': df_jobs.copy().rename(columns={x: x.replace('%', 'percentage').replace(' ', '_') for x in df_jobs.columns}),\n",
    "}\n",
    "\n",
    "# Variable names for statsmodels regression formulas with '%' and spaces removed and replaced with '_'\n",
    "ivs_perc_ = list(map(lambda x: x.replace('%', 'percentage').replace(' ', '_'), ivs_perc))\n",
    "print('-'*20)\n",
    "print(f'IVs perc to use:\\n{ivs_perc_}')\n",
    "print('\\n')\n",
    "ivs_dummy_and_perc_for_analysis_ = list(map(lambda x: x.replace('%', 'percentage').replace(' ', '_'), ivs_dummy_and_perc_for_analysis))\n",
    "print('-'*20)\n",
    "print(f'IVs dummy and perc to use:\\n{ivs_dummy_and_perc_for_analysis_}')\n",
    "print('\\n')\n",
    "controls_ = list(map(lambda x: x.replace('%', 'percentage').replace(' ', '_'), controls))\n",
    "print('-'*20)\n",
    "print(f'All controls:\\n{controls_}')\n",
    "print('\\n')\n",
    "controls_for_formula = ' + '.join(controls_[:2])\n",
    "print('-'*20)\n",
    "print(f'Controls to use:\\n{controls_for_formula}')\n",
    "print('\\n')\n",
    "\n",
    "ivs_for_analysis_ = {\n",
    "    # 'categories': ['Categorical Gender and Age', ivs_dummy_for_analysis],\n",
    "    # 'percentages': ['PPS Gender and Age', ivs_perc_],\n",
    "    'categories and percentages': ['Categorical and PPS Gender and Age', ivs_dummy_and_perc_for_analysis_],\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_full_summary_excel(\n",
    "    df_full_summary,\n",
    "    title,\n",
    "    text_to_add_list,\n",
    "    file_save_path,\n",
    "    sheet_name=None,\n",
    "    startrow=None,\n",
    "    startcol=None,\n",
    "): \n",
    "    if sheet_name is None:\n",
    "        sheet_name = 'All'\n",
    "    if startrow is None:\n",
    "        startrow = 1\n",
    "    if startcol is None:\n",
    "        startcol = 1\n",
    "\n",
    "    # Define last rows and cols locs\n",
    "    header_range = 2\n",
    "    endrow = startrow + header_range + df_full_summary.shape[0]\n",
    "    endcol = startcol + df_full_summary.shape[1]\n",
    "\n",
    "    # Remove NAs\n",
    "    df_full_summary = df_full_summary.fillna('')\n",
    "\n",
    "    # Write\n",
    "    writer = pd.ExcelWriter(f'{file_save_path}.xlsx', engine='xlsxwriter')\n",
    "    df_full_summary.to_excel(writer, sheet_name=sheet_name, merge_cells=True, startrow=startrow, startcol=startcol)\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    worksheet.set_row(startrow, None, None, {'hidden': True}) # hide the empty row that appears after the headers\n",
    "    worksheet.set_column(startrow, 1, None, None, {'hidden': True}) # hide the index column\n",
    "\n",
    "    # Title\n",
    "    worksheet.merge_range(1, startcol, 1, endcol, title, workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'left', 'top': True, 'bottom': True, 'left': False, 'right': False}))\n",
    "\n",
    "    # Main body\n",
    "    body_max_row_idx, body_max_col_idx = df_full_summary.shape\n",
    "\n",
    "    for c, r in tqdm_product(range(body_max_col_idx), range(body_max_row_idx)):\n",
    "        row_to_write = startrow + r # 1 is for the hidden empty column under the header\n",
    "        col_to_write = startcol + c # 1 is for index\n",
    "        body_formats = {'num_format': '0.00', 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'text_wrap': True, 'left': False, 'right': False}\n",
    "\n",
    "        if r == 0:\n",
    "            body_formats |= {'top': True, 'bottom': True, 'left': False, 'right': False}\n",
    "            worksheet.set_column(col_to_write, col_to_write, 10)\n",
    "\n",
    "        if r == body_max_row_idx-1:\n",
    "            body_formats |= {'bottom': True}\n",
    "\n",
    "        if c == 0:\n",
    "            body_formats |= {'align': 'left'}\n",
    "            worksheet.set_column(col_to_write, col_to_write, 15)\n",
    "\n",
    "        worksheet.write(row_to_write, col_to_write, df_full_summary.iloc[r, c], workbook.add_format(body_formats))\n",
    "\n",
    "    # Add Note\n",
    "    note_format = {'italic': True, 'font_name': 'Times New Roman', 'font_size': 10, 'font_color': 'black', 'align': 'left', 'left': False, 'right': False}\n",
    "    worksheet.merge_range(endrow, startcol, endrow, endcol, 'Note.', workbook.add_format(note_format))\n",
    "    # Add text\n",
    "    for i, text in enumerate(text_to_add_list):\n",
    "        worksheet.merge_range(endrow + 1 + i , startcol, endrow + 1 + i, endcol, text, workbook.add_format(note_format))\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_full_report(\n",
    "    results, dv, analysis_type, model_name, dvs_name, ivs_name,\n",
    "    regression_info_dict=None, regressor_order=None, text_to_add_list=None, title=None, model_names=None\n",
    "):\n",
    "    '''\n",
    "    Make a full report for a regression analysis.\n",
    "    results: statsmodels regression results object or list of results objects\n",
    "    dv: str, dependent variable name\n",
    "    '''\n",
    "\n",
    "    if regression_info_dict is None:\n",
    "        # Regression info dict\n",
    "        regression_info_dict = {\n",
    "            'Model Name': lambda x: f'{x.model.__class__.__name__}',\n",
    "            'N': lambda x: f'{int(x.nobs):d}',\n",
    "            'R-squared': lambda x: f'{x.rsquared:.3f}',\n",
    "            'R-squared Adj.': lambda x: f'{x.rsquared_adj:.3f}',\n",
    "            'Log-Likelihood': lambda x: f'{x.llf:.3f}',\n",
    "            'Pseudo R2': lambda x: f'{x.prsquared:.3f}',\n",
    "            'F': lambda x: f'{x.fvalue:.3f}',\n",
    "            'F (p-value)': lambda x: f'{x.f_pvalue:.3f}',\n",
    "            'df_model': lambda x: f'{x.df_model:.0f}',\n",
    "            'df_total': lambda x: f'{x.df_resid + x.df_model + 1:.0f}',\n",
    "            'df_resid': lambda x: f'{x.df_resid:.0f}',\n",
    "            'AIC': lambda x: f'{x.aic:.3f}',\n",
    "            'BIC': lambda x: f'{x.bic:.3f}',\n",
    "            'ICC': lambda x: f'{x.rsquared / (x.rsquared + (x.nobs - 1) * x.mse_resid):.3f}',\n",
    "            'RMSE': lambda x: f'{x.mse_resid ** 0.5:.3f}',\n",
    "            'RMSE (std)': lambda x: f'{x.mse_resid ** 0.5 / x.model.endog.std():.3f}',\n",
    "            'Omnibus': lambda x: f'{sms.omni_normtest(x.resid).statistic:.3f}',\n",
    "            'Omnibus (p-value)': lambda x: f'{sms.omni_normtest(x.resid).pvalue:.3f}',\n",
    "            'Skew': lambda x: f'{sms.jarque_bera(x.resid)[-2]:.3f}',\n",
    "            'Kurtosis': lambda x: f'{sms.jarque_bera(x.resid)[-1]:.3f}',\n",
    "            'Jarque-Bera (JB)': lambda x: f'{sms.jarque_bera(x.resid)[0]:.3f}',\n",
    "            'Jarque-Bera (p-value)': lambda x: f'{sms.jarque_bera(x.resid)[1]:.3f}',\n",
    "            'Intercept': lambda x: f'{x.params[\"const\"]:.3f}',\n",
    "            'Intercept (std)': lambda x: f'{x.bse[\"const\"]:.3f}',\n",
    "            'Intercept t': lambda x: f'{x.tvalues[\"const\"]:.3f}',\n",
    "            'Intercept t (p-value)': lambda x: f'{x.pvalues[\"const\"]:.3f}',\n",
    "            'Intercept (95% CI)': lambda x: f'{x.conf_int().loc[\"const\"][0]:.3f} - {x.conf_int().loc[\"const\"][1]:.3f}',\n",
    "            'Unstandardized Coefficent B (b)': lambda x: f'{x.params[0]:.3f}',\n",
    "            'Standard Error (SE)': lambda x: f'{x.bse[0]:.3f}',\n",
    "            'Standardized Coefficient b* (β)': lambda x: f'{x.params[0] / x.model.endog.std():.3f}',\n",
    "            't': lambda x: f'{x.tvalues[0]:.3f}',\n",
    "            't (p-value)': lambda x: f'{x.pvalues[0]:.3f}',\n",
    "            '95% CI': lambda x: f'{x.conf_int().iloc[0, 1]:.3f} - {x.conf_int().iloc[0, 1]:.3f}',\n",
    "            # 'Summary': lambda x: f'{x.summary()}',\n",
    "            # 'F (p-value - FDR)': lambda x: f'{x.f_pvalue_fdr:.3f}',\n",
    "            # 'F (p-value - Bonferroni)': lambda x: f'{x.f_pvalue_bonf:.3f}',\n",
    "            # 't (p-value - FDR)': lambda x: f'{x.pvalues_fdr[1]:.3f}',\n",
    "            # 't (p-value - Bonferroni)': lambda x: f'{x.pvalues_bonf[1]:.3f}',\n",
    "        }\n",
    "    if model_names is None:\n",
    "        if isinstance(results, list):\n",
    "            model_names = [\n",
    "                f'{results[0].model.endog_names.split(\"_\")[0] if \"_\" in results[0].model.endog_names else results[0].model.endog_names} Model {i+1}'\n",
    "                for i in range(len(results[0].model.endog_names))\n",
    "            ]\n",
    "            model_names[0] = model_names[0].replace('Model 1', 'Full Model')\n",
    "        else:\n",
    "            model_names = [\n",
    "                f'{results.model.endog_names.split(\"_\")[0] if \"_\" in results.model.endog_names else results.model.endog_names}'\n",
    "            ]\n",
    "\n",
    "    order_type = 'unordered' if regressor_order is None else 'ordered'\n",
    "    if text_to_add_list is None:\n",
    "        text_to_add_list = []\n",
    "        if regressor_order is not None:\n",
    "            text_to_add_list.append('Models are ordered by coefficient size, largest to smallest.')\n",
    "        else:\n",
    "            text_to_add_list.append('Models are ordered by independent variable type.')\n",
    "\n",
    "    if title is None:\n",
    "        title = f'{model_name} {analysis_type}: {dvs_name} x {ivs_name}'\n",
    "\n",
    "    # Statsmodels summary_col\n",
    "    full_summary = summary_col(\n",
    "        results,\n",
    "        stars=True,\n",
    "        info_dict=regression_info_dict,\n",
    "        regressor_order=regressor_order,\n",
    "        float_format='%0.3f',\n",
    "        model_names=model_names,\n",
    "    )\n",
    "    if isinstance(results, list) and len(results) > 4:\n",
    "        full_summary.tables[0][full_summary.tables[0].filter(regex='Full Model').columns[0]].loc['Unstandardized Coefficent B (b)': '95% CI'] = ''\n",
    "\n",
    "    # Add title and notes\n",
    "    full_summary.add_title(title)\n",
    "    text_to_add_list.extend(full_summary.extra_txt)\n",
    "    for text in text_to_add_list:\n",
    "        full_summary.add_text(text)\n",
    "\n",
    "    # Save\n",
    "    save_name = f'{table_save_path}{model_name} {df_name} - ALL {dv} {order_type} {analysis_type} on {ivs_type}'\n",
    "    df_full_summary = pd.read_html(full_summary.as_html())[0]\n",
    "    df_full_summary.to_csv(f'{save_name}.csv')\n",
    "    df_full_summary.style.to_latex(f'{save_name}.tex')\n",
    "    save_df_full_summary_excel(df_full_summary, title, text_to_add_list, save_name)\n",
    "\n",
    "    return full_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standardized_coefficients(results):\n",
    "\n",
    "    # # Get standardized regression coefficients\n",
    "    # std = np.asarray(constant.std(0))\n",
    "\n",
    "    # if 'const' in results.params and 'const' in constant:\n",
    "    #     std[0] = 1\n",
    "    # tt = results.t_test(np.diag(std))\n",
    "\n",
    "    # t-test\n",
    "    std = results.model.exog.std(0)\n",
    "    if 'const' in results.params:\n",
    "        std[0] = 1\n",
    "    tt = results.t_test(np.diag(std))\n",
    "\n",
    "    # Make df with standardized and unstandardized coefficients\n",
    "    df_std_coef = pd.DataFrame(\n",
    "        {\n",
    "            'coef': results.params,\n",
    "            'std err': results.bse,\n",
    "            'std coef': results.params / results.model.endog.std(),\n",
    "            't': results.tvalues,\n",
    "            'P>|t|': results.pvalues,\n",
    "            '[0.025': results.conf_int()[0],\n",
    "            '0.975]': results.conf_int()[1],\n",
    "        }\n",
    "    )\n",
    "    # if 'Group Var' in df_std_coef.index:\n",
    "    #     df_std_coef = df_std_coef.drop('Group Var', axis='index')\n",
    "    # # Add standardized coefficients and other data from t-test\n",
    "    # df_std_coef['std coef'] = tt.effect\n",
    "    # df_std_coef['std err'] = tt.sd\n",
    "    # df_std_coef['t'] = tt.statistic\n",
    "    # df_std_coef['P>|t|'] = tt.pvalue\n",
    "    # df_std_coef['[0.025'] = tt.conf_int()[:, 0]\n",
    "    # df_std_coef['0.975]'] = tt.conf_int()[:, 1]\n",
    "    # df_std_coef['var'] = [names[i] for i in range(len(results.model.exog_names))]\n",
    "    # df_std_coef = df_std_coef.sort_values('std coef', ascending=False)\n",
    "    df_std_coef = df_std_coef.reset_index().rename(columns={'index': 'var'})\n",
    "    df_std_coef = df_std_coef.rename(\n",
    "        columns={\n",
    "            'var': 'Variable',\n",
    "            'coef': 'Unstandardized Coefficent B (b)',\n",
    "            'std err': 'Standard Error',\n",
    "            'std coef':'Standardized Coefficient b* (β)', \n",
    "            't': 't-value', \n",
    "            'P>|t|': 'p-value', \n",
    "            '[0.025': '95% CI Lower',\n",
    "            '0.975]': '95% CI Upper'\n",
    "        }\n",
    "    )\n",
    "    # Reorder columns\n",
    "    df_std_coef = df_std_coef[[\n",
    "        'Variable',\n",
    "        'Unstandardized Coefficent B (b)',\n",
    "        'Standard Error',\n",
    "        'Standardized Coefficient b* (β)',\n",
    "        't-value',\n",
    "        'p-value',\n",
    "        '95% CI Lower',\n",
    "        '95% CI Upper'\n",
    "    ]]\n",
    "\n",
    "    return tt, df_std_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multilevel_reg_data(results, endog, groups, exog_restricted=None):\n",
    "    '''\n",
    "    perform likelihood ratio test of random-effects (LRT)\n",
    "    + Degrees of Freedom (df)\n",
    "    + Pseudo R-squared (pseudo_r2)\n",
    "    + Intraclass Correlation Coefficient (ICC)\n",
    "    + Bayesian Information Criterion (BIC)\n",
    "    + Akaike Information Criterion (AIC)\n",
    "    '''\n",
    "\n",
    "    if exog_restricted is None:\n",
    "        exog_names = results.params.index[:-1].tolist()\n",
    "        exog_restricted = np.zeros((len(endog), 1))\n",
    "        exog_restricted[1:, :] = 1\n",
    "\n",
    "    # Null model\n",
    "    null_model = sm.MixedLM(endog=endog, exog=exog_restricted, groups=groups)\n",
    "    null_results = null_model.fit(reml=False)\n",
    "\n",
    "    # LRT\n",
    "    lrt = np.abs(null_results.llf - results.llf) * 2\n",
    "\n",
    "    # Degrees of Freedom (df)\n",
    "    dsf = results.df_modelwc - null_results.df_modelwc\n",
    "\n",
    "    # P-value\n",
    "    p_value = 1 - scipy.stats.chi2.sf(lrt, dsf)\n",
    "\n",
    "    # Pseudo R-squared (pseudo_r2)\n",
    "    pseudo_r2 = 1 - (\n",
    "        np.exp(-2 * (results.llf - null_results.llf) / len(endog)) ** (2 / (len(endog) - len(exog_names) - 1))\n",
    "    )\n",
    "\n",
    "    # ICC\n",
    "    icc = results.cov_re.iloc[0, 0] / (results.cov_re.iloc[0, 0] + results.scale) # Variance at level 2 (due to belonging to a certain job ad)/ Total variance\n",
    "\n",
    "    # ICC null\n",
    "    icc_null = null_results.cov_re.iloc[0, 0] / (null_results.cov_re.iloc[0, 0] + null_results.scale) # Level 2 variance/ Total variance\n",
    "\n",
    "    # AIC\n",
    "    aic = -2 * results.llf + 2 * np.log(results.nobs)\n",
    "\n",
    "    # AIC null\n",
    "    aic_null = -2 * null_results.llf + 2 * np.log(null_results.nobs)\n",
    "\n",
    "    # BIC\n",
    "    bic = -2 * results.llf + np.log(results.nobs) * (results.df_modelwc)\n",
    "\n",
    "    # BIC null\n",
    "    bic_null = -2 * null_results.llf + np.log(null_results.nobs) * (null_results.df_modelwc)\n",
    "\n",
    "    return (\n",
    "        lrt, dsf, p_value, pseudo_r2, icc, aic, bic,\n",
    "        null_model, null_results, icc_null, aic_null, bic_null\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Logistic Regression for 0:1 Warmth and Competence\n",
    "for (df_name, df), (ivs_type, [ivs_name, ivs_]) in tqdm_product(dataframes.items(), ivs_for_analysis.items()):\n",
    "\n",
    "    model_name = 'Logistic'\n",
    "    analysis_type = 'regression'\n",
    "    print('\\n')\n",
    "    print('+'*120)\n",
    "    print(f'{\"=\"*50} RESULTS FOR {df_name} {ivs_name} {\"=\"*50}')\n",
    "    for dv in tqdm.tqdm(dvs):\n",
    "        print('+'*120)\n",
    "        print('\\n')\n",
    "        print(f'DEPENDENT VARIABLE: {dv}\\nINDEPENDENT VARIABLE: {ivs_}\\nCONTROLS: {controls[:2]}')\n",
    "        print('\\n')\n",
    "        print('+'*120)\n",
    "\n",
    "        endog_names = dv\n",
    "        exog_names = [iv for iv in ivs_ if 'Mixed' not in ivs_] + controls[:2]\n",
    "\n",
    "        endog = df[endog_names]\n",
    "        exog = df[exog_names]\n",
    "        constant = sm.add_constant(exog)\n",
    "\n",
    "        model = sm.Logit(endog=endog, exog=constant, data=df)\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]}*{ivs_dummy[3]} + {ivs_dummy[0]}*{ivs_dummy[4]} + {ivs_dummy[0]}*{ivs_dummy[5]} + {ivs_dummy[1]}*{ivs_dummy[3]} + {ivs_dummy[1]}*{ivs_dummy[4]} + {ivs_dummy[1]}*{ivs_dummy[5]} + {ivs_dummy[2]}*{ivs_dummy[3]} + {ivs_dummy[2]}*{ivs_dummy[4]} + {ivs_dummy[2]}*{ivs_dummy[5]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]} + {ivs_dummy[1]} + {ivs_dummy[2]} + {ivs_dummy[3]} + {ivs_dummy[4]} + {ivs_dummy[5]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]} + {ivs_dummy[1]} + {ivs_dummy[2]} + {ivs_dummy[3]} + {ivs_dummy[4]} + {ivs_dummy[5]}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]} + {ivs_dummy[2]} + {ivs_dummy[3]} + {ivs_dummy[5]}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]}*{ivs_dummy[3]} + {ivs_dummy[2]}*{ivs_dummy[5]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]}*{ivs_dummy[3]} + {ivs_dummy[2]}*{ivs_dummy[5]}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]} + {ivs_dummy[2]} + {ivs_dummy[3]} + {ivs_dummy[5]} + {ivs_dummy[0]}:{ivs_dummy[3]} + {ivs_dummy[2]}:{ivs_dummy[5]} + {controls_for_formula}'\n",
    "\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]} + {ivs_dummy[2]} + {ivs_dummy[3]} + {ivs_dummy[5]} + {controls_for_formula}'\n",
    "\n",
    "        # print('-'*20)\n",
    "        # print(f'Using formula: {formula}')\n",
    "        # print('-'*20)\n",
    "\n",
    "        # # with contextlib.suppress(np.linalg.LinAlgError):\n",
    "        # model = smf.logit(formula=formula, data=df)\n",
    "        results = model.fit()\n",
    "        full_summary = make_full_report(\n",
    "            results, dv, dvs_name=dv, ivs_name=ivs_name, model_name=model_name, analysis_type=analysis_type\n",
    "        )\n",
    "        tt, df_std_coef = get_standardized_coefficients(results)\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "        print(f'{dv}\\n')\n",
    "        print('-'*20)\n",
    "        print('\\n')\n",
    "        print(f'SUMMARY RESULTS:')\n",
    "        print(full_summary)\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "        print(f'STANDARDIZED BETA REGRESSION COEFFICIENTS:\\n{df_std_coef}')\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "\n",
    "        # # Display Results\n",
    "        # print('~'*20)\n",
    "        # print('+'*20)\n",
    "        # print(f'{dv} x {ivs_}\\n')\n",
    "        # print('+'*20)\n",
    "        # print('\\n')\n",
    "        # print(f'SUMMARY RESULTS:\\n{results.summary()}\\n')\n",
    "        # print('~'*20)\n",
    "        # # print(f'SUMMARY RESULTS2:\\n{results.summary2()}')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'y = {results.params.const:.2f} + {results.params.x:.2f} * x')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'COEFFICIENT:\\n{results.params}')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'CONFIDENCE INTERVALS:\\n{results.conf_int()}')\n",
    "        # # print(f'P-VALUES:\\n{results.pvalues}')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'ODDS RATIOS:\\n{np.exp(results.params)}')\n",
    "        # # print(f'AIC:\\n{results.aic:.2f}')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'BIC:\\n{results.bic:.2f}')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'Coehn\\'s F2:\\n{results.prsquared:.3f}')\n",
    "        # # print('-'*20)\n",
    "\n",
    "        # save results\n",
    "        save_name = f'{table_save_path}{model_name} {analysis_type} on {ivs_type} {df_name} - {dv} x {ivs_name}'\n",
    "        results.save(f'{save_name}.pickle')\n",
    "        df_to_save = pd.DataFrame(csv.reader(results.summary().as_csv().split('\\n'), delimiter=','))\n",
    "        df_to_save.to_csv(f'{save_name}.csv')\n",
    "        df_to_save.style.to_latex(f'{save_name}.tex')\n",
    "        # df_std_coef.to_csv(f'{save_name} - standardized coefficients.csv')\n",
    "        # df_std_coef.style.to_latex(f'{save_name} - standardized coefficients.tex')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (df_name, df), (ivs_type, [ivs_name, ivs_]) in tqdm_product(dataframes.items(), ivs_for_analysis.items()):\n",
    "\n",
    "    model_name = 'OLS'\n",
    "    analysis_type = 'regression'\n",
    "    if df_name == 'df_manual':\n",
    "        dvs_ = dvs\n",
    "    elif df_name == 'df_jobs':\n",
    "        dvs_ = dvs_prob\n",
    "\n",
    "    print('\\n')\n",
    "    print('+'*120)\n",
    "    print(f'{\"=\"*50} RESULTS FOR {df_name} {\"=\"*50}')\n",
    "    for dv in tqdm.tqdm(dvs_):\n",
    "        print('+'*120)\n",
    "        print('\\n')\n",
    "        print(f'DEPENDENT VARIABLE: {dvs_}\\nINDEPENDENT VARIABLE: {ivs_}\\nCONTROLS: {controls[:2]}')\n",
    "        print('\\n')\n",
    "        print('+'*120)\n",
    "\n",
    "        endog_names = dv\n",
    "        exog_names = ivs_[:] + controls[:2]\n",
    "\n",
    "        endog = df[endog_names]\n",
    "        exog = df[exog_names]\n",
    "        constant = sm.add_constant(exog)\n",
    "\n",
    "        model = sm.OLS(endog=endog, exog=constant, data=df)\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]} + {ivs_perc_[0]}:{ivs_perc_[2]} + {ivs_perc_[0]}:{ivs_perc_[3]} + {ivs_perc_[1]}:{ivs_perc_[2]} + {ivs_perc_[1]}:{ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]} + {controls_for_formula}'\n",
    "\n",
    "        # print('-'*20)\n",
    "        # print(f'Using formula: {formula}')\n",
    "        # print('-'*20)\n",
    "\n",
    "        # model = smf.ols(formula=formula, data=df)\n",
    "        results = model.fit()\n",
    "        full_summary = make_full_report(\n",
    "            results, dv, dvs_name=dv, ivs_name=ivs_name, model_name=model_name, analysis_type=analysis_type\n",
    "        )\n",
    "        tt, df_std_coef = get_standardized_coefficients(results)\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "        print(f'{dv}\\n')\n",
    "        print('-'*20)\n",
    "        print('\\n')\n",
    "        print(f'SUMMARY RESULTS:')\n",
    "        print(full_summary)\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "        print(f'STANDARDIZED BETA REGRESSION COEFFICIENTS:\\n{df_std_coef}')\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "\n",
    "        # # Display Results\n",
    "        # print('~'*20)\n",
    "        # print('+'*20)\n",
    "        # print(f'{dv} x {ivs_[:] + controls[:2]}\\n')\n",
    "        # print('+'*20)\n",
    "        # print('\\n')\n",
    "        # print(f'SUMMARY RESULTS:\\n{results.summary()}\\n')\n",
    "        # print('~'*20)\n",
    "        # print(f'STANDARDIZED COEFFICIENTS:\\n{df_std_coef}')\n",
    "        # print('~'*20)\n",
    "        # # print(f'SUMMARY RESULTS2:\\n{results.summary2()}')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'y = {results.params.const:.2f} + {results.params.x:.2f} * x')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'COEFFICIENT:\\n{results.params}')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'CONFIDENCE INTERVALS:\\n{results.conf_int()}')\n",
    "        # # print(f'P-VALUES:\\n{results.pvalues}')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'ODDS RATIOS:\\n{np.exp(results.params)}')\n",
    "        # print(f'AIC:\\n{results.aic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # print(f'BIC:\\n{results.bic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # # print(f'Coehn\\'s F2:\\n{results.rsquared_adj:.3f}')\n",
    "        # # print('-'*20)\n",
    "        # # table = sm.stats.anova_lm(results, typ=2)\n",
    "        # # print(f'ANOVA:\\n{table}')\n",
    "        # # print('-'*20)\n",
    "\n",
    "        # save results\n",
    "        save_name = f'{table_save_path}{model_name} {analysis_type} on {ivs_type} {df_name} - {dv} x {ivs_name}'\n",
    "        results.save(f'{save_name}.pickle')\n",
    "        df_summary_results = pd.DataFrame(csv.reader(results.summary().as_csv().split('\\n'), delimiter=','))\n",
    "        df_summary_results.to_csv(f'{save_name}.csv')\n",
    "        df_summary_results.style.to_latex(f'{save_name}.tex')\n",
    "        df_std_coef.to_csv(f'{save_name} - standardized coefficients.csv')\n",
    "        df_std_coef.style.to_latex(f'{save_name} - standardized coefficients.tex')\n",
    "\n",
    "        # # Boxplot\n",
    "        # boxplot = df.boxplot([dv], by = [ivs_perc_[2], ivs_perc_[0]],\n",
    "        #                     figsize = (16, 9),\n",
    "        #                     showmeans = True,\n",
    "        #                     notch = True)\n",
    "\n",
    "        # boxplot.set_xlabel('Categories')\n",
    "        # boxplot.set_ylabel(dv)\n",
    "        # # Creating a path to save the plot.\n",
    "        # plt.show()\n",
    "        # plt.pause(.001)\n",
    "        # # for image_save_format in ['eps', 'png', 'svg']:\n",
    "        # #     save_path = f'{plot_save_path}Probability Boxplot - {df_name} - {dv} x Social Category Percentages.{image_save_format}'\n",
    "        # #     boxplot.figure.savefig(\n",
    "        # #         save_path, format=image_save_format,\n",
    "        # #     )\n",
    "        # plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (df_name, df), (ivs_type, [ivs_name, ivs_]) in tqdm_product(dataframes_.items(), ivs_for_analysis_.items()):\n",
    "\n",
    "    model_name = 'Multivariate OLS'\n",
    "    analysis_type = 'regression'\n",
    "    if df_name == 'df_manual_':\n",
    "        dvs_ = dvs\n",
    "    elif df_name == 'df_jobs_':\n",
    "        dvs_ = dvs_all\n",
    "\n",
    "    print('\\n')\n",
    "    print('+'*120)\n",
    "    print(f'{\"=\"*50} RESULTS FOR {df_name} {\"=\"*50}')\n",
    "    print('+'*120)\n",
    "    print('\\n')\n",
    "    print(f'DEPENDENT VARIABLE: {dvs_}\\nINDEPENDENT VARIABLE: {ivs_}\\nCONTROLS: {controls[:2]}')\n",
    "    print('\\n')\n",
    "    print('+'*120)\n",
    "\n",
    "    # endog_names = dvs_\n",
    "    # exog_names = ivs_perc[:] + controls[:2]\n",
    "\n",
    "    # endog = df[endog_names]\n",
    "    # exog = df[exog_names]\n",
    "    # constant = sm.add_constant(exog)\n",
    "\n",
    "    # model = statsmodels.multivariate.multivariate_ols._MultivariateOLS(endog=endog, exog=constant, data=df)\n",
    "    # formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]} + {ivs_perc_[0]}:{ivs_perc_[2]} + {ivs_perc_[0]}:{ivs_perc_[3]} + {ivs_perc_[1]}:{ivs_perc_[2]} + {ivs_perc_[1]}:{ivs_perc_[3]} + {controls_for_formula}'\n",
    "    # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]} + {controls_for_formula}'\n",
    "    # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]}'\n",
    "    formula = f'{\" + \".join(dvs_)} ~ {\" + \".join(ivs_)} + {controls_for_formula}'\n",
    "\n",
    "    model = statsmodels.multivariate.multivariate_ols._MultivariateOLS.from_formula(formula=formula, data=df)\n",
    "\n",
    "    # print('-'*20)\n",
    "    # print(f'Using formula: {formula}')\n",
    "    # print('-'*20)\n",
    "\n",
    "    with contextlib.suppress(ValueError):\n",
    "        # model = smf.ols(formula=formula, data=df)\n",
    "        results = model.fit()\n",
    "        full_summary = results.mv_test().summary()\n",
    "        # full_summary = make_full_report(\n",
    "        #     results, dv, dvs_name=dv, ivs_name=ivs_name, model_name=model_name, analysis_type=analysis_type\n",
    "        # )\n",
    "        # tt, df_std_coef = get_standardized_coefficients(results)\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "        print(f'{dv}\\n')\n",
    "        print('-'*20)\n",
    "        print('\\n')\n",
    "        print(f'SUMMARY RESULTS:')\n",
    "        print(full_summary)\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "        print(f'STANDARDIZED BETA REGRESSION COEFFICIENTS:\\n{df_std_coef}')\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "        # print(f'SUMMARY RESULTS2:\\n{results.summary2()}')\n",
    "        # print('-'*20)\n",
    "        # print(f'y = {results.params.const:.2f} + {results.params.x:.2f} * x')\n",
    "        # print('-'*20)\n",
    "        # print(f'COEFFICIENT:\\n{results.params}')\n",
    "        # print('-'*20)\n",
    "        # print(f'CONFIDENCE INTERVALS:\\n{results.conf_int()}')\n",
    "        # print(f'P-VALUES:\\n{results.pvalues}')\n",
    "        # print('-'*20)\n",
    "        # print(f'ODDS RATIOS:\\n{np.exp(results.params)}')\n",
    "        # print(f'AIC:\\n{results.aic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # print(f'BIC:\\n{results.bic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # print(f'Coehn\\'s F2:\\n{results.rsquared_adj:.3f}')\n",
    "        # print('-'*20)\n",
    "        # table = sm.stats.anova_lm(results, typ=2)\n",
    "        # print(f'ANOVA:\\n{table}')\n",
    "        # print('-'*20)\n",
    "\n",
    "        # save results\n",
    "        save_name = f'{table_save_path}{model_name} {analysis_type} on {ivs_type} {df_name} - {dvs_} x {ivs_name}'\n",
    "        df_to_save = pd.concat(pd.read_html(results.mv_test().summary().as_html()), axis='index', ignore_index=True)\n",
    "        df_to_save.to_csv(f'{save_name}.csv')\n",
    "        df_to_save.style.to_latex(f'{save_name}.tex')\n",
    "        # df_std_coef.to_csv(f'{save_name} - standardized coefficients.csv')\n",
    "        # df_std_coef.style.to_latex(f'{save_name} - standardized coefficients.tex')\n",
    "\n",
    "        # # Boxplot\n",
    "        # boxplot = df.boxplot([dv], by = [ivs_perc_[2], ivs_perc_[0]],\n",
    "        #                     figsize = (16, 9),\n",
    "        #                     showmeans = True,\n",
    "        #                     notch = True)\n",
    "\n",
    "        # boxplot.set_xlabel('Categories')\n",
    "        # boxplot.set_ylabel(dv)\n",
    "        # # Creating a path to save the plot.\n",
    "        # plt.show()\n",
    "        # plt.pause(.001)\n",
    "        # # for image_save_format in ['eps', 'png', 'svg']:\n",
    "        # #     save_path = f'{plot_save_path}Probability Boxplot - {df_name} - {dv} x Social Category Percentages.{image_save_format}'\n",
    "        # #     boxplot.figure.savefig(\n",
    "        # #         save_path, format=image_save_format,\n",
    "        # #     )\n",
    "        # plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-level OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (df_name, df), (ivs_type, [ivs_name, ivs_]) in tqdm_product(dataframes.items(), ivs_for_analysis.items()):\n",
    "\n",
    "    model_name = 'Multilevel OLS'\n",
    "    analysis_type = 'regression'\n",
    "    if df_name == 'df_manual':\n",
    "        dvs_ = dvs\n",
    "    elif df_name == 'df_jobs':\n",
    "        dvs_ = dvs_prob\n",
    "\n",
    "    print('\\n')\n",
    "    print('+'*120)\n",
    "    print(f'{\"=\"*50} RESULTS FOR {df_name} {\"=\"*50}')\n",
    "    for dv in tqdm.tqdm(dvs_):\n",
    "        print('+'*120)\n",
    "        print('\\n')\n",
    "        print(f'DEPENDENT VARIABLE: {dv}\\nINDEPENDENT VARIABLE: {ivs_}\\nCONTROLS: {controls[:2]}')\n",
    "        print('\\n')\n",
    "        print('+'*120)\n",
    "\n",
    "        endog_names = dv\n",
    "        exog_names = ivs_[:] + controls[:2]\n",
    "        random_intercept_names = 'Job ID'\n",
    "\n",
    "        endog = df[endog_names]\n",
    "        exog = df[exog_names]\n",
    "        constant = sm.add_constant(exog)\n",
    "        groups = df[random_intercept_names]\n",
    "\n",
    "        # Main model\n",
    "        model = sm.MixedLM(endog=endog, exog=constant, groups=groups)\n",
    "        results = model.fit()\n",
    "\n",
    "        # Get fit statistics\n",
    "        (\n",
    "            lrt, dsf, p_value, pseudo_r2, icc, aic, bic, null_model, null_results, icc_null, aic_null, bic_null\n",
    "        ) = get_multilevel_reg_data(\n",
    "            results, endog, groups\n",
    "        )\n",
    "\n",
    "        # Get standardized beta regression coefficients\n",
    "        full_summary = make_full_report(\n",
    "            results, dv,\n",
    "            dvs_name=dv, ivs_name=ivs_name,\n",
    "            model_name=model_name, analysis_type=analysis_type, title=f'Multilevel: {dv} x {ivs_name}'\n",
    "        )\n",
    "        tt, df_std_coef = get_standardized_coefficients(results)\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "        print(f'{dv}\\n')\n",
    "        print('-'*20)\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "        print(f'SUMMARY RESULTS:\\n{full_summary}')\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "        print(f'FIT STATISTICS:\\nLRT: {lrt:.3f}\\nDSF: {dsf:.3f}\\nP-VALUE: {p_value:.3f}\\nPSEUDO R2: {pseudo_r2:.3f}\\nICC: {icc:.3f}\\nAIC: {aic:.3f}\\nBIC: {bic:.3f}\\n')\n",
    "        print('-'*20)\n",
    "        print(f'STANDARDIZED BETA REGRESSION COEFFICIENTS:\\n{df_std_coef}')\n",
    "        print('\\n')\n",
    "        print('-'*20)\n",
    "\n",
    "        # formula = f'{dv} ~ ' + ' + '.join(exog_names)\n",
    "        # model0 = smf.mixedlm(formula, data=df, groups=groups, exog_re=exog_names)\n",
    "        # results0 = model0.fit()\n",
    "        # cov_params = results0.cov_params()\n",
    "        # exog_vc = sm_mlm.cov_struct.CovarianceStruct().from_params(cov_params.values, cov_type='custom')\n",
    "\n",
    "        # model = sm.MixedLM(endog=endog, exog=constant, exog_re=exog_names, exog_vc=exog_vc, groups=groups)\n",
    "        # results = model.fit()\n",
    "\n",
    "        # endog = df[dv]\n",
    "        # exog0 = df[['Intercept', f'{list(iter(ivs_for_analysis))[0]}']]\n",
    "        # exog1 = df[['Intercept', f'{list(iter(ivs_for_analysis))[1]}']]\n",
    "        # iv_1 = list(iter(ivs_for_analysis))[0]\n",
    "        # iv_1_treatment = ivs_for_analysis[iv_1][0]\n",
    "        # iv_2 = list(iter(ivs_for_analysis))[1]\n",
    "        # iv_2_treatment = ivs_for_analysis[iv_2][0]\n",
    "\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]} + {ivs_perc_[0]}:{ivs_perc_[2]} + {ivs_perc_[0]}:{ivs_perc_[3]} + {ivs_perc_[1]}:{ivs_perc_[2]} + {ivs_perc_[1]}:{ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]}'\n",
    "\n",
    "        # print('-'*20)\n",
    "        # print(f'Using formula: {formula}')\n",
    "        # print('-'*20)\n",
    "\n",
    "        # vc_formula = {f'{controls_[1]}': f'0 + {controls_[1]}'}\n",
    "        # re_formula = f'1 + {controls_[1]}'\n",
    "\n",
    "        # model = smf.mixedlm(formula=formula, data=df, groups='Job_ID',) #vc_formula=vc_formula, re_formula=re_formula)\n",
    "        # results = model.fit(method='lbfgs')\n",
    "        # gradient = model.score(results.params_object)\n",
    "\n",
    "        # # Display Results\n",
    "        # print('~'*20)\n",
    "        # print('+'*20)\n",
    "        # print(f'{dv} x {ivs_}\\n')\n",
    "        # print('+'*20)\n",
    "        # # print(f'Gradient:\\n{gradient}')\n",
    "        # # print('\\n')\n",
    "        # print(f'SUMMARY RESULTS:\\n{results.summary()}\\n')\n",
    "        # print('~'*20)\n",
    "        # print(f'STANDARDIZED COEFFICIENTS:\\n{df_std_coef}')\n",
    "        # print('~'*20)\n",
    "        # print(f'NULL MODEL SUMMARY:\\n{null_results.summary()}')\n",
    "        # print('\\n')\n",
    "        # print('+'*20)\n",
    "        # # print(f'SUMMARY RESULTS2:\\n{results.summary2()}')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'y = {results.params.const:.2f} + {results.params.x:.2f} * x')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'COEFFICIENT:\\n{results.params}')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'CONFIDENCE INTERVALS:\\n{results.conf_int()}')\n",
    "        # # print(f'P-VALUES:\\n{results.pvalues}')\n",
    "        # # print('-'*20)\n",
    "        # # print(f'ODDS RATIOS:\\n{np.exp(results.params)}')\n",
    "        # print('+'*20)\n",
    "        # print('-'*20)\n",
    "        # print(f'Akaike Information Criterion (AIC):\\n{aic}')\n",
    "        # print('-'*20)\n",
    "        # print(f'AIC NULL:\\n{aic_null}')\n",
    "        # print('-'*20)\n",
    "        # print(f'Bayesian Information Criterion (BIC):\\n{bic}')\n",
    "        # print('-'*20)\n",
    "        # print(f'BIC NULL:\\n{bic_null}')\n",
    "        # print('-'*20)\n",
    "        # print(f'Intraclass Correlation Coefficient (ICC):\\n{icc}')\n",
    "        # print('-'*20)\n",
    "        # print(f'ICC NULL:\\n{icc_null}')\n",
    "        # print('-'*20)\n",
    "        # print(f'Pseudo R2:\\n{pseudo_r2}')\n",
    "        # print('-'*20)\n",
    "        # print(f'Likelihood Ratio Test of random-effects (LRT):\\n{lrt}')\n",
    "        # print('-'*20)\n",
    "        # print(f'Degrees of Freedom:\\n{dsf}')\n",
    "        # print('-'*20)\n",
    "        # print(f'P-VALUE:\\n{p_value}')\n",
    "        # print('-'*20)\n",
    "        # print('+'*20)\n",
    "        # # print(f'Coehn\\'s F2:\\n{results.rsquared_adj:.3f}')\n",
    "        # # print('-'*20)\n",
    "        # # table = sm.stats.anova_lm(results, typ=2)\n",
    "        # # print(f'ANOVA:\\n{table}')\n",
    "        # # print('-'*20)\n",
    "\n",
    "        # save results\n",
    "        save_name = f'{table_save_path}{model_name} {analysis_type} on {ivs_type} {df_name} - {dv} x {ivs_name}'\n",
    "        df_to_save = pd.concat(pd.read_html(results.summary().as_html()), axis='index', ignore_index=True)\n",
    "        df_to_save.to_csv(f'{save_name}.csv')\n",
    "        df_to_save.style.to_latex(f'{save_name}.tex')\n",
    "        df_std_coef.to_csv(f'{save_name} - standardized coefficients.csv')\n",
    "        df_std_coef.style.to_latex(f'{save_name} - standardized coefficients.tex')\n",
    "\n",
    "        # # Normality Tests (https://www.pythonfordatascience.org/mixed-effects-regression-python/)\n",
    "        # ## Residual and Kernal Density Estimate (KDE) Plot for Homoskedasticity\n",
    "        # fig = plt.figure(figsize = (16, 9))\n",
    "\n",
    "        # ax = sns.distplot(results.resid, hist = True, kde_kws = {\"shade\" : True, \"lw\": 1}, fit = scipy.stats.norm, kde=True, palette='colorblind')\n",
    "\n",
    "        # ax.set_title(f\"Kernal Density Estimate (KDE) Plot of Model Residuals (Blue) and Normal Distribution (Black)\\n{save_name}\")\n",
    "        # ax.set_xlabel(\"Residuals\")\n",
    "        # fig.show('notebook')\n",
    "        # plt.pause(.001)\n",
    "\n",
    "        # # Q-Q Plot\n",
    "        # fig = plt.figure(figsize = (16, 9))\n",
    "        # ax = fig.add_subplot(111)\n",
    "\n",
    "        # qq = sm.qqplot(results.resid, dist = scipy.stats.norm, line = 's', ax = ax, color='blue', markerfacecolor='blue')\n",
    "        # ax.set_title(f\"Q-Q Plot\\n{save_name}\",fontsize=15)\n",
    "        # ax.xaxis.get_label().set_fontsize(12)\n",
    "        # ax.yaxis.get_label().set_fontsize(12)\n",
    "        # ax.get_lines()[0].set_color('black')\n",
    "        # ax.get_lines()[0].set_linewidth('2')\n",
    "        # ax.get_lines()[1].set_color('black')\n",
    "        # ax.get_lines()[1].set_linewidth('2')\n",
    "        # fig.show('notebook')\n",
    "        # plt.pause(.001)\n",
    "\n",
    "        # # Test of Normality\n",
    "        # norm = scipy.stats.normaltest(results.resid)\n",
    "\n",
    "        # print('='*80)\n",
    "        # print(f'{dv} Test of Normality:')\n",
    "        # print('-'*80)\n",
    "        # for key, val in dict(zip(normality_tests_labels, norm)).items():\n",
    "        #     print(key,': ', val) # Significant\n",
    "        # print('\\n')\n",
    "\n",
    "        # # Skewness-Kurtosis Test of Normality\n",
    "        # norm_sk = scipy.stats.kurtosistest(results.resid)\n",
    "\n",
    "        # print('='*80)\n",
    "        # print(f'{dv} Skewness-Kurtosis Test of Normality:')\n",
    "        # print('-'*80)\n",
    "        # for key, val in dict(zip(normality_tests_labels, norm_sk)).items():\n",
    "        #     print(key,': ', val) # Significant\n",
    "        # print('\\n')\n",
    "\n",
    "        # # Shapir-Wilk Test of Normality\n",
    "        # norm_res = scipy.stats.shapiro(results.resid)\n",
    "\n",
    "        # print('='*80)\n",
    "        # print(f'{dv} Shapir-Wilk Test of Normality:')\n",
    "        # print('-'*80)\n",
    "        # for key, val in dict(zip(normality_tests_labels, norm_res)).items():\n",
    "        #     print(key,': ', val) # Significant\n",
    "        # print('\\n')\n",
    "\n",
    "        # # Anderson-Darling Test of Normality\n",
    "        # norm_and = scipy.stats.anderson(results.resid)\n",
    "\n",
    "        # print('='*80)\n",
    "        # print(f'{dv} Anderson-Darling Test of Normality:')\n",
    "        # print('-'*80)\n",
    "        # for key, val in dict(zip(normality_tests_labels, norm_and)).items():\n",
    "        #     print(key,': ', val) # Significant\n",
    "        # print('\\n')\n",
    "\n",
    "        # # Residuals versus Fitted values (RVF) Plot for Homoskedasticity\n",
    "        # fig = plt.figure(figsize = (16, 9))\n",
    "\n",
    "        # ax = sns.scatterplot(y = results.resid, x = results.fittedvalues, palette='colorblind')\n",
    "\n",
    "        # ax.set_title(f\"Residuals versus Fitted values (RVF) Plot\\n{save_name}\")\n",
    "        # ax.set_xlabel(\"Fitted Values\")\n",
    "        # ax.set_ylabel(\"Residuals\")\n",
    "        # fig.show('notebook')\n",
    "        # plt.pause(.001)\n",
    "\n",
    "        # # White’s Lagrange Multiplier Test for Heteroscedasticity\n",
    "        # het_white_res = het_white(results.resid, results.model.exog)\n",
    "\n",
    "        # het_white_labels = [\"LM Statistic\", \"LM-Test p-value\", \"F-Statistic\", \"F-Test p-value\"]\n",
    "\n",
    "        # print('='*80)\n",
    "        # print('White’s Lagrange Multiplier Test for Heteroscedasticity')\n",
    "        # print('-'*80)\n",
    "        # for key, val in dict(zip(het_white_labels, het_white_res)).items():\n",
    "        #     print(key, val)\n",
    "        # print('\\n')\n",
    "        # print('\\n')\n",
    "        # print('+'*120)\n",
    "        # print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
