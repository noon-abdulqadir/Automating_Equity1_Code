{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "import sys  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from pathlib import Path  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "sys.path.append(code_dir)\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_module.imports import *  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module import researchpy_fork as rp # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module import specification_curve_fork as specy # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}df_manual_len.txt', 'r') as f:\n",
    "    df_manual_len = int(f.read())\n",
    "\n",
    "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_training.pkl')\n",
    "assert len(df_manual) == df_manual_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_manual_len} BUT IS OF LENGTH {len(df_manual)}'\n",
    "print(f'Dataframe loaded with shape: {df_manual.shape}')\n",
    "df_manual = categorize_df_gender_age(df_manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'r') as f:\n",
    "    df_jobs_len = int(f.read())\n",
    "\n",
    "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
    "assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_jobs)}'\n",
    "print(f'Dataframe loaded with shape: {df_jobs.shape}')\n",
    "df_jobs = categorize_df_gender_age(df_jobs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis plan:\n",
    "\n",
    "1. ## [Descriptives, visualizations, and tables](./1.%20descriptives_visualization_and_tables.ipynb)\n",
    "2. ## [Frequencies and Normality tests](./2.%20frequencies_and_normality_test.ipynb)\n",
    "   1. ### Frequencies, histograms, and QQ plots\n",
    "      * Normal test\n",
    "      * Kurtosis test\n",
    "      * Shapiro\n",
    "      * Anderson\n",
    "      * Bartlett\n",
    "   2. ### Correlation between independent variables (IVs) and control variables and Multicolinarity test\n",
    "      * Pearson's R\n",
    "      * VIF\n",
    "     - ***ivs_dummy*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "     - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "     - ***% Sector per Workforce*** (continous ratio) = Sector percentage per worksforce (0-100)\n",
    "     - ***num_words*** (continous ratio) = Number of words in job description\n",
    "     - ***English Requirement in Job Ad*** (binary nominal) = English requirement in job description (0 vs. 1)\n",
    "     - ***Dutch Requirement in Job Ad*** (binary nominal) = Dutch requirement in job description (0 vs. 1)\n",
    "     - ***Platform*** (binary dummy) = LinkedIn (0 vs. 1), Indeed (0 vs. 1), Glassdoor (0 vs. 1)\n",
    "\n",
    "3. ## [ANOVA and Chi-square (Pearson's R)](./3.%20chisqt_and_anova.ipynb)\n",
    "\n",
    "   1. ### Chi-square\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "\n",
    "   2. ### One-way ANOVA, interactions, and post-hoc test\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "          - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "          - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "      * **df_jobs:**\n",
    "         - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "         - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "           - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "           - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "\n",
    "4. ## [Regression Analysis](./3.%20regression_analysis.ipynb)\n",
    "   1. ### Logistic Regression  with all interaction (smf):\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   3. ### Multilevel OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "\n",
    "5. ## [Specification Curve Analysis](./4.%20specification_curve_analysis.ipynb)\n",
    "\n",
    "   1. ### Logistic Specification Curve Analysis:\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Specification Curve Analysis:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframes dict and ivs + controls for statsmodels regression formulas ('%' and spaces removed and replaced with '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes with '%' and spaces removed and replaced with '_'\n",
    "dataframes_ = {\n",
    "    # 'df_manual_': df_manual.copy().rename(columns={x: x.replace('%', 'percentage').replace(' ', '_') for x in df_manual.columns}),\n",
    "    'df_jobs_': df_jobs.copy().rename(columns={x: x.replace('%', 'percentage').replace(' ', '_') for x in df_jobs.columns}),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable names for statsmodels regression formulas with '%' and spaces removed and replaced with '_'\n",
    "ivs_perc_ = list(map(lambda x: x.replace('%', 'percentage').replace(' ', '_'), ivs_perc))\n",
    "print('-'*20)\n",
    "print(f'IVs to use:\\n{ivs_perc_}')\n",
    "print('\\n')\n",
    "controls_ = list(map(lambda x: x.replace('%', 'percentage').replace(' ', '_'), controls))\n",
    "print('-'*20)\n",
    "print(f'All controls:\\n{controls_}')\n",
    "print('\\n')\n",
    "controls_for_formula = ' + '.join(controls_[:4])\n",
    "print('-'*20)\n",
    "print(f'Controls to use:\\n{controls_for_formula}')\n",
    "print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Social Category Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Logistic Regression for 0:1 Warmth and Competence x 0:1 Gender and Age\n",
    "for df_name, df in dataframes_.items():\n",
    "\n",
    "    print('\\n')\n",
    "    print('+'*120)\n",
    "    print(f'{\"=\"*50} RESULTS FOR {df_name} {\"=\"*50}')\n",
    "    for dv in tqdm.tqdm(dvs):\n",
    "        print('+'*120)\n",
    "        print('\\n')\n",
    "        print(f'DEPENDENT VARIABLE: {dv}\\n\\nINDEPENDENT VARIABLE: {ivs_dummy[0]} + {ivs_dummy[2]} + {ivs_dummy[3]} + {ivs_dummy[5]}')\n",
    "        print('\\n')\n",
    "        print('+'*120)\n",
    "\n",
    "        # model = sm.Logit(endog=df[dv], exog=df[ivs_perc], data=df)\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]}*{ivs_dummy[3]} + {ivs_dummy[0]}*{ivs_dummy[4]} + {ivs_dummy[0]}*{ivs_dummy[5]} + {ivs_dummy[1]}*{ivs_dummy[3]} + {ivs_dummy[1]}*{ivs_dummy[4]} + {ivs_dummy[1]}*{ivs_dummy[5]} + {ivs_dummy[2]}*{ivs_dummy[3]} + {ivs_dummy[2]}*{ivs_dummy[4]} + {ivs_dummy[2]}*{ivs_dummy[5]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]} + {ivs_dummy[1]} + {ivs_dummy[2]} + {ivs_dummy[3]} + {ivs_dummy[4]} + {ivs_dummy[5]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]} + {ivs_dummy[1]} + {ivs_dummy[2]} + {ivs_dummy[3]} + {ivs_dummy[4]} + {ivs_dummy[5]}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]} + {ivs_dummy[2]} + {ivs_dummy[3]} + {ivs_dummy[5]}'\n",
    "        formula = f'{dv} ~ {ivs_dummy[0]} + {ivs_dummy[2]} + {ivs_dummy[3]} + {ivs_dummy[5]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]}*{ivs_dummy[3]} + {ivs_dummy[2]}*{ivs_dummy[5]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]}*{ivs_dummy[3]} + {ivs_dummy[2]}*{ivs_dummy[5]}'\n",
    "        # formula = f'{dv} ~ {ivs_dummy[0]} + {ivs_dummy[2]} + {ivs_dummy[3]} + {ivs_dummy[5]} + {ivs_dummy[0]}:{ivs_dummy[3]} + {ivs_dummy[2]}:{ivs_dummy[5]} + {controls_for_formula}'\n",
    "\n",
    "        print('-'*20)\n",
    "        print(f'Using formula: {formula}')\n",
    "        print('-'*20)\n",
    "\n",
    "        # with contextlib.suppress(np.linalg.LinAlgError):\n",
    "        model = smf.logit(formula=formula, data=df)\n",
    "        results = model.fit()\n",
    "        df_summary_results = pd.DataFrame(csv.reader(results.summary().as_csv().split('\\n'), delimiter=','))\n",
    "\n",
    "        # Display Results\n",
    "        print('~'*20)\n",
    "        print('\\n')\n",
    "        print(f'SUMMARY RESULTS:\\n{results.summary()}\\n')\n",
    "        print('~'*20)\n",
    "        # print(f'SUMMARY RESULTS2:\\n{results.summary2()}')\n",
    "        # print('-'*20)\n",
    "        # print(f'y = {results.params.const:.2f} + {results.params.x:.2f} * x')\n",
    "        # print('-'*20)\n",
    "        # print(f'COEFFICIENT:\\n{results.params}')\n",
    "        # print('-'*20)\n",
    "        # print(f'CONFIDENCE INTERVALS:\\n{results.conf_int()}')\n",
    "        # print(f'P-VALUES:\\n{results.pvalues}')\n",
    "        # print('-'*20)\n",
    "        # print(f'ODDS RATIOS:\\n{np.exp(results.params)}')\n",
    "        # print(f'AIC:\\n{results.aic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # print(f'BIC:\\n{results.bic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # print(f'Coehn\\'s F2:\\n{results.prsquared:.3f}')\n",
    "        # print('-'*20)\n",
    "\n",
    "        # save results\n",
    "        df_summary_results = pd.DataFrame(csv.reader(results.summary().as_csv().split('\\n'), delimiter=','))\n",
    "        df_summary_results.to_csv(f'{table_save_path}logistic regression on categories {df_name} - {dv} x Social Category Percentages.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Social Category percentage per Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Logistic Regression for 0:1 Warmth and Competence x percentage Gender and Age\n",
    "for df_name, df in dataframes_.items():\n",
    "\n",
    "    print('\\n')\n",
    "    print('+'*120)\n",
    "    print(f'{\"=\"*50} RESULTS FOR {df_name} {\"=\"*50}')\n",
    "    for dv in tqdm.tqdm(dvs):\n",
    "        print('+'*120)\n",
    "        print('\\n')\n",
    "        print(f'DEPENDENT VARIABLE: {dv}\\n\\nINDEPENDENT VARIABLE: {ivs_perc_}')\n",
    "        print('\\n')\n",
    "        print('+'*120)\n",
    "\n",
    "        # model = sm.Logit(endog=df[dv], exog=df[ivs_perc], data=df)\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]} + {ivs_perc_[0]}:{ivs_perc_[2]} + {ivs_perc_[0]}:{ivs_perc_[3]} + {ivs_perc_[1]}:{ivs_perc_[2]} + {ivs_perc_[1]}:{ivs_perc_[3]}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]}'\n",
    "        formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]} + {controls_for_formula}'\n",
    "\n",
    "        print('-'*20)\n",
    "        print(f'Using formula: {formula}')\n",
    "        print('-'*20)\n",
    "\n",
    "        model = smf.logit(formula=formula, data=df)\n",
    "        results = model.fit()\n",
    "\n",
    "        # Display Results\n",
    "        print('~'*20)\n",
    "        print('\\n')\n",
    "        print(f'SUMMARY RESULTS:\\n{results.summary()}\\n')\n",
    "        print('~'*20)\n",
    "        # print(f'SUMMARY RESULTS2:\\n{results.summary2()}')\n",
    "        # print('-'*20)\n",
    "        # print(f'y = {results.params.const:.2f} + {results.params.x:.2f} * x')\n",
    "        # print('-'*20)\n",
    "        # print(f'COEFFICIENT:\\n{results.params}')\n",
    "        # print('-'*20)\n",
    "        # print(f'CONFIDENCE INTERVALS:\\n{results.conf_int()}')\n",
    "        # print(f'P-VALUES:\\n{results.pvalues}')\n",
    "        # print('-'*20)\n",
    "        # print(f'ODDS RATIOS:\\n{np.exp(results.params)}')\n",
    "        # print(f'AIC:\\n{results.aic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # print(f'BIC:\\n{results.bic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # print(f'Coehn\\'s F2:\\n{results.prsquared:.3f}')\n",
    "        # print('-'*20)\n",
    "\n",
    "        # save results\n",
    "        df_summary_results = pd.DataFrame(csv.reader(results.summary().as_csv().split('\\n'), delimiter=','))\n",
    "        df_summary_results.to_csv(f'{table_save_path}logistic regression on percentages {df_name} - {dv} x Social Category Percentages.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in dataframes_.items():\n",
    "\n",
    "    if df_name == 'df_manual_':\n",
    "        dvs_ = dvs\n",
    "    elif df_name == 'df_jobs_':\n",
    "        dvs_ = dvs_all\n",
    "\n",
    "    print('\\n')\n",
    "    print('+'*120)\n",
    "    print(f'{\"=\"*50} RESULTS FOR {df_name} {\"=\"*50}')\n",
    "    for dv in tqdm.tqdm(dvs_):\n",
    "        print('+'*120)\n",
    "        print('\\n')\n",
    "        print(f'DEPENDENT VARIABLE: {dv}\\n\\nINDEPENDENT VARIABLE: {ivs_perc_}')\n",
    "        print('\\n')\n",
    "        print('+'*120)\n",
    "\n",
    "        # constant = sm.add_constant(df[ivs_perc_])\n",
    "        # model = sm.OLS(df[dv], constant)\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]} + {ivs_perc_[0]}:{ivs_perc_[2]} + {ivs_perc_[0]}:{ivs_perc_[3]} + {ivs_perc_[1]}:{ivs_perc_[2]} + {ivs_perc_[1]}:{ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]}'\n",
    "        formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]} + {controls_for_formula}'\n",
    "\n",
    "        print('-'*20)\n",
    "        print(f'Using formula: {formula}')\n",
    "        print('-'*20)\n",
    "\n",
    "        model = smf.ols(formula=formula, data=df)\n",
    "        results = model.fit()\n",
    "\n",
    "        # Display Results\n",
    "        print('~'*20)\n",
    "        print('\\n')\n",
    "        print(f'SUMMARY RESULTS:\\n{results.summary()}\\n')\n",
    "        print('~'*20)\n",
    "        # print(f'SUMMARY RESULTS2:\\n{results.summary2()}')\n",
    "        # print('-'*20)\n",
    "        # print(f'y = {results.params.const:.2f} + {results.params.x:.2f} * x')\n",
    "        # print('-'*20)\n",
    "        # print(f'COEFFICIENT:\\n{results.params}')\n",
    "        # print('-'*20)\n",
    "        # print(f'CONFIDENCE INTERVALS:\\n{results.conf_int()}')\n",
    "        # print(f'P-VALUES:\\n{results.pvalues}')\n",
    "        # print('-'*20)\n",
    "        # print(f'ODDS RATIOS:\\n{np.exp(results.params)}')\n",
    "        # print(f'AIC:\\n{results.aic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # print(f'BIC:\\n{results.bic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # print(f'Coehn\\'s F2:\\n{results.rsquared_adj:.3f}')\n",
    "        print('-'*20)\n",
    "        table = sm.stats.anova_lm(results, typ=2)\n",
    "        print(f'ANOVA:\\n{table}')\n",
    "        print('-'*20)\n",
    "\n",
    "        # # Boxplot\n",
    "        # boxplot = df.boxplot([dv], by = [ivs_perc_[2], ivs_perc_[0]],\n",
    "        #                     figsize = (16, 9),\n",
    "        #                     showmeans = True,\n",
    "        #                     notch = True)\n",
    "\n",
    "        # boxplot.set_xlabel('Categories')\n",
    "        # boxplot.set_ylabel(dv)\n",
    "        # # Creating a path to save the plot.\n",
    "        # plt.ion()\n",
    "        # plt.show()\n",
    "        # plt.pause(.001)\n",
    "        # # for image_save_format in ['eps', 'png', 'svg']:\n",
    "        # #     save_path = f'{plot_save_path}Probability Boxplot - {df_name} - {dv} x Social Category Percentages.{image_save_format}'\n",
    "        # #     boxplot.figure.savefig(\n",
    "        # #         save_path, format=image_save_format,\n",
    "        # #     )\n",
    "        # plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-level OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in dataframes_.items():\n",
    "\n",
    "    if df_name == 'df_manual_':\n",
    "        dvs_ = dvs\n",
    "    elif df_name == 'df_jobs_':\n",
    "        dvs_ = dvs_all\n",
    "\n",
    "    df['Intercept'] = 1\n",
    "\n",
    "    print('\\n')\n",
    "    print('+'*120)\n",
    "    print(f'{\"=\"*50} RESULTS FOR {df_name} {\"=\"*50}')\n",
    "    for dv in tqdm.tqdm(dvs_):\n",
    "        print('+'*120)\n",
    "        print('\\n')\n",
    "        print(f'DEPENDENT VARIABLE: {dv}\\n\\nINDEPENDENT VARIABLE: {ivs_perc_}')\n",
    "        print('\\n')\n",
    "        print('+'*120)\n",
    "\n",
    "        save_name = f'Multilevel Logistic Regression {df_name} - {list(iter(ivs_dict))[0]} + {list(iter(ivs_dict))[1]} x {dv}'\n",
    "        # endog = df[dv]\n",
    "        # exog0 = df[['Intercept', f'{list(iter(ivs_dict))[0]}']]\n",
    "        # exog1 = df[['Intercept', f'{list(iter(ivs_dict))[1]}']]\n",
    "        # iv_1 = list(iter(ivs_dict))[0]\n",
    "        # iv_1_treatment = ivs_dict[iv_1][0]\n",
    "        # iv_2 = list(iter(ivs_dict))[1]\n",
    "        # iv_2_treatment = ivs_dict[iv_2][0]\n",
    "\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]} + {ivs_perc_[0]}:{ivs_perc_[2]} + {ivs_perc_[0]}:{ivs_perc_[3]} + {ivs_perc_[1]}:{ivs_perc_[2]} + {ivs_perc_[1]}:{ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]} + {controls_for_formula}'\n",
    "        # formula = f'{dv} ~ {ivs_perc_[0]}*{ivs_perc_[2]} + {ivs_perc_[0]}*{ivs_perc_[3]} + {ivs_perc_[1]}*{ivs_perc_[2]} + {ivs_perc_[1]}*{ivs_perc_[3]}'\n",
    "        formula = f'{dv} ~ {ivs_perc_[0]} + {ivs_perc_[1]} + {ivs_perc_[2]} + {ivs_perc_[3]}'\n",
    "\n",
    "        print('-'*20)\n",
    "        print(f'Using formula: {formula}')\n",
    "        print('-'*20)\n",
    "\n",
    "        vc_formula = {f'{controls_[1]}': f'0 + {controls_[1]}'}\n",
    "        re_formula = f'1 + {controls_[1]}'\n",
    "\n",
    "        model = smf.mixedlm(formula=formula, data=df, groups='Job_ID',) #vc_formula=vc_formula, re_formula=re_formula)\n",
    "        results = model.fit(method='lbfgs')\n",
    "        gradient = model.score(results.params_object)\n",
    "\n",
    "        # Display Results\n",
    "        print('~'*20)\n",
    "        print(f'Gradient:\\n{gradient}')\n",
    "        print('\\n')\n",
    "        print(f'SUMMARY RESULTS:\\n{results.summary()}\\n')\n",
    "        print('~'*20)\n",
    "        # print(f'SUMMARY RESULTS2:\\n{results.summary2()}')\n",
    "        # print('-'*20)\n",
    "        # print(f'y = {results.params.const:.2f} + {results.params.x:.2f} * x')\n",
    "        # print('-'*20)\n",
    "        # print(f'COEFFICIENT:\\n{results.params}')\n",
    "        # print('-'*20)\n",
    "        # print(f'CONFIDENCE INTERVALS:\\n{results.conf_int()}')\n",
    "        # print(f'P-VALUES:\\n{results.pvalues}')\n",
    "        # print('-'*20)\n",
    "        # print(f'ODDS RATIOS:\\n{np.exp(results.params)}')\n",
    "        # print(f'AIC:\\n{results.aic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # print(f'BIC:\\n{results.bic:.2f}')\n",
    "        # print('-'*20)\n",
    "        # print(f'Coehn\\'s F2:\\n{results.rsquared_adj:.3f}')\n",
    "        # print('-'*20)\n",
    "        # table = sm.stats.anova_lm(results, typ=2)\n",
    "        # print(f'ANOVA:\\n{table}')\n",
    "        # print('-'*20)\n",
    "\n",
    "        # df_results = pd.DataFrame(index=['Descriptives', 'Results'], columns=[f'{save_name}'])\n",
    "        # df_results[f'{save_name}']['Descriptives'] = results.summary().tables[0]\n",
    "        # df_results[f'{save_name}']['Results'] = results.summary().tables[1]\n",
    "\n",
    "        # df_results.to_csv(f'{table_save_path}{save_name.split(\" results\")[0].lower() + \" results\" + save_name.split(\" results\")[1]}.csv', header=True, index=True, index_label=['Index col: Descriptives and Results'])\n",
    "\n",
    "        # # Normality Tests (https://www.pythonfordatascience.org/mixed-effects-regression-python/)\n",
    "        # ## Residual and Kernal Density Estimate (KDE) Plot for Homoskedasticity\n",
    "        # fig = plt.figure(figsize = (16, 9))\n",
    "\n",
    "        # ax = sns.distplot(results.resid, hist = True, kde_kws = {\"shade\" : True, \"lw\": 1}, fit = scipy.stats.norm, kde=True, palette='colorblind')\n",
    "\n",
    "        # ax.set_title(f\"Kernal Density Estimate (KDE) Plot of Model Residuals (Blue) and Normal Distribution (Black)\\n{save_name}\")\n",
    "        # ax.set_xlabel(\"Residuals\")\n",
    "        # plt.ion()\n",
    "        # fig.show('notebook')\n",
    "        # plt.pause(.001)\n",
    "\n",
    "        # # Q-Q Plot\n",
    "        # fig = plt.figure(figsize = (16, 9))\n",
    "        # ax = fig.add_subplot(111)\n",
    "\n",
    "        # qq = sm.qqplot(results.resid, dist = scipy.stats.norm, line = 's', ax = ax, color='blue', markerfacecolor='blue')\n",
    "        # ax.set_title(f\"Q-Q Plot\\n{save_name}\",fontsize=15)\n",
    "        # ax.xaxis.get_label().set_fontsize(12)\n",
    "        # ax.yaxis.get_label().set_fontsize(12)\n",
    "        # ax.get_lines()[0].set_color('black')\n",
    "        # ax.get_lines()[0].set_linewidth('2')\n",
    "        # ax.get_lines()[1].set_color('black')\n",
    "        # ax.get_lines()[1].set_linewidth('2')\n",
    "        # plt.ion()\n",
    "        # fig.show('notebook')\n",
    "        # plt.pause(.001)\n",
    "\n",
    "        # # Test of Normality\n",
    "        # norm = scipy.stats.normaltest(results.resid)\n",
    "\n",
    "        # print('='*80)\n",
    "        # print(f'{dv} Test of Normality:')\n",
    "        # print('-'*80)\n",
    "        # for key, val in dict(zip(normality_tests_labels, norm)).items():\n",
    "        #     print(key,': ', val) # Significant\n",
    "        # print('\\n')\n",
    "\n",
    "        # # Skewness-Kurtosis Test of Normality\n",
    "        # norm_sk = scipy.stats.kurtosistest(results.resid)\n",
    "\n",
    "        # print('='*80)\n",
    "        # print(f'{dv} Skewness-Kurtosis Test of Normality:')\n",
    "        # print('-'*80)\n",
    "        # for key, val in dict(zip(normality_tests_labels, norm_sk)).items():\n",
    "        #     print(key,': ', val) # Significant\n",
    "        # print('\\n')\n",
    "\n",
    "        # # Shapir-Wilk Test of Normality\n",
    "        # norm_res = scipy.stats.shapiro(results.resid)\n",
    "\n",
    "        # print('='*80)\n",
    "        # print(f'{dv} Shapir-Wilk Test of Normality:')\n",
    "        # print('-'*80)\n",
    "        # for key, val in dict(zip(normality_tests_labels, norm_res)).items():\n",
    "        #     print(key,': ', val) # Significant\n",
    "        # print('\\n')\n",
    "\n",
    "        # # Anderson-Darling Test of Normality\n",
    "        # norm_and = scipy.stats.anderson(results.resid)\n",
    "\n",
    "        # print('='*80)\n",
    "        # print(f'{dv} Anderson-Darling Test of Normality:')\n",
    "        # print('-'*80)\n",
    "        # for key, val in dict(zip(normality_tests_labels, norm_and)).items():\n",
    "        #     print(key,': ', val) # Significant\n",
    "        # print('\\n')\n",
    "\n",
    "        # # Residuals versus Fitted values (RVF) Plot for Homoskedasticity\n",
    "        # fig = plt.figure(figsize = (16, 9))\n",
    "\n",
    "        # ax = sns.scatterplot(y = results.resid, x = results.fittedvalues, palette='colorblind')\n",
    "\n",
    "        # ax.set_title(f\"Residuals versus Fitted values (RVF) Plot\\n{save_name}\")\n",
    "        # ax.set_xlabel(\"Fitted Values\")\n",
    "        # ax.set_ylabel(\"Residuals\")\n",
    "        # plt.ion()\n",
    "        # fig.show('notebook')\n",
    "        # plt.pause(.001)\n",
    "\n",
    "        # # White’s Lagrange Multiplier Test for Heteroscedasticity\n",
    "        # het_white_res = het_white(results.resid, results.model.exog)\n",
    "\n",
    "        # het_white_labels = [\"LM Statistic\", \"LM-Test p-value\", \"F-Statistic\", \"F-Test p-value\"]\n",
    "\n",
    "        # print('='*80)\n",
    "        # print('White’s Lagrange Multiplier Test for Heteroscedasticity')\n",
    "        # print('-'*80)\n",
    "        # for key, val in dict(zip(het_white_labels, het_white_res)).items():\n",
    "        #     print(key, val)\n",
    "        # print('\\n')\n",
    "        # print('\\n')\n",
    "        # print('+'*120)\n",
    "        # print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
