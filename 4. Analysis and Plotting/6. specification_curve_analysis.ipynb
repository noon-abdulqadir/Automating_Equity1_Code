{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "if code_dir_name not in str(Path.cwd()).split('/')[-1]:\n",
    "    for _ in range(5):\n",
    "\n",
    "        parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "        if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "            code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "            if code_dir is not None:\n",
    "                break\n",
    "else:\n",
    "    code_dir = str(Path.cwd())\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_module.imports import *  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module import researchpy_fork as rp # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module import specification_curve_fork as specy # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}df_manual_len.txt', 'r') as f:\n",
    "    df_manual_len = int(f.read())\n",
    "\n",
    "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_training.pkl')\n",
    "assert len(df_manual) == df_manual_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_manual_len} BUT IS OF LENGTH {len(df_manual)}'\n",
    "print(f'Dataframe loaded with shape: {df_manual.shape}')\n",
    "df_manual = categorize_df_gender_age(df_manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'r') as f:\n",
    "    df_jobs_len = int(f.read())\n",
    "\n",
    "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
    "assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_jobs)}'\n",
    "print(f'Dataframe loaded with shape: {df_jobs.shape}')\n",
    "df_jobs = categorize_df_gender_age(df_jobs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis plan:\n",
    "\n",
    "1. ## [Descriptives and tables](./1.%20descriptives_and_tables.ipynb)\n",
    "2. ## [Visualization](./2.%20visualization.ipynb)\n",
    "3. ## [Frequencies and Normality tests](./2.%20frequencies_and_normality_test.ipynb)\n",
    "   1. ### Frequencies, histograms, and QQ plots\n",
    "      * Normal test\n",
    "      * Kurtosis test\n",
    "      * Shapiro\n",
    "      * Anderson\n",
    "      * Bartlett\n",
    "   2. ### Correlation between independent variables (IVs) and control variables and Multicolinarity test\n",
    "      * Pearson's R\n",
    "      * VIF\n",
    "     - ***ivs_dummy*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "     - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "     - ***% Sector per Workforce*** (continous ratio) = Sector percentage per worksforce (0-100)\n",
    "     - ***num_words*** (continous ratio) = Number of words in job description\n",
    "     - ***English Requirement in Job Ad*** (binary nominal) = English requirement in job description (0 vs. 1)\n",
    "     - ***Dutch Requirement in Job Ad*** (binary nominal) = Dutch requirement in job description (0 vs. 1)\n",
    "     - ***Platform*** (binary dummy) = LinkedIn (0 vs. 1), Indeed (0 vs. 1), Glassdoor (0 vs. 1)\n",
    "\n",
    "4. ## [ANOVA and Chi-square (Pearson's R)](./3.%20chisqt_and_anova.ipynb)\n",
    "\n",
    "   1. ### Chi-square\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "\n",
    "   2. ### One-way ANOVA, interactions, and post-hoc test\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "          - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "          - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "      * **df_jobs:**\n",
    "         - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "         - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)\n",
    "           - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test\n",
    "           - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test\n",
    "\n",
    "5. ## [Regression Analysis](./3.%20regression_analysis.ipynb)\n",
    "   1. ### Logistic Regression  with all interaction (smf):\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   3. ### Multilevel OLS Regression with all interaction:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "\n",
    "6. ## [Specification Curve Analysis](./4.%20specification_curve_analysis.ipynb)\n",
    "\n",
    "   1. ### Logistic Specification Curve Analysis:\n",
    "      * **df_manual:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "      * **df_jobs:**\n",
    "        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n",
    "   2. ### OLS Specification Curve Analysis:\n",
    "      * **df_jobs:**\n",
    "        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)\n",
    "        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes dict\n",
    "dataframes = {\n",
    "    'df_jobs': df_jobs,\n",
    "    'df_manual': df_manual,\n",
    "}\n",
    "\n",
    "# Models dict\n",
    "sm_models = {\n",
    "    'OLS': sm.OLS,\n",
    "    'Logistic': sm.Logit,\n",
    "}\n",
    "\n",
    "# DVs dict for analysis\n",
    "dvs_for_analysis = {\n",
    "    'probability': ['Probability Warmth and Competence', dvs_prob],\n",
    "    'binary': ['Categorical Warmth and Competence', dvs],\n",
    "    'binary and probability': ['Categorical and Probability Warmth and Competence', dvs_all],\n",
    "}\n",
    "\n",
    "# Make extra IV dicts\n",
    "ivs_dummy_for_analysis = [iv for iv in ivs_dummy if 'Mixed' not in iv]\n",
    "ivs_dummy_and_perc_for_analysis = [iv for iv in ivs_dummy_and_perc if 'Mixed' not in iv]\n",
    "ivs_dummy_perc_and_perc_interactions_for_analysis = [iv for iv in ivs_dummy_perc_and_perc_interactions if 'Mixed' not in iv]\n",
    "\n",
    "# IVs dict for analysis\n",
    "ivs_for_analysis = {\n",
    "    'categories, percentages, and interactions': [\n",
    "        'Categorical, PPS, and PPS Interactions Gender and Age',\n",
    "        ivs_dummy_perc_and_perc_interactions_for_analysis\n",
    "    ],\n",
    "    'categories and percentages': [\n",
    "        'Categorical and PPS Gender and Age',\n",
    "        ivs_dummy_and_perc_for_analysis\n",
    "    ],\n",
    "    'percentages and interactions': [\n",
    "        'PPS and PPS Interactions',\n",
    "        ivs_perc_and_perc_interactions\n",
    "    ],\n",
    "    'categories': [\n",
    "        'Categorical Gender and Age',\n",
    "        ivs_dummy_for_analysis\n",
    "    ],\n",
    "    'percentages': [\n",
    "        'PPS Gender and Age',\n",
    "        ivs_perc\n",
    "    ],\n",
    "    'interactions': [\n",
    "        'PPS Interactions',\n",
    "        ivs_perc_interactions\n",
    "    ],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df_full_summary_excel(\n",
    "    df_full_summary,\n",
    "    title,\n",
    "    text_to_add_list,\n",
    "    file_save_path,\n",
    "    sheet_name=None,\n",
    "    startrow=None,\n",
    "    startcol=None,\n",
    "):\n",
    "    if sheet_name is None:\n",
    "        sheet_name = 'All'\n",
    "    if startrow is None:\n",
    "        startrow = 1\n",
    "    if startcol is None:\n",
    "        startcol = 1\n",
    "\n",
    "    # Define last rows and cols locs\n",
    "    header_range = 1\n",
    "    endrow = startrow + header_range + df_full_summary.shape[0]\n",
    "    endcol = startcol + df_full_summary.shape[1]\n",
    "\n",
    "    # Remove NAs\n",
    "    df_full_summary = df_full_summary.fillna('')\n",
    "\n",
    "    # Write\n",
    "    writer = pd.ExcelWriter(f'{file_save_path}.xlsx')\n",
    "    df_full_summary.to_excel(writer, sheet_name=sheet_name, merge_cells=True, startrow=startrow, startcol=startcol)\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    worksheet.set_column(startrow, 1, None, None, {'hidden': True}) # hide the index column\n",
    "\n",
    "    # Title\n",
    "    worksheet.merge_range(1, startcol, 1, endcol, title, workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'left', 'top': True, 'bottom': True, 'left': False, 'right': False}))\n",
    "\n",
    "    # Main body\n",
    "    body_max_row_idx, body_max_col_idx = df_full_summary.shape\n",
    "\n",
    "    for c, r in tqdm_product(range(body_max_col_idx), range(body_max_row_idx)):\n",
    "        row_to_write = startrow + header_range + r\n",
    "        col_to_write = startcol + 1 + c # 1 is for index\n",
    "        body_formats = {'num_format': '0.00', 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'text_wrap': True, 'left': False, 'right': False}\n",
    "\n",
    "        if r == 0:\n",
    "            body_formats |= {'top': True, 'bottom': True, 'left': False, 'right': False}\n",
    "            worksheet.set_column(col_to_write, col_to_write, 10)\n",
    "\n",
    "        if r == body_max_row_idx-1:\n",
    "            body_formats |= {'bottom': True}\n",
    "\n",
    "        if c == 0:\n",
    "            body_formats |= {'align': 'left'}\n",
    "            worksheet.set_column(col_to_write, col_to_write, 15)\n",
    "\n",
    "        worksheet.write(row_to_write, col_to_write, df_full_summary.iloc[r, c], workbook.add_format(body_formats))\n",
    "\n",
    "    # Add Note\n",
    "    note_format = {'italic': True, 'font_name': 'Times New Roman', 'font_size': 10, 'font_color': 'black', 'align': 'left', 'left': False, 'right': False}\n",
    "    worksheet.merge_range(endrow, startcol, endrow, endcol, 'Note.', workbook.add_format(note_format))\n",
    "    # Add text\n",
    "    for i, text in enumerate(text_to_add_list):\n",
    "        worksheet.merge_range(endrow + 1 + i , startcol, endrow + 1 + i, endcol, text, workbook.add_format(note_format))\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_full_report(\n",
    "    results, dv, analysis_type, model_name, dvs_name, ivs_name, ivs_type, df_name,\n",
    "    regression_info_dict=None, regressor_order=None, text_to_add_list=None, title=None, model_names=None\n",
    "):\n",
    "    '''\n",
    "    Make a full report for a regression analysis.\n",
    "    results: statsmodels regression results object or list of results objects\n",
    "    dv: str, dependent variable name\n",
    "    '''\n",
    "\n",
    "    if regression_info_dict is None:\n",
    "        # Regression info dict\n",
    "        regression_info_dict = {\n",
    "            'Model Name': lambda x: f'{x.model.__class__.__name__}',\n",
    "            'N': lambda x: f'{int(x.nobs):d}',\n",
    "            'R-squared': lambda x: f'{x.rsquared:.5f}',\n",
    "            'R-squared Adj.': lambda x: f'{x.rsquared_adj:.5f}',\n",
    "            'Log-Likelihood': lambda x: f'{x.llf:.5f}',\n",
    "            'Pseudo R2': lambda x: f'{x.prsquared:.5f}',\n",
    "            'F': lambda x: f'{x.fvalue:.5f}',\n",
    "            'F (p-value)': lambda x: f'{x.f_pvalue:.5f}',\n",
    "            'df_model': lambda x: f'{x.df_model:.0f}',\n",
    "            'df_total': lambda x: f'{x.df_resid + x.df_model + 1:.0f}',\n",
    "            'df_resid': lambda x: f'{x.df_resid:.0f}',\n",
    "            'AIC': lambda x: f'{x.aic:.5f}',\n",
    "            'BIC': lambda x: f'{x.bic:.5f}',\n",
    "            'ICC': lambda x: f'{x.rsquared / (x.rsquared + (x.nobs - 1) * x.mse_resid):.5f}',\n",
    "            'RMSE': lambda x: f'{x.mse_resid ** 0.5:.5f}',\n",
    "            'RMSE (std)': lambda x: f'{x.mse_resid ** 0.5 / x.model.endog.std():.5f}',\n",
    "            'Omnibus': lambda x: f'{sms.omni_normtest(x.resid).statistic:.5f}',\n",
    "            'Omnibus (p-value)': lambda x: f'{sms.omni_normtest(x.resid).pvalue:.5f}',\n",
    "            'Skew': lambda x: f'{sms.jarque_bera(x.resid)[-2]:.5f}',\n",
    "            'Kurtosis': lambda x: f'{sms.jarque_bera(x.resid)[-1]:.5f}',\n",
    "            'Jarque-Bera (JB)': lambda x: f'{sms.jarque_bera(x.resid)[0]:.5f}',\n",
    "            'Jarque-Bera (p-value)': lambda x: f'{sms.jarque_bera(x.resid)[1]:.5f}',\n",
    "            'Intercept': lambda x: f'{x.params[\"const\"]:.5f}',\n",
    "            'Intercept (std)': lambda x: f'{x.bse[\"const\"]:.5f}',\n",
    "            'Intercept t': lambda x: f'{x.tvalues[\"const\"]:.5f}',\n",
    "            'Intercept t (p-value)': lambda x: f'{x.pvalues[\"const\"]:.5f}',\n",
    "            'Intercept (95% CI)': lambda x: f'{x.conf_int().loc[\"const\"][0]:.5f} - {x.conf_int().loc[\"const\"][1]:.5f}',\n",
    "            'Unstandardized Coefficent B (b)': lambda x: f'{x.params[0]:.5f}',\n",
    "            'Standard Error (SE)': lambda x: f'{x.bse[0]:.5f}',\n",
    "            'Standardized Coefficient b* (β)': lambda x: f'{x.params[0] / x.model.endog.std():.5f}',\n",
    "            't': lambda x: f'{x.tvalues[0]:.5f}',\n",
    "            't (p-value)': lambda x: f'{x.pvalues[0]:.5f}',\n",
    "            '95% CI': lambda x: f'{x.conf_int().iloc[0, 1]:.5f} - {x.conf_int().iloc[0, 1]:.5f}',\n",
    "            # 'Summary': lambda x: f'{x.summary()}',\n",
    "            # 'F (p-value - FDR)': lambda x: f'{x.f_pvalue_fdr:.5f}',\n",
    "            # 'F (p-value - Bonferroni)': lambda x: f'{x.f_pvalue_bonf:.5f}',\n",
    "            # 't (p-value - FDR)': lambda x: f'{x.pvalues_fdr[1]:.5f}',\n",
    "            # 't (p-value - Bonferroni)': lambda x: f'{x.pvalues_bonf[1]:.5f}',\n",
    "        }\n",
    "    if model_names is None:\n",
    "        if isinstance(results, list):\n",
    "            model_names = [\n",
    "                f'{results[0].model.endog_names.split(\"_\")[0] if \"_\" in results[0].model.endog_names else results[0].model.endog_names} Model {i}'\n",
    "                for i in range(len(results))\n",
    "            ]\n",
    "            model_names[0] = model_names[0].replace('Model 0', 'Full Model')\n",
    "        else:\n",
    "            model_names = [\n",
    "                f'{results.model.endog_names.split(\"_\")[0] if \"_\" in results.model.endog_names else results.model.endog_names}'\n",
    "            ]\n",
    "\n",
    "    order_type = 'unordered' if regressor_order is None else 'ordered'\n",
    "    if text_to_add_list is None:\n",
    "        text_to_add_list = []\n",
    "        if regressor_order is not None:\n",
    "            text_to_add_list.append('Models are ordered by independent variable type.')\n",
    "\n",
    "        else:\n",
    "            text_to_add_list.append('Models are ordered by coefficient size, largest to smallest.')\n",
    "\n",
    "    if title is None:\n",
    "        title = f'{model_name} {analysis_type}: {dvs_name} x {ivs_name}'\n",
    "\n",
    "    try:\n",
    "        # Statsmodels summary_col\n",
    "        full_summary = summary_col(\n",
    "            results,\n",
    "            stars=True,\n",
    "            info_dict=regression_info_dict,\n",
    "            regressor_order=regressor_order,\n",
    "            float_format='%0.3f',\n",
    "            model_names=model_names,\n",
    "        )\n",
    "        if isinstance(results, list) and len(results) > 4:\n",
    "            full_summary.tables[0][full_summary.tables[0].filter(regex='Full Model').columns[0]].loc['Unstandardized Coefficent B (b)': '95% CI'] = ''\n",
    "\n",
    "        # Add title and notes\n",
    "        full_summary.add_title(title)\n",
    "        text_to_add_list.extend(full_summary.extra_txt)\n",
    "        for text in text_to_add_list:\n",
    "            full_summary.add_text(text)\n",
    "        # Save\n",
    "        save_name = f'{table_save_path}{model_name} {df_name} - ALL {dv} {order_type} {analysis_type} on {ivs_type}'\n",
    "        df_full_summary = pd.read_html(full_summary.as_html())[0]\n",
    "        df_full_summary.to_csv(f'{save_name}.csv')\n",
    "        df_full_summary.style.to_latex(f'{save_name}.tex', hrules=True)\n",
    "        save_df_full_summary_excel(df_full_summary, title, text_to_add_list, save_name)\n",
    "\n",
    "        return full_summary\n",
    "    except IndexError as e:\n",
    "        print(f'Making full report for {model_names[0]} due to the following error: {e}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_masks(df_results, mask_gender_ivs=None, mask_age_ivs=None, mask_ivs=None, mask_dvs=None, masks_dict=None):\n",
    "\n",
    "    if mask_gender_ivs is None:\n",
    "        mask_gender_ivs = ['Female', 'Male', 'Gender_Mixed']\n",
    "    if mask_age_ivs is None:\n",
    "        mask_age_ivs = ['Older', 'Younger', 'Age_Mixed']\n",
    "    if mask_ivs is None:\n",
    "        mask_ivs = mask_gender_ivs + mask_age_ivs\n",
    "    if mask_dvs is None:\n",
    "        mask_dvs = dvs\n",
    "    if masks_dict is None:\n",
    "        masks_dict = {}\n",
    "\n",
    "    # Warmth and Competence masks\n",
    "    for mask_dv in mask_dvs:\n",
    "        masks_dict[f'{mask_dv.lower()}_mask'] = df_results['Specification'].apply(\n",
    "            lambda x: any(mask_dv in item for item in x if item in x)\n",
    "            # HACK\n",
    "            # & any('Interaction' not in item for item in x if item in x)\n",
    "        )\n",
    "\n",
    "    # Gender and Age masks\n",
    "    for mask_iv in mask_ivs:\n",
    "        masks_dict[f'{mask_iv.lower()}_mask'] = df_results['Specification'].apply(\n",
    "            lambda x: any(mask_iv in item for item in x if item in x)\n",
    "            # HACK\n",
    "            # & any('Interaction' not in item for item in x if item in x)\n",
    "        )\n",
    "\n",
    "    # IV and DV masks\n",
    "    for mask_iv, mask_dv in tqdm_product(mask_ivs, mask_dvs):\n",
    "        masks_dict[f'{mask_iv.lower()}_{mask_dv.lower()}_mask'] = df_results['Specification'].apply(\n",
    "            lambda x: any(mask_iv in item for item in x if item in x)\n",
    "            & any(mask_dv in item for item in x if item in x)\n",
    "            # HACK\n",
    "            # & any('Interaction' not in item for item in x if item in x)\n",
    "        )\n",
    "\n",
    "    # All Gender masks\n",
    "    masks_dict['gender_mask'] = pd.Series([False] * len(df_results))\n",
    "    for mask_gender_iv in mask_gender_ivs:\n",
    "        masks_dict['gender_mask'] |= masks_dict[f'{mask_gender_iv.lower()}_mask']\n",
    "\n",
    "    for mask_dv in mask_dvs:\n",
    "        masks_dict[f'gender_{mask_dv.lower()}_mask'] = pd.Series([False] * len(df_results))\n",
    "        for mask_gender_iv in mask_gender_ivs:\n",
    "            masks_dict[f'gender_{mask_dv.lower()}_mask'] |= masks_dict[f'{mask_gender_iv.lower()}_{mask_dv.lower()}_mask']\n",
    "\n",
    "    # All Age masks\n",
    "    masks_dict['age_mask'] = pd.Series([False] * len(df_results))\n",
    "    for mask_age_iv in mask_age_ivs:\n",
    "        masks_dict['age_mask'] |= masks_dict[f'{mask_age_iv.lower()}_mask']\n",
    "\n",
    "    for mask_dv in mask_dvs:\n",
    "        masks_dict[f'age_{mask_dv.lower()}_mask'] = pd.Series([False] * len(df_results))\n",
    "        for mask_age_iv in mask_age_ivs:\n",
    "            masks_dict[f'age_{mask_dv.lower()}_mask'] |= masks_dict[f'{mask_age_iv.lower()}_{mask_dv.lower()}_mask']\n",
    "\n",
    "    # Interaction masks\n",
    "    masks_dict['interactions_mask'] = df_results['Specification'].apply(\n",
    "        lambda x: any('Interaction' in item for item in x)\n",
    "    )\n",
    "    for mask_dv in mask_dvs:\n",
    "        masks_dict[f'interactions_{mask_dv.lower()}_mask'] = df_results['Specification'].apply(\n",
    "            lambda x: any('Interaction' in item for item in x)\n",
    "            & any(mask_dv in item for item in x)\n",
    "        )\n",
    "\n",
    "    return masks_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sc_stats(\n",
    "    df_results,\n",
    "    dvs_,\n",
    "    masks_dict,\n",
    "    text_to_add_list=None,\n",
    "    sc_stats_dict=None,\n",
    "):\n",
    "    if text_to_add_list is None:\n",
    "        text_to_add_list = []\n",
    "    if sc_stats_dict is None:\n",
    "        sc_stats_dict = {}\n",
    "        # Stouffer’s Z-score and p-value for each mask\n",
    "        for mask_name, mask in masks_dict.items():\n",
    "            if not all(df_results[mask]['coeff_pvals'] == False):\n",
    "                # Share of significant effects\n",
    "                significant_count = (df_results[mask]['coeff_pvals'] < alpha).sum()\n",
    "                total_count = len(df_results[mask])\n",
    "                share_significant = significant_count / total_count\n",
    "                null_share = 1 / total_count\n",
    "                share_significant_pval = scipy.stats.binom_test(significant_count, n=total_count, p=null_share, alternative='greater')\n",
    "                share_fraction = f'{significant_count}/{len(df_results[mask])}'\n",
    "                # Stoutffer\n",
    "                pvalues = df_results[mask]['coeff_pvals'].tolist()\n",
    "                stouffer_z , stouffer_pval = scipy.stats.combine_pvalues(pvalues=pvalues, method='stouffer')\n",
    "\n",
    "                sc_stats_dict[mask_name] = {\n",
    "                    'share_significant': share_significant,\n",
    "                    'share_significant_pval': share_significant_pval,\n",
    "                    'stouffer_z': stouffer_z,\n",
    "                    'stouffer_pval': stouffer_pval,\n",
    "                }\n",
    "\n",
    "                text_to_add_list.extend(\n",
    "                    f'{\"-\" * 10}\\n{dv.split(\"_Probability\")[0]}:\\nSign. share: {share_fraction}\\np-value = {share_significant_pval:.2f}\\nStouffer Z: {stouffer_z:.2f}\\np-value = {stouffer_pval:.2f}'\n",
    "                    for dv in dvs_\n",
    "                    if mask_name.split('_mask')[0]\n",
    "                    == f'{dv.split(\"_Probability\")[0].lower()}'\n",
    "                )\n",
    "\n",
    "                print(f'{\"=\"*5} SCA {mask_name.split(\"_mask\")[0].upper()} {\"=\"*5}')\n",
    "                print(f'Length of {mask_name.split(\"_mask\")[0]}: {len(df_results[mask])}')\n",
    "                print(f'Number of significant p-values for {mask_name.split(\"_mask\")[0]}: {significant_count}')\n",
    "                print(f'Share of significant effects for {mask_name.split(\"_mask\")[0]}: {share_significant:.2f} - {significant_count}/{len(df_results[mask])}')\n",
    "                print(f'Share of significant effects p-value: {share_significant_pval:.2f}')\n",
    "                print(f'Stoutffer Z: {stouffer_z:.2f}')\n",
    "                print(f'Stoutffer p-value: {stouffer_pval:.2f}')\n",
    "                print('-'*20)\n",
    "                print('\\n')\n",
    "            else:\n",
    "                sc_stats_dict[mask_name] = {\n",
    "                    'share_significant': 0,\n",
    "                    'share_significant_pval': 1,\n",
    "                    'stouffer_z': 0,\n",
    "                    'stouffer_pval': 1,\n",
    "                }\n",
    "\n",
    "    return sc_stats_dict, text_to_add_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standardized_coefficients(results):\n",
    "\n",
    "    # # Get standardized regression coefficients\n",
    "    # std = np.asarray(constant.std(0))\n",
    "\n",
    "    # if 'const' in results.params and 'const' in constant:\n",
    "    #     std[0] = 1\n",
    "    # tt = results.t_test(np.diag(std))\n",
    "    # tt.c_names = results.model.exog_names\n",
    "\n",
    "    # t-test\n",
    "    std = results.model.exog.std(0)\n",
    "    if 'const' in results.params:\n",
    "        std[0] = 1\n",
    "    tt = results.t_test(np.diag(std))\n",
    "    if results.model.__class__.__name__ == 'MixedLM' or 'Group Var' in results.model.exog_names:\n",
    "        offset = slice(None, -1)\n",
    "        tt.c_names = results.model.exog_names[offset]\n",
    "    else:\n",
    "        offset = slice(None, None)\n",
    "        tt.c_names = results.model.exog_names\n",
    "\n",
    "    # Make df with standardized and unstandardized coefficients\n",
    "    df_std_coef = pd.DataFrame(\n",
    "        {\n",
    "            'coef': results.params[offset].apply(lambda x: f'{x:.4f}'),\n",
    "            'std err': results.bse[offset].apply(lambda x: f'{x:.4f}'),\n",
    "            'std coef': (results.params[offset] / results.model.exog[offset].std(axis=0)).apply(lambda x: f'{x:.4f}'),\n",
    "            't': results.tvalues[offset].apply(lambda x: f'{x:.4f}'),\n",
    "            'P>|t|': results.pvalues[offset].apply(lambda x: f'{x:.4f}'),\n",
    "            '[0.025': results.conf_int()[0][offset].apply(lambda x: f'{x:.4f}'),\n",
    "            '0.975]': results.conf_int()[1][offset].apply(lambda x: f'{x:.4f}'),\n",
    "        }\n",
    "    )\n",
    "    # if 'Group Var' in df_std_coef.index:\n",
    "    #     df_std_coef = df_std_coef.drop('Group Var', axis='index')\n",
    "    # # Add standardized coefficients and other data from t-test\n",
    "    # df_std_coef['std coef'] = tt.effect\n",
    "    # df_std_coef['std err'] = tt.sd\n",
    "    # df_std_coef['t'] = tt.statistic\n",
    "    # df_std_coef['P>|t|'] = tt.pvalue\n",
    "    # df_std_coef['[0.025'] = tt.conf_int()[:, 0]\n",
    "    # df_std_coef['0.975]'] = tt.conf_int()[:, 1]\n",
    "    # df_std_coef['var'] = [names[i] for i in range(len(results.model.exog_names))]\n",
    "    # df_std_coef = df_std_coef.sort_values('std coef', ascending=False)\n",
    "    df_std_coef = df_std_coef.reset_index().rename(columns={'index': 'var'})\n",
    "    df_std_coef = df_std_coef.rename(\n",
    "        columns={\n",
    "            'var': 'Variable',\n",
    "            'coef': 'Unstandardized Coefficent B (b)',\n",
    "            'std err': 'Standard Error',\n",
    "            'std coef':'Standardized Coefficient b* (β)',\n",
    "            't': 't-value',\n",
    "            'P>|t|': 'p-value',\n",
    "            '[0.025': '95% CI Lower',\n",
    "            '0.975]': '95% CI Upper'\n",
    "        }\n",
    "    )\n",
    "    # Reorder columns\n",
    "    df_std_coef = df_std_coef[[\n",
    "        'Variable',\n",
    "        'Unstandardized Coefficent B (b)',\n",
    "        'Standard Error',\n",
    "        'Standardized Coefficient b* (β)',\n",
    "        't-value',\n",
    "        'p-value',\n",
    "        '95% CI Lower',\n",
    "        '95% CI Upper'\n",
    "    ]]\n",
    "\n",
    "    return tt, df_std_coef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_predictors(df_results, top_n=None, dv_name=None, alpha=None, asc=None, enable_return=False):\n",
    "    if top_n is None:\n",
    "        top_n = 10\n",
    "    if alpha is None:\n",
    "        alpha = 0.05\n",
    "    if asc is None:\n",
    "        asc = False\n",
    "\n",
    "    condition = (df_results['coeff_pvals'] < alpha) & (df_results['x_exog'] != 'const')\n",
    "    if dv_name is not None:\n",
    "        condition = pd.concat([condition, (df_results['y_endog'] == dv_name)])\n",
    "\n",
    "    df_top_coeff_p = df_results.loc[condition].sort_values(by=['Coefficient'], ascending=asc)\n",
    "    print('\\n')\n",
    "    print('+'*20)\n",
    "    print('\\n')\n",
    "    print('-'*20)\n",
    "    print(f\"{top_n} {'Highest' if asc==False else 'Lowest'} significant coefficients:\\n{df_top_coeff_p[['x_exog', 'y_endog', 'coeff_pvals', 'Coefficient', 'conf_int', 'pvalues']].head(top_n)}\")\n",
    "    print('-'*20)\n",
    "    print('\\n')\n",
    "    print('+'*20)\n",
    "    print('\\n')\n",
    "\n",
    "    if enable_return:\n",
    "        return df_top_coeff_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dfs(row, save_name, df_to_save, df_std_coef):\n",
    "    row['Results'].save(f'{save_name}.pkl')\n",
    "    df_to_save.to_csv(f'{save_name}.csv')\n",
    "    df_to_save.style.to_latex(f'{save_name}.tex', hrules=True)\n",
    "    df_std_coef.to_csv(f'{save_name} - standardized coefficients.csv')\n",
    "    df_std_coef.style.to_latex(f'{save_name} - standardized coefficients.tex', hrules=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specification Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sc(df_name, df, model_name, model, dvs_type, dvs_name, dvs_, ivs_type, ivs_name, ivs_):\n",
    "\n",
    "    # Set DVs for df_manual\n",
    "    if df_name == 'df_manual':\n",
    "        dvs_ = dvs\n",
    "\n",
    "    # Run specification curve analysis\n",
    "    print('\\n')\n",
    "    print(f'{df_name} Running specification curve analysis with:\\nDEPENDENT VARIABLES = {dvs_}\\nINDEPENDENT VARIABLES = {ivs_}\\nCONTROLS = {controls}')\n",
    "    print(f'{\"=\"*5} {df_name} {model_name.upper()} SPECIFICATION MODE RESULTS FOR {df_name} USING {dvs_type.upper()} x {ivs_type.upper()} {\"=\"*5}')\n",
    "    print('\\n')\n",
    "\n",
    "    # Add constant\n",
    "    df = sm.add_constant(df)\n",
    "    constant = ivs_[:] + ['const']\n",
    "\n",
    "    try:\n",
    "        plot_title = f'{model_name}: {dvs_name} x {ivs_name}'\n",
    "        sc = specy.SpecificationCurve(df=df, y_endog=dvs_, x_exog=constant, controls=controls[:2], always_include=['const'])\n",
    "        sc.fit(estimator=model)\n",
    "        df_results = sc.df_r\n",
    "\n",
    "        # Compare models with controls\n",
    "        controls_mask = df_results['Specification'].apply(lambda x: all(control in x for control in controls[:2]))\n",
    "        df_results_controls = df_results.loc[controls_mask]\n",
    "\n",
    "        # Warmth\n",
    "        for dv in dvs_[:len(dvs_)//2]:\n",
    "            warmth_results_list = [sm.OLS(endog=df[dv], exog=df[constant + controls[:2]]).fit()] + df_results_controls['Results'].loc[df_results_controls['y_endog'] == dv].tolist()\n",
    "            warmth_full_summary = make_full_report(\n",
    "                warmth_results_list, dv,\n",
    "                dvs_name=dvs_name, ivs_name=ivs_name, ivs_type=ivs_type, df_name=df_name,\n",
    "                model_name=model_name, analysis_type='specification curve'\n",
    "            )\n",
    "            ordered_warmth_full_summary = make_full_report(\n",
    "                warmth_results_list, dv,\n",
    "                dvs_name=dvs_name, ivs_name=ivs_name, ivs_type=ivs_type, df_name=df_name,\n",
    "                model_name=model_name, analysis_type='specification curve', regressor_order=ivs_[:] + controls[:2]\n",
    "            )\n",
    "            print('\\n')\n",
    "            print('-'*20)\n",
    "            print(f'{dv}\\n')\n",
    "            print('-'*20)\n",
    "            print('\\n')\n",
    "            print(f'Warmth SUMMARY RESULTS:\\n{warmth_full_summary}')\n",
    "            print('\\n')\n",
    "\n",
    "        # Competence\n",
    "        for dv in dvs_[len(dvs_)//2:]:\n",
    "            competence_results_list = [sm.OLS(endog=df[dv], exog=df[constant + controls[:2]]).fit()] + df_results_controls['Results'].loc[df_results_controls['y_endog'] == dv].tolist()\n",
    "            competence_full_summary = make_full_report(\n",
    "                competence_results_list, dv,\n",
    "                dvs_name=dvs_name, ivs_name=ivs_name, ivs_type=ivs_type, df_name=df_name,\n",
    "                model_name=model_name, analysis_type='specification curve'\n",
    "            )\n",
    "            ordered_competence_full_summary = make_full_report(\n",
    "                competence_results_list, dv,\n",
    "                dvs_name=dvs_name, ivs_name=ivs_name, ivs_type=ivs_type, df_name=df_name,\n",
    "                model_name=model_name, analysis_type='specification curve', regressor_order=ivs_[:] + controls[:2]\n",
    "            )\n",
    "            print('\\n')\n",
    "            print('-'*20)\n",
    "            print(f'{dv}\\n')\n",
    "            print('-'*20)\n",
    "            print('\\n')\n",
    "            print(f'Competence SUMMARY RESULTS:\\n{competence_full_summary}')\n",
    "            print('\\n')\n",
    "\n",
    "        # Get Specification Curve Analysis stats\n",
    "        masks_dict = make_masks(df_results)\n",
    "        sc_stats_dict, text_to_add_list = get_sc_stats(df_results, dvs_, masks_dict)\n",
    "\n",
    "        # Get gender and age masks with controls for final regression reporting\n",
    "        df_results_gender = df_results_controls.loc[masks_dict['gender_mask']]\n",
    "        df_results_gender = df_results_gender.reset_index(drop=True)\n",
    "        df_results_age = df_results_controls.loc[masks_dict['age_mask']]\n",
    "        df_results_age = df_results_age.reset_index(drop=True)\n",
    "\n",
    "        # Iterate over results and print summary\n",
    "        df_std_coef_dict = {}\n",
    "        for df_masked in [df_results_gender, df_results_age]:\n",
    "            for idx, row in df_masked.iterrows():\n",
    "                iv_name = row['x_exog']\n",
    "                dv_name = row['y_endog']\n",
    "                print('\\n')\n",
    "                print('+'*20)\n",
    "                print(f'{dv_name} x {iv_name}\\n')\n",
    "                print('+'*20)\n",
    "                print(f'{row[\"Results\"].summary(title=plot_title)}')\n",
    "                tt, df_std_coef = get_standardized_coefficients(row['Results'])\n",
    "                df_std_coef_dict[f'{iv_name} x {dv_name}'] = df_std_coef\n",
    "                print(f'STANDARDIZED BETA REGRESSION COEFFICIENTS FOR {iv_name} x {dv_name}:\\n{df_std_coef}')\n",
    "                print('-'*20)\n",
    "                print('~'*20)\n",
    "\n",
    "                # Save results to file\n",
    "                save_name = f'{table_save_path}{model_name} specification curve on {ivs_type} {df_name} - {dv_name} x {iv_name} ({dvs_type} Warmth and Competence x {ivs_type} Gender and Age)'\n",
    "                df_to_save = pd.DataFrame(csv.reader(row['Results'].summary(title=plot_title).as_csv().split('\\n'), delimiter=','))\n",
    "                try:\n",
    "                    save_dfs(row, save_name, df_to_save, df_std_coef)\n",
    "                except OSError:\n",
    "                    save_name = f'{table_save_path}{model_name} specification curve on {ivs_type} {df_name} - {dv_name} x {iv_name} ({dvs_type} WarmComp x {ivs_type} GenAge)'\n",
    "                    save_dfs(row, save_name, df_to_save, df_std_coef)\n",
    "\n",
    "        # Get top predictors\n",
    "        df_top_coeff_p = get_significant_predictors(df_results, top_n=10, enable_return=True)\n",
    "\n",
    "        # Get bottom predictors\n",
    "        get_significant_predictors(df_results, top_n=10, asc=True)\n",
    "\n",
    "        # Plot and save\n",
    "        print('\\n')\n",
    "        print('~'*80)\n",
    "        print(f'\\n{\"=\"*5} {df_name} RESULTS FOR {plot_title} {\"=\"*5}\\n')\n",
    "        print('~'*80)\n",
    "        print('\\n')\n",
    "\n",
    "        for image_save_format in tqdm.tqdm(['eps', 'png', 'svg']):\n",
    "            # Use following if not using forked specification_curve\n",
    "            # sc.plot(preferred_spec=[iv, dv], save_path=save_path,)\n",
    "            save_path = f'{plot_save_path}{df_name} - {model_name} Specification Curve - {dvs_type} Warmth and Competence x {ivs_type} Gender and Age.{image_save_format}'\n",
    "            sc_fig = sc.plot(\n",
    "                save_path=save_path,\n",
    "                show_plot=False,\n",
    "                return_fig=True,\n",
    "                plot_title=plot_title,\n",
    "                text_to_add=text_to_add_list,\n",
    "            )\n",
    "\n",
    "    except(np.linalg.LinAlgError):\n",
    "        print(f'Singular matrix when using {model_name} with {dvs_type} x {ivs_type}')\n",
    "        df_results = None\n",
    "\n",
    "    print(f'{\"=\"*5} END OF {df_name} RESULTS FOR {dvs_type.upper()} x {ivs_type.upper()} {\"=\"*5}')\n",
    "    print('~'*80, '\\n')\n",
    "\n",
    "    return sc, df_results, df_top_coeff_p, df_std_coef_dict, df_to_save, masks_dict, sc_stats_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if len(dataframes) > 1:\n",
    "    @interact(df_name=dataframes.keys(), model_name=sm_models.keys(), dvs_type=dvs_for_analysis.keys(), ivs_type=ivs_for_analysis.keys())\n",
    "    def run_sc_interactive(df_name, model_name, dvs_type, ivs_type):\n",
    "        sc, df_results, df_top_coeff_p, df_std_coef_dict, df_to_save, masks_dict, sc_stats_dict = run_sc(\n",
    "            df_name=df_name,\n",
    "            df=dataframes[df_name],\n",
    "            model_name=model_name,\n",
    "            model=sm_models[model_name],\n",
    "            dvs_type=dvs_type,\n",
    "            dvs_name=dvs_for_analysis[dvs_type][0],\n",
    "            dvs_=dvs_for_analysis[dvs_type][1],\n",
    "            ivs_type=ivs_type,\n",
    "            ivs_name=ivs_for_analysis[ivs_type][0],\n",
    "            ivs_=ivs_for_analysis[ivs_type][1],\n",
    "        )\n",
    "else:\n",
    "    df_name = list(dataframes.keys())[0]\n",
    "    model_name = list(sm_models.keys())[0]\n",
    "    dvs_type = list(dvs_for_analysis.keys())[0]\n",
    "    dv_name = dvs_for_analysis[dvs_type][0]\n",
    "    dvs_ = dvs_for_analysis[dvs_type][1]\n",
    "    ivs_type = list(ivs_for_analysis.keys())[0]\n",
    "    iv_name = ivs_for_analysis[ivs_type][0]\n",
    "    ivs_ = ivs_for_analysis[ivs_type][1]\n",
    "    sc, df_results, df_top_coeff_p, df_std_coef_dict, df_to_save, masks_dict, sc_stats_dict = run_sc(\n",
    "        df_name=df_name,\n",
    "        df=dataframes[df_name],\n",
    "        model_name=model_name,\n",
    "        model=sm_models[model_name],\n",
    "        dvs_type=dvs_type,\n",
    "        dvs_name=dv_name,\n",
    "        dvs_=dvs_,\n",
    "        ivs_type=ivs_type,\n",
    "        ivs_name=iv_name,\n",
    "        ivs_=ivs_,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Automating_Equity1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
