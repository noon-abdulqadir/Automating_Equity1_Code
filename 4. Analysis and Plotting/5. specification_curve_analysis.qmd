---
title: Functions
jupyter: python3
---

```{python}
import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8
import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8
from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8

mod = sys.modules[__name__]

code_dir = None
code_dir_name = 'Code'
unwanted_subdir_name = 'Analysis'

if code_dir_name not in str(Path.cwd()).split('/')[-1]:
    for _ in range(5):

        parent_path = str(Path.cwd().parents[_]).split('/')[-1]

        if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):

            code_dir = str(Path.cwd().parents[_])

            if code_dir is not None:
                break
else:
    code_dir = Path.cwd()
sys.path.append(code_dir)

# %load_ext autoreload
# %autoreload 2
```

```{python}
from setup_module.imports import *  # type:ignore # isort:skip # fmt:skip # noqa # nopep8
from setup_module import researchpy_fork as rp # type:ignore # isort:skip # fmt:skip # noqa # nopep8
from setup_module import specification_curve_fork as specy # type:ignore # isort:skip # fmt:skip # noqa # nopep8
```



# READ DATA

```{python}
with open(f'{data_dir}df_manual_len.txt', 'r') as f:
    df_manual_len = int(f.read())

df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_training.pkl')
assert len(df_manual) == df_manual_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_manual_len} BUT IS OF LENGTH {len(df_manual)}'
print(f'Dataframe loaded with shape: {df_manual.shape}')
df_manual = categorize_df_gender_age(df_manual)
```

```{python}
with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'r') as f:
    df_jobs_len = int(f.read())

df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')
assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_jobs)}'
print(f'Dataframe loaded with shape: {df_jobs.shape}')
df_jobs = categorize_df_gender_age(df_jobs)
```

# Analysis plan:

1. ## [Descriptives, visualizations, and tables](./1.%20descriptives_visualization_and_tables.ipynb)
2. ## [Frequencies and Normality tests](./2.%20frequencies_and_normality_test.ipynb)
   1. ### Frequencies, histograms, and QQ plots
      * Normal test
      * Kurtosis test
      * Shapiro
      * Anderson
      * Bartlett
   2. ### Correlation between independent variables (IVs) and control variables and Multicolinarity test
      * Pearson's R
      * VIF
     - ***ivs_dummy*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)
     - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)
     - ***% Sector per Workforce*** (continous ratio) = Sector percentage per worksforce (0-100)
     - ***num_words*** (continous ratio) = Number of words in job description
     - ***English Requirement in Job Ad*** (binary nominal) = English requirement in job description (0 vs. 1)
     - ***Dutch Requirement in Job Ad*** (binary nominal) = Dutch requirement in job description (0 vs. 1)
     - ***Platform*** (binary dummy) = LinkedIn (0 vs. 1), Indeed (0 vs. 1), Glassdoor (0 vs. 1)

3. ## [ANOVA and Chi-square (Pearson's R)](./3.%20chisqt_and_anova.ipynb)

   1. ### Chi-square
      * **df_manual:**
        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)
        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)
      * **df_jobs:**
        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)
        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)

   2. ### One-way ANOVA, interactions, and post-hoc test
      * **df_manual:**
        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)
        - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)
          - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test
          - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test
      * **df_jobs:**
         - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)
         - ***ivs*** (binary nominal) = Social category designation (Female, Male, Mixed Gender)
           - If Levene's test is *not significant*, use classic ANOVA and Tukey's post hoc test
           - If Levene's test is *significant*, use Welch's and Kruskal-Wallis ANOVA and Games Howell's post hoc test

4. ## [Regression Analysis](./3.%20regression_analysis.ipynb)
   1. ### Logistic Regression  with all interaction (smf):
      * **df_manual:**
        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)
        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)
      * **df_jobs:**
        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)
        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)
   2. ### OLS Regression with all interaction:
      * **df_jobs:**
        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)
        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)
   3. ### Multilevel OLS Regression with all interaction:
      * **df_jobs:**
        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)
        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)

5. ## [Specification Curve Analysis](./4.%20specification_curve_analysis.ipynb)

   1. ### Logistic Specification Curve Analysis:
      * **df_manual:**
        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)
        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)
      * **df_jobs:**
        - ***dvs*** (binary nominal) = 'Warmth' and 'Competence' (0 vs. 1)
        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)
   2. ### OLS Specification Curve Analysis:
      * **df_jobs:**
        - ***dvs_prob*** (continous ratio) = 'Warmth' and 'Competence' probabilities (0-1)
        - ***ivs_perc*** (continous ratio) = Social category percentage per sector (0-100)

## Set dataframes

#### Set variables

```{python}
# Dataframes dict
dataframes = {
    # 'df_manual': df_manual,
    'df_jobs': df_jobs,
}

# Models dict
sm_models = {
    # 'Logistic': sm.Logit,
    'OLS': sm.OLS,
}

# DVs dict
dvs_for_analysis = {
    # 'binary': ['Categorical Warmth and Competence', dvs],
    'probability': ['Probability Warmth and Competence', dvs_prob],
    # 'binary and probability': ['Categorical and Probability Warmth and Competence', dvs_all],
}

# IVs dict
ivs_for_analysis = {
    # 'categories': ['Categorical Gender and Age', ivs_dummy],
    # 'percentages': ['PPS Gender and Age', ivs_perc],
    'categories and percentages': ['Categorical and PPS Gender and Age', ivs_dummy_and_perc],
}

```

```{python}
def save_df_full_summary_excel(
    df_full_summary,
    title,
    text_to_add_list,
    file_save_path,
    sheet_name=None,
    startrow=None,
    startcol=None,
):
    if sheet_name is None:
        sheet_name = 'All'
    if startrow is None:
        startrow = 1
    if startcol is None:
        startcol = 1

    # Define last rows and cols locs
    header_range = 1
    endrow = startrow + header_range + df_full_summary.shape[0]
    endcol = startcol + df_full_summary.shape[1]

    # Remove NAs
    df_full_summary = df_full_summary.fillna('')

    # Write
    writer = pd.ExcelWriter(f'{file_save_path}.xlsx')
    df_full_summary.to_excel(writer, sheet_name=sheet_name, merge_cells=True, startrow=startrow, startcol=startcol)
    workbook  = writer.book
    worksheet = writer.sheets[sheet_name]
    worksheet.set_column(startrow, 1, None, None, {'hidden': True}) # hide the index column

    # Title
    worksheet.merge_range(1, startcol, 1, endcol, title, workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'left', 'top': True, 'bottom': True, 'left': False, 'right': False}))

    # Main body
    body_max_row_idx, body_max_col_idx = df_full_summary.shape

    for c, r in tqdm_product(range(body_max_col_idx), range(body_max_row_idx)):
        row_to_write = startrow + header_range + r
        col_to_write = startcol + 1 + c # 1 is for index
        body_formats = {'num_format': '0.00', 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'text_wrap': True, 'left': False, 'right': False}

        if r == 0:
            body_formats |= {'top': True, 'bottom': True, 'left': False, 'right': False}
            worksheet.set_column(col_to_write, col_to_write, 10)

        if r == body_max_row_idx-1:
            body_formats |= {'bottom': True}

        if c == 0:
            body_formats |= {'align': 'left'}
            worksheet.set_column(col_to_write, col_to_write, 15)

        worksheet.write(row_to_write, col_to_write, df_full_summary.iloc[r, c], workbook.add_format(body_formats))

    # Add Note
    note_format = {'italic': True, 'font_name': 'Times New Roman', 'font_size': 10, 'font_color': 'black', 'align': 'left', 'left': False, 'right': False}
    worksheet.merge_range(endrow, startcol, endrow, endcol, 'Note.', workbook.add_format(note_format))
    # Add text
    for i, text in enumerate(text_to_add_list):
        worksheet.merge_range(endrow + 1 + i , startcol, endrow + 1 + i, endcol, text, workbook.add_format(note_format))

    writer.close()
```

```{python}
def make_masks(df_results):

    ## Warmth only results
    warmth_mask = df_results['Specification'].apply(lambda x: any('Warmth' in item for item in x if item in x))

    ## Competence only results
    competence_mask = df_results['Specification'].apply(lambda x: any('Competence' in item for item in x if item in x))

    ## Get gender only results
    # gender_mask = df_results['Specification'].apply(lambda x: any(item for item in ivs_[:-len(ivs_)//2] if item in x))
    female_mask = df_results['Specification'].apply(lambda x: any('Female' in item for item in x if item in x))
    female_warmth_mask = df_results['Specification'].apply(lambda x: any('Female' in item for item in x if item in x) & any('Warmth' in item for item in x if item in x))
    female_competence_mask = df_results['Specification'].apply(lambda x: any('Female' in item for item in x if item in x) & any('Competence' in item for item in x if item in x))
    male_mask = df_results['Specification'].apply(lambda x: any('Male' in item for item in x if item in x))
    male_competence_mask = df_results['Specification'].apply(lambda x: any('Male' in item for item in x if item in x) & any('Competence' in item for item in x if item in x))
    male_warmth_mask = df_results['Specification'].apply(lambda x: any('Male' in item for item in x if item in x) & any('Warmth' in item for item in x if item in x))
    mixed_gender_mask = df_results['Specification'].apply(lambda x: any('Gender_Mixed' in item for item in x if item in x))
    mixed_gender_warmth_mask = df_results['Specification'].apply(lambda x: any('Gender_Mixed' in item for item in x if item in x) & any('Warmth' in item for item in x if item in x))
    mixed_gender_competence_mask = df_results['Specification'].apply(lambda x: any('Gender_Mixed' in item for item in x if item in x) & any('Competence' in item for item in x if item in x))
    gender_mask = female_mask | male_mask | mixed_gender_mask
    gender_warmth_mask = female_warmth_mask | male_warmth_mask | mixed_gender_warmth_mask
    gender_competence_mask = female_competence_mask | male_competence_mask | mixed_gender_competence_mask

    # Get age only results
    # age_mask = df_results['Specification'].apply(lambda x: any(item for item in ivs_[len(ivs_)//2:] if item in x))
    older_mask = df_results['Specification'].apply(lambda x: any('Older' in item for item in x))
    older_warmth_mask = df_results['Specification'].apply(lambda x: any('Older' in item for item in x) & any('Warmth' in item for item in x))
    older_competence_mask = df_results['Specification'].apply(lambda x: any('Older' in item for item in x) & any('Competence' in item for item in x))
    younger_mask = df_results['Specification'].apply(lambda x: any('Younger' in item for item in x))
    younger_competence_mask = df_results['Specification'].apply(lambda x: any('Younger' in item for item in x) & any('Competence' in item for item in x))
    younger_warmth_mask = df_results['Specification'].apply(lambda x: any('Younger' in item for item in x) & any('Warmth' in item for item in x))
    mixed_age_mask = df_results['Specification'].apply(lambda x: any('Age_Mixed' in item for item in x))
    mixed_age_warmth_mask = df_results['Specification'].apply(lambda x: any('Age_Mixed' in item for item in x) & any('Warmth' in item for item in x))
    mixed_age_competence_mask = df_results['Specification'].apply(lambda x: any('Age_Mixed' in item for item in x) & any('Competence' in item for item in x))
    age_mask = older_mask | younger_mask | mixed_age_mask
    age_warmth_mask = older_warmth_mask | younger_warmth_mask | mixed_age_warmth_mask
    age_competence_mask = older_competence_mask | younger_competence_mask | mixed_age_competence_mask

    return {
        'warmth_mask': warmth_mask,
        'competence_mask': competence_mask,
        'female_mask': female_mask,
        'female_warmth_mask': female_warmth_mask,
        'female_competence_mask': female_competence_mask,
        'male_mask': male_mask,
        'male_warmth_mask': male_warmth_mask,
        'male_competence_mask': male_competence_mask,
        'mixed_gender_mask': mixed_gender_mask,
        'mixed_gender_warmth_mask': mixed_gender_warmth_mask,
        'mixed_gender_competence_mask': mixed_gender_competence_mask,
        'gender_mask': gender_mask,
        'gender_warmth_mask': gender_warmth_mask,
        'gender_competence_mask': gender_competence_mask,
        'older_mask': older_mask,
        'older_warmth_mask': older_warmth_mask,
        'older_competence_mask': older_competence_mask,
        'younger_mask': younger_mask,
        'younger_warmth_mask': younger_warmth_mask,
        'younger_competence_mask': younger_competence_mask,
        'mixed_age_mask': mixed_age_mask,
        'mixed_age_warmth_mask': mixed_age_warmth_mask,
        'mixed_age_competence_mask': mixed_age_competence_mask,
        'age_mask': age_mask,
        'age_warmth_mask': age_warmth_mask,
        'age_competence_mask': age_competence_mask,
    }
```

```{python}
def make_full_report(
    results, dv, analysis_type, model_name, dvs_name, ivs_name,
    regression_info_dict=None, regressor_order=None, text_to_add_list=None, title=None, model_names=None
):
    '''
    Make a full report for a regression analysis.
    results: statsmodels regression results object or list of results objects
    dv: str, dependent variable name
    '''

    if regression_info_dict is None:
        # Regression info dict
        regression_info_dict = {
            'Model Name': lambda x: f'{x.model.__class__.__name__}',
            'N': lambda x: f'{int(x.nobs):d}',
            'R-squared': lambda x: f'{x.rsquared:.5f}',
            'R-squared Adj.': lambda x: f'{x.rsquared_adj:.5f}',
            'Log-Likelihood': lambda x: f'{x.llf:.5f}',
            'Pseudo R2': lambda x: f'{x.prsquared:.5f}',
            'F': lambda x: f'{x.fvalue:.5f}',
            'F (p-value)': lambda x: f'{x.f_pvalue:.5f}',
            'df_model': lambda x: f'{x.df_model:.0f}',
            'df_total': lambda x: f'{x.df_resid + x.df_model + 1:.0f}',
            'df_resid': lambda x: f'{x.df_resid:.0f}',
            'AIC': lambda x: f'{x.aic:.5f}',
            'BIC': lambda x: f'{x.bic:.5f}',
            'ICC': lambda x: f'{x.rsquared / (x.rsquared + (x.nobs - 1) * x.mse_resid):.5f}',
            'RMSE': lambda x: f'{x.mse_resid ** 0.5:.5f}',
            'RMSE (std)': lambda x: f'{x.mse_resid ** 0.5 / x.model.endog.std():.5f}',
            'Omnibus': lambda x: f'{sms.omni_normtest(x.resid).statistic:.5f}',
            'Omnibus (p-value)': lambda x: f'{sms.omni_normtest(x.resid).pvalue:.5f}',
            'Skew': lambda x: f'{sms.jarque_bera(x.resid)[-2]:.5f}',
            'Kurtosis': lambda x: f'{sms.jarque_bera(x.resid)[-1]:.5f}',
            'Jarque-Bera (JB)': lambda x: f'{sms.jarque_bera(x.resid)[0]:.5f}',
            'Jarque-Bera (p-value)': lambda x: f'{sms.jarque_bera(x.resid)[1]:.5f}',
            'Intercept': lambda x: f'{x.params["const"]:.5f}',
            'Intercept (std)': lambda x: f'{x.bse["const"]:.5f}',
            'Intercept t': lambda x: f'{x.tvalues["const"]:.5f}',
            'Intercept t (p-value)': lambda x: f'{x.pvalues["const"]:.5f}',
            'Intercept (95% CI)': lambda x: f'{x.conf_int().loc["const"][0]:.5f} - {x.conf_int().loc["const"][1]:.5f}',
            'Unstandardized Coefficent B (b)': lambda x: f'{x.params[0]:.5f}',
            'Standard Error (SE)': lambda x: f'{x.bse[0]:.5f}',
            'Standardized Coefficient b* (β)': lambda x: f'{x.params[0] / x.model.endog.std():.5f}',
            't': lambda x: f'{x.tvalues[0]:.5f}',
            't (p-value)': lambda x: f'{x.pvalues[0]:.5f}',
            '95% CI': lambda x: f'{x.conf_int().iloc[0, 1]:.5f} - {x.conf_int().iloc[0, 1]:.5f}',
            # 'Summary': lambda x: f'{x.summary()}',
            # 'F (p-value - FDR)': lambda x: f'{x.f_pvalue_fdr:.5f}',
            # 'F (p-value - Bonferroni)': lambda x: f'{x.f_pvalue_bonf:.5f}',
            # 't (p-value - FDR)': lambda x: f'{x.pvalues_fdr[1]:.5f}',
            # 't (p-value - Bonferroni)': lambda x: f'{x.pvalues_bonf[1]:.5f}',
        }
    if model_names is None:
        if isinstance(results, list):
            model_names = [
                f'{results[0].model.endog_names.split("_")[0] if "_" in results[0].model.endog_names else results[0].model.endog_names} Model {i}'
                for i in range(len(results[0].model.endog_names))
            ]
            model_names[0] = model_names[0].replace('Model 0', 'Full Model')
        else:
            model_names = [
                f'{results.model.endog_names.split("_")[0] if "_" in results.model.endog_names else results.model.endog_names}'
            ]

    order_type = 'unordered' if regressor_order is None else 'ordered'
    if text_to_add_list is None:
        text_to_add_list = []
        if regressor_order is not None:
            text_to_add_list.append('Models are ordered by independent variable type.')

        else:
            text_to_add_list.append('Models are ordered by coefficient size, largest to smallest.')

    if title is None:
        title = f'{model_name} {analysis_type}: {dvs_name} x {ivs_name}'

    # Statsmodels summary_col
    full_summary = summary_col(
        results,
        stars=True,
        info_dict=regression_info_dict,
        regressor_order=regressor_order,
        float_format='%0.3f',
        model_names=model_names,
    )
    if isinstance(results, list) and len(results) > 4:
        full_summary.tables[0][full_summary.tables[0].filter(regex='Full Model').columns[0]].loc['Unstandardized Coefficent B (b)': '95% CI'] = ''

    # Add title and notes
    full_summary.add_title(title)
    text_to_add_list.extend(full_summary.extra_txt)
    for text in text_to_add_list:
        full_summary.add_text(text)

    # Save
    save_name = f'{table_save_path}{model_name} {df_name} - ALL {dv} {order_type} {analysis_type} on {ivs_type}'
    df_full_summary = pd.read_html(full_summary.as_html())[0]
    df_full_summary.to_csv(f'{save_name}.csv')
    df_full_summary.style.to_latex(f'{save_name}.tex', hrules=True)
    save_df_full_summary_excel(df_full_summary, title, text_to_add_list, save_name)

    return full_summary
```

```{python}
def get_standardized_coefficients(results):

    # # Get standardized regression coefficients
    # std = np.asarray(constant.std(0))

    # if 'const' in results.params and 'const' in constant:
    #     std[0] = 1
    # tt = results.t_test(np.diag(std))
    # tt.c_names = results.model.exog_names

    # t-test
    std = results.model.exog.std(0)
    if 'const' in results.params:
        std[0] = 1
    tt = results.t_test(np.diag(std))
    if results.model.__class__.__name__ == 'MixedLM' or 'Group Var' in results.model.exog_names:
        offset = slice(None, -1)
        tt.c_names = results.model.exog_names[offset]
    else:
        offset = slice(None, None)
        tt.c_names = results.model.exog_names

    # Make df with standardized and unstandardized coefficients
    df_std_coef = pd.DataFrame(
        {
            'coef': results.params[offset].apply(lambda x: f'{x:.4f}'),
            'std err': results.bse[offset].apply(lambda x: f'{x:.4f}'),
            'std coef': (results.params[offset] / results.model.exog[offset].std(axis=0)).apply(lambda x: f'{x:.4f}'),
            't': results.tvalues[offset].apply(lambda x: f'{x:.4f}'),
            'P>|t|': results.pvalues[offset].apply(lambda x: f'{x:.4f}'),
            '[0.025': results.conf_int()[0][offset].apply(lambda x: f'{x:.4f}'),
            '0.975]': results.conf_int()[1][offset].apply(lambda x: f'{x:.4f}'),
        }
    )
    # if 'Group Var' in df_std_coef.index:
    #     df_std_coef = df_std_coef.drop('Group Var', axis='index')
    # # Add standardized coefficients and other data from t-test
    # df_std_coef['std coef'] = tt.effect
    # df_std_coef['std err'] = tt.sd
    # df_std_coef['t'] = tt.statistic
    # df_std_coef['P>|t|'] = tt.pvalue
    # df_std_coef['[0.025'] = tt.conf_int()[:, 0]
    # df_std_coef['0.975]'] = tt.conf_int()[:, 1]
    # df_std_coef['var'] = [names[i] for i in range(len(results.model.exog_names))]
    # df_std_coef = df_std_coef.sort_values('std coef', ascending=False)
    df_std_coef = df_std_coef.reset_index().rename(columns={'index': 'var'})
    df_std_coef = df_std_coef.rename(
        columns={
            'var': 'Variable',
            'coef': 'Unstandardized Coefficent B (b)',
            'std err': 'Standard Error',
            'std coef':'Standardized Coefficient b* (β)',
            't': 't-value',
            'P>|t|': 'p-value',
            '[0.025': '95% CI Lower',
            '0.975]': '95% CI Upper'
        }
    )
    # Reorder columns
    df_std_coef = df_std_coef[[
        'Variable',
        'Unstandardized Coefficent B (b)',
        'Standard Error',
        'Standardized Coefficient b* (β)',
        't-value',
        'p-value',
        '95% CI Lower',
        '95% CI Upper'
    ]]

    return tt, df_std_coef
```

```{python}
def get_significant_predictors(df_results, top_n=None, dv_name=None, alpha=None, asc=None):
    if top_n is None:
        top_n = 10
    if alpha is None:
        alpha = 0.05
    if asc is None:
        asc = False

    condition = (df_results['coeff_pvals'] < alpha) & (df_results['x_exog'] != 'const')
    if dv_name is not None:
        condition = pd.concat([condition, (df_results['y_endog'] == dv_name)])

    df_top_coeff_p = df_results.loc[condition].sort_values(by=['Coefficient'], ascending=asc)
    print('\n')
    print('+'*20)
    print('\n')
    print('-'*20)
    print(f"{top_n} {'Highest' if asc==False else 'Lowest'} significant coefficients:\n{df_top_coeff_p[['x_exog', 'y_endog', 'coeff_pvals', 'Coefficient', 'conf_int', 'pvalues']].head(top_n)}")
    print('-'*20)
    print('\n')
    print('+'*20)
    print('\n')
```

# Specification Curve Analysis

```{python}
%%time
for (df_name, df), (model_name, model), (dvs_type, [dvs_name, dvs_]), (ivs_type, [ivs_name, ivs_]) in tqdm_product(dataframes.items(), sm_models.items(), dvs_for_analysis.items(), ivs_for_analysis.items()):

    # Set DVs for df_manual
    if df_name == 'df_manual':
        dvs_ = dvs

    # Run specification curve analysis
    print('\n')
    print(f'{df_name} Running specification curve analysis with:\nDEPENDENT VARIABLES = {dvs_}\nINDEPENDENT VARIABLES = {ivs_}\nCONTROLS = {controls}')
    print(f'{"="*5} {df_name} {model_name.upper()} SPECIFICATION MODE RESULTS FOR {df_name} USING {dvs_type.upper()} x {ivs_type.upper()} {"="*5}')
    print('\n')

    # Add constant
    df = sm.add_constant(df)
    constant = ivs_[:] + ['const']

    try:
        plot_title = f'{model_name}: {dvs_name} x {ivs_name}'
        sc = specy.SpecificationCurve(df=df, y_endog=dvs_, x_exog=constant, controls=controls[:2], always_include=['const'])
        sc.fit(estimator=model)
        df_results = sc.df_r
        print(df_results.columns)
        print(df_results.head())

        # Compare models with controls
        controls_mask = df_results['Specification'].apply(lambda x: all(control in x for control in controls[:2]))
        df_results_controls = df_results.loc[controls_mask]

        # Warmth
        for dv in dvs_[:len(dvs_)//2]:
            warmth_results_list = [sm.OLS(endog=df[dv], exog=df[constant + controls[:2]]).fit()] + df_results_controls['Results'].loc[df_results_controls['y_endog'] == dv].tolist()
            warmth_full_summary = make_full_report(
                warmth_results_list, dv,
                dvs_name=dvs_name, ivs_name=ivs_name,
                model_name=model_name, analysis_type='specification curve'
            )
            ordered_warmth_full_summary = make_full_report(
                warmth_results_list, dv,
                dvs_name=dvs_name, ivs_name=ivs_name,
                model_name=model_name, analysis_type='specification curve', regressor_order=ivs_[:] + controls[:2]
            )
            print('\n')
            print('-'*20)
            print(f'{dv}\n')
            print('-'*20)
            print('\n')
            print(f'Warmth SUMMARY RESULTS:')
            print(warmth_full_summary)
            print('\n')

        # Competence
        for dv in dvs_[len(dvs_)//2:]:
            competence_results_list = [sm.OLS(endog=df[dv], exog=df[constant + controls[:2]]).fit()] + df_results_controls['Results'].loc[df_results_controls['y_endog'] == dv].tolist()
            competence_full_summary = make_full_report(
                competence_results_list, dv,
                dvs_name=dvs_name, ivs_name=ivs_name,
                model_name=model_name, analysis_type='specification curve'
            )
            ordered_competence_full_summary = make_full_report(
                competence_results_list, dv,
                dvs_name=dvs_name, ivs_name=ivs_name,
                model_name=model_name, analysis_type='specification curve', regressor_order=ivs_[:] + controls[:2]
            )
            print('\n')
            print('-'*20)
            print(f'{dv}\n')
            print('-'*20)
            print('\n')
            print(f'Competence SUMMARY RESULTS:')
            print(competence_full_summary)
            print('\n')

        # Get masks and make dfs
        masks_dict = make_masks(df_results)
        text_to_add_list = []
        # Stouffer’s Z-score and p-value for each mask
        for mask_name, mask in masks_dict.items():
            # Share of significant effects
            significant_count = (df_results[mask]['coeff_pvals'] < alpha).sum()
            total_count = len(df_results[mask])
            share_significant = significant_count / total_count
            null_share = 1 / total_count
            share_significant_pval = scipy.stats.binom_test(significant_count, n=total_count, p=null_share, alternative='greater')
            share_fraction = f'{significant_count}/{len(df_results[mask])}'
            # Stoutffer
            pvalues = df_results[mask]['coeff_pvals'].tolist()
            stouffer_z , stouffer_pval = scipy.stats.combine_pvalues(pvalues=pvalues, method='stouffer')

            for dv in dvs_:
                if mask_name.split('_mask')[0] == f'{dv.split("_Probability")[0].lower()}':
                    text_to_add_list.append(
                        f'{"-"*10}\n{dv.split("_Probability")[0]}:\nSign. share: {share_fraction}\np-value = {share_significant_pval:.2f}\nStouffer Z: {stouffer_z:.2f}\np-value = {stouffer_pval:.2f}',
                    )

            print(f'{"="*5} SCA {mask_name.split("_mask")[0].upper()} {"="*5}')
            print(f'Length of {mask_name.split("_mask")[0]}: {len(df_results[mask])}')
            print(f'Number of significant p-values for {mask_name.split("_mask")[0]}: {significant_count}')
            print(f'Share of significant effects for {mask_name.split("_mask")[0]}: {share_significant:.2f} - {significant_count}/{len(df_results[mask])}')
            print(f'Share of significant effects p-value: {share_significant_pval:.2f}')
            print(f'Stoutffer Z: {stouffer_z:.2f}')
            print(f'Stoutffer p-value: {stouffer_pval:.2f}')
            print('-'*20)
            print('\n')

        # Get gender and age masks with controls for final regression reporting
        df_results_gender = df_results_controls.loc[masks_dict['gender_mask']]
        df_results_gender = df_results_gender.reset_index(drop=True)
        df_results_age = df_results_controls.loc[masks_dict['age_mask']]
        df_results_age = df_results_age.reset_index(drop=True)

        # Iterate over results and print summary
        for df_masked in [df_results_gender, df_results_age]:
            for idx, row in df_masked.iterrows():
                iv_name = row['x_exog']
                dv_name = row['y_endog']
                print('\n')
                print('+'*20)
                print(f'{dv_name} x {iv_name}\n')
                print('+'*20)
                print(f'{row["Results"].summary(title=plot_title)}')
                tt, df_std_coef = get_standardized_coefficients(row['Results'])
                print(f'STANDARDIZED BETA REGRESSION COEFFICIENTS:\n{df_std_coef}')
                print('-'*20)
                print('~'*20)

                # Save results to file
                save_name = f'{table_save_path}{model_name} specification curve on {ivs_type} {df_name} - {dv_name} x {iv_name} ({dvs_type} Warmth and Competence x {ivs_type} Gender and Age)'
                row['Results'].save(f'{save_name}.pkl')
                df_to_save = pd.DataFrame(csv.reader(row['Results'].summary(title=plot_title).as_csv().split('\n'), delimiter=','))
                df_to_save.to_csv(f'{save_name}.csv')
                df_to_save.style.to_latex(f'{save_name}.tex', hrules=True)
                df_std_coef.to_csv(f'{save_name} - standardized coefficients.csv')
                df_std_coef.style.to_latex(f'{save_name} - standardized coefficients.tex', hrules=True)

        # Get top predictors
        get_significant_predictors(df_results, top_n=10)

        # Get bottom predictors
        get_significant_predictors(df_results, top_n=10, asc=True)

        # Plot and save
        print('\n')
        print('~'*80)
        print(f'\n{"="*5} {df_name} RESULTS FOR {plot_title} {"="*5}\n')
        print('~'*80)
        print('\n')

        for image_save_format in tqdm.tqdm(['eps', 'png', 'svg']):
            # Use following if not using forked specification_curve
            # sc.plot(preferred_spec=[iv, dv], save_path=save_path,)
            save_path = f'{plot_save_path}{df_name} - {model_name} Specification Curve - {dvs_type} Warmth and Competence x {ivs_type} Gender and Age.{image_save_format}'
            sc_fig = sc.plot(
                save_path=save_path,
                show_plot=False,
                return_fig=True,
                plot_title=plot_title,
                text_to_add=text_to_add_list,
            )

    except(np.linalg.LinAlgError):
        print(f'Singular matrix when using {model_name} with {dvs_type} x {ivs_type}')

    print(f'{"="*5} END OF {df_name} RESULTS FOR {dvs_type.upper()} x {ivs_type.upper()} {"="*5}')
    print('~'*80, '\n')
```


