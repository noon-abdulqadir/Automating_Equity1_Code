{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d4c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "import sys  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from pathlib import Path  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "sys.path.append(code_dir)\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3abbb866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff07ce2db1e34b76879790c40ae9b1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244d98ebcf8646b2bf24e4ab1522a37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from setup_module.imports import *  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from estimators_get_pipe import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65134b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02efe2d424d45b09fd5d01e577999c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set random seed\n",
    "random_state = 42\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Transformer variables\n",
    "method = 'Transformers'\n",
    "results_save_path = f'{models_save_path}{method} Results/'\n",
    "with open(f'{data_dir}{method}_results_save_path.txt', 'w') as f:\n",
    "    f.write(results_save_path)\n",
    "if not os.path.exists(results_save_path):\n",
    "    os.makedirs(results_save_path)\n",
    "done_xy_save_path = f'{results_save_path}Search+Xy/'\n",
    "with open(f'{data_dir}{method}_done_xy_save_path.txt', 'w') as f:\n",
    "    f.write(done_xy_save_path)\n",
    "if not os.path.exists(done_xy_save_path):\n",
    "    os.makedirs(done_xy_save_path)\n",
    "\n",
    "t = time.time()\n",
    "n_jobs = -1\n",
    "n_splits = 10\n",
    "n_repeats = 3\n",
    "random_state = 42\n",
    "refit = True\n",
    "class_weight = 'balanced'\n",
    "cv = RepeatedStratifiedKFold(\n",
    "    n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
    ")\n",
    "scoring = 'recall'\n",
    "scores = [\n",
    "    'recall', 'accuracy', 'f1', 'roc_auc',\n",
    "    'explained_variance', 'matthews_corrcoef'\n",
    "]\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score),\n",
    "}\n",
    "analysis_columns = ['Warmth', 'Competence']\n",
    "text_col = 'Job Description spacy_sentencized'\n",
    "metrics_dict = {\n",
    "    'Mean Cross Validation Train Score': np.nan,\n",
    "    f'Mean Cross Validation Train - {scoring.title()}': np.nan,\n",
    "    f'Mean Explained Train Variance - {scoring.title()}': np.nan,\n",
    "    'Mean Cross Validation Test Score': np.nan,\n",
    "    f'Mean Cross Validation Test - {scoring.title()}': np.nan,\n",
    "    f'Mean Explained Test Variance - {scoring.title()}': np.nan,\n",
    "    'Explained Variance': np.nan,\n",
    "    'Accuracy': np.nan,\n",
    "    'Balanced Accuracy': np.nan,\n",
    "    'Precision': np.nan,\n",
    "    'Recall': np.nan,\n",
    "    'F1-score': np.nan,\n",
    "    'Matthews Correlation Coefficient': np.nan,\n",
    "    'Fowlkes–Mallows Index': np.nan,\n",
    "    'R2 Score': np.nan,\n",
    "    'ROC': np.nan,\n",
    "    'AUC': np.nan,\n",
    "    f'{scoring.title()} Best Threshold': np.nan,\n",
    "    f'{scoring.title()} Best Score': np.nan,\n",
    "    'Log Loss/Cross Entropy': np.nan,\n",
    "    'Cohen’s Kappa': np.nan,\n",
    "    'Geometric Mean': np.nan,\n",
    "    'Classification Report': np.nan,\n",
    "    'Imbalanced Classification Report': np.nan,\n",
    "    'Confusion Matrix': np.nan,\n",
    "    'Normalized Confusion Matrix': np.nan\n",
    "}\n",
    "\n",
    "# Transformer variables\n",
    "max_length = 512\n",
    "returned_tensor = 'pt'\n",
    "cpu_counts = torch.multiprocessing.cpu_count()\n",
    "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available(\n",
    ") else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device_name = str(device.type)\n",
    "print(f'Using {device_name.upper()}')\n",
    "# Set random seed\n",
    "random_state = 42\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "cores = multiprocessing.cpu_count()\n",
    "torch.Generator(device_name).manual_seed(random_state)\n",
    "cores = multiprocessing.cpu_count()\n",
    "accelerator = Accelerator()\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "os.environ.get('TOKENIZERS_PARALLELISM')\n",
    "best_trial_args = [\n",
    "    'num_train_epochs', 'per_device_train_batch_size', 'per_device_eval_batch_size', 'learning_rate', 'warmup_steps', 'weight_decay'\n",
    "]\n",
    "training_args_dict = {\n",
    "    'seed': random_state,\n",
    "    'resume_from_checkpoint': True,\n",
    "    'overwrite_output_dir': True,\n",
    "    'logging_steps': 500,\n",
    "    'evaluation_strategy': 'steps',\n",
    "    'eval_steps': 500,\n",
    "    'save_strategy': 'steps',\n",
    "    'save_steps': 500,\n",
    "    # 'metric_for_best_model': 'recall',\n",
    "    # 'torch_compile': bool(transformers.file_utils.is_torch_available()),\n",
    "    'use_mps_device': bool(device_name == 'mps' and torch.backends.mps.is_available()),\n",
    "    'optim': 'adamw_torch',\n",
    "    'load_best_model_at_end': True,\n",
    "    # The below metrics are used by hyperparameter search\n",
    "    'num_train_epochs': 3,\n",
    "    'per_device_train_batch_size': 16,\n",
    "    'per_device_eval_batch_size': 20,\n",
    "    'learning_rate': 5e-5,\n",
    "    'warmup_steps': 100,\n",
    "    'weight_decay': 0.01,\n",
    "}\n",
    "training_args_dict_for_best_trial = {\n",
    "    arg_name: arg_\n",
    "    for arg_name, arg_ in training_args_dict.items()\n",
    "    if arg_name not in best_trial_args\n",
    "}\n",
    "\n",
    "# Plotting variables\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "tqdm.tqdm.pandas(desc='progress-bar')\n",
    "tqdm_auto.tqdm.pandas(desc='progress-bar')\n",
    "# tqdm.notebook.tqdm().pandas(desc='progress-bar')\n",
    "tqdm_auto.notebook_tqdm().pandas(desc='progress-bar')\n",
    "# pbar = progressbar.ProgressBar(maxval=10)\n",
    "mpl.style.use(f'{code_dir}/setup_module/apa.mplstyle-main/apa.mplstyle')\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "font = {'family': 'arial', 'weight': 'normal', 'size': 10}\n",
    "mpl.rc('font', **font)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "plt.set_cmap('Blues')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55afc383",
   "metadata": {},
   "source": [
    "# Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d7b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_files(\n",
    "    results_save_path= results_save_path,\n",
    "    estimator_names_list=None,\n",
    "    vectorizer_names_list=None,\n",
    "    classifier_names_list=None,\n",
    "):\n",
    "    if estimator_names_list is None:\n",
    "        estimator_names_list = []\n",
    "\n",
    "    print(f'Searching for existing estimators in directory:\\n{results_save_path}')\n",
    "\n",
    "    for estimators_file in tqdm.tqdm(glob.glob(f'{results_save_path}*.pkl')):\n",
    "        if f'{method} Estimator - ' in estimators_file:\n",
    "\n",
    "            col=estimators_file.split(f'{method} Estimator - ')[-1].split(' - ')[0]\n",
    "            vectorizer_name=estimators_file.split(f'{col} - ')[-1].split(' + ')[0]\n",
    "            classifier_name=estimators_file.split(f'{vectorizer_name} + ')[-1].split(' (Save_protocol=')[0]\n",
    "\n",
    "            estimator_names_list.append(f'{col} - {vectorizer_name} + {classifier_name}')\n",
    "\n",
    "    return (\n",
    "        list(set(estimator_names_list))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70db7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to place Xy and CV data in df and save\n",
    "def save_Xy(\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    X_val, y_val,\n",
    "    col,\n",
    "    results_save_path=results_save_path,\n",
    "    method=method, done_xy_save_path=done_xy_save_path,\n",
    "    compression=None, protocol=None, path_suffix=None, data_dict=None\n",
    "):\n",
    "    if compression is None:\n",
    "        compression = False\n",
    "    if protocol is None:\n",
    "        protocol = pickle.HIGHEST_PROTOCOL\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {col} - (Save_protocol={protocol}).pkl'\n",
    "    if data_dict is None:\n",
    "        data_dict = {}\n",
    "\n",
    "    # Check data\n",
    "    check_consistent_length(X_train, y_train)\n",
    "    check_consistent_length(X_test, y_test)\n",
    "    check_consistent_length(X_val, y_val)\n",
    "\n",
    "    # Make df_train_data\n",
    "    df_train_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "        },\n",
    "    )\n",
    "    # Make df_test_data\n",
    "    df_test_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "        },\n",
    "    )\n",
    "    # Make df_test_data\n",
    "    df_val_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_val': X_val,\n",
    "            'y_val': y_val,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Assign dfs to variables\n",
    "    data_dict['df_train_data'] = df_train_data\n",
    "    data_dict['df_test_data'] = df_test_data\n",
    "    data_dict['df_val_data'] = df_val_data\n",
    "\n",
    "    # Save files\n",
    "    print('='*20)\n",
    "    for file_name, file_ in data_dict.items():\n",
    "        save_path = f'{models_save_path}{file_name}{path_suffix}'\n",
    "        print(f'Saving Xy {file_name} at {save_path}')\n",
    "        file_.to_pickle(\n",
    "            save_path, protocol=protocol\n",
    "        )\n",
    "    print(f'Done saving Xy!\\n{list(data_dict.keys())}')\n",
    "    print('='*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef9e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    X_val, y_val,\n",
    "):\n",
    "    # Get train class weights\n",
    "    train_class_weights = compute_class_weight(class_weight = class_weight, classes = np.unique(y_train), y = y_train)\n",
    "    train_class_weights_ratio = train_class_weights[0]/train_class_weights[1]\n",
    "    train_class_weights_dict = dict(zip(np.unique(y_train), train_class_weights))\n",
    "\n",
    "    # Get train class weights\n",
    "    test_class_weights = compute_class_weight(class_weight = class_weight, classes = np.unique(y_train), y = y_test)\n",
    "    test_class_weights_ratio = test_class_weights[0]/test_class_weights[1]\n",
    "    test_class_weights_dict = dict(zip(np.unique(y_test), test_class_weights))\n",
    "\n",
    "    # Get val class weights\n",
    "    val_class_weights = compute_class_weight(class_weight = class_weight, classes = np.unique(y_train), y = y_val)\n",
    "    val_class_weights_ratio = val_class_weights[0]/val_class_weights[1]\n",
    "    val_class_weights_dict = dict(zip(np.unique(y_val), val_class_weights))\n",
    "\n",
    "    return (\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "        val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad68773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_Xy(\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    X_val, y_val,\n",
    "    train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "    test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "    val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "):\n",
    "    # Check for consistent length\n",
    "    check_consistent_length(X_train, y_train)\n",
    "    check_consistent_length(X_test, y_test)\n",
    "    check_consistent_length(X_val, y_val)\n",
    "\n",
    "    print('Done splitting data into training and testing sets.')\n",
    "    print('='*20)\n",
    "    print(f'Training set shape: {y_train.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Training set example:\\n{X_train[0]}')\n",
    "    print('~'*10)\n",
    "    print(f'Testing set shape: {y_test.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Testing set example:\\n{X_test[0]}')\n",
    "    print('~'*10)\n",
    "    print(f'Validation set shape: {y_val.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Validation set example:\\n{X_val[0]}')\n",
    "    print('~'*10)\n",
    "    print(f'Training data class weights:\\nRatio = {train_class_weights_ratio:.2f} (0 = {train_class_weights[0]:.2f}, 1 = {train_class_weights[1]:.2f})')\n",
    "    print('-'*10)\n",
    "    print(f'Testing data class weights:\\nRatio = {test_class_weights_ratio:.2f} (0 = {test_class_weights[0]:.2f}, 1 = {test_class_weights[1]:.2f})')\n",
    "    print('-'*10)\n",
    "    print(f'Validation data class weights:\\nRatio = {val_class_weights_ratio:.2f} (0 = {val_class_weights[0]:.2f}, 1 = {val_class_weights[1]:.2f})')\n",
    "    print('='*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "395dffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, col, analysis_columns=analysis_columns, text_col=text_col):\n",
    "\n",
    "    train_ratio = 0.75\n",
    "    test_ratio = 0.10\n",
    "    validation_ratio = 0.15\n",
    "    test_split = test_size = 1 - train_ratio\n",
    "    validation_split = test_ratio / (test_ratio + validation_ratio)\n",
    "\n",
    "    # Split\n",
    "    print('='*20)\n",
    "    print('Splitting data into training, testing, and validation sets:')\n",
    "    print(f'Ratios: train_size = {train_ratio}, test size = {test_ratio}, validation size = {validation_ratio}')\n",
    "\n",
    "    df = df.dropna(subset=analysis_columns, how='any')\n",
    "    df = df.loc[df[text_col].apply(len) >= 5]\n",
    "    print(f'DF length: {len(df)}')\n",
    "\n",
    "    train, test = train_test_split(\n",
    "        df, train_size=1-test_split, test_size=test_split, random_state=random_state\n",
    "    )\n",
    "    val, test = train_test_split(\n",
    "        test, test_size=validation_split, random_state=random_state\n",
    "    )\n",
    "\n",
    "    X_train = np.array(list(train[text_col].astype('str').values))\n",
    "    y_train = column_or_1d(train[col].astype('int64').values.tolist(), warn=True)\n",
    "\n",
    "    X_test = np.array(list(test[text_col].astype('str').values))\n",
    "    y_test = column_or_1d(test[col].astype('int64').values.tolist(), warn=True)\n",
    "\n",
    "    X_val = np.array(list(val[text_col].astype('str').values))\n",
    "    y_val = column_or_1d(val[col].astype('int64').values.tolist(), warn=True)\n",
    "\n",
    "    # Get class weights\n",
    "    (\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "        val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "    ) = get_class_weights(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        X_val, y_val,\n",
    "    )\n",
    "    # Print info\n",
    "    print_Xy(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        X_val, y_val,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "        val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        train, X_train, y_train,\n",
    "        test, X_test, y_test,\n",
    "        val, X_val, y_val,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "        val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f07a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx], device=device).clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], device=device).clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c0e7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_Xy_encodings(\n",
    "    X_train, y_train, train_dataset,\n",
    "    X_test, y_test, test_dataset,\n",
    "    X_val, y_val, val_dataset,\n",
    "):\n",
    "    # Check for consistent length\n",
    "    check_consistent_length(X_train, y_train, train_dataset)\n",
    "    check_consistent_length(X_test, y_test, test_dataset)\n",
    "    check_consistent_length(X_val, y_val, val_dataset)\n",
    "\n",
    "    # Check encodings\n",
    "    assert all(y_train == train_dataset.labels), 'y_train and train_dataset labels are not the same'\n",
    "    assert all(y_test == test_dataset.labels), 'y_test and test_dataset labels are not the same'\n",
    "\n",
    "    print('Done encoding training, testing, and validation sets.')\n",
    "    print('='*20)\n",
    "    print(f'Training set encodings example:\\n{\" \".join(train_dataset.encodings[0].tokens[:30])}')\n",
    "    print('~'*10)\n",
    "    print(f'Testing set encodings example:\\n{\" \".join(test_dataset.encodings[0].tokens[:30])}')\n",
    "    print('~'*10)\n",
    "    print(f'Validation set encodings example:\\n{\" \".join(val_dataset.encodings[0].tokens[:30])}')\n",
    "    print('='*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3840ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    X_val, y_val,\n",
    "    tokenizer,\n",
    "):\n",
    "    print('='*20)\n",
    "    print(f'Encoding training, testing, and validation sets with {f\"{tokenizer=}\".split(\"=\")[0]}.from_pretrained using {tokenizer.name_or_path}.')\n",
    "\n",
    "    X_train_encodings = tokenizer(\n",
    "        X_train.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
    "    ).to(device)\n",
    "    train_dataset = ToDataset(X_train_encodings, y_train)\n",
    "\n",
    "    X_test_encodings = tokenizer(\n",
    "        X_test.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
    "    ).to(device)\n",
    "    test_dataset = ToDataset(X_test_encodings, y_test)\n",
    "\n",
    "    X_val_encodings = tokenizer(\n",
    "        X_val.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
    "    ).to(device)\n",
    "    val_dataset = ToDataset(X_val_encodings, y_val)\n",
    "\n",
    "    # Print info\n",
    "    print_Xy_encodings(\n",
    "        X_train, y_train, train_dataset,\n",
    "        X_test, y_test, test_dataset,\n",
    "        X_val, y_val, val_dataset,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        X_train_encodings, train_dataset,\n",
    "        X_test_encodings, test_dataset,\n",
    "        X_val_encodings, val_dataset,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ddcc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Xy(\n",
    "    col,\n",
    "    results_save_path=results_save_path, method=method,\n",
    "    data_dict=None, protocol=None, path_suffix=None, \n",
    "):\n",
    "    if data_dict is None:\n",
    "        data_dict = {}\n",
    "    if protocol is None:\n",
    "        protocol = pickle.HIGHEST_PROTOCOL\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {col} - (Save_protocol={protocol}).pkl'\n",
    "\n",
    "    print('+'*30)\n",
    "    print(f'{\"=\"*10} Loading Xy from previous for {col} {\"=\"*10}')\n",
    "    print('+'*30)\n",
    "    # Read all dfs\n",
    "    for file_path in glob.glob(f'{models_save_path}*{path_suffix}'):\n",
    "        file_name = file_path.split(f'{models_save_path}')[-1].split(path_suffix)[0]\n",
    "        print(f'Loading {file_name} from {file_path}')\n",
    "        if path_suffix in file_path and 'df_' in file_name and 'cv_results' not in file_name:\n",
    "            data_dict[file_name] = pd.read_pickle(file_path)\n",
    "\n",
    "    # Train data\n",
    "    df_train_data = data_dict['df_train_data']\n",
    "    X_train = df_train_data['X_train'].values\n",
    "    y_train = df_train_data['y_train'].values\n",
    "    # Test data\n",
    "    df_test_data = data_dict['df_test_data']\n",
    "    X_test = df_test_data['X_test'].values\n",
    "    y_test = df_test_data['y_test'].values\n",
    "    # Val data\n",
    "    df_val_data = data_dict['df_val_data']\n",
    "    X_val = df_val_data['X_val'].values\n",
    "    y_val = df_val_data['y_val'].values\n",
    "\n",
    "    print(f'Done loading Xy from previous for {col}!')\n",
    "\n",
    "    # Get class weights\n",
    "    (\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "        val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "    ) = get_class_weights(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        X_val, y_val,\n",
    "    )\n",
    "\n",
    "    # Print info\n",
    "    print_Xy(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        X_val, y_val,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "        val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "    )\n",
    "    return (\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        X_val, y_val,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "        val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b78bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna hyperparameter tuning\n",
    "# https://huggingface.co/docs/transformers/v4.27.2/en/hpo_train#hyperparameter-search-using-trainer-api\n",
    "def optuna_hp_space(trial):\n",
    "    return {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-6, 1e-4, log=True),\n",
    "        'num_train_epochs': trial.suggest_int('num_train_epochs', 1, 5),\n",
    "        'per_device_train_batch_size': trial.suggest_categorical('per_device_train_batch_size', [4, 8, 16, 32, 64, 128]),\n",
    "        'per_device_eval_batch_size': trial.suggest_categorical('per_device_eval_batch_size', [4, 8, 16, 32, 64, 128]),\n",
    "        'warmup_steps': trial.suggest_int('warmup_steps', 0, 500),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-12, 1e-1, log=True),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c7abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute objective for hyperparameter tuning\n",
    "# https://github.com/huggingface/transformers/issues/13019\n",
    "def compute_objective(metrics_dict):\n",
    "    return metrics_dict['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7c888f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_with_y_pred(\n",
    "    y_labels, y_pred,\n",
    "    pos_label=None, labels=None, zero_division=None, alpha=None\n",
    "):\n",
    "    if pos_label is None:\n",
    "        pos_label = 1\n",
    "    if labels is None:\n",
    "        labels = np.unique(y_pred)\n",
    "    if zero_division is None:\n",
    "        zero_division = 0\n",
    "    if alpha is None:\n",
    "        alpha = 0.1\n",
    "\n",
    "    print('Computing metrics using y_pred.')\n",
    "    # Using y_pred\n",
    "    explained_variance = metrics.explained_variance_score(y_labels, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_labels, y_pred)\n",
    "    balanced_accuracy = metrics.balanced_accuracy_score(y_labels, y_pred)\n",
    "    precision = metrics.precision_score(y_labels, y_pred, pos_label=pos_label, labels=labels, zero_division=zero_division)\n",
    "    recall = metrics.recall_score(y_labels, y_pred, pos_label=pos_label, labels=labels, zero_division=zero_division)\n",
    "    f1 = metrics.f1_score(y_labels, y_pred, pos_label=pos_label,labels=labels, zero_division=zero_division)\n",
    "    mcc = metrics.matthews_corrcoef(y_labels, y_pred)\n",
    "    fm = metrics.fowlkes_mallows_score(y_labels, y_pred)\n",
    "    r2 = metrics.r2_score(y_labels, y_pred)\n",
    "    kappa = metrics.cohen_kappa_score(y_labels, y_pred, labels=labels)\n",
    "    gmean_iba = imblearn.metrics.make_index_balanced_accuracy(alpha=alpha, squared=True)(geometric_mean_score)\n",
    "    gmean = gmean_iba(y_labels, y_pred)\n",
    "    report = metrics.classification_report(y_labels, y_pred, labels=labels, zero_division=zero_division)\n",
    "    imblearn_report = classification_report_imbalanced(y_labels, y_pred, labels=labels, zero_division=zero_division)\n",
    "    cm = metrics.confusion_matrix(y_labels, y_pred, labels=labels)\n",
    "    cm_normalized = metrics.confusion_matrix(y_labels, y_pred, normalize='true', labels=labels)\n",
    "\n",
    "    return (\n",
    "        explained_variance, accuracy, balanced_accuracy, precision,\n",
    "        recall, f1, mcc, fm, r2, kappa, gmean, report, imblearn_report, cm, cm_normalized\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e2dcb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_with_y_pred_prob(\n",
    "    y_labels, y_pred_prob,\n",
    "    pos_label=None\n",
    "):\n",
    "    if pos_label is None:\n",
    "        pos_label = 1\n",
    "\n",
    "    print('Computing metrics using y_pred_prob.')\n",
    "    average_precision = metrics.average_precision_score(y_labels, y_pred_prob)\n",
    "    roc_auc = metrics.roc_auc_score(y_labels, y_pred_prob)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_labels, y_pred_prob, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    loss = metrics.log_loss(y_labels, y_pred_prob)\n",
    "    precision_pr, recall_pr, threshold_pr = metrics.precision_recall_curve(y_labels, y_pred_prob, pos_label=1)\n",
    "\n",
    "    return (\n",
    "        average_precision, roc_auc, auc,\n",
    "        fpr, tpr, threshold, loss,\n",
    "        precision_pr, recall_pr, threshold_pr\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea5ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_all(\n",
    "    y_labels, y_pred, y_pred_prob\n",
    "):\n",
    "    # Get metrics\n",
    "    print('='*20)\n",
    "    # Using y_pred\n",
    "    if y_pred:\n",
    "        print('-'*20)\n",
    "        (\n",
    "            explained_variance, accuracy, balanced_accuracy, precision,\n",
    "            recall, f1, mcc, fm, r2, kappa, gmean, report, imblearn_report, cm, cm_normalized\n",
    "        ) = compute_metrics_with_y_pred(\n",
    "            y_labels, y_pred\n",
    "        )\n",
    "    # Using y_pred_prob\n",
    "    if y_pred_prob:\n",
    "        print('-'*20)\n",
    "        (\n",
    "            average_precision, roc_auc, auc,\n",
    "            fpr, tpr, threshold, loss,\n",
    "            precision_pr, recall_pr, threshold_pr\n",
    "        ) = compute_metrics_with_y_pred_prob(\n",
    "            y_labels, y_pred_prob\n",
    "        )\n",
    "\n",
    "    # Place metrics into dict\n",
    "    print('-'*20)\n",
    "    print('Appending metrics to dict.')\n",
    "    metrics_dict = {\n",
    "        # f'{scoring.title()} Best Score': float(best_train_score),\n",
    "        # f'{scoring.title()} Best Threshold': threshold,\n",
    "        # 'Train - Mean Cross Validation Score': float(cv_train_scores),\n",
    "        # f'Train - Mean Cross Validation - {scoring.title()}': float(cv_train_recall),\n",
    "        # f'Train - Mean Explained Variance - {scoring.title()}': float(cv_train_explained_variance_recall),\n",
    "        # 'Test - Mean Cross Validation Score': float(cv_test_scores),\n",
    "        # f'Test - Mean Cross Validation - {scoring.title()}': float(cv_test_recall),\n",
    "        # f'Test - Mean Explained Variance - {scoring.title()}': float(cv_test_explained_variance_recall),\n",
    "        'Explained Variance': float(explained_variance),\n",
    "        'Accuracy': float(accuracy),\n",
    "        'Balanced Accuracy': float(balanced_accuracy),\n",
    "        'Precision': float(precision),\n",
    "        'Average Precision': float(average_precision),\n",
    "        'Recall': float(recall),\n",
    "        'F1-score': float(f1),\n",
    "        'Matthews Correlation Coefficient': float(mcc),\n",
    "        'Fowlkes–Mallows Index': float(fm),\n",
    "        'R2 Score': float(r2),\n",
    "        'ROC': float(roc_auc),\n",
    "        'AUC': float(auc),\n",
    "        'Log Loss/Cross Entropy': float(loss),\n",
    "        'Cohen’s Kappa': float(kappa),\n",
    "        'Geometric Mean': float(gmean),\n",
    "        'Classification Report': report,\n",
    "        'Imbalanced Classification Report': imblearn_report,\n",
    "        'Confusion Matrix': cm,\n",
    "        'Normalized Confusion Matrix': cm_normalized,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_prob': y_pred_prob,\n",
    "    }\n",
    "\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28661d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_metrics_dict(metrics_dict, prefix_to_remove):\n",
    "    for metric_name in list(metrics_dict):\n",
    "        if metric_name.startswith(prefix_to_remove):\n",
    "            new_metric_name = ' '.join(metric_name.split(prefix_to_remove)[-1].split('_')).strip()\n",
    "        if not new_metric_name[0].isupper():\n",
    "            new_metric_name = new_metric_name.title()\n",
    "        if new_metric_name == 'Loss':\n",
    "            metrics_dict['Log Loss/Cross Entropy'] = metrics_dict.pop(metric_name)\n",
    "        else:\n",
    "            metrics_dict[new_metric_name] = metrics_dict.pop(metric_name)\n",
    "\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f77d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get y_pred and y_pred_prob\n",
    "def preprocess_logits_for_metrics_y_pred_prob(y_pred_logits, y_labels):\n",
    "\n",
    "    print('-'*20)\n",
    "    print(f'Preprocessing y_pred logits and labels for {col}:')\n",
    "    print('-'*20)\n",
    "\n",
    "    if isinstance(y_pred_logits, tuple):\n",
    "        y_pred_logits = y_pred_logits[0]\n",
    "\n",
    "    if not torch.is_tensor(y_pred_logits):\n",
    "        y_pred_logits_tensor = torch.tensor(y_pred_logits, device=device)\n",
    "    else:\n",
    "        y_pred_logits_tensor = y_pred_logits.to(device)\n",
    "\n",
    "    print(f'y_pred_logits shape: {y_pred_logits_tensor.shape}, {y_pred_logits_tensor.dtype}')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Get y_pred_prob\n",
    "    # https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop\n",
    "    print('-'*20)\n",
    "    print('Getting y_pred_prob through softmax of y_pred_logits.')\n",
    "    try:\n",
    "        y_pred_prob_array = torch.nn.functional.softmax(y_pred_logits_tensor, dim=-1).cpu().numpy()\n",
    "        print('Using torch.nn.functional.softmax.')\n",
    "    except Exception:\n",
    "        y_pred_prob_array = scipy.special.softmax(y_pred_logits, axis=-1)\n",
    "        print('Using scipy.special.softmax.')\n",
    "\n",
    "    print(f'y_pred_prob_array shape: {y_pred_prob_array.shape}, {y_pred_prob_array.dtype}')\n",
    "\n",
    "    y_pred_logits_tensor.detach()\n",
    "\n",
    "    return torch.tensor(y_pred_prob_array, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "935f15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get y_pred and y_pred_prob\n",
    "def preprocess_logits_for_metrics_y_pred(y_pred_prob_array):\n",
    "\n",
    "    # https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d\n",
    "    print('-'*20)\n",
    "    print(f'Getting y_pred from y_pred_prob for {col}:')\n",
    "    print('-'*20)\n",
    "\n",
    "    if isinstance(y_pred_prob_array, tuple):\n",
    "        y_pred_prob_array = y_pred_prob_array[0]\n",
    "\n",
    "    if not torch.is_tensor(y_pred_prob_array):\n",
    "        y_pred_prob_tensor = torch.tensor(y_pred_prob_array, device=device)\n",
    "    else:\n",
    "        y_pred_prob_tensor = y_pred_prob_array.to(device)\n",
    "\n",
    "    print(f'y_pred_prob_array shape: {y_pred_prob_tensor.shape}. {y_pred_prob_tensor.dtype}')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Get y_pred\n",
    "    print('-'*20)\n",
    "    print('Getting y_pred through argmax of y_pred_prob.')\n",
    "    try:\n",
    "        y_pred_array = torch.argmax(y_pred_prob_tensor, axis=-1).cpu().numpy()\n",
    "        print('Using torch.argmax.')\n",
    "    except Exception:\n",
    "        y_pred_array = y_pred_prob.argmax(axis=-1)\n",
    "        print('Using np.argmax.')\n",
    "\n",
    "    print(f'y_pred_array shape: {y_pred_array.shape}')\n",
    "\n",
    "    return y_pred_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81d6916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(\n",
    "    predicted_results_from_eval,\n",
    "):\n",
    "    y_pred_prob_array, y_labels_array = predicted_results_from_eval\n",
    "\n",
    "    # Get y_pred_prob\n",
    "    (\n",
    "        y_pred_array\n",
    "    ) = preprocess_logits_for_metrics_y_pred(y_pred_prob_array)\n",
    "\n",
    "    # Get the the whole of the last column, which is the  probability of 1, and flatten to list\n",
    "    print('-'*20)\n",
    "    print('Flattening y_labels , y_pred_array, and y_pred_prob_array, then extracting probabilities of 1.')\n",
    "    y_labels = y_labels_array.flatten().tolist()\n",
    "    y_pred = y_pred_array.flatten().tolist()\n",
    "    y_pred_prob = y_pred_prob_array[:, -1].flatten().tolist()\n",
    "    print(f'y_pred_prob length: {len(y_pred_prob)}')\n",
    "    print(f'y_labels length: {len(y_labels)}')\n",
    "    print('-'*20)\n",
    "\n",
    "    return compute_metrics_all(y_labels, y_pred, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a625b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get y_pred and y_pred_prob\n",
    "def preprocess_logits_for_metrics_in_compute_metrics(y_pred_logits):\n",
    "\n",
    "    # Get y_pred\n",
    "    print('-'*20)\n",
    "    y_pred_logits_tensor = torch.tensor(y_pred_logits, device=device)\n",
    "    print('Getting y_pred through argmax of y_pred_logits...')\n",
    "    try:\n",
    "        y_pred_array = torch.argmax(y_pred_logits_tensor, axis=-1).cpu().numpy()\n",
    "        print('Using torch.argmax.')\n",
    "    except Exception:\n",
    "        y_pred_array = y_pred_logits.argmax(axis=-1)\n",
    "        print('Using np.argmax.')\n",
    "    print(f'y_pred_array shape: {y_pred_array.shape}')\n",
    "    print('-'*20)\n",
    "    print('Flattening y_pred...')\n",
    "    y_pred = [bert_label2id[l] for l in y_pred_array.flatten().tolist()]\n",
    "    print(f'y_pred length: {len(y_pred)}')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Get y_pred_prob\n",
    "    print('-'*20)\n",
    "    print('Getting y_pred_prob through softmax of y_pred_logits...')\n",
    "    try:\n",
    "        y_pred_prob_array = torch.nn.functional.softmax(y_pred_logits_tensor, dim=-1).cpu().numpy()\n",
    "        print('Using torch.nn.functional.softmax.')\n",
    "    except Exception:\n",
    "        y_pred_prob_array = scipy.special.softmax(y_pred_logits, axis=-1)\n",
    "        print('Using scipy.special.softmax.')\n",
    "    # from: https://discuss.huggingface.co/t/different-results-predicting-from-trainer-and-model/12922\n",
    "    assert all(y_pred_prob_array.argmax(axis=-1) == y_pred_array), 'Argmax of y_pred_prob_array does not match y_pred_array.'\n",
    "    print(f'y_pred_prob shape: {y_pred_prob_array.shape}')\n",
    "    print('-'*20)\n",
    "    print('Flattening y_pred_prob and extracting probabilities of 1...')\n",
    "    y_pred_prob = y_pred_prob_array[:, -1].flatten().tolist()\n",
    "    print(f'y_pred length: {len(y_pred_prob)}')\n",
    "    print('-'*20)\n",
    "\n",
    "    y_pred_logits_tensor.detach()\n",
    "\n",
    "    return (\n",
    "        y_pred_array, y_pred, y_pred_prob_array, y_pred_prob\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ab4fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_from_logits(\n",
    "    predicted_results_from_eval,\n",
    "):\n",
    "    # Get predictions\n",
    "    print('-'*20)\n",
    "    print(f'Getting y_pred logits and ids for {col}:')\n",
    "    y_pred_logits, y_labels = predicted_results_from_eval\n",
    "    print(f'y_pred_logits shape: {y_pred_logits.shape}')\n",
    "    print(f'y shape: {y_labels.shape}')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Get y_test_pred and y_test_pred_prob\n",
    "    (\n",
    "        y_pred_array, y_pred, y_pred_prob_array, y_pred_prob\n",
    "    ) = preprocess_logits_for_metrics_in_compute_metrics(y_pred_logits)\n",
    "\n",
    "    return compute_metrics_all(y_labels, y_pred, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c44994c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(\n",
    "    metrics_dict, df_metrics,\n",
    "    col, vectorizer_name, classifier_name\n",
    "):\n",
    "    # Print metrics\n",
    "    print('=' * 20)\n",
    "    print('~' * 20)\n",
    "    print(' Metrics:')\n",
    "    print('~' * 20)\n",
    "    print(f'Classification Report:\\n {metrics_dict[\"Classification Report\"]}')\n",
    "    print('-' * 20)\n",
    "    for metric_name, metric_value in metrics_dict.items():\n",
    "        if metric_name not in ['Runtime', 'Samples Per Second', 'Steps Per Second']:\n",
    "            with contextlib.suppress(TypeError, ValueError):\n",
    "                metric_value = float(metric_value)\n",
    "            if isinstance(metric_name, (int, float)):\n",
    "                df_metrics.loc[\n",
    "                    (classifier_name), (col, vectorizer_name, metric_name)\n",
    "                ] = metric_value\n",
    "                print(f'{metric_name}: {round(metric_value, 2)}')\n",
    "            else:\n",
    "                df_metrics.loc[\n",
    "                    (classifier_name), (col, vectorizer_name, metric_name)\n",
    "                ] = str(metric_value)\n",
    "                print(f'{metric_name}: {metric_value}')\n",
    "            print('-' * 20)\n",
    "\n",
    "    print('=' * 20)\n",
    "\n",
    "    return df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93960eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to place Xy data in df and save\n",
    "def save_Xy_estimator(\n",
    "    X_train, y_train, train_dataset,\n",
    "    X_test, y_test, y_test_pred, y_test_pred_prob, test_dataset,\n",
    "    X_val, y_val, y_val_pred, y_val_pred_prob, val_dataset,\n",
    "    estimator, accelerator, eval_metrics_dict, test_metrics_dict,\n",
    "    col, vectorizer_name, classifier_name,\n",
    "    results_save_path=results_save_path,\n",
    "    method=method, done_xy_save_path=done_xy_save_path,\n",
    "    path_suffix=None, data_dict=None,\n",
    "    compression=None, protocol=None,\n",
    "):\n",
    "    if data_dict is None:\n",
    "        data_dict = {}\n",
    "    if compression is None:\n",
    "        compression = False\n",
    "    if protocol is None:\n",
    "        protocol = pickle.HIGHEST_PROTOCOL\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {col} - {vectorizer_name} + {classifier_name} (Save_protocol={protocol}).pkl'\n",
    "\n",
    "    # Check predicted data\n",
    "    check_consistent_length(X_train, y_train, train_dataset)\n",
    "    check_consistent_length(X_test, y_test, y_test_pred, y_test_pred_prob, test_dataset)\n",
    "    check_consistent_length(X_val, y_val, y_val_pred, y_val_pred_prob, val_dataset)\n",
    "\n",
    "    # Make data dict\n",
    "    data_dict['Estimator'] = estimator\n",
    "    data_dict['accelerator'] = accelerator\n",
    "    data_dict['eval_metrics_dict'] = eval_metrics_dict\n",
    "    data_dict['test_metrics_dict'] = test_metrics_dict\n",
    "\n",
    "    # Make df_train_data\n",
    "    data_dict['df_train_data'] = pd.DataFrame(\n",
    "        {\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "            'train_dataset': train_dataset,\n",
    "        },\n",
    "    )\n",
    "    # Make df_test_data\n",
    "    data_dict['df_test_data'] = pd.DataFrame(\n",
    "        {\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'y_test_pred': y_test_pred,\n",
    "            'y_test_pred_prob': y_test_pred_prob,\n",
    "            'test_dataset': test_dataset,\n",
    "        },\n",
    "    )\n",
    "    # Make df_val_data\n",
    "    data_dict['df_val_data'] = pd.DataFrame(\n",
    "        {\n",
    "            'X_val': X_val,\n",
    "            'y_val': y_val,\n",
    "            'y_val_pred': y_val_pred,\n",
    "            'y_val_pred_prob': y_val_pred_prob,\n",
    "            'val_dataset': val_dataset,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Save files\n",
    "    print('='*20)\n",
    "    saved_files_list = []\n",
    "    for file_name, file_ in data_dict.items():\n",
    "        save_path = (\n",
    "            done_xy_save_path\n",
    "            if file_name not in ['Estimator', 'accelerator']\n",
    "            else results_save_path\n",
    "        )\n",
    "        print(f'Saving {file_name} at {save_path}')\n",
    "        if not isinstance(file_, pd.DataFrame) and file_name == 'Estimator' and 'df_' not in file_name and 'metrics_dict' not in file_name:\n",
    "            # Save as .model\n",
    "            file_.save_model(f'{save_path}{method} {file_name}{path_suffix.replace(\"pkl\", \"model\")}')\n",
    "            saved_files_list.append(file_name)\n",
    "        elif not isinstance(file_, pd.DataFrame) and file_name == 'accelerator' and 'df_' not in file_name and 'metrics_dict' not in file_name:\n",
    "            file_.save(estimator.state, f'{save_path}{method} Estimator{path_suffix.replace(\"pkl\", \"model\")}/accelerator')\n",
    "            saved_files_list.append(file_name)\n",
    "        elif isinstance(file_, dict) and file_name != 'Estimator' and file_name != 'accelerator' and 'df_' not in file_name and 'metrics_dict' in file_name:\n",
    "            with open(f'{save_path}{method} {file_name}{path_suffix}', 'wb') as f:\n",
    "                pickle.dump(file_, f, protocol=protocol)\n",
    "            saved_files_list.append(file_name)\n",
    "        elif isinstance(file_, pd.DataFrame) and file_name != 'Estimator' and file_name != 'accelerator' and 'df_' in file_name and 'metrics_dict' not in file_name:\n",
    "            file_.to_pickle(\n",
    "                f'{save_path}{method} {file_name}{path_suffix}', protocol=protocol\n",
    "            )\n",
    "            saved_files_list.append(file_name)\n",
    "\n",
    "    assert set(data_dict.keys()) == set(saved_files_list), f'Not all files were saved! Missing: {set(data_dict.keys()) ^ set(saved_files_list)}'\n",
    "    print(f'Done saving Xy, labels and estimator!\\n{list(data_dict.keys())}')\n",
    "    print('='*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fb3f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that all classifiers were used\n",
    "def assert_all_classifiers_used(\n",
    "    estimators_list=None, used_classifiers=None, results_save_path=results_save_path, method=method, classifiers_pipe=transformers_pipe,\n",
    "):\n",
    "    if estimators_list is None:\n",
    "        estimators_list = []\n",
    "    if used_classifiers is None:\n",
    "        used_classifiers = []\n",
    "\n",
    "    for estimator_path in glob.glob(f'{results_save_path}{method} Estimator - *.pkl'):\n",
    "        classifier_name = estimator_path.split(f'{results_save_path}{method} ')[1].split(' + ')[1].split(' (Save_protocol=')[0]\n",
    "        used_classifiers.append(classifier_name)\n",
    "\n",
    "    assert set(list(classifiers_pipe.keys())) == set(used_classifiers), f'Not all classifiers were used!\\nAvaliable Classifiers:\\n{set(list(classifiers_pipe.keys()))}\\nUsed Classifiers:\\n{set(used_classifiers)}\\nLeftout Classifiers:\\n{set(list(classifiers_pipe.keys())) ^ set(used_classifiers)}'\n",
    "    print('All classifiers were used!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f64ab3",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fe8e7a",
   "metadata": {},
   "source": [
    "### READ DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7fbe29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded with shape: (5947, 68)\n"
     ]
    }
   ],
   "source": [
    "with open(f'{data_dir}df_manual_len.txt', 'r') as f:\n",
    "    df_manual_len = int(f.read())\n",
    "\n",
    "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_training.pkl')\n",
    "assert len(df_manual) == df_manual_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_manual_len} BUT IS OF LENGTH {len(df_manual)}'\n",
    "print(f'Dataframe loaded with shape: {df_manual.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ea2f60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Starting!\n",
      "########################################\n",
      "Searching for existing estimators in directory:\n",
      "/Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "============================== TRAINING DATASET OF LENGTH 5947 ON WARMTH ==============================\n",
      "--------------------\n",
      "classifiers to be used (2):\n",
      "['BertForSequenceClassification', 'GPT2ForSequenceClassification']\n",
      "Splitting data.\n",
      "====================\n",
      "Splitting data into training, testing, and validation sets:\n",
      "Ratios: train_size = 0.75, test size = 0.1, validation size = 0.15\n",
      "DF length: 5928\n",
      "Done splitting data into training and testing sets.\n",
      "====================\n",
      "Training set shape: (4446,)\n",
      "----------\n",
      "Training set example:\n",
      "Understand, advocate, and embody the Netflix culture and team goals.\n",
      "~~~~~~~~~~\n",
      "Testing set shape: (593,)\n",
      "----------\n",
      "Testing set example:\n",
      "They will coach you, inspire you, introduce you to their network and share their knowledge and insights with you.\n",
      "~~~~~~~~~~\n",
      "Validation set shape: (889,)\n",
      "----------\n",
      "Validation set example:\n",
      "The Ideal Candidate:\n",
      "~~~~~~~~~~\n",
      "Training data class weights:\n",
      "Ratio = 0.37 (0 = 0.69, 1 = 1.85)\n",
      "----------\n",
      "Testing data class weights:\n",
      "Ratio = 0.29 (0 = 0.64, 1 = 2.23)\n",
      "----------\n",
      "Validation data class weights:\n",
      "Ratio = 0.46 (0 = 0.73, 1 = 1.58)\n",
      "====================\n",
      "====================\n",
      "Saving Xy df_train_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_train_data - Warmth - (Save_protocol=5).pkl\n",
      "Saving Xy df_test_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_test_data - Warmth - (Save_protocol=5).pkl\n",
      "Saving Xy df_val_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_val_data - Warmth - (Save_protocol=5).pkl\n",
      "Done saving Xy!\n",
      "['df_train_data', 'df_test_data', 'df_val_data']\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Encoding training, testing, and validation sets with tokenizer.from_pretrained using bert-base-uncased.\n",
      "Done encoding training, testing, and validation sets.\n",
      "====================\n",
      "Training set encodings example:\n",
      "[CLS] understand , advocate , and em ##body the netflix culture and team goals . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "~~~~~~~~~~\n",
      "Testing set encodings example:\n",
      "[CLS] they will coach you , inspire you , introduce you to their network and share their knowledge and insights with you . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "~~~~~~~~~~\n",
      "Validation set encodings example:\n",
      "[CLS] the ideal candidate : [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "====================\n",
      "--------------------\n",
      "==============================\n",
      "============================== Initializing Trainer using BERTBASEUNCASED + BertForSequenceClassification ==============================\n",
      "++++++++++++++++++++++++++++++\n",
      "--------------------\n",
      "Passing data and arguments to Trainer.\n",
      "--------------------\n",
      "Starting training for Warmth using BertForSequenceClassification.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c705bc1f1754e0e9ec015be80bd8368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/834 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_88184/193241225.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx], device=device).clone().detach() for key, val in self.encodings.items()}\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                     \n",
      "  0%|          | 0/2 [32:38<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3615, 'learning_rate': 2.2752043596730245e-05, 'epoch': 1.8}\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cacfc6bcd24cefa7a2ece21bf9a9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n",
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([20, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (20, 2), float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                     \n",
      "  0%|          | 0/2 [32:54<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Preprocessing y_pred logits and labels for Warmth:\n",
      "--------------------\n",
      "y_pred_logits shape: torch.Size([9, 2]), torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits.\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob_array shape: (9, 2), float32\n",
      "--------------------\n",
      "Getting y_pred from y_pred_prob for Warmth:\n",
      "--------------------\n",
      "y_pred_prob_array shape: torch.Size([889, 2]). torch.float32\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred through argmax of y_pred_prob.\n",
      "Using torch.argmax.\n",
      "y_pred_array shape: (889,)\n",
      "--------------------\n",
      "Flattening y_labels , y_pred_array, and y_pred_prob_array, then extracting probabilities of 1.\n",
      "y_pred_prob length: 889\n",
      "y_labels length: 889\n",
      "--------------------\n",
      "====================\n",
      "--------------------\n",
      "Computing metrics using y_pred.\n",
      "--------------------\n",
      "Computing metrics using y_pred_prob.\n",
      "--------------------\n",
      "Appending metrics to dict.\n",
      "{'eval_loss': 0.35031774640083313, 'eval_Explained Variance': 0.3703877130548794, 'eval_Accuracy': 0.8638920134983127, 'eval_Balanced Accuracy': 0.8430739604794906, 'eval_Precision': 0.7836879432624113, 'eval_Average Precision': 0.8504687991254654, 'eval_Recall': 0.7864768683274022, 'eval_F1-score': 0.7850799289520426, 'eval_Matthews Correlation Coefficient': 0.685494226983462, 'eval_Fowlkes–Mallows Index': 0.7922981026344733, 'eval_R2 Score': 0.3703818598988575, 'eval_ROC': 0.9211521352313168, 'eval_AUC': 0.9211521352313168, 'eval_Log Loss/Cross Entropy': 0.3503177381552593, 'eval_Cohen’s Kappa': 0.6854919113626861, 'eval_Geometric Mean': 0.7075704719985016, 'eval_Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.90      0.90      0.90       608\\n           1       0.78      0.79      0.79       281\\n\\n    accuracy                           0.86       889\\n   macro avg       0.84      0.84      0.84       889\\nweighted avg       0.86      0.86      0.86       889\\n', 'eval_Imbalanced Classification Report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n          0       0.90      0.90      0.79      0.90      0.84      0.72       608\\n          1       0.78      0.79      0.90      0.79      0.84      0.70       281\\n\\navg / total       0.86      0.86      0.82      0.86      0.84      0.71       889\\n', 'eval_Confusion Matrix': array([[547,  61],\n",
      "       [ 60, 221]]), 'eval_Normalized Confusion Matrix': array([[0.89967105, 0.10032895],\n",
      "       [0.21352313, 0.78647687]]), 'eval_y_pred': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1], 'eval_y_pred_prob': [0.0024248401168733835, 0.010333250276744366, 0.06711715459823608, 0.2755500078201294, 0.47736304998397827, 0.005546401720494032, 0.014473401941359043, 0.488275945186615, 0.018372761085629463, 0.9523971080780029, 0.047799549996852875, 0.6886382699012756, 0.010943451896309853, 0.2291690856218338, 0.0388038270175457, 0.005586469080299139, 0.4042882025241852, 0.9404007792472839, 0.015819063410162926, 0.4552682638168335, 0.834384024143219, 0.003434307174757123, 0.007151314523071051, 0.4837808609008789, 0.8691763877868652, 0.04264342039823532, 0.10666561126708984, 0.9328083992004395, 0.9310628175735474, 0.00335382716730237, 0.06619428843259811, 0.2380611002445221, 0.0032023414969444275, 0.00330324936658144, 0.004948030225932598, 0.0495116300880909, 0.0170294176787138, 0.040815167129039764, 0.02101612277328968, 0.0028904052451252937, 0.04305831715464592, 0.007929008454084396, 0.004613857716321945, 0.9137693047523499, 0.9468083381652832, 0.20728616416454315, 0.0021660595666617155, 0.952279269695282, 0.010925963521003723, 0.004411252215504646, 0.026917586103081703, 0.03222561627626419, 0.7438095808029175, 0.015410109423100948, 0.8462924361228943, 0.007727811578661203, 0.003760992083698511, 0.9076727628707886, 0.9300227165222168, 0.006345637142658234, 0.005964066833257675, 0.28786635398864746, 0.0027639998588711023, 0.004904548637568951, 0.24063289165496826, 0.03043523244559765, 0.17008309066295624, 0.01992182992398739, 0.7837547063827515, 0.024264315143227577, 0.008359936065971851, 0.022276902571320534, 0.012189260683953762, 0.907972514629364, 0.898042619228363, 0.008959615603089333, 0.9270996451377869, 0.7792834043502808, 0.005141112487763166, 0.8727886080741882, 0.889549732208252, 0.013482675887644291, 0.0024632529821246862, 0.482807457447052, 0.04034718498587608, 0.0032232499215751886, 0.834579586982727, 0.00873231515288353, 0.15436437726020813, 0.06044824793934822, 0.006711001507937908, 0.013011949136853218, 0.6968795657157898, 0.9505621194839478, 0.753803014755249, 0.007390665356069803, 0.9023749828338623, 0.0026434033643454313, 0.004955397918820381, 0.030333176255226135, 0.067610964179039, 0.762013852596283, 0.0025235211942344904, 0.07057733088731766, 0.037420853972435, 0.9515763521194458, 0.8303573727607727, 0.9365650415420532, 0.12372199445962906, 0.03911957889795303, 0.10002629458904266, 0.45166051387786865, 0.04374047368764877, 0.002924704924225807, 0.0048685697838664055, 0.10268856585025787, 0.003595965914428234, 0.6195768117904663, 0.947270929813385, 0.09586875885725021, 0.896521270275116, 0.002917269477620721, 0.8958570957183838, 0.01769063249230385, 0.028252385556697845, 0.9514924883842468, 0.7870574593544006, 0.893985390663147, 0.00674501433968544, 0.9033502340316772, 0.9398882389068604, 0.002858982188627124, 0.009569833055138588, 0.0103747034445405, 0.002721355063840747, 0.942513644695282, 0.01961132138967514, 0.049883097410202026, 0.9413179755210876, 0.22344481945037842, 0.020483501255512238, 0.005195567384362221, 0.02027849666774273, 0.0026405700482428074, 0.92377108335495, 0.8469688892364502, 0.9277024269104004, 0.15805117785930634, 0.0026268146466463804, 0.0028931384440511465, 0.060026656836271286, 0.004302293062210083, 0.2114049792289734, 0.0780288502573967, 0.9180923700332642, 0.9354623556137085, 0.014682922512292862, 0.8959672451019287, 0.0025714754592627287, 0.0023102026898413897, 0.11753468215465546, 0.09597350656986237, 0.9294739365577698, 0.05008545517921448, 0.6217480897903442, 0.03310199826955795, 0.006754838861525059, 0.06974957883358002, 0.011405282653868198, 0.03085445426404476, 0.02002331241965294, 0.8004554510116577, 0.9534651041030884, 0.9236288666725159, 0.8856426477432251, 0.006185164675116539, 0.002193434163928032, 0.9364610314369202, 0.02002331241965294, 0.15629686415195465, 0.012596934102475643, 0.9482269287109375, 0.018718359991908073, 0.009809126146137714, 0.9512309432029724, 0.01864035613834858, 0.7130318880081177, 0.9445611834526062, 0.003627271158620715, 0.9343631863594055, 0.0033648128155618906, 0.9363411068916321, 0.0021154433488845825, 0.9118887782096863, 0.003383027156814933, 0.6324387192726135, 0.9210567474365234, 0.026263482868671417, 0.843741774559021, 0.7505967020988464, 0.38483524322509766, 0.060026656836271286, 0.003092011669650674, 0.9385051727294922, 0.00923163816332817, 0.0032770149409770966, 0.004773391876369715, 0.006605504080653191, 0.007293457165360451, 0.0033424366265535355, 0.02437158115208149, 0.7624583840370178, 0.5137009024620056, 0.9336381554603577, 0.002838684478774667, 0.9413108229637146, 0.003093696665018797, 0.07116062939167023, 0.9444583058357239, 0.9502328634262085, 0.21918581426143646, 0.31880810856819153, 0.5757840275764465, 0.0712968185544014, 0.9432224035263062, 0.0032574571669101715, 0.9453722834587097, 0.9367906451225281, 0.046627480536699295, 0.007045033387839794, 0.005847730673849583, 0.9326666593551636, 0.03826340660452843, 0.4264793395996094, 0.026933781802654266, 0.0025960314087569714, 0.005701612215489149, 0.39649447798728943, 0.002570097567513585, 0.00474619260057807, 0.11471501737833023, 0.5565449595451355, 0.04855015501379967, 0.02233693189918995, 0.4808124005794525, 0.902590274810791, 0.9023435711860657, 0.05147761479020119, 0.002696165582165122, 0.7210248708724976, 0.7377853989601135, 0.008935479447245598, 0.9534375667572021, 0.008908149786293507, 0.7477351427078247, 0.8860722184181213, 0.3003377318382263, 0.9195788502693176, 0.7385458946228027, 0.003906242549419403, 0.003404169576242566, 0.08006562292575836, 0.0036384419072419405, 0.004731441847980022, 0.030360249802470207, 0.019723929464817047, 0.3887852132320404, 0.9433225393295288, 0.07507580518722534, 0.00265735131688416, 0.006836057640612125, 0.027387255802750587, 0.9475085735321045, 0.0951155573129654, 0.011278582736849785, 0.006635785568505526, 0.9426653385162354, 0.004415309987962246, 0.8943027257919312, 0.22178266942501068, 0.08253386616706848, 0.0026623059529811144, 0.9506329894065857, 0.0044455500319600105, 0.007366034667938948, 0.002261417219415307, 0.040777191519737244, 0.008643662557005882, 0.09686005860567093, 0.027303006500005722, 0.03285139426589012, 0.007661363109946251, 0.014774927869439125, 0.04562053829431534, 0.003487600712105632, 0.0028324376326054335, 0.006620736792683601, 0.8319881558418274, 0.9490296840667725, 0.08006562292575836, 0.003596046008169651, 0.9519287943840027, 0.9383686780929565, 0.00490880711004138, 0.003141698893159628, 0.8796147704124451, 0.012464780360460281, 0.002930718008428812, 0.08505824208259583, 0.01577642746269703, 0.0027907153125852346, 0.002627386711537838, 0.026827966794371605, 0.00304761016741395, 0.03543948382139206, 0.0037368275225162506, 0.025737350806593895, 0.9283832311630249, 0.0024373687338083982, 0.06476913392543793, 0.003963751252740622, 0.012069085612893105, 0.9130256175994873, 0.01748402789235115, 0.015990309417247772, 0.003633328713476658, 0.007822339423000813, 0.9255082607269287, 0.10249289870262146, 0.058466777205467224, 0.012398703955113888, 0.9400577545166016, 0.06654636561870575, 0.9430307149887085, 0.13919690251350403, 0.06730891019105911, 0.032273903489112854, 0.09002117067575455, 0.018472712486982346, 0.005972148384898901, 0.01115462090820074, 0.9442958831787109, 0.05043322220444679, 0.004714054986834526, 0.02689753845334053, 0.9463995099067688, 0.002728712745010853, 0.004501474555581808, 0.019131913781166077, 0.6846568584442139, 0.09012910723686218, 0.032273903489112854, 0.32784199714660645, 0.020612094551324844, 0.0030436995439231396, 0.950645923614502, 0.003947610501199961, 0.9169908761978149, 0.16248062252998352, 0.17493374645709991, 0.011205232702195644, 0.03213103488087654, 0.9401993155479431, 0.004777989350259304, 0.8860606551170349, 0.9309371709823608, 0.2580149173736572, 0.002907239133492112, 0.9379302263259888, 0.008952867239713669, 0.005145399831235409, 0.014251421205699444, 0.9146050214767456, 0.004380621947348118, 0.47736304998397827, 0.006767574232071638, 0.06043029949069023, 0.05752180516719818, 0.009853153489530087, 0.5623853802680969, 0.8577159643173218, 0.9381999373435974, 0.05576169118285179, 0.9437294006347656, 0.010318915359675884, 0.0029602774884551764, 0.00801557581871748, 0.020428458228707314, 0.0029887945856899023, 0.015514340251684189, 0.0034271629992872477, 0.1135316714644432, 0.06244893744587898, 0.0025578478816896677, 0.8591933250427246, 0.07399073243141174, 0.9419795870780945, 0.9404295682907104, 0.9035784602165222, 0.926206648349762, 0.9471901655197144, 0.8257908225059509, 0.0029866984114050865, 0.9077081084251404, 0.946811854839325, 0.033466748893260956, 0.07854869216680527, 0.23700928688049316, 0.0022154543548822403, 0.016077999025583267, 0.020152604207396507, 0.02607055939733982, 0.7688639163970947, 0.00470400508493185, 0.8693492412567139, 0.9520278573036194, 0.0036384419072419405, 0.005631270818412304, 0.30049416422843933, 0.023495683446526527, 0.002762655494734645, 0.9223480820655823, 0.003601485164836049, 0.0026429572608321905, 0.9317739605903625, 0.00306494883261621, 0.9447790384292603, 0.5468593835830688, 0.9366739392280579, 0.21604543924331665, 0.46522408723831177, 0.9180923700332642, 0.08666662871837616, 0.052640557289123535, 0.9248430132865906, 0.9406411647796631, 0.0103747034445405, 0.0033058517146855593, 0.9247863292694092, 0.004364152904599905, 0.03543948382139206, 0.08758074045181274, 0.9460655450820923, 0.002539224922657013, 0.01868511736392975, 0.007280607707798481, 0.0043531195260584354, 0.2457824945449829, 0.005782474298030138, 0.0062522878870368, 0.0032999964896589518, 0.010046789422631264, 0.6328141689300537, 0.03310199826955795, 0.2945064902305603, 0.8913883566856384, 0.00347298476845026, 0.18307943642139435, 0.50020432472229, 0.43558698892593384, 0.1812426745891571, 0.37978529930114746, 0.007064781617373228, 0.008081638254225254, 0.038643766194581985, 0.003947610501199961, 0.004955397918820381, 0.06019498035311699, 0.017541436478495598, 0.8216082453727722, 0.0025334234815090895, 0.8549443483352661, 0.7862749099731445, 0.8490896821022034, 0.3608431816101074, 0.7874519228935242, 0.052830860018730164, 0.9458596706390381, 0.8753171563148499, 0.024340428411960602, 0.008399121463298798, 0.9525554180145264, 0.00794033333659172, 0.08297531306743622, 0.05263489857316017, 0.38251540064811707, 0.002223824616521597, 0.0035191297065466642, 0.8015046715736389, 0.9147149920463562, 0.9225637912750244, 0.028786636888980865, 0.004955397918820381, 0.8782045245170593, 0.2153540700674057, 0.1447717845439911, 0.007388639729470015, 0.6328141689300537, 0.05076419934630394, 0.015846185386180878, 0.9465961456298828, 0.047672051936388016, 0.8703752756118774, 0.6150301694869995, 0.3862009048461914, 0.3679414689540863, 0.003704383037984371, 0.033696163445711136, 0.042872097343206406, 0.00411666976287961, 0.4476962089538574, 0.0045381831005215645, 0.046215977519750595, 0.009995471686124802, 0.8817166090011597, 0.884127140045166, 0.5179170370101929, 0.9268668293952942, 0.6875690817832947, 0.05837056040763855, 0.05600115656852722, 0.005146446637809277, 0.00725325383245945, 0.5337100028991699, 0.006755385547876358, 0.012951529584825039, 0.9458867311477661, 0.002545935334637761, 0.9272750020027161, 0.02773629128932953, 0.06881420314311981, 0.6112973093986511, 0.5422869920730591, 0.10517331212759018, 0.0022143330425024033, 0.0027764877304434776, 0.008677538484334946, 0.004418724216520786, 0.0483105406165123, 0.006659438833594322, 0.9483848214149475, 0.9204113483428955, 0.008295479230582714, 0.907972514629364, 0.017461517825722694, 0.9318009614944458, 0.0479079894721508, 0.012386996299028397, 0.26480215787887573, 0.8805022239685059, 0.7900238037109375, 0.8839012980461121, 0.21876466274261475, 0.08792835474014282, 0.15420804917812347, 0.0026105642318725586, 0.23882392048835754, 0.02151697687804699, 0.08856914937496185, 0.7333963513374329, 0.45784106850624084, 0.07833489030599594, 0.0023615930695086718, 0.0065666926093399525, 0.03358172997832298, 0.0042676483280956745, 0.19822624325752258, 0.9490907788276672, 0.02298663929104805, 0.008146344684064388, 0.9490132331848145, 0.0037990363780409098, 0.0056153289042413235, 0.013324037194252014, 0.0023384883534163237, 0.6013774871826172, 0.10290560126304626, 0.0029445600230246782, 0.003117671236395836, 0.007285130210220814, 0.9437687397003174, 0.032018981873989105, 0.011802169494330883, 0.8595697283744812, 0.8397719264030457, 0.06267380714416504, 0.006782178767025471, 0.019081424921751022, 0.002170139690861106, 0.0036082849837839603, 0.9488668441772461, 0.012418420985341072, 0.03826998546719551, 0.2167407125234604, 0.013114430010318756, 0.9473863840103149, 0.002971956040710211, 0.0030786870047450066, 0.014137616381049156, 0.024011531844735146, 0.8768510818481445, 0.2088490128517151, 0.44370269775390625, 0.0036951270885765553, 0.8081610202789307, 0.11095138639211655, 0.9496280550956726, 0.9462356567382812, 0.9121367335319519, 0.1493067443370819, 0.010779439471662045, 0.20782826840877533, 0.04860519990324974, 0.10675154626369476, 0.7037675976753235, 0.9506397843360901, 0.0029887945856899023, 0.006957351230084896, 0.022210409864783287, 0.9199780225753784, 0.25952965021133423, 0.004501767456531525, 0.1297997534275055, 0.0043540410697460175, 0.05543088912963867, 0.007047298364341259, 0.9401172399520874, 0.00924928393214941, 0.9380515813827515, 0.9096007347106934, 0.1687495857477188, 0.0028730903286486864, 0.044896822422742844, 0.004393835552036762, 0.7256038188934326, 0.9447210431098938, 0.9360288381576538, 0.010283401235938072, 0.0036385732237249613, 0.49417832493782043, 0.007800952065736055, 0.002961817430332303, 0.35527440905570984, 0.00529815349727869, 0.7575554251670837, 0.08695139735937119, 0.03034793771803379, 0.946818470954895, 0.0030436720699071884, 0.0030553217511624098, 0.10741043835878372, 0.011693730019032955, 0.005500554572790861, 0.9538248181343079, 0.4008098244667053, 0.013307910412549973, 0.8858067989349365, 0.9243834614753723, 0.9499509930610657, 0.7014413475990295, 0.8817599415779114, 0.06333853304386139, 0.06069205701351166, 0.5063688158988953, 0.30454879999160767, 0.6066028475761414, 0.06846275925636292, 0.010360077023506165, 0.9332473874092102, 0.004335927311331034, 0.0028954145964235067, 0.36901095509529114, 0.8792212009429932, 0.08431803435087204, 0.006678075063973665, 0.005927738267928362, 0.37315669655799866, 0.49560365080833435, 0.9536076188087463, 0.020964503288269043, 0.01803852990269661, 0.2688373923301697, 0.028387444093823433, 0.028827928006649017, 0.9489624500274658, 0.02425641193985939, 0.8590222001075745, 0.0024216677993535995, 0.08094745129346848, 0.035957179963588715, 0.06055791303515434, 0.09476159512996674, 0.031006259843707085, 0.9029058814048767, 0.06391236931085587, 0.6515082716941833, 0.202920064330101, 0.9448840618133545, 0.014277489855885506, 0.9431232810020447, 0.0033762494567781687, 0.8904598355293274, 0.0030804553534835577, 0.11912272870540619, 0.0751790925860405, 0.14841848611831665, 0.008209291845560074, 0.003269930137321353, 0.880179762840271, 0.00529172969982028, 0.44775721430778503, 0.040047869086265564, 0.0026823447551578283, 0.9487027525901794, 0.8994483351707458, 0.036557864397764206, 0.0031504295766353607, 0.10980439931154251, 0.9413469433784485, 0.22479641437530518, 0.10932870209217072, 0.449853777885437, 0.2609251141548157, 0.006385142914950848, 0.0023471841122955084, 0.9393227696418762, 0.08755164593458176, 0.009230438619852066, 0.9379931688308716, 0.09114919602870941, 0.9316766858100891, 0.9437351822853088, 0.005509315058588982, 0.016389671713113785, 0.869337797164917, 0.03332645818591118, 0.9241225719451904, 0.019630245864391327, 0.004831982310861349, 0.005316206719726324, 0.5873353481292725, 0.006883036810904741, 0.0742693543434143, 0.03861301764845848, 0.7584670186042786, 0.016373392194509506, 0.39404046535491943, 0.002475025365129113, 0.9472431540489197, 0.07687845826148987, 0.26577049493789673, 0.008982457220554352, 0.8959672451019287, 0.08805699646472931, 0.021506566554307938, 0.9226014614105225, 0.886160671710968, 0.7272188067436218, 0.0021666616667062044, 0.8176456093788147, 0.908728301525116, 0.8952982425689697, 0.7387590408325195, 0.00338294031098485, 0.25749126076698303, 0.04445166513323784, 0.5505466461181641, 0.7694790363311768, 0.0040709394961595535, 0.2174319326877594, 0.04766860976815224, 0.29557839035987854, 0.9486350417137146, 0.2176460176706314, 0.9493749737739563, 0.0053225550800561905, 0.0051217940635979176, 0.006346491631120443, 0.04664070904254913, 0.9170825481414795, 0.0021666616667062044, 0.9513429403305054, 0.8465593457221985, 0.0036842203699052334, 0.016955342143774033, 0.9195526242256165, 0.9323800206184387, 0.9367198348045349, 0.0027944070752710104, 0.0030448066536337137, 0.2940957546234131, 0.8914561867713928, 0.70721036195755, 0.040336865931749344, 0.16896457970142365, 0.12763553857803345, 0.06526552140712738, 0.06619428843259811, 0.0029649115167558193, 0.9480856657028198, 0.9385691285133362, 0.14928942918777466, 0.00506201758980751, 0.28279146552085876, 0.012560557574033737, 0.0022624179255217314, 0.02695375308394432, 0.5798590183258057, 0.03371729701757431, 0.0038528037257492542, 0.07328825443983078, 0.4273715317249298, 0.9295748472213745, 0.04397577792406082, 0.9214527010917664, 0.11317871510982513, 0.08200317621231079, 0.003075518412515521, 0.008071915246546268, 0.06987690925598145, 0.08722209185361862, 0.07275725901126862, 0.1670832335948944, 0.8648900389671326, 0.9114862680435181, 0.28465932607650757, 0.0033877959940582514, 0.0028389596845954657, 0.008900045417249203, 0.45221227407455444, 0.9064894318580627, 0.018718359991908073, 0.9468305110931396, 0.8490896821022034, 0.003075518412515521, 0.9268929958343506, 0.9037729501724243, 0.003722802735865116, 0.5366523861885071, 0.03483710065484047, 0.0021944213658571243, 0.022062692791223526, 0.06413708627223969, 0.39649447798728943, 0.9269306063652039, 0.9368221163749695, 0.019081424921751022, 0.04234950616955757, 0.10678110271692276, 0.040495291352272034, 0.03367575258016586, 0.9415425062179565, 0.6961689591407776, 0.0045381831005215645, 0.828267514705658, 0.03536488860845566, 0.902038037776947, 0.9476903080940247, 0.019065771251916885, 0.06835753470659256, 0.00258133583702147, 0.003166072303429246, 0.006881784647703171, 0.9501582384109497, 0.024749286472797394, 0.003540678881108761, 0.002688308712095022, 0.01101311668753624, 0.6274421811103821, 0.04254045709967613, 0.006123567000031471, 0.9333025217056274, 0.9477202892303467, 0.026110751554369926, 0.9419651031494141, 0.5366137027740479, 0.05445413663983345, 0.9509434700012207, 0.8384119272232056, 0.006965961307287216, 0.0024157550651580095, 0.015234507620334625, 0.012098167091608047, 0.050600845366716385, 0.518341600894928, 0.9495159387588501, 0.9391671419143677, 0.03896833583712578, 0.8465783596038818], 'eval_runtime': 16.1635, 'eval_samples_per_second': 55.001, 'eval_steps_per_second': 2.784, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [32:57<?, ?it/s]\n",
      "  0%|          | 0/2 [32:57<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/IPython/cor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">e/magics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">execution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1325</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">time</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1322 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1323 │   │   │   </span>st = clock2()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1324 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1325 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>exec(code, glob, local_ns)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1326 │   │   │   │   </span>out=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1327 │   │   │   │   # multi-line %%time case</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1328 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> expr_val <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;timed exec&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">152</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1633</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1630 │   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1631 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1632 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1633 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1634 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1635 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1636 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1979</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1976 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.epoch = epoch + (step + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> + steps_skipped) / steps_in_epo  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1977 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_step_end(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">s</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1978 │   │   │   │   │   </span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1979 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_k  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1980 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1981 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_substep_end(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1982 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2240</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_maybe_log_save_evaluate</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2237 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._report_to_hp_search(trial, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.global_step, metrics)             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2238 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2239 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control.should_save:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2240 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._save_checkpoint(model, trial, metrics=metrics)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2241 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_save(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.con  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2242 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2243 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_load_rng_state</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, checkpoint):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2356</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_save_checkpoint</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2353 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2354 │   │   # Save the Trainer state</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2355 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.should_save:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2356 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.save_to_json(os.path.join(output_dir, TRAINER_STATE_NAME))         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2357 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2358 │   │   # Save RNG state in non-distributed training</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2359 │   │   </span>rng_states = {                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer_callback.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">97</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">save_to_json</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 94 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 95 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">save_to_json</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, json_path: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 96 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Save the content of this instance in JSON format inside `json_path`.\"\"\"</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 97 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>json_string = json.dumps(dataclasses.asdict(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>), indent=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>, sort_keys=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>) + <span style=\"color: #808000; text-decoration-color: #808000\">\"</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(json_path, <span style=\"color: #808000; text-decoration-color: #808000\">\"w\"</span>, encoding=<span style=\"color: #808000; text-decoration-color: #808000\">\"utf-8\"</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> f:                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 │   │   │   </span>f.write(json_string)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">238</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">dumps</span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">235 │   │   </span>skipkeys=skipkeys, ensure_ascii=ensure_ascii,                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">236 │   │   </span>check_circular=check_circular, allow_nan=allow_nan, indent=indent,                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">237 │   │   </span>separators=separators, default=default, sort_keys=sort_keys,                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>238 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>**kw).encode(obj)                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">239 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">240 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">241 </span>_default_decoder = JSONDecoder(object_hook=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, object_pairs_hook=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">encoder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">201</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">encode</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   │   # equivalent to the PySequence_Fast that ''.join() would do.</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   │   </span>chunks = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.iterencode(o, _one_shot=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(chunks, (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>)):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>201 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>chunks = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(chunks)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #808000; text-decoration-color: #808000\">''</span>.join(chunks)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">204 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">iterencode</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, o, _one_shot=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">encoder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">431</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_iterencode</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">428 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(o, (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>)):                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">429 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield from</span> _iterencode_list(o, _current_indent_level)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">430 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(o, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>):                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>431 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield from</span> _iterencode_dict(o, _current_indent_level)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">432 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">433 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> markers <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">434 │   │   │   │   </span>markerid = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">id</span>(o)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">encoder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">405</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_iterencode_dict</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">402 │   │   │   │   │   </span>chunks = _iterencode_dict(value, _current_indent_level)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">403 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">404 │   │   │   │   │   </span>chunks = _iterencode(value, _current_indent_level)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>405 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield from</span> chunks                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">406 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> newline_indent <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">407 │   │   │   </span>_current_indent_level -= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">408 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> <span style=\"color: #808000; text-decoration-color: #808000\">'\\n'</span> + _indent * _current_indent_level                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">encoder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">325</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_iterencode_list</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">322 │   │   │   │   │   </span>chunks = _iterencode_dict(value, _current_indent_level)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">323 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">324 │   │   │   │   │   </span>chunks = _iterencode(value, _current_indent_level)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>325 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield from</span> chunks                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">326 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> newline_indent <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">327 │   │   │   </span>_current_indent_level -= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">328 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> <span style=\"color: #808000; text-decoration-color: #808000\">'\\n'</span> + _indent * _current_indent_level                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">encoder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">405</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_iterencode_dict</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">402 │   │   │   │   │   </span>chunks = _iterencode_dict(value, _current_indent_level)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">403 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">404 │   │   │   │   │   </span>chunks = _iterencode(value, _current_indent_level)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>405 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield from</span> chunks                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">406 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> newline_indent <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">407 │   │   │   </span>_current_indent_level -= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">408 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span> <span style=\"color: #808000; text-decoration-color: #808000\">'\\n'</span> + _indent * _current_indent_level                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">encoder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">438</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_iterencode</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">435 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> markerid <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> markers:                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">436 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Circular reference detected\"</span>)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">437 │   │   │   │   </span>markers[markerid] = o                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>438 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>o = _default(o)                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">439 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield from</span> _iterencode(o, _current_indent_level)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">440 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> markers <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">441 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">del</span> markers[markerid]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">encoder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">179</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">default</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">176 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">return JSONEncoder.default(self, o)</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">177 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>179 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f'Object of type {</span>o.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">} '</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180 │   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f'is not JSON serializable'</span>)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">181 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">182 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">encode</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, o):                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>Object of type ndarray is not JSON serializable\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/IPython/cor\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33me/magics/\u001b[0m\u001b[1;33mexecution.py\u001b[0m:\u001b[94m1325\u001b[0m in \u001b[92mtime\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1322 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1323 \u001b[0m\u001b[2m│   │   │   \u001b[0mst = clock2()                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1324 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1325 \u001b[2m│   │   │   │   \u001b[0mexec(code, glob, local_ns)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1326 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mout=\u001b[94mNone\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1327 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# multi-line %%time case\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1328 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m expr_val \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<timed exec>\u001b[0m:\u001b[94m152\u001b[0m in \u001b[92m<module>\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1633\u001b[0m in \u001b[92mtrain\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1630 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1631 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1632 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1633 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1634 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1635 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1636 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1979\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1976 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.state.epoch = epoch + (step + \u001b[94m1\u001b[0m + steps_skipped) / steps_in_epo  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1977 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_step_end(args, \u001b[96mself\u001b[0m.state, \u001b[96ms\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1978 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1979 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_k  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1980 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1981 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_substep_end(args, \u001b[96mself\u001b[0m.state  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1982 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2240\u001b[0m in \u001b[92m_maybe_log_save_evaluate\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2237 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._report_to_hp_search(trial, \u001b[96mself\u001b[0m.state.global_step, metrics)             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2238 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2239 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.control.should_save:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2240 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._save_checkpoint(model, trial, metrics=metrics)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2241 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_save(\u001b[96mself\u001b[0m.args, \u001b[96mself\u001b[0m.state, \u001b[96mself\u001b[0m.con  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2242 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2243 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_load_rng_state\u001b[0m(\u001b[96mself\u001b[0m, checkpoint):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2356\u001b[0m in \u001b[92m_save_checkpoint\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2353 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2354 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Save the Trainer state\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2355 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.should_save:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2356 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.state.save_to_json(os.path.join(output_dir, TRAINER_STATE_NAME))         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2357 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2358 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Save RNG state in non-distributed training\u001b[0m                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2359 \u001b[0m\u001b[2m│   │   \u001b[0mrng_states = {                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer_callback.py\u001b[0m:\u001b[94m97\u001b[0m in \u001b[92msave_to_json\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msave_to_json\u001b[0m(\u001b[96mself\u001b[0m, json_path: \u001b[96mstr\u001b[0m):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Save the content of this instance in JSON format inside `json_path`.\"\"\"\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 97 \u001b[2m│   │   \u001b[0mjson_string = json.dumps(dataclasses.asdict(\u001b[96mself\u001b[0m), indent=\u001b[94m2\u001b[0m, sort_keys=\u001b[94mTrue\u001b[0m) + \u001b[33m\"\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mopen\u001b[0m(json_path, \u001b[33m\"\u001b[0m\u001b[33mw\u001b[0m\u001b[33m\"\u001b[0m, encoding=\u001b[33m\"\u001b[0m\u001b[33mutf-8\u001b[0m\u001b[33m\"\u001b[0m) \u001b[94mas\u001b[0m f:                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   │   \u001b[0mf.write(json_string)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m238\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mdumps\u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m235 \u001b[0m\u001b[2m│   │   \u001b[0mskipkeys=skipkeys, ensure_ascii=ensure_ascii,                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m236 \u001b[0m\u001b[2m│   │   \u001b[0mcheck_circular=check_circular, allow_nan=allow_nan, indent=indent,                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m237 \u001b[0m\u001b[2m│   │   \u001b[0mseparators=separators, default=default, sort_keys=sort_keys,                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m238 \u001b[2m│   │   \u001b[0m**kw).encode(obj)                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m239 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m240 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m241 \u001b[0m_default_decoder = JSONDecoder(object_hook=\u001b[94mNone\u001b[0m, object_pairs_hook=\u001b[94mNone\u001b[0m)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/\u001b[0m\u001b[1;33mencoder.py\u001b[0m:\u001b[94m201\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mencode\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   \u001b[0mchunks = \u001b[96mself\u001b[0m.iterencode(o, _one_shot=\u001b[94mTrue\u001b[0m)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(chunks, (\u001b[96mlist\u001b[0m, \u001b[96mtuple\u001b[0m)):                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m201 \u001b[2m│   │   │   \u001b[0mchunks = \u001b[96mlist\u001b[0m(chunks)                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m.join(chunks)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m204 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92miterencode\u001b[0m(\u001b[96mself\u001b[0m, o, _one_shot=\u001b[94mFalse\u001b[0m):                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/\u001b[0m\u001b[1;33mencoder.py\u001b[0m:\u001b[94m431\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_iterencode\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m428 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96misinstance\u001b[0m(o, (\u001b[96mlist\u001b[0m, \u001b[96mtuple\u001b[0m)):                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m429 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94myield from\u001b[0m _iterencode_list(o, _current_indent_level)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m430 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96misinstance\u001b[0m(o, \u001b[96mdict\u001b[0m):                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m431 \u001b[2m│   │   │   \u001b[0m\u001b[94myield from\u001b[0m _iterencode_dict(o, _current_indent_level)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m432 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m433 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m markers \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m434 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmarkerid = \u001b[96mid\u001b[0m(o)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/\u001b[0m\u001b[1;33mencoder.py\u001b[0m:\u001b[94m405\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_iterencode_dict\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m402 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mchunks = _iterencode_dict(value, _current_indent_level)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m403 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m404 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mchunks = _iterencode(value, _current_indent_level)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m405 \u001b[2m│   │   │   │   \u001b[0m\u001b[94myield from\u001b[0m chunks                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m406 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m newline_indent \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m407 \u001b[0m\u001b[2m│   │   │   \u001b[0m_current_indent_level -= \u001b[94m1\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m408 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94myield\u001b[0m \u001b[33m'\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m'\u001b[0m + _indent * _current_indent_level                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/\u001b[0m\u001b[1;33mencoder.py\u001b[0m:\u001b[94m325\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_iterencode_list\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m322 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mchunks = _iterencode_dict(value, _current_indent_level)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m323 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m324 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mchunks = _iterencode(value, _current_indent_level)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m325 \u001b[2m│   │   │   │   \u001b[0m\u001b[94myield from\u001b[0m chunks                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m326 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m newline_indent \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m327 \u001b[0m\u001b[2m│   │   │   \u001b[0m_current_indent_level -= \u001b[94m1\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m328 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94myield\u001b[0m \u001b[33m'\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m'\u001b[0m + _indent * _current_indent_level                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/\u001b[0m\u001b[1;33mencoder.py\u001b[0m:\u001b[94m405\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_iterencode_dict\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m402 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mchunks = _iterencode_dict(value, _current_indent_level)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m403 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m404 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mchunks = _iterencode(value, _current_indent_level)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m405 \u001b[2m│   │   │   │   \u001b[0m\u001b[94myield from\u001b[0m chunks                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m406 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m newline_indent \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m407 \u001b[0m\u001b[2m│   │   │   \u001b[0m_current_indent_level -= \u001b[94m1\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m408 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94myield\u001b[0m \u001b[33m'\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m'\u001b[0m + _indent * _current_indent_level                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/\u001b[0m\u001b[1;33mencoder.py\u001b[0m:\u001b[94m438\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_iterencode\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m435 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m markerid \u001b[95min\u001b[0m markers:                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m436 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mCircular reference detected\u001b[0m\u001b[33m\"\u001b[0m)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m437 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmarkers[markerid] = o                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m438 \u001b[2m│   │   │   \u001b[0mo = _default(o)                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m439 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94myield from\u001b[0m _iterencode(o, _current_indent_level)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m440 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m markers \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m441 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mdel\u001b[0m markers[markerid]                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/json/\u001b[0m\u001b[1;33mencoder.py\u001b[0m:\u001b[94m179\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mdefault\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m176 \u001b[0m\u001b[2;33m│   │   │   │   \u001b[0m\u001b[33mreturn JSONEncoder.default(self, o)\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m177 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m179 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33mObject of type \u001b[0m\u001b[33m{\u001b[0mo.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m \u001b[0m\u001b[33m'\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m180 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33mis not JSON serializable\u001b[0m\u001b[33m'\u001b[0m)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m181 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m182 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mencode\u001b[0m(\u001b[96mself\u001b[0m, o):                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0mObject of type ndarray is not JSON serializable\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "print('#'*40)\n",
    "print('Starting!')\n",
    "print('#'*40)\n",
    "\n",
    "analysis_columns = ['Warmth', 'Competence']\n",
    "text_col = 'Job Description spacy_sentencized'\n",
    "\n",
    "# Get existing estimators\n",
    "estimator_names_list = get_existing_files()\n",
    "\n",
    "for col in tqdm.tqdm(analysis_columns):\n",
    "\n",
    "    print('-'*20)\n",
    "    print(f'{\"=\"*30} TRAINING DATASET OF LENGTH {len(df_manual)} ON {col.upper()} {\"=\"*30}')\n",
    "    print('-'*20)\n",
    "    print(\n",
    "        f'classifiers to be used ({len(list(transformers_pipe.keys()))}):\\n{list(transformers_pipe.keys())}'\n",
    "    )\n",
    "    assert len(df_manual[df_manual[str(col)].map(df_manual[str(col)].value_counts() > 1)]) != 0, f'Dataframe has no {col} values!'\n",
    "\n",
    "    if len(glob.glob(f'{results_save_path}{method} df_*_data - {col} - (Save_protocol=*).pkl')) == 3:\n",
    "        # Load previous Xy\n",
    "        print('Loading previous Xy.')\n",
    "        (\n",
    "            X_train, y_train,\n",
    "            X_test, y_test,\n",
    "            X_val, y_val,\n",
    "            train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "            test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict,\n",
    "            val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "        ) = load_Xy(\n",
    "            col\n",
    "        )\n",
    "    else:\n",
    "        print('Splitting data.')\n",
    "        # Split data\n",
    "        (\n",
    "            train, X_train, y_train,\n",
    "            test, X_test, y_test,\n",
    "            val, X_val, y_val,\n",
    "            train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "            test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "            val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "        ) = split_data(\n",
    "            df_manual, col,\n",
    "        )\n",
    "        # Save Xy data\n",
    "        save_Xy(\n",
    "            X_train, y_train,\n",
    "            X_test, y_test,\n",
    "            X_val, y_val,\n",
    "            col,\n",
    "        )\n",
    "\n",
    "    # Get model_name, tokenizer, model and optimizer\n",
    "    for transformer_name, transformer_dict in tqdm.tqdm(transformers_pipe.items()):\n",
    "        model_name = transformer_dict['model_name']\n",
    "        config = transformer_dict['config'].from_pretrained(model_name)\n",
    "        tokenizer = transformer_dict['tokenizer'].from_pretrained(model_name, num_labels=2)\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        model = transformer_dict['model'].from_pretrained(model_name, config=config,).to(device)\n",
    "        if model.config.pad_token_id is None:\n",
    "            try:\n",
    "                model.config.pad_token_id = tokenizer.pad_token_id\n",
    "            except:\n",
    "                model.config.pad_token_id = model.config.eos_token_id\n",
    "        def model_init(trial): return model\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "        vectorizer_name = ''.join(model.name_or_path.split('-')).upper()\n",
    "        classifier_name = model.__class__.__name__\n",
    "        output_dir = training_args_dict['output_dir'] = training_args_dict_for_best_trial['output_dir'] = f'{results_save_path}{method} Estimator - {col} - {vectorizer_name} + {classifier_name} (Save_protocol={pickle.HIGHEST_PROTOCOL}).model'\n",
    "        log_dir = training_args_dict['logging_dir'] = training_args_dict_for_best_trial['logging_dir'] = f'{results_save_path}{method} Estimator - {col} - {vectorizer_name} + {classifier_name} (Save_protocol={pickle.HIGHEST_PROTOCOL}).log'\n",
    "\n",
    "        # Encode data\n",
    "        (\n",
    "            X_train_encodings, train_dataset,\n",
    "            X_test_encodings, test_dataset,\n",
    "            X_val_encodings, val_dataset,\n",
    "        ) = encode_data(\n",
    "            X_train, y_train,\n",
    "            X_test, y_test,\n",
    "            X_val, y_val,\n",
    "            tokenizer,\n",
    "        )\n",
    "\n",
    "        if f'{col} - {vectorizer_name} + {classifier_name}' in estimator_names_list:\n",
    "            print('-'*20)\n",
    "            print(\n",
    "                f'Already trained {col} - {vectorizer_name} + {classifier_name}'\n",
    "            )\n",
    "            print('-'*20)\n",
    "            continue\n",
    "\n",
    "        # Accelerate model\n",
    "        (\n",
    "            model, tokenizer, optimizer, train_dataset, test_dataset, val_dataset\n",
    "        ) = accelerator.prepare(\n",
    "            model, tokenizer, optimizer, train_dataset, test_dataset, val_dataset\n",
    "        )\n",
    "        # model.eval()\n",
    "\n",
    "        # Initialize Trainer\n",
    "        print('-'*20)\n",
    "        print('='*30)\n",
    "        print(f'{\"=\"*30} Initializing Trainer using {vectorizer_name} + {classifier_name} {\"=\"*30}')\n",
    "        print('+'*30)\n",
    "\n",
    "        # Make trainer with fine-tuning arguments\n",
    "        print('-'*20)\n",
    "        print('Passing data and arguments to Trainer.')\n",
    "        estimator = Trainer(\n",
    "            # model_init=model_init,\n",
    "            # args=TrainingArguments(**training_args_dict_for_best_trial),\n",
    "            model=model,\n",
    "            args=TrainingArguments(**training_args_dict),\n",
    "            tokenizer=tokenizer,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            preprocess_logits_for_metrics=preprocess_logits_for_metrics_y_pred_prob,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "            # data_collator=transformers.DataCollatorWithPadding(tokenizer),\n",
    "        )\n",
    "        if estimator.place_model_on_device:\n",
    "            estimator.model.to(device)\n",
    "\n",
    "        # # Hyperparameter search\n",
    "        # print('-'*20)\n",
    "        # print(f'Starting hyperparameter search for {col}.')\n",
    "        # best_trial = estimator.hyperparameter_search(\n",
    "        #     direction='maximize',\n",
    "        #     backend='optuna',\n",
    "        #     n_trials=10,\n",
    "        #     hp_space=optuna_hp_space,\n",
    "        #     sampler=optuna.samplers.TPESampler(seed=random_state),\n",
    "        #     pruner=optuna.pruners.SuccessiveHalvingPruner(),\n",
    "        #     compute_objective=compute_objective,\n",
    "        #     n_jobs=n_jobs,\n",
    "        # )\n",
    "        # estimator.save_state()\n",
    "        # estimator.save_metrics('all', metrics_dict)\n",
    "        # estimator.save_model(output_dir)\n",
    "        # accelerator.save(estimator.state, f'{output_dir}/accelerator')\n",
    "        # print('Done hyperparameter search!')\n",
    "        # print('-'*20)\n",
    "\n",
    "        # Train trainer\n",
    "        print('-'*20)\n",
    "        print(f'Starting training for {col} using {classifier_name}.')\n",
    "        estimator.train()#trial=best_trial)\n",
    "        estimator.save_state()\n",
    "        estimator.save_metrics('all', metrics_dict)\n",
    "        estimator.save_model(output_dir)\n",
    "        accelerator.save(estimator.state, f'{output_dir}/accelerator')\n",
    "        print('Done training!')\n",
    "        print('-'*20)\n",
    "\n",
    "        # Evaluate\n",
    "        print('-'*20)\n",
    "        print(f'Evaluating estimator for {col}.')\n",
    "        eval_metrics_dict = estimator.evaluate()\n",
    "        y_val_pred = eval_metrics_dict.pop('eval_y_pred')\n",
    "        y_val_pred_prob = eval_metrics_dict.pop('eval_y_pred_prob')\n",
    "        eval_metrics_dict = clean_metrics_dict(eval_metrics_dict, list(eval_metrics_dict.keys())[0].split('_')[0])\n",
    "        print('Done evaluating!')\n",
    "\n",
    "        # Get predictions\n",
    "        print(f'Getting prediction results for {col}.')\n",
    "        y_test_pred_logits, y_test_labels, test_metrics_dict = estimator.predict(test_dataset)\n",
    "        y_test_pred = test_metrics_dict.pop('test_y_pred')\n",
    "        y_test_pred_prob = test_metrics_dict.pop('test_y_pred_prob')\n",
    "        test_metrics_dict = clean_metrics_dict(test_metrics_dict, list(test_metrics_dict.keys())[0].split('_')[0])\n",
    "        print('Done predicting!')\n",
    "        print('-'*20)\n",
    "\n",
    "        # Save model\n",
    "        print('-'*20)\n",
    "        print(f'Saving model for {col}.')\n",
    "        save_Xy_estimator(\n",
    "            X_train, y_train, train_dataset,\n",
    "            X_test, y_test, y_test_pred, y_test_pred_prob, test_dataset,\n",
    "            X_val, y_val, y_val_pred, y_val_pred_prob, val_dataset,\n",
    "            estimator, accelerator, eval_metrics_dict, test_metrics_dict,\n",
    "            col, vectorizer_name, classifier_name,\n",
    "        )\n",
    "        print('Done training!')\n",
    "        print('-'*20)\n",
    "\n",
    "# Assert that all classifiers were used\n",
    "assert_all_classifiers_used(classifiers_pipe=transformers_pipe)\n",
    "print('#'*40)\n",
    "print('DONE!')\n",
    "print('#'*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ecc31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
