{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "50d4c434",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "if code_dir_name not in str(Path.cwd()).split('/')[-1]:\n",
                "    for _ in range(5):\n",
                "\n",
                "        parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "        if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "            code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "            if code_dir is not None:\n",
                "                break\n",
                "else:\n",
                "    code_dir = str(Path.cwd())\n",
                "sys.path.append(code_dir)\n",
                "\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "fef3f604",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using MPS\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "98d0aa5ef14545ad9be80c33e9ccd07b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using MPS\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 640x480 with 0 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from setup_module.estimators_get_pipe import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from setup_module.forestIV import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e3936e59",
            "metadata": {},
            "source": [
                "### Set variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "3b9d1a7b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using MPS\n"
                    ]
                }
            ],
            "source": [
                "# Variables\n",
                "method = 'Supervised'\n",
                "classifiers_type = 'all'\n",
                "if classifiers_type == 'nonlinear':\n",
                "    classifiers_pipe = classifiers_pipe_nonlinear\n",
                "elif classifiers_type == 'linear':\n",
                "    classifiers_pipe = classifiers_pipe_linear\n",
                "elif classifiers_type == 'ensemble':\n",
                "    classifiers_pipe = classifiers_pipe_ensemble\n",
                "elif classifiers_type == 'all':\n",
                "    classifiers_pipe = classifiers_pipe\n",
                "\n",
                "results_save_path = f'{models_save_path}{method} Results/'\n",
                "with open(f'{data_dir}{method}_results_save_path.txt', 'w') as f:\n",
                "    f.write(results_save_path)\n",
                "if not os.path.exists(results_save_path):\n",
                "    os.makedirs(results_save_path)\n",
                "done_xy_save_path = f'{results_save_path}Search+Xy/'\n",
                "with open(f'{data_dir}{method}_done_xy_save_path.txt', 'w') as f:\n",
                "    f.write(done_xy_save_path)\n",
                "if not os.path.exists(done_xy_save_path):\n",
                "    os.makedirs(done_xy_save_path)\n",
                "\n",
                "t = time.time()\n",
                "n_jobs = -1\n",
                "n_splits = 10\n",
                "n_repeats = 3\n",
                "random_state = 42\n",
                "refit = True\n",
                "class_weight = 'balanced'\n",
                "cv = RepeatedStratifiedKFold(\n",
                "    n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
                ")\n",
                "scoring = 'recall'\n",
                "scores = [\n",
                "    'recall', 'accuracy', 'f1', 'roc_auc',\n",
                "    'explained_variance', 'matthews_corrcoef'\n",
                "]\n",
                "scorers = {\n",
                "    'precision_score': make_scorer(precision_score, zero_division=0),\n",
                "    'recall_score': make_scorer(recall_score, zero_division=0),\n",
                "    'accuracy_score': make_scorer(accuracy_score, zero_division=0),\n",
                "}\n",
                "analysis_columns = ['Warmth', 'Competence']\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "metrics_dict = {\n",
                "    f'{scoring.title()} Best Score': np.nan,\n",
                "    f'{scoring.title()} Best Threshold': np.nan,\n",
                "    'Train - Mean Cross Validation Score': np.nan,\n",
                "    f'Train - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    f'Train - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Test - Mean Cross Validation Score': np.nan,\n",
                "    f'Test - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    f'Test - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Explained Variance': np.nan,\n",
                "    'Accuracy': np.nan,\n",
                "    'Balanced Accuracy': np.nan,\n",
                "    'Precision': np.nan,\n",
                "\n",
                "    'Average Precision': np.nan,\n",
                "    'Recall': np.nan,\n",
                "    'F1-score': np.nan,\n",
                "    'Matthews Correlation Coefficient': np.nan,\n",
                "    'Brier Score': np.nan,\n",
                "    'Fowlkes–Mallows Index': np.nan,\n",
                "    'R2 Score': np.nan,\n",
                "    'ROC': np.nan,\n",
                "    'AUC': np.nan,\n",
                "    'Log Loss/Cross Entropy': np.nan,\n",
                "    'Cohen’s Kappa': np.nan,\n",
                "    'Geometric Mean': np.nan,\n",
                "    'Classification Report': np.nan,\n",
                "    'Imbalanced Classification Report': np.nan,\n",
                "    'Confusion Matrix': np.nan,\n",
                "    'Normalized Confusion Matrix': np.nan,\n",
                "}\n",
                "\n",
                "# Transformer variables\n",
                "max_length = 512\n",
                "returned_tensor = 'pt'\n",
                "cpu_counts = torch.multiprocessing.cpu_count()\n",
                "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available(\n",
                ") else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "device_name = str(device.type)\n",
                "print(f'Using {device_name.upper()}')\n",
                "# Set random seed\n",
                "random_state = 42\n",
                "random.seed(random_state)\n",
                "np.random.seed(random_state)\n",
                "torch.manual_seed(random_state)\n",
                "cores = multiprocessing.cpu_count()\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "55afc383",
            "metadata": {},
            "source": [
                "### Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def prob_confirmatory_tests(y_pred, y_pred_prob):\n",
                "\n",
                "    # Confirmatory Regression\n",
                "    print('+'*20)\n",
                "    print('Confirmatory Tests validating the linear relationship between y_pred and y_pred_prob')\n",
                "    print('-'*20)\n",
                "    print('T-Test y_pred_prob ~ y_pred:')\n",
                "    levene = scipy.stats.levene(y_pred_prob, y_pred)\n",
                "    equal_var_levene = levene.pvalue < 0.05\n",
                "    print(scipy.stats.ttest_ind(y_pred_prob, y_pred, equal_var=equal_var_levene))\n",
                "\n",
                "    print('\\n')\n",
                "    print('-'*20)\n",
                "    print('Logit y_pred ~ y_pred_prob:')\n",
                "    try:\n",
                "        logit_model = sm.Logit(endog=y_pred, exog=y_pred_prob)\n",
                "        logit_results = logit_model.fit()\n",
                "        std_coef = logit_results.params[0] / np.std(y_pred_prob)\n",
                "        std_err = logit_results.bse[0]\n",
                "        log_likelihood = logit_results.llf\n",
                "        print(logit_results.summary())\n",
                "        print('-'*20)\n",
                "        print(f'Std Coef: {std_coef}')\n",
                "        print(f'Std Err: {std_err}')\n",
                "        print(f'Log Likelihood: {log_likelihood}')\n",
                "    except Exception as e:\n",
                "        print(type(e).__name__)\n",
                "\n",
                "    print('-'*20)\n",
                "    print('\\n')\n",
                "    print('-'*20)\n",
                "    print('OLS y_pred_prob ~ y_pred:')\n",
                "    try:\n",
                "        ols_model = sm.OLS(endog=y_pred_prob, exog=y_pred)\n",
                "        ols_results = ols_model.fit()\n",
                "        std_coef = ols_results.params[0] / np.std(y_pred)\n",
                "        std_err = ols_results.bse[0]\n",
                "        print(ols_results.summary())\n",
                "        print('-'*20)\n",
                "        print(f'Std Coef: {std_coef}')\n",
                "        print(f'Std Err: {std_err}')\n",
                "    except Exception as e:\n",
                "        print(type(e).__name__)\n",
                "\n",
                "    print('-'*20)\n",
                "    print('+'*20)\n",
                "    print('\\n')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "f15e44f8",
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_df_full_summary_excel(\n",
                "    df_full_summary,\n",
                "    title,\n",
                "    text_to_add_list,\n",
                "    file_save_path,\n",
                "    sheet_name=None,\n",
                "    startrow=None,\n",
                "    startcol=None,\n",
                "):\n",
                "    if sheet_name is None:\n",
                "        sheet_name = 'All'\n",
                "    if startrow is None:\n",
                "        startrow = 1\n",
                "    if startcol is None:\n",
                "        startcol = 1\n",
                "\n",
                "    # Define last rows and cols locs\n",
                "    header_range = 1\n",
                "    endrow = startrow + header_range + df_full_summary.shape[0]\n",
                "    endcol = startcol + df_full_summary.shape[1]\n",
                "\n",
                "    # Remove NAs\n",
                "    df_full_summary = df_full_summary.fillna('')\n",
                "\n",
                "    # Write\n",
                "    writer = pd.ExcelWriter(f'{file_save_path}.xlsx')\n",
                "    df_full_summary.to_excel(writer, sheet_name=sheet_name, merge_cells=True, startrow=startrow, startcol=startcol)\n",
                "    workbook  = writer.book\n",
                "    worksheet = writer.sheets[sheet_name]\n",
                "    worksheet.set_column(startrow, 1, None, None, {'hidden': True}) # hide the index column\n",
                "\n",
                "    # Title\n",
                "    worksheet.merge_range(1, startcol, 1, endcol, title, workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'left', 'top': True, 'bottom': True, 'left': False, 'right': False}))\n",
                "\n",
                "    # Main body\n",
                "    body_max_row_idx, body_max_col_idx = df_full_summary.shape\n",
                "\n",
                "    for c, r in tqdm_product(range(body_max_col_idx), range(body_max_row_idx)):\n",
                "        row_to_write = startrow + header_range + r\n",
                "        col_to_write = startcol + 1 + c # 1 is for index\n",
                "        body_formats = {'num_format': '0.00', 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'text_wrap': True, 'left': False, 'right': False}\n",
                "\n",
                "        if r == 0:\n",
                "            body_formats |= {'top': True, 'bottom': True, 'left': False, 'right': False}\n",
                "            worksheet.set_column(col_to_write, col_to_write, 10)\n",
                "\n",
                "        if r == body_max_row_idx-1:\n",
                "            body_formats |= {'bottom': True}\n",
                "\n",
                "        if c == 0:\n",
                "            body_formats |= {'align': 'left'}\n",
                "            worksheet.set_column(col_to_write, col_to_write, 15)\n",
                "\n",
                "        worksheet.write(row_to_write, col_to_write, df_full_summary.iloc[r, c], workbook.add_format(body_formats))\n",
                "\n",
                "    # Add Note\n",
                "    note_format = {'italic': True, 'font_name': 'Times New Roman', 'font_size': 10, 'font_color': 'black', 'align': 'left', 'left': False, 'right': False}\n",
                "    worksheet.merge_range(endrow, startcol, endrow, endcol, 'Note.', workbook.add_format(note_format))\n",
                "    # Add text\n",
                "    for i, text in enumerate(text_to_add_list):\n",
                "        worksheet.merge_range(endrow + 1 + i , startcol, endrow + 1 + i, endcol, text, workbook.add_format(note_format))\n",
                "\n",
                "    writer.close()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "96e6d325",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_full_report(\n",
                "    results, dv, analysis_type, model_name, dvs_name, ivs_name, ivs_type, df_name,\n",
                "    regression_info_dict=None, regressor_order=None, text_to_add_list=None, title=None, model_names=None\n",
                "):\n",
                "    '''\n",
                "    Make a full report for a regression analysis.\n",
                "    results: statsmodels regression results object or list of results objects\n",
                "    dv: str, dependent variable name\n",
                "    '''\n",
                "\n",
                "    if regression_info_dict is None:\n",
                "        # Regression info dict\n",
                "        regression_info_dict = {\n",
                "            'Model Name': lambda x: f'{x.model.__class__.__name__}',\n",
                "            'N': lambda x: f'{int(x.nobs):d}',\n",
                "            'R-squared': lambda x: f'{x.rsquared:.5f}',\n",
                "            'R-squared Adj.': lambda x: f'{x.rsquared_adj:.5f}',\n",
                "            'Log-Likelihood': lambda x: f'{x.llf:.5f}',\n",
                "            'Pseudo R2': lambda x: f'{x.prsquared:.5f}',\n",
                "            'F': lambda x: f'{x.fvalue:.5f}',\n",
                "            'F (p-value)': lambda x: f'{x.f_pvalue:.5f}',\n",
                "            'df_model': lambda x: f'{x.df_model:.0f}',\n",
                "            'df_total': lambda x: f'{x.df_resid + x.df_model + 1:.0f}',\n",
                "            'df_resid': lambda x: f'{x.df_resid:.0f}',\n",
                "            'AIC': lambda x: f'{x.aic:.5f}',\n",
                "            'BIC': lambda x: f'{x.bic:.5f}',\n",
                "            'ICC': lambda x: f'{x.rsquared / (x.rsquared + (x.nobs - 1) * x.mse_resid):.5f}',\n",
                "            'RMSE': lambda x: f'{x.mse_resid ** 0.5:.5f}',\n",
                "            'RMSE (std)': lambda x: f'{x.mse_resid ** 0.5 / x.model.endog.std():.5f}',\n",
                "            'Omnibus': lambda x: f'{sms.omni_normtest(x.resid).statistic:.5f}',\n",
                "            'Omnibus (p-value)': lambda x: f'{sms.omni_normtest(x.resid).pvalue:.5f}',\n",
                "            'Skew': lambda x: f'{sms.jarque_bera(x.resid)[-2]:.5f}',\n",
                "            'Kurtosis': lambda x: f'{sms.jarque_bera(x.resid)[-1]:.5f}',\n",
                "            'Jarque-Bera (JB)': lambda x: f'{sms.jarque_bera(x.resid)[0]:.5f}',\n",
                "            'Jarque-Bera (p-value)': lambda x: f'{sms.jarque_bera(x.resid)[1]:.5f}',\n",
                "            'Unstandardized Coefficent B (b)': lambda x: f'{x.params[0]:.5f}',\n",
                "            'Standard Error (SE)': lambda x: f'{x.bse[0]:.5f}',\n",
                "            'Standardized Coefficient b* (β)': lambda x: f'{x.params[0] / x.model.endog.std():.5f}',\n",
                "            't': lambda x: f'{x.tvalues[0]:.5f}',\n",
                "            't (p-value)': lambda x: f'{x.pvalues[0]:.5f}',\n",
                "            '95% CI': lambda x: f'{x.conf_int().iloc[0, 1]:.5f} - {x.conf_int().iloc[0, 1]:.5f}',\n",
                "            # 'Summary': lambda x: f'{x.summary()}',\n",
                "            # 'F (p-value - FDR)': lambda x: f'{x.f_pvalue_fdr:.5f}',\n",
                "            # 'F (p-value - Bonferroni)': lambda x: f'{x.f_pvalue_bonf:.5f}',\n",
                "            # 't (p-value - FDR)': lambda x: f'{x.pvalues_fdr[1]:.5f}',\n",
                "            # 't (p-value - Bonferroni)': lambda x: f'{x.pvalues_bonf[1]:.5f}',\n",
                "        }\n",
                "        if isinstance(results, list):\n",
                "            results_to_check = results[0]\n",
                "        else:\n",
                "            results_to_check = results\n",
                "        if all('const' in x for x in zip(results_to_check.params.index, results_to_check.bse.index, results_to_check.tvalues.index, results_to_check.pvalues.index)):\n",
                "            regression_info_dict = regression_info_dict | {\n",
                "                'Intercept': lambda x: f'{x.params[\"const\"]:.5f}',\n",
                "                'Intercept (std)': lambda x: f'{x.bse[\"const\"]:.5f}',\n",
                "                'Intercept t': lambda x: f'{x.tvalues[\"const\"]:.5f}',\n",
                "                'Intercept t (p-value)': lambda x: f'{x.pvalues[\"const\"]:.5f}',\n",
                "                'Intercept (95% CI)': lambda x: f'{x.conf_int().loc[\"const\"][0]:.5f} - {x.conf_int().loc[\"const\"][1]:.5f}',\n",
                "            }\n",
                "    if model_names is None:\n",
                "        if isinstance(results, list):\n",
                "            model_names = [\n",
                "                f'{results_to_check.model.endog_names.split(\"_\")[0] if \"_\" in results_to_check.model.endog_names else results_to_check.model.endog_names} Model {i}'\n",
                "                for i in range(len(results))\n",
                "            ]\n",
                "            model_names[0] = model_names[0].replace('Model 0', 'Full Model')\n",
                "        else:\n",
                "            model_names = [\n",
                "                f'{results.model.endog_names.split(\"_\")[0] if \"_\" in results.model.endog_names else results.model.endog_names}'\n",
                "            ]\n",
                "\n",
                "    order_type = 'unordered' if regressor_order is None else 'ordered'\n",
                "    if text_to_add_list is None:\n",
                "        text_to_add_list = []\n",
                "        if regressor_order is not None:\n",
                "            text_to_add_list.append('Models are ordered by independent variable type.')\n",
                "\n",
                "        else:\n",
                "            text_to_add_list.append('Models are ordered by coefficient size, largest to smallest.')\n",
                "\n",
                "    if title is None:\n",
                "        title = f'{model_name} {analysis_type}: {dvs_name} x {ivs_name}'\n",
                "\n",
                "    try:\n",
                "        # Statsmodels summary_col\n",
                "        full_summary = summary_col(\n",
                "            results,\n",
                "            stars=True,\n",
                "            info_dict=regression_info_dict,\n",
                "            regressor_order=regressor_order,\n",
                "            float_format='%0.3f',\n",
                "            model_names=model_names,\n",
                "        )\n",
                "        if isinstance(results, list) and len(results) > 4:\n",
                "            full_summary.tables[0][full_summary.tables[0].filter(regex='Full Model').columns[0]].loc['Unstandardized Coefficent B (b)': '95% CI'] = ''\n",
                "\n",
                "        # Add title and notes\n",
                "        full_summary.add_title(title)\n",
                "        text_to_add_list.extend(full_summary.extra_txt)\n",
                "        for text in text_to_add_list:\n",
                "            full_summary.add_text(text)\n",
                "        # Save\n",
                "        save_name = f'{table_save_path}{model_name} {df_name} - ALL {dv} {order_type} {analysis_type} on {ivs_type}'\n",
                "        df_full_summary = pd.read_html(full_summary.as_html())[0]\n",
                "        df_full_summary.to_csv(f'{save_name}.csv')\n",
                "        df_full_summary.style.to_latex(f'{save_name}.tex', hrules=True)\n",
                "        save_df_full_summary_excel(df_full_summary, title, text_to_add_list, save_name)\n",
                "\n",
                "        return full_summary\n",
                "    except IndexError as e:\n",
                "        print(f'Making full report for {model_names[0]} due to the following error: {e}')\n",
                "        return None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "ad45ea49",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_standardized_coefficients(results):\n",
                "\n",
                "    # # Get standardized regression coefficients\n",
                "    # std = np.asarray(constant.std(0))\n",
                "\n",
                "    # if 'const' in results.params and 'const' in constant:\n",
                "    #     std[0] = 1\n",
                "    # tt = results.t_test(np.diag(std))\n",
                "    # tt.c_names = results.model.exog_names\n",
                "\n",
                "    # t-test\n",
                "    std = results.model.exog.std(0)\n",
                "    if 'const' in results.params:\n",
                "        std[0] = 1\n",
                "    tt = results.t_test(np.diag(std))\n",
                "    if results.model.__class__.__name__ == 'MixedLM' or 'Group Var' in results.model.exog_names:\n",
                "        offset = slice(None, -1)\n",
                "        tt.c_names = results.model.exog_names[offset]\n",
                "    else:\n",
                "        offset = slice(None, None)\n",
                "        tt.c_names = results.model.exog_names\n",
                "\n",
                "    # Make df with standardized and unstandardized coefficients\n",
                "    df_std_coef = pd.DataFrame(\n",
                "        {\n",
                "            'coef': results.params[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'std err': results.bse[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'std coef': (results.params[offset] / results.model.exog[offset].std(axis=0)).apply(lambda x: f'{x:.5f}'),\n",
                "            't': results.tvalues[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'P>|t|': results.pvalues[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            '[0.025': results.conf_int()[0][offset].apply(lambda x: f'{x:.5f}'),\n",
                "            '0.975]': results.conf_int()[1][offset].apply(lambda x: f'{x:.5f}'),\n",
                "        }\n",
                "    )\n",
                "    # if 'Group Var' in df_std_coef.index:\n",
                "    #     df_std_coef = df_std_coef.drop('Group Var', axis='index')\n",
                "    # # Add standardized coefficients and other data from t-test\n",
                "    # df_std_coef['std coef'] = tt.effect\n",
                "    # df_std_coef['std err'] = tt.sd\n",
                "    # df_std_coef['t'] = tt.statistic\n",
                "    # df_std_coef['P>|t|'] = tt.pvalue\n",
                "    # df_std_coef['[0.025'] = tt.conf_int()[:, 0]\n",
                "    # df_std_coef['0.975]'] = tt.conf_int()[:, 1]\n",
                "    # df_std_coef['var'] = [names[i] for i in range(len(results.model.exog_names))]\n",
                "    # df_std_coef = df_std_coef.sort_values('std coef', ascending=False)\n",
                "    df_std_coef = df_std_coef.reset_index().rename(columns={'index': 'var'})\n",
                "    df_std_coef = df_std_coef.rename(\n",
                "        columns={\n",
                "            'var': 'Variable',\n",
                "            'coef': 'Unstandardized Coefficent B (b)',\n",
                "            'std err': 'Standard Error',\n",
                "            'std coef':'Standardized Coefficient b* (β)',\n",
                "            't': 't-value',\n",
                "            'P>|t|': 'p-value',\n",
                "            '[0.025': '95% CI Lower',\n",
                "            '0.975]': '95% CI Upper'\n",
                "        }\n",
                "    )\n",
                "    # Reorder columns\n",
                "    df_std_coef = df_std_coef[[\n",
                "        'Variable',\n",
                "        'Unstandardized Coefficent B (b)',\n",
                "        'Standard Error',\n",
                "        'Standardized Coefficient b* (β)',\n",
                "        't-value',\n",
                "        'p-value',\n",
                "        '95% CI Lower',\n",
                "        '95% CI Upper'\n",
                "    ]]\n",
                "\n",
                "    return tt, df_std_coef\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "bbe40924",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to compare and produce Unbiased and Biased OLS Models\n",
                "def compare_actual_and_predicted(df, analysis_type, iv_names=None, print_enabled=None):\n",
                "    if print_enabled is None:\n",
                "        print_enabled = True\n",
                "    dv_names_dict = defaultdict(lambda: defaultdict())\n",
                "\n",
                "    for dv in tqdm.tqdm(dvs):\n",
                "        if analysis_type == 'pre_classification':\n",
                "            if iv_names is None:\n",
                "                iv_names = ivs_dummy_perc_and_perc_interactions + controls[:2]\n",
                "            dv_names_dict[dv] = {\n",
                "                'Unbiased': {'dv_names': f'{dv}_actual'},\n",
                "                'Biased': {'dv_names': f'{dv}_predicted'}\n",
                "            }\n",
                "            df = df.loc[\n",
                "                (~df[dv_names_dict[dv]['Unbiased']['dv_names']].isna())\n",
                "                & (~df[dv_names_dict[dv]['Biased']['dv_names']].isna())\n",
                "            ]\n",
                "            print(f'Processing dataframe of length {len(df)}')\n",
                "\n",
                "        elif analysis_type == 'post_classification':\n",
                "            if iv_names is None:\n",
                "                iv_names = ivs_dummy_perc_and_perc_interactions[0]\n",
                "            if f'{dv}_aggr_unlabeled_predicted' in df.columns:\n",
                "                dv_names_dict[dv] = {\n",
                "                    'Biased': {'dv_names': f'{dv}_aggr_unlabeled_predicted'},\n",
                "                }\n",
                "                df = df.loc[\n",
                "                    (~df[dv_names_dict[dv]['Biased']['dv_names']].isna())\n",
                "                ]\n",
                "                print(f'Processing dataframe of length {len(df)}')\n",
                "            elif f'{dv}_actual' in df.columns:\n",
                "                dv_names_dict[dv] = {\n",
                "                    'Unbiased': {'dv_names': f'{dv}_actual'},\n",
                "                }\n",
                "                df = df.loc[\n",
                "                    (~df[dv_names_dict[dv]['Unbiased']['dv_names']].isna())\n",
                "                ]\n",
                "                print(f'Processing dataframe of length {len(df)}')\n",
                "\n",
                "        print(f'Analyzing {dv} {dv_names_dict[dv].keys()} Models')\n",
                "\n",
                "        for dv_type, dv_names in tqdm.tqdm(dv_names_dict[dv].items()):\n",
                "            if analysis_type == 'pre_classification':\n",
                "                endog = df[dv_names['dv_names']]\n",
                "                exog = df[iv_names]\n",
                "            elif analysis_type == 'post_classification':\n",
                "                endog = df[iv_names]\n",
                "                exog = df[dv_names['dv_names']]\n",
                "\n",
                "            model = sm.OLS(endog=endog, exog=exog, data=df)\n",
                "            results = model.fit()\n",
                "            tt, df_std_coef = get_standardized_coefficients(results)\n",
                "            title = f'{analysis_type} {dv_type} OLS Regression {dv_names[\"dv_names\"]} x {iv_names[:3]} etc.'\n",
                "            full_summary = make_full_report(\n",
                "                results=results, dv=dv, analysis_type=dv_names['dv_names'], model_name=analysis_type, df_name=dv_type,\n",
                "                dvs_name=dv_names['dv_names'], ivs_name=iv_names[:3], ivs_type=iv_names[:3], title=title\n",
                "            )\n",
                "\n",
                "            dv_names_dict[dv][dv_type]['R-squared'] = results.rsquared\n",
                "            dv_names_dict[dv][dv_type]['Results'] = results\n",
                "\n",
                "            if print_enabled:\n",
                "                print('\\n')\n",
                "                print('-'*20)\n",
                "                print(f'{dv_type.upper()} {dv}\\n')\n",
                "                print('-'*20)\n",
                "                print('\\n')\n",
                "                print(f'{dv_type.upper()} SUMMARY RESULTS:')\n",
                "                print(results.summary())\n",
                "                print(full_summary)\n",
                "                print('\\n')\n",
                "                print('-'*20)\n",
                "                print(f'{dv_type.upper()} STANDARDIZED BETA REGRESSION COEFFICIENTS FOR {dv}:\\n{df_std_coef}')\n",
                "                print('\\n')\n",
                "                print('-'*20)\n",
                "\n",
                "            df_summary_results = pd.DataFrame(csv.reader(results.summary().as_csv().split('\\n'), delimiter=','))\n",
                "            save_name = f'{table_save_path}{title}'\n",
                "            df_summary_results.to_csv(f'{save_name}.csv')\n",
                "            df_summary_results.style.to_latex(f'{save_name}.tex', hrules=True)\n",
                "            df_std_coef.to_csv(f'{save_name} - standardized coefficients.csv')\n",
                "            df_std_coef.style.to_latex(f'{save_name} - standardized coefficients.tex', hrules=True)\n",
                "\n",
                "        if dv_names_dict[dv][list(dv_names_dict[dv])[0]]['R-squared'] != dv_names_dict[dv][list(dv_names_dict[dv])[-1]]['R-squared']:\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "            print(f'{dv} {list(dv_names_dict[dv])[0]} R-Squared does not equal {list(dv_names_dict[dv])[-1]} R-Squared:')\n",
                "            print(f'{dv} {list(dv_names_dict[dv])[0]} = {dv_names_dict[dv][list(dv_names_dict[dv])[0]][\"R-squared\"]:.3f}')\n",
                "            print(f'{dv} {list(dv_names_dict[dv])[-1]} = {dv_names_dict[dv][list(dv_names_dict[dv])[-1]][\"R-squared\"]:.3f}')\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "\n",
                "    return dict(dv_names_dict)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "fd32c435",
            "metadata": {},
            "source": [
                "### READ DATA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "923fee85",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataframe df_jobs_for_analysis loaded with shape: (309144, 79)\n"
                    ]
                }
            ],
            "source": [
                "with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'r') as f:\n",
                "    df_jobs_len = int(f.read())\n",
                "\n",
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
                "assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_jobs)}'\n",
                "print(f'Dataframe df_jobs_for_analysis loaded with shape: {df_jobs.shape}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "aee1fd3d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "False"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_jobs['Warmth'].equals(df_jobs['Warmth_predicted'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "a183fc9d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "False"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_jobs['Competence'].equals(df_jobs['Competence_predicted'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "++++++++++++++++++++\n",
                        "Confirmatory Tests validating the linear relationship between y_pred and y_pred_prob\n",
                        "--------------------\n",
                        "T-Test y_pred_prob ~ y_pred:\n",
                        "TtestResult(statistic=2.4676218209820364, pvalue=0.013616102570478466, df=11298.0)\n",
                        "\n",
                        "\n",
                        "--------------------\n",
                        "Logit y_pred ~ y_pred_prob:\n",
                        "Optimization terminated successfully.\n",
                        "         Current function value: 0.646807\n",
                        "         Iterations 5\n",
                        "                           Logit Regression Results                           \n",
                        "==============================================================================\n",
                        "Dep. Variable:       Warmth_predicted   No. Observations:                 5650\n",
                        "Model:                          Logit   Df Residuals:                     5649\n",
                        "Method:                           MLE   Df Model:                            0\n",
                        "Date:                Wed, 15 Nov 2023   Pseudo R-squ.:                 -0.1512\n",
                        "Time:                        02:40:41   Log-Likelihood:                -3654.5\n",
                        "converged:                       True   LL-Null:                       -3174.4\n",
                        "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
                        "==============================================================================\n",
                        "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
                        "------------------------------------------------------------------------------\n",
                        "Warmth         1.2907      0.062     20.732      0.000       1.169       1.413\n",
                        "==============================================================================\n",
                        "--------------------\n",
                        "Std Coef: 2.907503135621585\n",
                        "Std Err: 0.06225459082790081\n",
                        "Log Likelihood: -3654.458825921623\n",
                        "--------------------\n",
                        "\n",
                        "\n",
                        "--------------------\n",
                        "OLS y_pred_prob ~ y_pred:\n",
                        "                                 OLS Regression Results                                \n",
                        "=======================================================================================\n",
                        "Dep. Variable:                 Warmth   R-squared (uncentered):                   0.665\n",
                        "Model:                            OLS   Adj. R-squared (uncentered):              0.665\n",
                        "Method:                 Least Squares   F-statistic:                          1.123e+04\n",
                        "Date:                Wed, 15 Nov 2023   Prob (F-statistic):                        0.00\n",
                        "Time:                        02:40:41   Log-Likelihood:                         -1225.8\n",
                        "No. Observations:                5650   AIC:                                      2454.\n",
                        "Df Residuals:                    5649   BIC:                                      2460.\n",
                        "Df Model:                           1                                                  \n",
                        "Covariance Type:            nonrobust                                                  \n",
                        "====================================================================================\n",
                        "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
                        "------------------------------------------------------------------------------------\n",
                        "Warmth_predicted     0.8482      0.008    105.950      0.000       0.833       0.864\n",
                        "==============================================================================\n",
                        "Omnibus:                     1225.179   Durbin-Watson:                   1.670\n",
                        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10365.195\n",
                        "Skew:                           0.798   Prob(JB):                         0.00\n",
                        "Kurtosis:                       9.441   Cond. No.                         1.00\n",
                        "==============================================================================\n",
                        "\n",
                        "Notes:\n",
                        "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
                        "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                        "--------------------\n",
                        "Std Coef: 1.9600539717682264\n",
                        "Std Err: 0.008005920587312632\n",
                        "--------------------\n",
                        "++++++++++++++++++++\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "prob_confirmatory_tests(\n",
                "    df_jobs.dropna(subset=dvs_predicted)['Warmth_predicted'],\n",
                "    df_jobs.dropna(subset=dvs_predicted)['Warmth'],\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "++++++++++++++++++++\n",
                        "Confirmatory Tests validating the linear relationship between y_pred and y_pred_prob\n",
                        "--------------------\n",
                        "T-Test y_pred_prob ~ y_pred:\n",
                        "TtestResult(statistic=-0.5089219636602621, pvalue=0.6108168622758917, df=11297.996031865623)\n",
                        "\n",
                        "\n",
                        "--------------------\n",
                        "Logit y_pred ~ y_pred_prob:\n",
                        "Optimization terminated successfully.\n",
                        "         Current function value: 0.506983\n",
                        "         Iterations 6\n",
                        "                            Logit Regression Results                            \n",
                        "================================================================================\n",
                        "Dep. Variable:     Competence_predicted   No. Observations:                 5650\n",
                        "Model:                            Logit   Df Residuals:                     5649\n",
                        "Method:                             MLE   Df Model:                            0\n",
                        "Date:                  Wed, 15 Nov 2023   Pseudo R-squ.:                  0.2669\n",
                        "Time:                          02:40:41   Log-Likelihood:                -2864.5\n",
                        "converged:                         True   LL-Null:                       -3907.1\n",
                        "Covariance Type:              nonrobust   LLR p-value:                       nan\n",
                        "==============================================================================\n",
                        "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
                        "------------------------------------------------------------------------------\n",
                        "Competence     2.3576      0.069     34.026      0.000       2.222       2.493\n",
                        "==============================================================================\n",
                        "--------------------\n",
                        "Std Coef: 4.725718815569072\n",
                        "Std Err: 0.06928978940963729\n",
                        "Log Likelihood: -2864.4545227398944\n",
                        "--------------------\n",
                        "\n",
                        "\n",
                        "--------------------\n",
                        "OLS y_pred_prob ~ y_pred:\n",
                        "                                 OLS Regression Results                                \n",
                        "=======================================================================================\n",
                        "Dep. Variable:             Competence   R-squared (uncentered):                   0.826\n",
                        "Model:                            OLS   Adj. R-squared (uncentered):              0.826\n",
                        "Method:                 Least Squares   F-statistic:                          2.683e+04\n",
                        "Date:                Wed, 15 Nov 2023   Prob (F-statistic):                        0.00\n",
                        "Time:                        02:40:41   Log-Likelihood:                         -922.72\n",
                        "No. Observations:                5650   AIC:                                      1847.\n",
                        "Df Residuals:                    5649   BIC:                                      1854.\n",
                        "Df Model:                           1                                                  \n",
                        "Covariance Type:            nonrobust                                                  \n",
                        "========================================================================================\n",
                        "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
                        "----------------------------------------------------------------------------------------\n",
                        "Competence_predicted     0.9043      0.006    163.811      0.000       0.893       0.915\n",
                        "==============================================================================\n",
                        "Omnibus:                      885.551   Durbin-Watson:                   1.727\n",
                        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            15422.447\n",
                        "Skew:                          -0.104   Prob(JB):                         0.00\n",
                        "Kurtosis:                      11.091   Cond. No.                         1.00\n",
                        "==============================================================================\n",
                        "\n",
                        "Notes:\n",
                        "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
                        "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                        "--------------------\n",
                        "Std Coef: 1.8115028238813564\n",
                        "Std Err: 0.005520265532643802\n",
                        "--------------------\n",
                        "++++++++++++++++++++\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "prob_confirmatory_tests(\n",
                "    df_jobs.dropna(subset=dvs_predicted)['Competence_predicted'],\n",
                "    df_jobs.dropna(subset=dvs_predicted)['Competence'],\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2ebecb79",
            "metadata": {},
            "source": [
                "## Check biased and unbiased regressions models using human annotated and classifier predicted Warmth and Competence\n",
                "Source: https://mochenyang.github.io/mochenyangblog/research/2022/01/10/ForestIV.html"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5499a77b",
            "metadata": {},
            "source": [
                "### Unbiased and Biased Warmth and CompetenceOLS regression with human annotated actual values as DV and all IVs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "08d54a15",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/2 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing dataframe of length 5650\n",
                        "Analyzing Warmth dict_keys(['Unbiased', 'Biased']) Models\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": []
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "996624c0cfbb4467b25edbca37e4de9b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/126 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": []
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "fabc7caf55ba49fe9e08d251f333669b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/126 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 2/2 [00:00<00:00,  6.99it/s]\n",
                        " 50%|█████     | 1/2 [00:00<00:00,  3.41it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "--------------------\n",
                        "Warmth Unbiased R-Squared does not equal Biased R-Squared:\n",
                        "Warmth Unbiased = 0.077\n",
                        "Warmth Biased = 0.066\n",
                        "\n",
                        "\n",
                        "--------------------\n",
                        "Processing dataframe of length 5650\n",
                        "Analyzing Competence dict_keys(['Unbiased', 'Biased']) Models\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": []
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5cea2256ee374b1b80e7f35935089320",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/126 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": []
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8f726ea0ed41435dbd42bee5c9eb14fd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/126 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 2/2 [00:00<00:00,  7.23it/s]\n",
                        "100%|██████████| 2/2 [00:00<00:00,  3.18it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "--------------------\n",
                        "Competence Unbiased R-Squared does not equal Biased R-Squared:\n",
                        "Competence Unbiased = 0.101\n",
                        "Competence Biased = 0.115\n",
                        "\n",
                        "\n",
                        "--------------------\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "dv_names_dict_pre_classification = compare_actual_and_predicted(df_jobs, analysis_type='pre_classification', print_enabled=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "33e3488f",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'Warmth': {'Unbiased': {'dv_names': 'Warmth_actual',\n",
                            "   'R-squared': 0.07692323512582688,\n",
                            "   'Results': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x107097df0>},\n",
                            "  'Biased': {'dv_names': 'Warmth_predicted',\n",
                            "   'R-squared': 0.06597100861003291,\n",
                            "   'Results': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x29b18e380>}},\n",
                            " 'Competence': {'Unbiased': {'dv_names': 'Competence_actual',\n",
                            "   'R-squared': 0.10100927171509122,\n",
                            "   'Results': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x2a376cd90>},\n",
                            "  'Biased': {'dv_names': 'Competence_predicted',\n",
                            "   'R-squared': 0.11465842823221661,\n",
                            "   'Results': <statsmodels.regression.linear_model.RegressionResultsWrapper at 0x29d750d90>}}}"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dv_names_dict_pre_classification\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table class=\"simpletable\">\n",
                            "<caption>OLS Regression Results</caption>\n",
                            "<tr>\n",
                            "  <th>Dep. Variable:</th>      <td>Warmth_actual</td>  <th>  R-squared:         </th> <td>   0.077</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.075</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   33.54</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Date:</th>             <td>Wed, 15 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>1.70e-87</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Time:</th>                 <td>02:41:47</td>     <th>  Log-Likelihood:    </th> <td> -3202.4</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>No. Observations:</th>      <td>  5650</td>      <th>  AIC:               </th> <td>   6435.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Residuals:</th>          <td>  5635</td>      <th>  BIC:               </th> <td>   6534.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "                       <td></td>                          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female</th>                               <td>-2.405e+04</td> <td> 2.37e+04</td> <td>   -1.016</td> <td> 0.310</td> <td>-7.05e+04</td> <td> 2.24e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Mixed</th>                                <td>-2.405e+04</td> <td> 2.37e+04</td> <td>   -1.016</td> <td> 0.310</td> <td>-7.05e+04</td> <td> 2.24e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male</th>                                 <td>-2.405e+04</td> <td> 2.37e+04</td> <td>   -1.016</td> <td> 0.310</td> <td>-7.05e+04</td> <td> 2.24e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female_% per Sector</th>                  <td>  481.6445</td> <td>  473.771</td> <td>    1.017</td> <td> 0.309</td> <td> -447.130</td> <td> 1410.419</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male_% per Sector</th>                    <td>  480.7993</td> <td>  473.524</td> <td>    1.015</td> <td> 0.310</td> <td> -447.491</td> <td> 1409.089</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older</th>                                   <td>-2.405e+04</td> <td> 2.37e+04</td> <td>   -1.016</td> <td> 0.310</td> <td>-7.05e+04</td> <td> 2.24e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Mixed</th>                                   <td>-2.405e+04</td> <td> 2.37e+04</td> <td>   -1.016</td> <td> 0.310</td> <td>-7.05e+04</td> <td> 2.24e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger</th>                                 <td>-2.405e+04</td> <td> 2.37e+04</td> <td>   -1.016</td> <td> 0.310</td> <td>-7.05e+04</td> <td> 2.24e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older_% per Sector</th>                      <td>  489.9778</td> <td>  480.877</td> <td>    1.019</td> <td> 0.308</td> <td> -452.727</td> <td> 1432.682</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger_% per Sector</th>                    <td>  480.0486</td> <td>  473.940</td> <td>    1.013</td> <td> 0.311</td> <td> -449.057</td> <td> 1409.154</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Older_% per Sector</th>       <td>   -4.9066</td> <td>    4.811</td> <td>   -1.020</td> <td> 0.308</td> <td>  -14.338</td> <td>    4.524</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Younger_% per Sector</th>     <td>   -4.8071</td> <td>    4.742</td> <td>   -1.014</td> <td> 0.311</td> <td>  -14.102</td> <td>    4.488</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Older_% per Sector</th>         <td>   -4.8980</td> <td>    4.808</td> <td>   -1.019</td> <td> 0.308</td> <td>  -14.324</td> <td>    4.528</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Younger_% per Sector</th>       <td>   -4.7986</td> <td>    4.739</td> <td>   -1.013</td> <td> 0.311</td> <td>  -14.089</td> <td>    4.491</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>% Sector per Workforce</th>                      <td>    0.0039</td> <td>    0.003</td> <td>    1.438</td> <td> 0.151</td> <td>   -0.001</td> <td>    0.009</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Job Description spacy_sentencized_num_words</th> <td>    0.0111</td> <td>    0.001</td> <td>   20.500</td> <td> 0.000</td> <td>    0.010</td> <td>    0.012</td>\n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "  <th>Omnibus:</th>       <td>922.904</td> <th>  Durbin-Watson:     </th> <td>   1.417</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 901.084</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Skew:</th>          <td> 0.907</td>  <th>  Prob(JB):          </th> <td>2.15e-196</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Kurtosis:</th>      <td> 2.268</td>  <th>  Cond. No.          </th> <td>5.50e+17</td> \n",
                            "</tr>\n",
                            "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.96e-25. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/latex": [
                            "\\begin{center}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\toprule\n",
                            "\\textbf{Dep. Variable:}                                 &  Warmth\\_actual  & \\textbf{  R-squared:         } &     0.077   \\\\\n",
                            "\\textbf{Model:}                                         &       OLS        & \\textbf{  Adj. R-squared:    } &     0.075   \\\\\n",
                            "\\textbf{Method:}                                        &  Least Squares   & \\textbf{  F-statistic:       } &     33.54   \\\\\n",
                            "\\textbf{Date:}                                          & Wed, 15 Nov 2023 & \\textbf{  Prob (F-statistic):} &  1.70e-87   \\\\\n",
                            "\\textbf{Time:}                                          &     02:41:47     & \\textbf{  Log-Likelihood:    } &   -3202.4   \\\\\n",
                            "\\textbf{No. Observations:}                              &        5650      & \\textbf{  AIC:               } &     6435.   \\\\\n",
                            "\\textbf{Df Residuals:}                                  &        5635      & \\textbf{  BIC:               } &     6534.   \\\\\n",
                            "\\textbf{Df Model:}                                      &          14      & \\textbf{                     } &             \\\\\n",
                            "\\textbf{Covariance Type:}                               &    nonrobust     & \\textbf{                     } &             \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lcccccc}\n",
                            "                                                        & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
                            "\\midrule\n",
                            "\\textbf{Gender\\_Female}                                 &   -2.405e+04  &     2.37e+04     &    -1.016  &         0.310        &    -7.05e+04    &     2.24e+04     \\\\\n",
                            "\\textbf{Gender\\_Mixed}                                  &   -2.405e+04  &     2.37e+04     &    -1.016  &         0.310        &    -7.05e+04    &     2.24e+04     \\\\\n",
                            "\\textbf{Gender\\_Male}                                   &   -2.405e+04  &     2.37e+04     &    -1.016  &         0.310        &    -7.05e+04    &     2.24e+04     \\\\\n",
                            "\\textbf{Gender\\_Female\\_\\% per Sector}                  &     481.6445  &      473.771     &     1.017  &         0.309        &     -447.130    &     1410.419     \\\\\n",
                            "\\textbf{Gender\\_Male\\_\\% per Sector}                    &     480.7993  &      473.524     &     1.015  &         0.310        &     -447.491    &     1409.089     \\\\\n",
                            "\\textbf{Age\\_Older}                                     &   -2.405e+04  &     2.37e+04     &    -1.016  &         0.310        &    -7.05e+04    &     2.24e+04     \\\\\n",
                            "\\textbf{Age\\_Mixed}                                     &   -2.405e+04  &     2.37e+04     &    -1.016  &         0.310        &    -7.05e+04    &     2.24e+04     \\\\\n",
                            "\\textbf{Age\\_Younger}                                   &   -2.405e+04  &     2.37e+04     &    -1.016  &         0.310        &    -7.05e+04    &     2.24e+04     \\\\\n",
                            "\\textbf{Age\\_Older\\_\\% per Sector}                      &     489.9778  &      480.877     &     1.019  &         0.308        &     -452.727    &     1432.682     \\\\\n",
                            "\\textbf{Age\\_Younger\\_\\% per Sector}                    &     480.0486  &      473.940     &     1.013  &         0.311        &     -449.057    &     1409.154     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Older\\_\\% per Sector}      &      -4.9066  &        4.811     &    -1.020  &         0.308        &      -14.338    &        4.524     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Younger\\_\\% per Sector}    &      -4.8071  &        4.742     &    -1.014  &         0.311        &      -14.102    &        4.488     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Older\\_\\% per Sector}        &      -4.8980  &        4.808     &    -1.019  &         0.308        &      -14.324    &        4.528     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Younger\\_\\% per Sector}      &      -4.7986  &        4.739     &    -1.013  &         0.311        &      -14.089    &        4.491     \\\\\n",
                            "\\textbf{\\% Sector per Workforce}                        &       0.0039  &        0.003     &     1.438  &         0.151        &       -0.001    &        0.009     \\\\\n",
                            "\\textbf{Job Description spacy\\_sentencized\\_num\\_words} &       0.0111  &        0.001     &    20.500  &         0.000        &        0.010    &        0.012     \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\textbf{Omnibus:}       & 922.904 & \\textbf{  Durbin-Watson:     } &     1.417  \\\\\n",
                            "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &   901.084  \\\\\n",
                            "\\textbf{Skew:}          &   0.907 & \\textbf{  Prob(JB):          } & 2.15e-196  \\\\\n",
                            "\\textbf{Kurtosis:}      &   2.268 & \\textbf{  Cond. No.          } &  5.50e+17  \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "%\\caption{OLS Regression Results}\n",
                            "\\end{center}\n",
                            "\n",
                            "Notes: \\newline\n",
                            " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
                            " [2] The smallest eigenvalue is 4.96e-25. This might indicate that there are \\newline\n",
                            " strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/plain": [
                            "<class 'statsmodels.iolib.summary.Summary'>\n",
                            "\"\"\"\n",
                            "                            OLS Regression Results                            \n",
                            "==============================================================================\n",
                            "Dep. Variable:          Warmth_actual   R-squared:                       0.077\n",
                            "Model:                            OLS   Adj. R-squared:                  0.075\n",
                            "Method:                 Least Squares   F-statistic:                     33.54\n",
                            "Date:                Wed, 15 Nov 2023   Prob (F-statistic):           1.70e-87\n",
                            "Time:                        02:41:47   Log-Likelihood:                -3202.4\n",
                            "No. Observations:                5650   AIC:                             6435.\n",
                            "Df Residuals:                    5635   BIC:                             6534.\n",
                            "Df Model:                          14                                         \n",
                            "Covariance Type:            nonrobust                                         \n",
                            "===============================================================================================================\n",
                            "                                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
                            "---------------------------------------------------------------------------------------------------------------\n",
                            "Gender_Female                               -2.405e+04   2.37e+04     -1.016      0.310   -7.05e+04    2.24e+04\n",
                            "Gender_Mixed                                -2.405e+04   2.37e+04     -1.016      0.310   -7.05e+04    2.24e+04\n",
                            "Gender_Male                                 -2.405e+04   2.37e+04     -1.016      0.310   -7.05e+04    2.24e+04\n",
                            "Gender_Female_% per Sector                    481.6445    473.771      1.017      0.309    -447.130    1410.419\n",
                            "Gender_Male_% per Sector                      480.7993    473.524      1.015      0.310    -447.491    1409.089\n",
                            "Age_Older                                   -2.405e+04   2.37e+04     -1.016      0.310   -7.05e+04    2.24e+04\n",
                            "Age_Mixed                                   -2.405e+04   2.37e+04     -1.016      0.310   -7.05e+04    2.24e+04\n",
                            "Age_Younger                                 -2.405e+04   2.37e+04     -1.016      0.310   -7.05e+04    2.24e+04\n",
                            "Age_Older_% per Sector                        489.9778    480.877      1.019      0.308    -452.727    1432.682\n",
                            "Age_Younger_% per Sector                      480.0486    473.940      1.013      0.311    -449.057    1409.154\n",
                            "Interaction_Female_Older_% per Sector          -4.9066      4.811     -1.020      0.308     -14.338       4.524\n",
                            "Interaction_Female_Younger_% per Sector        -4.8071      4.742     -1.014      0.311     -14.102       4.488\n",
                            "Interaction_Male_Older_% per Sector            -4.8980      4.808     -1.019      0.308     -14.324       4.528\n",
                            "Interaction_Male_Younger_% per Sector          -4.7986      4.739     -1.013      0.311     -14.089       4.491\n",
                            "% Sector per Workforce                          0.0039      0.003      1.438      0.151      -0.001       0.009\n",
                            "Job Description spacy_sentencized_num_words     0.0111      0.001     20.500      0.000       0.010       0.012\n",
                            "==============================================================================\n",
                            "Omnibus:                      922.904   Durbin-Watson:                   1.417\n",
                            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              901.084\n",
                            "Skew:                           0.907   Prob(JB):                    2.15e-196\n",
                            "Kurtosis:                       2.268   Cond. No.                     5.50e+17\n",
                            "==============================================================================\n",
                            "\n",
                            "Notes:\n",
                            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                            "[2] The smallest eigenvalue is 4.96e-25. This might indicate that there are\n",
                            "strong multicollinearity problems or that the design matrix is singular.\n",
                            "\"\"\""
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dv_names_dict_pre_classification['Warmth']['Unbiased']['Results'].summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table class=\"simpletable\">\n",
                            "<caption>OLS Regression Results</caption>\n",
                            "<tr>\n",
                            "  <th>Dep. Variable:</th>    <td>Warmth_predicted</td> <th>  R-squared:         </th> <td>   0.066</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.064</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   28.43</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Date:</th>             <td>Wed, 15 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>1.84e-73</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Time:</th>                 <td>02:42:06</td>     <th>  Log-Likelihood:    </th> <td> -3091.9</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>No. Observations:</th>      <td>  5650</td>      <th>  AIC:               </th> <td>   6214.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Residuals:</th>          <td>  5635</td>      <th>  BIC:               </th> <td>   6313.</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "                       <td></td>                          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female</th>                               <td> -2.01e+04</td> <td> 2.32e+04</td> <td>   -0.866</td> <td> 0.387</td> <td>-6.56e+04</td> <td> 2.54e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Mixed</th>                                <td> -2.01e+04</td> <td> 2.32e+04</td> <td>   -0.866</td> <td> 0.387</td> <td>-6.56e+04</td> <td> 2.54e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male</th>                                 <td> -2.01e+04</td> <td> 2.32e+04</td> <td>   -0.866</td> <td> 0.387</td> <td>-6.56e+04</td> <td> 2.54e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female_% per Sector</th>                  <td>  402.9754</td> <td>  464.596</td> <td>    0.867</td> <td> 0.386</td> <td> -507.812</td> <td> 1313.763</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male_% per Sector</th>                    <td>  401.7529</td> <td>  464.354</td> <td>    0.865</td> <td> 0.387</td> <td> -508.560</td> <td> 1312.066</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older</th>                                   <td> -2.01e+04</td> <td> 2.32e+04</td> <td>   -0.866</td> <td> 0.387</td> <td>-6.56e+04</td> <td> 2.54e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Mixed</th>                                   <td> -2.01e+04</td> <td> 2.32e+04</td> <td>   -0.866</td> <td> 0.387</td> <td>-6.56e+04</td> <td> 2.54e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger</th>                                 <td> -2.01e+04</td> <td> 2.32e+04</td> <td>   -0.866</td> <td> 0.387</td> <td>-6.56e+04</td> <td> 2.54e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older_% per Sector</th>                      <td>  409.5583</td> <td>  471.564</td> <td>    0.869</td> <td> 0.385</td> <td> -514.890</td> <td> 1334.006</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger_% per Sector</th>                    <td>  401.4372</td> <td>  464.762</td> <td>    0.864</td> <td> 0.388</td> <td> -509.675</td> <td> 1312.549</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Older_% per Sector</th>       <td>   -4.1048</td> <td>    4.718</td> <td>   -0.870</td> <td> 0.384</td> <td>  -13.353</td> <td>    5.144</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Younger_% per Sector</th>     <td>   -4.0237</td> <td>    4.650</td> <td>   -0.865</td> <td> 0.387</td> <td>  -13.139</td> <td>    5.092</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Older_% per Sector</th>         <td>   -4.0926</td> <td>    4.715</td> <td>   -0.868</td> <td> 0.385</td> <td>  -13.336</td> <td>    5.151</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Younger_% per Sector</th>       <td>   -4.0112</td> <td>    4.647</td> <td>   -0.863</td> <td> 0.388</td> <td>  -13.121</td> <td>    5.099</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>% Sector per Workforce</th>                      <td>    0.0029</td> <td>    0.003</td> <td>    1.070</td> <td> 0.285</td> <td>   -0.002</td> <td>    0.008</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Job Description spacy_sentencized_num_words</th> <td>    0.0100</td> <td>    0.001</td> <td>   18.738</td> <td> 0.000</td> <td>    0.009</td> <td>    0.011</td>\n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "  <th>Omnibus:</th>       <td>830.995</td> <th>  Durbin-Watson:     </th> <td>   1.553</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1061.267</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Skew:</th>          <td> 1.027</td>  <th>  Prob(JB):          </th> <td>3.54e-231</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Kurtosis:</th>      <td> 2.460</td>  <th>  Cond. No.          </th> <td>5.50e+17</td> \n",
                            "</tr>\n",
                            "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.96e-25. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/latex": [
                            "\\begin{center}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\toprule\n",
                            "\\textbf{Dep. Variable:}                                 & Warmth\\_predicted & \\textbf{  R-squared:         } &     0.066   \\\\\n",
                            "\\textbf{Model:}                                         &        OLS        & \\textbf{  Adj. R-squared:    } &     0.064   \\\\\n",
                            "\\textbf{Method:}                                        &   Least Squares   & \\textbf{  F-statistic:       } &     28.43   \\\\\n",
                            "\\textbf{Date:}                                          &  Wed, 15 Nov 2023 & \\textbf{  Prob (F-statistic):} &  1.84e-73   \\\\\n",
                            "\\textbf{Time:}                                          &      02:42:06     & \\textbf{  Log-Likelihood:    } &   -3091.9   \\\\\n",
                            "\\textbf{No. Observations:}                              &         5650      & \\textbf{  AIC:               } &     6214.   \\\\\n",
                            "\\textbf{Df Residuals:}                                  &         5635      & \\textbf{  BIC:               } &     6313.   \\\\\n",
                            "\\textbf{Df Model:}                                      &           14      & \\textbf{                     } &             \\\\\n",
                            "\\textbf{Covariance Type:}                               &     nonrobust     & \\textbf{                     } &             \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lcccccc}\n",
                            "                                                        & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
                            "\\midrule\n",
                            "\\textbf{Gender\\_Female}                                 &    -2.01e+04  &     2.32e+04     &    -0.866  &         0.387        &    -6.56e+04    &     2.54e+04     \\\\\n",
                            "\\textbf{Gender\\_Mixed}                                  &    -2.01e+04  &     2.32e+04     &    -0.866  &         0.387        &    -6.56e+04    &     2.54e+04     \\\\\n",
                            "\\textbf{Gender\\_Male}                                   &    -2.01e+04  &     2.32e+04     &    -0.866  &         0.387        &    -6.56e+04    &     2.54e+04     \\\\\n",
                            "\\textbf{Gender\\_Female\\_\\% per Sector}                  &     402.9754  &      464.596     &     0.867  &         0.386        &     -507.812    &     1313.763     \\\\\n",
                            "\\textbf{Gender\\_Male\\_\\% per Sector}                    &     401.7529  &      464.354     &     0.865  &         0.387        &     -508.560    &     1312.066     \\\\\n",
                            "\\textbf{Age\\_Older}                                     &    -2.01e+04  &     2.32e+04     &    -0.866  &         0.387        &    -6.56e+04    &     2.54e+04     \\\\\n",
                            "\\textbf{Age\\_Mixed}                                     &    -2.01e+04  &     2.32e+04     &    -0.866  &         0.387        &    -6.56e+04    &     2.54e+04     \\\\\n",
                            "\\textbf{Age\\_Younger}                                   &    -2.01e+04  &     2.32e+04     &    -0.866  &         0.387        &    -6.56e+04    &     2.54e+04     \\\\\n",
                            "\\textbf{Age\\_Older\\_\\% per Sector}                      &     409.5583  &      471.564     &     0.869  &         0.385        &     -514.890    &     1334.006     \\\\\n",
                            "\\textbf{Age\\_Younger\\_\\% per Sector}                    &     401.4372  &      464.762     &     0.864  &         0.388        &     -509.675    &     1312.549     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Older\\_\\% per Sector}      &      -4.1048  &        4.718     &    -0.870  &         0.384        &      -13.353    &        5.144     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Younger\\_\\% per Sector}    &      -4.0237  &        4.650     &    -0.865  &         0.387        &      -13.139    &        5.092     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Older\\_\\% per Sector}        &      -4.0926  &        4.715     &    -0.868  &         0.385        &      -13.336    &        5.151     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Younger\\_\\% per Sector}      &      -4.0112  &        4.647     &    -0.863  &         0.388        &      -13.121    &        5.099     \\\\\n",
                            "\\textbf{\\% Sector per Workforce}                        &       0.0029  &        0.003     &     1.070  &         0.285        &       -0.002    &        0.008     \\\\\n",
                            "\\textbf{Job Description spacy\\_sentencized\\_num\\_words} &       0.0100  &        0.001     &    18.738  &         0.000        &        0.009    &        0.011     \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\textbf{Omnibus:}       & 830.995 & \\textbf{  Durbin-Watson:     } &     1.553  \\\\\n",
                            "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  1061.267  \\\\\n",
                            "\\textbf{Skew:}          &   1.027 & \\textbf{  Prob(JB):          } & 3.54e-231  \\\\\n",
                            "\\textbf{Kurtosis:}      &   2.460 & \\textbf{  Cond. No.          } &  5.50e+17  \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "%\\caption{OLS Regression Results}\n",
                            "\\end{center}\n",
                            "\n",
                            "Notes: \\newline\n",
                            " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
                            " [2] The smallest eigenvalue is 4.96e-25. This might indicate that there are \\newline\n",
                            " strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/plain": [
                            "<class 'statsmodels.iolib.summary.Summary'>\n",
                            "\"\"\"\n",
                            "                            OLS Regression Results                            \n",
                            "==============================================================================\n",
                            "Dep. Variable:       Warmth_predicted   R-squared:                       0.066\n",
                            "Model:                            OLS   Adj. R-squared:                  0.064\n",
                            "Method:                 Least Squares   F-statistic:                     28.43\n",
                            "Date:                Wed, 15 Nov 2023   Prob (F-statistic):           1.84e-73\n",
                            "Time:                        02:42:06   Log-Likelihood:                -3091.9\n",
                            "No. Observations:                5650   AIC:                             6214.\n",
                            "Df Residuals:                    5635   BIC:                             6313.\n",
                            "Df Model:                          14                                         \n",
                            "Covariance Type:            nonrobust                                         \n",
                            "===============================================================================================================\n",
                            "                                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
                            "---------------------------------------------------------------------------------------------------------------\n",
                            "Gender_Female                                -2.01e+04   2.32e+04     -0.866      0.387   -6.56e+04    2.54e+04\n",
                            "Gender_Mixed                                 -2.01e+04   2.32e+04     -0.866      0.387   -6.56e+04    2.54e+04\n",
                            "Gender_Male                                  -2.01e+04   2.32e+04     -0.866      0.387   -6.56e+04    2.54e+04\n",
                            "Gender_Female_% per Sector                    402.9754    464.596      0.867      0.386    -507.812    1313.763\n",
                            "Gender_Male_% per Sector                      401.7529    464.354      0.865      0.387    -508.560    1312.066\n",
                            "Age_Older                                    -2.01e+04   2.32e+04     -0.866      0.387   -6.56e+04    2.54e+04\n",
                            "Age_Mixed                                    -2.01e+04   2.32e+04     -0.866      0.387   -6.56e+04    2.54e+04\n",
                            "Age_Younger                                  -2.01e+04   2.32e+04     -0.866      0.387   -6.56e+04    2.54e+04\n",
                            "Age_Older_% per Sector                        409.5583    471.564      0.869      0.385    -514.890    1334.006\n",
                            "Age_Younger_% per Sector                      401.4372    464.762      0.864      0.388    -509.675    1312.549\n",
                            "Interaction_Female_Older_% per Sector          -4.1048      4.718     -0.870      0.384     -13.353       5.144\n",
                            "Interaction_Female_Younger_% per Sector        -4.0237      4.650     -0.865      0.387     -13.139       5.092\n",
                            "Interaction_Male_Older_% per Sector            -4.0926      4.715     -0.868      0.385     -13.336       5.151\n",
                            "Interaction_Male_Younger_% per Sector          -4.0112      4.647     -0.863      0.388     -13.121       5.099\n",
                            "% Sector per Workforce                          0.0029      0.003      1.070      0.285      -0.002       0.008\n",
                            "Job Description spacy_sentencized_num_words     0.0100      0.001     18.738      0.000       0.009       0.011\n",
                            "==============================================================================\n",
                            "Omnibus:                      830.995   Durbin-Watson:                   1.553\n",
                            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1061.267\n",
                            "Skew:                           1.027   Prob(JB):                    3.54e-231\n",
                            "Kurtosis:                       2.460   Cond. No.                     5.50e+17\n",
                            "==============================================================================\n",
                            "\n",
                            "Notes:\n",
                            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                            "[2] The smallest eigenvalue is 4.96e-25. This might indicate that there are\n",
                            "strong multicollinearity problems or that the design matrix is singular.\n",
                            "\"\"\""
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dv_names_dict_pre_classification['Warmth']['Biased']['Results'].summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table class=\"simpletable\">\n",
                            "<caption>OLS Regression Results</caption>\n",
                            "<tr>\n",
                            "  <th>Dep. Variable:</th>    <td>Competence_actual</td> <th>  R-squared:         </th> <td>   0.101</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.099</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   45.22</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Date:</th>             <td>Wed, 15 Nov 2023</td>  <th>  Prob (F-statistic):</th> <td>3.84e-119</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Time:</th>                 <td>02:42:48</td>      <th>  Log-Likelihood:    </th> <td> -3787.4</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>No. Observations:</th>      <td>  5650</td>       <th>  AIC:               </th> <td>   7605.</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Residuals:</th>          <td>  5635</td>       <th>  BIC:               </th> <td>   7704.</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Model:</th>              <td>    14</td>       <th>                     </th>     <td> </td>    \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>    \n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "                       <td></td>                          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female</th>                               <td>-2.746e+04</td> <td> 2.63e+04</td> <td>   -1.045</td> <td> 0.296</td> <td>-7.89e+04</td> <td>  2.4e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Mixed</th>                                <td>-2.746e+04</td> <td> 2.63e+04</td> <td>   -1.046</td> <td> 0.296</td> <td>-7.89e+04</td> <td>  2.4e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male</th>                                 <td>-2.746e+04</td> <td> 2.63e+04</td> <td>   -1.046</td> <td> 0.296</td> <td>-7.89e+04</td> <td>  2.4e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female_% per Sector</th>                  <td>  549.1728</td> <td>  525.455</td> <td>    1.045</td> <td> 0.296</td> <td> -480.921</td> <td> 1579.266</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male_% per Sector</th>                    <td>  549.1992</td> <td>  525.181</td> <td>    1.046</td> <td> 0.296</td> <td> -480.357</td> <td> 1578.756</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older</th>                                   <td>-2.746e+04</td> <td> 2.63e+04</td> <td>   -1.046</td> <td> 0.296</td> <td>-7.89e+04</td> <td>  2.4e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Mixed</th>                                   <td>-2.746e+04</td> <td> 2.63e+04</td> <td>   -1.046</td> <td> 0.296</td> <td>-7.89e+04</td> <td>  2.4e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger</th>                                 <td>-2.746e+04</td> <td> 2.63e+04</td> <td>   -1.046</td> <td> 0.296</td> <td>-7.89e+04</td> <td>  2.4e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older_% per Sector</th>                      <td>  562.0209</td> <td>  533.336</td> <td>    1.054</td> <td> 0.292</td> <td> -483.522</td> <td> 1607.564</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger_% per Sector</th>                    <td>  548.1668</td> <td>  525.642</td> <td>    1.043</td> <td> 0.297</td> <td> -482.294</td> <td> 1578.627</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Older_% per Sector</th>       <td>   -5.6209</td> <td>    5.336</td> <td>   -1.053</td> <td> 0.292</td> <td>  -16.081</td> <td>    4.839</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Younger_% per Sector</th>     <td>   -5.4820</td> <td>    5.259</td> <td>   -1.042</td> <td> 0.297</td> <td>  -15.791</td> <td>    4.827</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Older_% per Sector</th>         <td>   -5.6208</td> <td>    5.333</td> <td>   -1.054</td> <td> 0.292</td> <td>  -16.075</td> <td>    4.834</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Younger_% per Sector</th>       <td>   -5.4822</td> <td>    5.256</td> <td>   -1.043</td> <td> 0.297</td> <td>  -15.786</td> <td>    4.821</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>% Sector per Workforce</th>                      <td>    0.0043</td> <td>    0.003</td> <td>    1.421</td> <td> 0.155</td> <td>   -0.002</td> <td>    0.010</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Job Description spacy_sentencized_num_words</th> <td>    0.0144</td> <td>    0.001</td> <td>   23.857</td> <td> 0.000</td> <td>    0.013</td> <td>    0.016</td>\n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "  <th>Omnibus:</th>       <td>28580.445</td> <th>  Durbin-Watson:     </th> <td>   1.142</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 611.852</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Skew:</th>           <td> 0.117</td>   <th>  Prob(JB):          </th> <td>1.37e-133</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Kurtosis:</th>       <td> 1.405</td>   <th>  Cond. No.          </th> <td>5.50e+17</td> \n",
                            "</tr>\n",
                            "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.96e-25. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/latex": [
                            "\\begin{center}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\toprule\n",
                            "\\textbf{Dep. Variable:}                                 & Competence\\_actual & \\textbf{  R-squared:         } &     0.101   \\\\\n",
                            "\\textbf{Model:}                                         &        OLS         & \\textbf{  Adj. R-squared:    } &     0.099   \\\\\n",
                            "\\textbf{Method:}                                        &   Least Squares    & \\textbf{  F-statistic:       } &     45.22   \\\\\n",
                            "\\textbf{Date:}                                          &  Wed, 15 Nov 2023  & \\textbf{  Prob (F-statistic):} & 3.84e-119   \\\\\n",
                            "\\textbf{Time:}                                          &      02:42:48      & \\textbf{  Log-Likelihood:    } &   -3787.4   \\\\\n",
                            "\\textbf{No. Observations:}                              &         5650       & \\textbf{  AIC:               } &     7605.   \\\\\n",
                            "\\textbf{Df Residuals:}                                  &         5635       & \\textbf{  BIC:               } &     7704.   \\\\\n",
                            "\\textbf{Df Model:}                                      &           14       & \\textbf{                     } &             \\\\\n",
                            "\\textbf{Covariance Type:}                               &     nonrobust      & \\textbf{                     } &             \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lcccccc}\n",
                            "                                                        & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
                            "\\midrule\n",
                            "\\textbf{Gender\\_Female}                                 &   -2.746e+04  &     2.63e+04     &    -1.045  &         0.296        &    -7.89e+04    &      2.4e+04     \\\\\n",
                            "\\textbf{Gender\\_Mixed}                                  &   -2.746e+04  &     2.63e+04     &    -1.046  &         0.296        &    -7.89e+04    &      2.4e+04     \\\\\n",
                            "\\textbf{Gender\\_Male}                                   &   -2.746e+04  &     2.63e+04     &    -1.046  &         0.296        &    -7.89e+04    &      2.4e+04     \\\\\n",
                            "\\textbf{Gender\\_Female\\_\\% per Sector}                  &     549.1728  &      525.455     &     1.045  &         0.296        &     -480.921    &     1579.266     \\\\\n",
                            "\\textbf{Gender\\_Male\\_\\% per Sector}                    &     549.1992  &      525.181     &     1.046  &         0.296        &     -480.357    &     1578.756     \\\\\n",
                            "\\textbf{Age\\_Older}                                     &   -2.746e+04  &     2.63e+04     &    -1.046  &         0.296        &    -7.89e+04    &      2.4e+04     \\\\\n",
                            "\\textbf{Age\\_Mixed}                                     &   -2.746e+04  &     2.63e+04     &    -1.046  &         0.296        &    -7.89e+04    &      2.4e+04     \\\\\n",
                            "\\textbf{Age\\_Younger}                                   &   -2.746e+04  &     2.63e+04     &    -1.046  &         0.296        &    -7.89e+04    &      2.4e+04     \\\\\n",
                            "\\textbf{Age\\_Older\\_\\% per Sector}                      &     562.0209  &      533.336     &     1.054  &         0.292        &     -483.522    &     1607.564     \\\\\n",
                            "\\textbf{Age\\_Younger\\_\\% per Sector}                    &     548.1668  &      525.642     &     1.043  &         0.297        &     -482.294    &     1578.627     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Older\\_\\% per Sector}      &      -5.6209  &        5.336     &    -1.053  &         0.292        &      -16.081    &        4.839     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Younger\\_\\% per Sector}    &      -5.4820  &        5.259     &    -1.042  &         0.297        &      -15.791    &        4.827     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Older\\_\\% per Sector}        &      -5.6208  &        5.333     &    -1.054  &         0.292        &      -16.075    &        4.834     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Younger\\_\\% per Sector}      &      -5.4822  &        5.256     &    -1.043  &         0.297        &      -15.786    &        4.821     \\\\\n",
                            "\\textbf{\\% Sector per Workforce}                        &       0.0043  &        0.003     &     1.421  &         0.155        &       -0.002    &        0.010     \\\\\n",
                            "\\textbf{Job Description spacy\\_sentencized\\_num\\_words} &       0.0144  &        0.001     &    23.857  &         0.000        &        0.013    &        0.016     \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\textbf{Omnibus:}       & 28580.445 & \\textbf{  Durbin-Watson:     } &     1.142  \\\\\n",
                            "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } &   611.852  \\\\\n",
                            "\\textbf{Skew:}          &    0.117  & \\textbf{  Prob(JB):          } & 1.37e-133  \\\\\n",
                            "\\textbf{Kurtosis:}      &    1.405  & \\textbf{  Cond. No.          } &  5.50e+17  \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "%\\caption{OLS Regression Results}\n",
                            "\\end{center}\n",
                            "\n",
                            "Notes: \\newline\n",
                            " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
                            " [2] The smallest eigenvalue is 4.96e-25. This might indicate that there are \\newline\n",
                            " strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/plain": [
                            "<class 'statsmodels.iolib.summary.Summary'>\n",
                            "\"\"\"\n",
                            "                            OLS Regression Results                            \n",
                            "==============================================================================\n",
                            "Dep. Variable:      Competence_actual   R-squared:                       0.101\n",
                            "Model:                            OLS   Adj. R-squared:                  0.099\n",
                            "Method:                 Least Squares   F-statistic:                     45.22\n",
                            "Date:                Wed, 15 Nov 2023   Prob (F-statistic):          3.84e-119\n",
                            "Time:                        02:42:48   Log-Likelihood:                -3787.4\n",
                            "No. Observations:                5650   AIC:                             7605.\n",
                            "Df Residuals:                    5635   BIC:                             7704.\n",
                            "Df Model:                          14                                         \n",
                            "Covariance Type:            nonrobust                                         \n",
                            "===============================================================================================================\n",
                            "                                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
                            "---------------------------------------------------------------------------------------------------------------\n",
                            "Gender_Female                               -2.746e+04   2.63e+04     -1.045      0.296   -7.89e+04     2.4e+04\n",
                            "Gender_Mixed                                -2.746e+04   2.63e+04     -1.046      0.296   -7.89e+04     2.4e+04\n",
                            "Gender_Male                                 -2.746e+04   2.63e+04     -1.046      0.296   -7.89e+04     2.4e+04\n",
                            "Gender_Female_% per Sector                    549.1728    525.455      1.045      0.296    -480.921    1579.266\n",
                            "Gender_Male_% per Sector                      549.1992    525.181      1.046      0.296    -480.357    1578.756\n",
                            "Age_Older                                   -2.746e+04   2.63e+04     -1.046      0.296   -7.89e+04     2.4e+04\n",
                            "Age_Mixed                                   -2.746e+04   2.63e+04     -1.046      0.296   -7.89e+04     2.4e+04\n",
                            "Age_Younger                                 -2.746e+04   2.63e+04     -1.046      0.296   -7.89e+04     2.4e+04\n",
                            "Age_Older_% per Sector                        562.0209    533.336      1.054      0.292    -483.522    1607.564\n",
                            "Age_Younger_% per Sector                      548.1668    525.642      1.043      0.297    -482.294    1578.627\n",
                            "Interaction_Female_Older_% per Sector          -5.6209      5.336     -1.053      0.292     -16.081       4.839\n",
                            "Interaction_Female_Younger_% per Sector        -5.4820      5.259     -1.042      0.297     -15.791       4.827\n",
                            "Interaction_Male_Older_% per Sector            -5.6208      5.333     -1.054      0.292     -16.075       4.834\n",
                            "Interaction_Male_Younger_% per Sector          -5.4822      5.256     -1.043      0.297     -15.786       4.821\n",
                            "% Sector per Workforce                          0.0043      0.003      1.421      0.155      -0.002       0.010\n",
                            "Job Description spacy_sentencized_num_words     0.0144      0.001     23.857      0.000       0.013       0.016\n",
                            "==============================================================================\n",
                            "Omnibus:                    28580.445   Durbin-Watson:                   1.142\n",
                            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              611.852\n",
                            "Skew:                           0.117   Prob(JB):                    1.37e-133\n",
                            "Kurtosis:                       1.405   Cond. No.                     5.50e+17\n",
                            "==============================================================================\n",
                            "\n",
                            "Notes:\n",
                            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                            "[2] The smallest eigenvalue is 4.96e-25. This might indicate that there are\n",
                            "strong multicollinearity problems or that the design matrix is singular.\n",
                            "\"\"\""
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dv_names_dict_pre_classification['Competence']['Unbiased']['Results'].summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<table class=\"simpletable\">\n",
                            "<caption>OLS Regression Results</caption>\n",
                            "<tr>\n",
                            "  <th>Dep. Variable:</th>    <td>Competence_predicted</td> <th>  R-squared:         </th> <td>   0.115</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Model:</th>                     <td>OLS</td>         <th>  Adj. R-squared:    </th> <td>   0.112</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Method:</th>               <td>Least Squares</td>    <th>  F-statistic:       </th> <td>   52.13</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Date:</th>               <td>Wed, 15 Nov 2023</td>   <th>  Prob (F-statistic):</th> <td>1.56e-137</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Time:</th>                   <td>02:42:58</td>       <th>  Log-Likelihood:    </th> <td> -3747.5</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>No. Observations:</th>        <td>  5650</td>        <th>  AIC:               </th> <td>   7525.</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Residuals:</th>            <td>  5635</td>        <th>  BIC:               </th> <td>   7625.</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Df Model:</th>                <td>    14</td>        <th>                     </th>     <td> </td>    \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Covariance Type:</th>        <td>nonrobust</td>      <th>                     </th>     <td> </td>    \n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "                       <td></td>                          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female</th>                               <td> 1950.6825</td> <td> 2.61e+04</td> <td>    0.075</td> <td> 0.940</td> <td>-4.92e+04</td> <td> 5.31e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Mixed</th>                                <td> 1950.4908</td> <td> 2.61e+04</td> <td>    0.075</td> <td> 0.940</td> <td>-4.92e+04</td> <td> 5.31e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male</th>                                 <td> 1950.5378</td> <td> 2.61e+04</td> <td>    0.075</td> <td> 0.940</td> <td>-4.92e+04</td> <td> 5.31e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Female_% per Sector</th>                  <td>  -38.7221</td> <td>  521.760</td> <td>   -0.074</td> <td> 0.941</td> <td>-1061.572</td> <td>  984.128</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Gender_Male_% per Sector</th>                    <td>  -39.1037</td> <td>  521.488</td> <td>   -0.075</td> <td> 0.940</td> <td>-1061.420</td> <td>  983.213</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older</th>                                   <td> 1950.6213</td> <td> 2.61e+04</td> <td>    0.075</td> <td> 0.940</td> <td>-4.92e+04</td> <td> 5.31e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Mixed</th>                                   <td> 1950.5198</td> <td> 2.61e+04</td> <td>    0.075</td> <td> 0.940</td> <td>-4.92e+04</td> <td> 5.31e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger</th>                                 <td> 1950.5700</td> <td> 2.61e+04</td> <td>    0.075</td> <td> 0.940</td> <td>-4.92e+04</td> <td> 5.31e+04</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Older_% per Sector</th>                      <td>  -38.2644</td> <td>  529.585</td> <td>   -0.072</td> <td> 0.942</td> <td>-1076.455</td> <td>  999.926</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Age_Younger_% per Sector</th>                    <td>  -38.5597</td> <td>  521.945</td> <td>   -0.074</td> <td> 0.941</td> <td>-1061.774</td> <td>  984.654</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Older_% per Sector</th>       <td>    0.3798</td> <td>    5.298</td> <td>    0.072</td> <td> 0.943</td> <td>  -10.006</td> <td>   10.766</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Female_Younger_% per Sector</th>     <td>    0.3827</td> <td>    5.222</td> <td>    0.073</td> <td> 0.942</td> <td>   -9.854</td> <td>   10.619</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Older_% per Sector</th>         <td>    0.3836</td> <td>    5.295</td> <td>    0.072</td> <td> 0.942</td> <td>   -9.997</td> <td>   10.765</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Interaction_Male_Younger_% per Sector</th>       <td>    0.3866</td> <td>    5.219</td> <td>    0.074</td> <td> 0.941</td> <td>   -9.844</td> <td>   10.618</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>% Sector per Workforce</th>                      <td>    0.0055</td> <td>    0.003</td> <td>    1.821</td> <td> 0.069</td> <td>   -0.000</td> <td>    0.011</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Job Description spacy_sentencized_num_words</th> <td>    0.0156</td> <td>    0.001</td> <td>   26.113</td> <td> 0.000</td> <td>    0.014</td> <td>    0.017</td>\n",
                            "</tr>\n",
                            "</table>\n",
                            "<table class=\"simpletable\">\n",
                            "<tr>\n",
                            "  <th>Omnibus:</th>       <td>38708.802</td> <th>  Durbin-Watson:     </th> <td>   1.259</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td> 513.002</td> \n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Skew:</th>           <td> 0.079</td>   <th>  Prob(JB):          </th> <td>4.01e-112</td>\n",
                            "</tr>\n",
                            "<tr>\n",
                            "  <th>Kurtosis:</th>       <td> 1.532</td>   <th>  Cond. No.          </th> <td>5.50e+17</td> \n",
                            "</tr>\n",
                            "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.96e-25. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/latex": [
                            "\\begin{center}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\toprule\n",
                            "\\textbf{Dep. Variable:}                                 & Competence\\_predicted & \\textbf{  R-squared:         } &     0.115   \\\\\n",
                            "\\textbf{Model:}                                         &          OLS          & \\textbf{  Adj. R-squared:    } &     0.112   \\\\\n",
                            "\\textbf{Method:}                                        &     Least Squares     & \\textbf{  F-statistic:       } &     52.13   \\\\\n",
                            "\\textbf{Date:}                                          &    Wed, 15 Nov 2023   & \\textbf{  Prob (F-statistic):} & 1.56e-137   \\\\\n",
                            "\\textbf{Time:}                                          &        02:42:58       & \\textbf{  Log-Likelihood:    } &   -3747.5   \\\\\n",
                            "\\textbf{No. Observations:}                              &           5650        & \\textbf{  AIC:               } &     7525.   \\\\\n",
                            "\\textbf{Df Residuals:}                                  &           5635        & \\textbf{  BIC:               } &     7625.   \\\\\n",
                            "\\textbf{Df Model:}                                      &             14        & \\textbf{                     } &             \\\\\n",
                            "\\textbf{Covariance Type:}                               &       nonrobust       & \\textbf{                     } &             \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lcccccc}\n",
                            "                                                        & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
                            "\\midrule\n",
                            "\\textbf{Gender\\_Female}                                 &    1950.6825  &     2.61e+04     &     0.075  &         0.940        &    -4.92e+04    &     5.31e+04     \\\\\n",
                            "\\textbf{Gender\\_Mixed}                                  &    1950.4908  &     2.61e+04     &     0.075  &         0.940        &    -4.92e+04    &     5.31e+04     \\\\\n",
                            "\\textbf{Gender\\_Male}                                   &    1950.5378  &     2.61e+04     &     0.075  &         0.940        &    -4.92e+04    &     5.31e+04     \\\\\n",
                            "\\textbf{Gender\\_Female\\_\\% per Sector}                  &     -38.7221  &      521.760     &    -0.074  &         0.941        &    -1061.572    &      984.128     \\\\\n",
                            "\\textbf{Gender\\_Male\\_\\% per Sector}                    &     -39.1037  &      521.488     &    -0.075  &         0.940        &    -1061.420    &      983.213     \\\\\n",
                            "\\textbf{Age\\_Older}                                     &    1950.6213  &     2.61e+04     &     0.075  &         0.940        &    -4.92e+04    &     5.31e+04     \\\\\n",
                            "\\textbf{Age\\_Mixed}                                     &    1950.5198  &     2.61e+04     &     0.075  &         0.940        &    -4.92e+04    &     5.31e+04     \\\\\n",
                            "\\textbf{Age\\_Younger}                                   &    1950.5700  &     2.61e+04     &     0.075  &         0.940        &    -4.92e+04    &     5.31e+04     \\\\\n",
                            "\\textbf{Age\\_Older\\_\\% per Sector}                      &     -38.2644  &      529.585     &    -0.072  &         0.942        &    -1076.455    &      999.926     \\\\\n",
                            "\\textbf{Age\\_Younger\\_\\% per Sector}                    &     -38.5597  &      521.945     &    -0.074  &         0.941        &    -1061.774    &      984.654     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Older\\_\\% per Sector}      &       0.3798  &        5.298     &     0.072  &         0.943        &      -10.006    &       10.766     \\\\\n",
                            "\\textbf{Interaction\\_Female\\_Younger\\_\\% per Sector}    &       0.3827  &        5.222     &     0.073  &         0.942        &       -9.854    &       10.619     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Older\\_\\% per Sector}        &       0.3836  &        5.295     &     0.072  &         0.942        &       -9.997    &       10.765     \\\\\n",
                            "\\textbf{Interaction\\_Male\\_Younger\\_\\% per Sector}      &       0.3866  &        5.219     &     0.074  &         0.941        &       -9.844    &       10.618     \\\\\n",
                            "\\textbf{\\% Sector per Workforce}                        &       0.0055  &        0.003     &     1.821  &         0.069        &       -0.000    &        0.011     \\\\\n",
                            "\\textbf{Job Description spacy\\_sentencized\\_num\\_words} &       0.0156  &        0.001     &    26.113  &         0.000        &        0.014    &        0.017     \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "\\begin{tabular}{lclc}\n",
                            "\\textbf{Omnibus:}       & 38708.802 & \\textbf{  Durbin-Watson:     } &     1.259  \\\\\n",
                            "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } &   513.002  \\\\\n",
                            "\\textbf{Skew:}          &    0.079  & \\textbf{  Prob(JB):          } & 4.01e-112  \\\\\n",
                            "\\textbf{Kurtosis:}      &    1.532  & \\textbf{  Cond. No.          } &  5.50e+17  \\\\\n",
                            "\\bottomrule\n",
                            "\\end{tabular}\n",
                            "%\\caption{OLS Regression Results}\n",
                            "\\end{center}\n",
                            "\n",
                            "Notes: \\newline\n",
                            " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
                            " [2] The smallest eigenvalue is 4.96e-25. This might indicate that there are \\newline\n",
                            " strong multicollinearity problems or that the design matrix is singular."
                        ],
                        "text/plain": [
                            "<class 'statsmodels.iolib.summary.Summary'>\n",
                            "\"\"\"\n",
                            "                             OLS Regression Results                             \n",
                            "================================================================================\n",
                            "Dep. Variable:     Competence_predicted   R-squared:                       0.115\n",
                            "Model:                              OLS   Adj. R-squared:                  0.112\n",
                            "Method:                   Least Squares   F-statistic:                     52.13\n",
                            "Date:                  Wed, 15 Nov 2023   Prob (F-statistic):          1.56e-137\n",
                            "Time:                          02:42:58   Log-Likelihood:                -3747.5\n",
                            "No. Observations:                  5650   AIC:                             7525.\n",
                            "Df Residuals:                      5635   BIC:                             7625.\n",
                            "Df Model:                            14                                         \n",
                            "Covariance Type:              nonrobust                                         \n",
                            "===============================================================================================================\n",
                            "                                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
                            "---------------------------------------------------------------------------------------------------------------\n",
                            "Gender_Female                                1950.6825   2.61e+04      0.075      0.940   -4.92e+04    5.31e+04\n",
                            "Gender_Mixed                                 1950.4908   2.61e+04      0.075      0.940   -4.92e+04    5.31e+04\n",
                            "Gender_Male                                  1950.5378   2.61e+04      0.075      0.940   -4.92e+04    5.31e+04\n",
                            "Gender_Female_% per Sector                    -38.7221    521.760     -0.074      0.941   -1061.572     984.128\n",
                            "Gender_Male_% per Sector                      -39.1037    521.488     -0.075      0.940   -1061.420     983.213\n",
                            "Age_Older                                    1950.6213   2.61e+04      0.075      0.940   -4.92e+04    5.31e+04\n",
                            "Age_Mixed                                    1950.5198   2.61e+04      0.075      0.940   -4.92e+04    5.31e+04\n",
                            "Age_Younger                                  1950.5700   2.61e+04      0.075      0.940   -4.92e+04    5.31e+04\n",
                            "Age_Older_% per Sector                        -38.2644    529.585     -0.072      0.942   -1076.455     999.926\n",
                            "Age_Younger_% per Sector                      -38.5597    521.945     -0.074      0.941   -1061.774     984.654\n",
                            "Interaction_Female_Older_% per Sector           0.3798      5.298      0.072      0.943     -10.006      10.766\n",
                            "Interaction_Female_Younger_% per Sector         0.3827      5.222      0.073      0.942      -9.854      10.619\n",
                            "Interaction_Male_Older_% per Sector             0.3836      5.295      0.072      0.942      -9.997      10.765\n",
                            "Interaction_Male_Younger_% per Sector           0.3866      5.219      0.074      0.941      -9.844      10.618\n",
                            "% Sector per Workforce                          0.0055      0.003      1.821      0.069      -0.000       0.011\n",
                            "Job Description spacy_sentencized_num_words     0.0156      0.001     26.113      0.000       0.014       0.017\n",
                            "==============================================================================\n",
                            "Omnibus:                    38708.802   Durbin-Watson:                   1.259\n",
                            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              513.002\n",
                            "Skew:                           0.079   Prob(JB):                    4.01e-112\n",
                            "Kurtosis:                       1.532   Cond. No.                     5.50e+17\n",
                            "==============================================================================\n",
                            "\n",
                            "Notes:\n",
                            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
                            "[2] The smallest eigenvalue is 4.96e-25. This might indicate that there are\n",
                            "strong multicollinearity problems or that the design matrix is singular.\n",
                            "\"\"\""
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dv_names_dict_pre_classification['Competence']['Biased']['Results'].summary()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b9202851",
            "metadata": {},
            "source": [
                "## Make RandomForestRegressor Classifier\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dcf1e9cb",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_final_indiv_and_aggr_preds(estimator, X):\n",
                "    pred = estimator.predict(X)\n",
                "    indiv_pred = [tree.predict(X) for tree in estimator.estimators_]\n",
                "    aggr_pred = np.mean(indiv_pred, axis=0)\n",
                "\n",
                "    return pred, indiv_pred, aggr_pred\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "50385c5e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_randomforest_instrumental_variable_estimator(df_jobs, cols_to_compare=None, text_col=None, n_trees=None):\n",
                "\n",
                "    if cols_to_compare is None:\n",
                "        cols_to_compare = ['Warmth_actual', 'Warmth_predicted', 'Competence_actual', 'Competence_predicted']\n",
                "    if text_col is None:\n",
                "        text_col = 'Job Description spacy_sentencized'\n",
                "    if n_trees is None:\n",
                "        n_trees = 100\n",
                "    cols_dict = defaultdict()\n",
                "    train_ratio = 0.75\n",
                "    test_ratio = 0.10\n",
                "    validation_ratio = 0.15\n",
                "    test_split = test_size = 1 - train_ratio\n",
                "    validation_split = test_ratio / (test_ratio + validation_ratio)\n",
                "\n",
                "    # Make df_jobs_unlabeled\n",
                "    df_jobs_unlabeled = df_jobs.loc[\n",
                "        (df_jobs[cols_to_compare].isna()).all(axis='columns')\n",
                "    ]\n",
                "\n",
                "    if all(df_jobs_unlabeled.isna().sum()) != 0:\n",
                "        raise IndexError('Missing data in df_jobs_labeled.')\n",
                "\n",
                "    df_jobs_unlabeled = df_jobs_unlabeled.dropna(subset=analysis_columns, how='any')\n",
                "    print(f'Dataframe df_jobs_unlabeled of length: {len(df_jobs_unlabeled)}')\n",
                "\n",
                "    # Make df_jobs_labeled\n",
                "    df_jobs_labeled = df_jobs.loc[\n",
                "        (~df_jobs[cols_to_compare].isna()).all(axis='columns')\n",
                "    ]\n",
                "\n",
                "    if all(df_jobs_labeled.isna().sum()) != 0:\n",
                "        raise IndexError('Missing data in df_jobs_labeled.')\n",
                "\n",
                "    df_jobs_labeled = df_jobs_labeled.dropna(subset=analysis_columns, how='any')\n",
                "    print(f'Dataframe df_jobs_labeled of length: {len(df_jobs_labeled)}')\n",
                "\n",
                "    # Make df labels dict\n",
                "    df_add_preds_dict = {\n",
                "        'labeled': df_jobs_labeled,\n",
                "        'unlabeled': df_jobs_unlabeled\n",
                "    }\n",
                "\n",
                "    # Split data\n",
                "    print('Splitting data...')\n",
                "    train, test = train_test_split(\n",
                "        df_jobs_labeled, train_size=1-test_split, test_size=test_split, random_state=random_state\n",
                "    )\n",
                "    print(f'Length of train dataset: {len(train)}')\n",
                "    print(f'Length of test dataset: {len(test)}')\n",
                "    cols_dict = {\n",
                "        'train': train, 'test': test,\n",
                "    }\n",
                "\n",
                "    for col in tqdm.tqdm(analysis_columns):\n",
                "        assert col in df_jobs_labeled.columns, f'{col} column not found in df_jobs_labeled'\n",
                "        print('='*20)\n",
                "        print(f'Training on {col}...')\n",
                "\n",
                "        X_train = np.array(list(train[text_col].astype('str').values))\n",
                "        y_train = column_or_1d(train[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_test = np.array(list(test[text_col].astype('str').values))\n",
                "        y_test = column_or_1d(test[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_labeled = np.array(list(df_jobs_labeled[text_col].astype('str').values))\n",
                "        y_labeled = column_or_1d(df_jobs_labeled[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_unlabeled = np.array(list(df_jobs_unlabeled[text_col].astype('str').values))\n",
                "        y_unlabeled = column_or_1d(df_jobs_unlabeled[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        # Vectorize using FeatueUnion\n",
                "        print(f'Vectorizing using {vectorizers_list[-1].__class__.__name__}...')\n",
                "        vectorizer = vectorizers_list[-1]\n",
                "        X_train = vectorizer.fit_transform(X_train)\n",
                "        X_test = vectorizer.transform(X_test)\n",
                "        X_labeled = vectorizer.transform(X_labeled)\n",
                "        X_unlabeled = vectorizer.transform(X_unlabeled)\n",
                "\n",
                "        # Train using RandomForestRegressor\n",
                "        print('Training using RandomForestRegressor...')\n",
                "        estimator = RandomForestRegressor(n_estimators=n_trees, random_state=random_state, n_jobs=n_jobs)\n",
                "        estimator.fit(X_train, y_train)\n",
                "\n",
                "        # Get predictions\n",
                "        print('Getting predictions...')\n",
                "        y_train_pred, indiv_y_train_pred, aggr_y_train_pred = make_final_indiv_and_aggr_preds(estimator, X_train)\n",
                "        y_test_pred, indiv_y_test_pred, aggr_y_test_pred = make_final_indiv_and_aggr_preds(estimator, X_test)\n",
                "        y_labeled_pred, indiv_y_labeled_pred, aggr_y_labeled_pred = make_final_indiv_and_aggr_preds(estimator, X_labeled)\n",
                "        y_unlabeled_pred, indiv_y_unlabeled_pred, aggr_y_unlabeled_pred = make_final_indiv_and_aggr_preds(estimator, X_unlabeled)\n",
                "\n",
                "        # Make col dict\n",
                "        cols_dict[col] = {\n",
                "            'estimator': estimator, 'vectorizer': vectorizer,\n",
                "            'X_train': X_train, 'y_train': y_train, 'y_train_pred': y_train_pred,\n",
                "            'indiv_y_train_pred': indiv_y_train_pred, 'aggr_y_train_pred': aggr_y_train_pred,\n",
                "            'X_test': X_test, 'y_test': y_test, 'y_test_pred': y_test_pred,\n",
                "            'indiv_y_test_pred': indiv_y_test_pred, 'aggr_y_test_pred': aggr_y_test_pred,\n",
                "            'X_labeled': X_labeled, 'y_labeled': y_labeled, 'y_labeled_pred': y_labeled_pred,\n",
                "            'indiv_y_labeled_pred': indiv_y_labeled_pred, 'aggr_y_labeled_pred': aggr_y_labeled_pred,\n",
                "            'X_unlabeled': X_unlabeled, 'y_unlabeled': y_unlabeled, 'y_unlabeled_pred': y_unlabeled_pred,\n",
                "            'indiv_y_unlabeled_pred': indiv_y_unlabeled_pred, 'aggr_y_unlabeled_pred': aggr_y_unlabeled_pred,\n",
                "        }\n",
                "\n",
                "        # Add columns to df\n",
                "        for df_lab, df in tqdm.tqdm(df_add_preds_dict.items()):\n",
                "            df = pd.concat(\n",
                "                [\n",
                "                    df.reset_index(drop=True),\n",
                "                    pd.DataFrame(\n",
                "                        {\n",
                "                            f'{col}_{df_lab}_predicted': cols_dict[col][f'y_{df_lab}_pred'],\n",
                "                            f'{col}_aggr_{df_lab}_predicted': cols_dict[col][f'aggr_y_{df_lab}_pred'],\n",
                "                        }\n",
                "                    ).reset_index(drop=True),\n",
                "                    pd.DataFrame(cols_dict[col][f'indiv_y_{df_lab}_pred']).transpose().add_prefix(f'{col}_tree_').reset_index(drop=True)\n",
                "                ],\n",
                "                axis='columns'\n",
                "            )\n",
                "            cols_dict[col][f'df_jobs_{df_lab}'] = df\n",
                "\n",
                "        # Evaluate\n",
                "        print('Evaluating...')\n",
                "        score = estimator.score(X_test, y_test)\n",
                "        mae = mean_absolute_error(y_test, y_test_pred)\n",
                "        mse = mean_squared_error(y_test, y_test_pred)\n",
                "        rmse = np.sqrt(mse)\n",
                "        r2 = r2_score(y_test, y_test_pred)\n",
                "\n",
                "        print('-'*20)\n",
                "        print(f'Mean Absolute Error: {mae:3f}')\n",
                "        print(f'Mean Squared Error: {mse:3f}')\n",
                "        print(f'Root Mean Squared Error: {rmse:3f}')\n",
                "        print(f'R-squared (R^2) Score: {r2:3f}')\n",
                "        print('-'*20)\n",
                "\n",
                "    return n_trees, dict(cols_dict)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14cc0d13",
            "metadata": {},
            "outputs": [],
            "source": [
                "n_trees, cols_dict = get_randomforest_instrumental_variable_estimator(df_jobs, n_trees=100)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59b7ec3b",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict.keys()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b3221c1c",
            "metadata": {},
            "outputs": [],
            "source": [
                "list_columns = [c for c in df_jobs.columns if df_jobs[c].apply(lambda x: isinstance(x, list)).any()]\n",
                "non_list_columns = [c for c in df_jobs.columns if not df_jobs[c].apply(lambda x: isinstance(x, list)).any()]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a993ee38",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Warmth']['df_jobs_labeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12167868",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Competence']['df_jobs_labeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2e23e857",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled = cols_dict['Warmth']['df_jobs_labeled']\\\n",
                "    .drop(columns=list_columns)\\\n",
                "    .merge(\n",
                "        cols_dict['Competence']['df_jobs_labeled'],\n",
                "        how='outer',\n",
                "        on=non_list_columns\n",
                "    ).dropna(axis='columns', how='all')\\\n",
                "        .reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a3b9868a",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fa150d05",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "25567198",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Warmth']['df_jobs_unlabeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eff0ccb5",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Competence']['df_jobs_unlabeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e8597d57",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled = cols_dict['Warmth']['df_jobs_unlabeled']\\\n",
                "    .drop(columns=list_columns)\\\n",
                "        .merge(\n",
                "            cols_dict['Competence']['df_jobs_unlabeled'],\n",
                "            how='outer',\n",
                "            on=non_list_columns\n",
                "        ).dropna(axis='columns', how='all')\\\n",
                "            .reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "57fd9028",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cb3b5c70",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4fa26dae",
            "metadata": {},
            "outputs": [],
            "source": [
                "train = cols_dict['train']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19353659",
            "metadata": {},
            "outputs": [],
            "source": [
                "train.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "09a72253",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_train = train.copy()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2adff07d",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_train.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "615db4ea",
            "metadata": {},
            "outputs": [],
            "source": [
                "test = cols_dict['test']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7a7cfb3f",
            "metadata": {},
            "outputs": [],
            "source": [
                "test.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9dbf219e",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test = test\\\n",
                "    .drop(columns=list_columns)\\\n",
                "    .merge(\n",
                "        df_jobs_labeled,\n",
                "        how='inner',\n",
                "        on=non_list_columns\n",
                "    ).reset_index(drop=True)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6b76d98f",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "47f90db7",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a1a9e627",
            "metadata": {},
            "source": [
                "# Make instrumental Variable"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "48060e42",
            "metadata": {},
            "source": [
                "### Make unbiased and biased models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0707e44c",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction = pd.concat([df_jobs_labeled, df_jobs_unlabeled], axis='index')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c8c27cbc",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1235f58a",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "68f95899",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Biased model\n",
                "biased_post_classification_dict = defaultdict()\n",
                "for iv in tqdm.tqdm(ivs_dummy_perc_and_perc_interactions):\n",
                "    dv_names_dict_unlabeled_post_classification = compare_actual_and_predicted(\n",
                "        df_jobs_unlabeled, analysis_type='post_classification', iv_names=iv, print_enabled=False\n",
                "    )\n",
                "    biased_post_classification_dict[iv] = dv_names_dict_unlabeled_post_classification\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ae3352a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uniased model\n",
                "unbiased_post_classification_dict = defaultdict()\n",
                "for iv in tqdm.tqdm(ivs_dummy_perc_and_perc_interactions):\n",
                "    dv_names_dict_labeled_post_classification = compare_actual_and_predicted(\n",
                "        df_jobs_labeled, analysis_type='post_classification', iv_names=iv, print_enabled=False\n",
                "    )\n",
                "    unbiased_post_classification_dict[iv] = dv_names_dict_labeled_post_classification\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1454b793",
            "metadata": {},
            "outputs": [],
            "source": [
                "unbiased_post_classification_dict.keys()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4fa12799",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get forest_iv results\n",
                "forest_iv_results_dict = defaultdict(lambda: defaultdict())\n",
                "forest_iv_params = {\n",
                "    # 'col': dv,\n",
                "    # 'var': iv,\n",
                "    # 'model_unbias': model_unbias,\n",
                "    'data_test': df_jobs_test,\n",
                "    'data_unlabel': df_jobs_for_correction,\n",
                "    # 'control': controls[:2],\n",
                "    'ntree': n_trees,\n",
                "    'iterative': True\n",
                "    # 'diagnostic': True,\n",
                "    # 'family': sm.families.Gaussian(link=sm.families.links.Identity()),\n",
                "    # 'select_method': 'optimal',\n",
                "    # 'method': 'Lasso',\n",
                "}\n",
                "\n",
                "for dv, iv in tqdm_product(dvs, ivs_dummy_perc_and_perc_interactions):\n",
                "    print('-'*20)\n",
                "    print(f'Analyzing {dv} with {iv}...')\n",
                "    forest_iv_params['col'] = dv\n",
                "    forest_iv_params['var'] = iv\n",
                "    forest_iv_params['model_unbias'] = unbiased_post_classification_dict[iv][dv]['Unbiased']['Results']\n",
                "\n",
                "    forest_iv_results_dict[dv][iv] = defaultdict()\n",
                "\n",
                "    results_IV, output, results  = forest_iv(**forest_iv_params)\n",
                "\n",
                "    forest_iv_results_dict[dv][iv]['Results_IV'] = results_IV\n",
                "    forest_iv_results_dict[dv][iv]['Output'] = output\n",
                "    forest_iv_results_dict[dv][iv]['Results'] = results\n",
                "\n",
                "# result = forest_iv(\n",
                "#     col=dv,\n",
                "#     data_test=df_jobs_test,\n",
                "#     data_unlabel=df_jobs_unlabeled,\n",
                "#     var=iv,\n",
                "#     control=controls[:2],\n",
                "#     ntree=n_trees,\n",
                "#     model_unbias=model_unbias,\n",
                "#     diagnostic=True,\n",
                "#     family=sm.families.Gaussian(link=sm.families.links.Identity()),\n",
                "#     select_method='optimal',\n",
                "#     method='Lasso',\n",
                "#     iterative=False\n",
                "# )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a63c9a57",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the critical value for a chi-squared distribution\n",
                "H_critical = scipy.stats.chi2.ppf(0.95, df=4)\n",
                "\n",
                "for dv, iv in tqdm_product(dvs, ivs_dummy_perc_and_perc_interactions):\n",
                "    # Get unbiased model\n",
                "    model_unbias = unbiased_post_classification_dict[iv][dv]['Unbiased']['Results']\n",
                "\n",
                "    # Get the unbiased coefficients\n",
                "    coef_unbiased = model_unbias.params\n",
                "\n",
                "    # Get results\n",
                "    results = forest_iv_results_dict[dv][iv]['Results']\n",
                "\n",
                "    # Calculate the squared bias for each beta\n",
                "    results['bias2'] = ((results[[beta for beta in results.columns if 'beta' in beta ]] - coef_unbiased) ** 2).sum(axis=1)\n",
                "\n",
                "    # Calculate the total variance\n",
                "    results['variance'] = (results[[se for se in results.columns if 'se' in se]] ** 2).sum(axis=1)\n",
                "\n",
                "    # Calculate the mean squared error (MSE)\n",
                "    results['mse'] = results['bias2'] + results['variance']\n",
                "\n",
                "    # Sort the DataFrame by MSE\n",
                "    results = results.sort_values(by='mse')\n",
                "\n",
                "    # Filter rows where Hotelling is less than H_critical and only keep the first row\n",
                "    filtered_results = results[(results['Hotelling'] < H_critical) & (results.index == results.index[0])]\n",
                "\n",
                "    # Display the filtered results\n",
                "    print(filtered_results[[beta for beta in results.columns if 'beta' in beta ]])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "biased_post_classification_dict[iv][dv]['Biased']['Results'].summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_unbias.summary()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a50be1b0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get valid instrumental variables from forest_iv_results_dict\n",
                "instrumental_variables = list(\n",
                "    {\n",
                "        instrument\n",
                "        for dv, iv in forest_iv_results_dict.items()\n",
                "        for k, v in iv.items()\n",
                "        for instrument in v['Output']['IVs']\n",
                "    }\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "instrumental_variables\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b60b30c",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = df_jobs_for_correction.loc[:,\n",
                "    (~df_jobs_for_correction.columns.str.contains('_tree_'))\n",
                "    | (df_jobs_for_correction.columns.isin(instrumental_variables))\n",
                "].reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9e5f3c1b",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "37533128",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a30d6c5b",
            "metadata": {},
            "outputs": [],
            "source": [
                "iv = ivs_perc[0]\n",
                "col = dvs[0]\n",
                "for dv in dvs:\n",
                "    print(dv, iv)\n",
                "    results_IV = forest_iv_results_dict[dv][iv]['Results_IV']\n",
                "    print(results_IV.summary())\n",
                "    corrected_var = results_IV.predict(df_jobs[col])\n",
                "    print(corrected_var)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "efec800f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "# df_jobs.to_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
                "# df_jobs.to_csv(f'{df_save_dir}df_jobs_for_analysis.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0ac17152",
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(f'Saving corrected df_jobs length {len(df_jobs)} to txt file.')\n",
                "# with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'w') as f:\n",
                "#     f.write(str(len(df_jobs)))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1b50e19e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Calculate the critical value of Hotelling's T-squared test\n",
                "# H_critical = chi2.ppf(0.95, df=4)\n",
                "\n",
                "# # Get the unbiased coefficients\n",
                "# coef_unbiased = model_unbias.coef\n",
                "\n",
                "# # Calculate the bias squared, variance, and mean squared error (MSE)\n",
                "# bias2 = np.sum((coef_unbiased - [beta_1, beta_2, beta_3, beta_4])**2)\n",
                "# variance = se_1**2 + se_2**2 + se_3**2 + se_4**2\n",
                "# mse = bias2 + variance\n",
                "\n",
                "# # Add these columns to the `result` DataFrame\n",
                "# result = result.assign(\n",
                "#     bias2=bias2,\n",
                "#     variance=variance,\n",
                "#     mse=mse,\n",
                "# )\n",
                "\n",
                "# # Sort the DataFrame by MSE and filter to the top row\n",
                "# result = result.sort_values(\"mse\").iloc[:1]\n",
                "\n",
                "# # Filter to the rows where Hotelling's T-squared test is less than the critical value\n",
                "# result = result.query(\"Hotelling < {}\".format(H_critical))\n",
                "\n",
                "# # Print the results\n",
                "# print(result)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fa9fb434",
            "metadata": {},
            "outputs": [],
            "source": [
                "# HACK\n",
                "# def compute_embeddings(model, input_ids):\n",
                "#     outputs = model(input_ids)\n",
                "#     hidden_states = outputs.hidden_states\n",
                "#     embeddings = hidden_states[-1]  # Extract embeddings from the last layer\n",
                "#     return embeddings\n",
                "\n",
                "# train_data = estimator.get_train_dataloader()\n",
                "# eval_data = estimator.get_eval_dataloader()\n",
                "\n",
                "# # Compute embeddings for your train and eval data\n",
                "# train_embeddings = compute_embeddings(model, next(iter(train_data))[0])\n",
                "# eval_embeddings = compute_embeddings(model, next(iter(eval_data))[0])\n",
                "\n",
                "# TODO: get train, test, datasets from transformers save folder, X = np.concatenate((X_test, X_val), axis=0) and y = np.concatenate((y_test, y_val), axis=0) so X_test, y_test will be both of these. Get these to become df_jobs_test and df_jobs_train, then df_jobs_unlabeled will be the same.\n",
                "\n",
                "# from transformers import BertModel, Trainer\n",
                "\n",
                "# model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
                "# trainer = Trainer(model)\n",
                "\n",
                "# trainer.train()\n",
                "\n",
                "# # Get the embeddings from the model\n",
                "# embeddings = model.get_input_embeddings()\n",
                "\n",
                "# print(embeddings.shape)\n",
                "\n",
                "# from transformers import BertModel, Trainer\n",
                "\n",
                "# model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
                "# trainer = Trainer(model)\n",
                "\n",
                "# trainer.train()\n",
                "\n",
                "# # Get the hidden states from the model\n",
                "# hidden_states = model.get_hidden_states()\n",
                "\n",
                "# # Get the embeddings from the last layer\n",
                "# embeddings = hidden_states[-1]\n",
                "\n",
                "# print(embeddings.shape)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Automating_Equity1_3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        },
        "varInspector": {
            "cols": {
                "lenName": 16,
                "lenType": 16,
                "lenVar": 40
            },
            "kernels_config": {
                "python": {
                    "delete_cmd_postfix": "",
                    "delete_cmd_prefix": "del ",
                    "library": "var_list.py",
                    "varRefreshCmd": "print(var_dic_list())"
                },
                "r": {
                    "delete_cmd_postfix": ") ",
                    "delete_cmd_prefix": "rm(",
                    "library": "var_list.r",
                    "varRefreshCmd": "cat(var_dic_list()) "
                }
            },
            "types_to_exclude": [
                "module",
                "function",
                "builtin_function_or_method",
                "instance",
                "_Feature"
            ],
            "window_display": false
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
