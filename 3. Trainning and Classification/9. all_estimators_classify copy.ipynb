{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "50d4c434",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fef3f604",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from estimators_get_pipe import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from setup_module import specification_curve_fork as specy # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "55afc383",
            "metadata": {},
            "source": [
                "### Set variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7b36fe18",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Variables\n",
                "method = 'Supervised'\n",
                "with open(f'{data_dir}{method}_results_save_path.txt', 'r') as f:\n",
                "    results_save_path = f.read()\n",
                "with open(f'{data_dir}{method}_done_xy_save_path.txt', 'r') as f:\n",
                "    done_xy_save_path = f.read()\n",
                "t = time.time()\n",
                "n_jobs = -1\n",
                "n_splits = 10\n",
                "n_repeats = 3\n",
                "random_state = 42\n",
                "refit = True\n",
                "class_weight = 'balanced'\n",
                "cv = RepeatedStratifiedKFold(\n",
                "    n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
                ")\n",
                "scoring = 'recall'\n",
                "scores = [\n",
                "    'recall', 'accuracy', 'f1', 'roc_auc',\n",
                "    'explained_variance', 'matthews_corrcoef'\n",
                "]\n",
                "scorers = {\n",
                "    'precision_score': make_scorer(precision_score, zero_division=0),\n",
                "    'recall_score': make_scorer(recall_score, zero_division=0),\n",
                "    'accuracy_score': make_scorer(accuracy_score, zero_division=0),\n",
                "}\n",
                "analysis_columns = ['Warmth', 'Competence']\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "metrics_dict = {\n",
                "    f'{scoring.title()} Best Score': np.nan,\n",
                "    f'{scoring.title()} Best Threshold': np.nan,\n",
                "    'Train - Mean Cross Validation Score': np.nan,\n",
                "    f'Train - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    f'Train - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Test - Mean Cross Validation Score': np.nan,\n",
                "    f'Test - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    f'Test - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Explained Variance': np.nan,\n",
                "    'Accuracy': np.nan,\n",
                "    'Balanced Accuracy': np.nan,\n",
                "    'Precision': np.nan,\n",
                "    'Average Precision': np.nan,\n",
                "    'Recall': np.nan,\n",
                "    'F1-score': np.nan,\n",
                "    'Matthews Correlation Coefficient': np.nan,\n",
                "    'Fowlkes–Mallows Index': np.nan,\n",
                "    'R2 Score': np.nan,\n",
                "    'ROC': np.nan,\n",
                "    'AUC': np.nan,\n",
                "    'Log Loss/Cross Entropy': np.nan,\n",
                "    'Cohen’s Kappa': np.nan,\n",
                "    'Geometric Mean': np.nan,\n",
                "    'Classification Report': np.nan,\n",
                "    'Imbalanced Classification Report': np.nan,\n",
                "    'Confusion Matrix': np.nan,\n",
                "    'Normalized Confusion Matrix': np.nan,\n",
                "}\n",
                "\n",
                "# Transformer variables\n",
                "max_length = 512\n",
                "returned_tensor = 'pt'\n",
                "cpu_counts = torch.multiprocessing.cpu_count()\n",
                "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available(\n",
                ") else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "device_name = str(device.type)\n",
                "print(f'Using {device_name.upper()}')\n",
                "# Set random seed\n",
                "random_state = 42\n",
                "random.seed(random_state)\n",
                "np.random.seed(random_state)\n",
                "torch.manual_seed(random_state)\n",
                "cores = multiprocessing.cpu_count()\n",
                "\n",
                "# Plotting variables\n",
                "pp = pprint.PrettyPrinter(indent=4)\n",
                "tqdm.tqdm.pandas(desc='progress-bar')\n",
                "tqdm_auto.tqdm.pandas(desc='progress-bar')\n",
                "# tqdm.notebook.tqdm().pandas(desc='progress-bar')\n",
                "tqdm_auto.notebook_tqdm().pandas(desc='progress-bar')\n",
                "# pbar = progressbar.ProgressBar(maxval=10)\n",
                "mpl.style.use(f'{code_dir}/setup_module/apa.mplstyle-main/apa.mplstyle')\n",
                "mpl.rcParams['text.usetex'] = False\n",
                "font = {'family': 'arial', 'weight': 'normal', 'size': 10}\n",
                "mpl.rc('font', **font)\n",
                "plt.style.use('tableau-colorblind10')\n",
                "plt.set_cmap('Blues')\n",
                "pd.set_option('display.max_rows', None)\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.width', 5000)\n",
                "pd.set_option('display.colheader_justify', 'center')\n",
                "pd.set_option('display.precision', 3)\n",
                "pd.set_option('display.float_format', '{:.2f}'.format)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "036fcf10",
            "metadata": {},
            "source": [
                "# Classifying"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "fd32c435",
            "metadata": {},
            "source": [
                "### READ DATA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1e310829",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(f'{data_dir}df_jobs_len.txt', 'r') as f:\n",
                "    df_jobs_len = int(f.read())\n",
                "\n",
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_training.pkl')\n",
                "assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_jobs)}'\n",
                "print(f'Dataframe loaded with shape: {df_jobs.shape}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a0212dc9",
            "metadata": {
                "code_folding": [],
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "%%time\n",
                "print('#'*40)\n",
                "print('Starting!')\n",
                "print('#'*40)\n",
                "\n",
                "protocol = pickle.HIGHEST_PROTOCOL\n",
                "analysis_columns = ['Warmth', 'Competence']\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "classified_columns = ['Warmth_Probability', 'Competence_Probability']\n",
                "final_estimators_dict = {\n",
                "    'Warmth': {\n",
                "        'vectorizer_name': 'TfidfVectorizer',\n",
                "        'classifier_name': 'LogisticRegression',\n",
                "    },\n",
                "    'Competence': {\n",
                "        'vectorizer_name': 'TfidfVectorizer',\n",
                "        'classifier_name': 'LogisticRegression',\n",
                "    },\n",
                "}\n",
                "\n",
                "for col in tqdm.tqdm(analysis_columns):\n",
                "    print('-'*20)\n",
                "    final_estimators_dict[col]['path_suffix'] = path_suffix = f' - {col} - {(vectorizer_name := final_estimators_dict[col][\"vectorizer_name\"])} + {(classifier_name := final_estimators_dict[col][\"classifier_name\"])} (Save_protocol={protocol})'\n",
                "\n",
                "    if classifier_name in list(classifiers_pipe.keys()):\n",
                "        method = 'Supervised'\n",
                "        print('-'*20)\n",
                "        print('Loading Supervised Estimator.')\n",
                "            with open(\n",
                "                f'{results_save_path}{method} Fitted Estimator {path_suffix}.pkl', 'rb'\n",
                "            ) as f:\n",
                "                estimator = joblib.load(f)\n",
                "            print('Done loading Fitted Estimator!')\n",
                "\n",
                "            print('-'*20)\n",
                "            print('Classifying data.')\n",
                "            X = np.array(list(df_jobs[text_col].astype('str').values))\n",
                "            df_jobs[col] = estimator.predict(X)\n",
                "            if hasattr(estimator, 'predict_proba'):\n",
                "                # Get the the whole of the last column, which is the  probability of 1, and flatten to list\n",
                "                df_jobs[f'{col}_Probability'] = estimator.predict_proba(X)[:, -1]\n",
                "\n",
                "            print(f'Done classifying data using {classifier_name} for {col}!')\n",
                "            print('-'*20)\n",
                "\n",
                "    elif classifier_name in list(transformers_pipe.keys()):\n",
                "        method = 'Transformers'\n",
                "        print('-'*20)\n",
                "        print('Loading Transformer Estimator.')\n",
                "        model = transformers_pipe[classifier_name]['model']\n",
                "        estimator = model.from_pretrained(f'{results_save_path}{method} Fitted Estimator {path_suffix}')\n",
                "        print('Done loading Fitted Estimator!')\n",
                "\n",
                "        print('-'*20)\n",
                "        print('Classifying data.')\n",
                "        y_pred_logits, y_labels, metrics_dict = estimator.predict(test_dataset)\n",
                "        df_jobs[col] = metrics_dict.pop('test_y_pred')\n",
                "        df_jobs[f'{col}_Probability'] = metrics_dict.pop('test_y_pred_prob')[:, -1]\n",
                "        metrics_dict = clean_metrics_dict(test_metrics_dict, list(test_metrics_dict.keys())[0].split('_')[0])\n",
                "\n",
                "        print(f'Done classifying data using {classifier_name} for {col}!')\n",
                "        print('-'*20)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "1154fedc",
            "metadata": {},
            "source": [
                "## Inspect classified data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "48b1df0f",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = df_jobs.dropna(subset=['Warmth', 'Competence', 'Warmth_Probability', 'Competence_Probability'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6e947093",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e6ed0fd9",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.describe()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1e252eb4",
            "metadata": {},
            "outputs": [],
            "source": [
                "get_df_info(df_jobs, ivs_all=[analysis_columns])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1635aac9",
            "metadata": {},
            "outputs": [],
            "source": [
                "get_df_info(df_jobs, ivs_all=[classified_columns])\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "9e7aea9a",
            "metadata": {},
            "source": [
                "### Plot classified data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7d1aa329",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Counts plot of classifed warmthh and competence\n",
                "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
                "sns.countplot(x='Warmth', data=df_jobs, ax=ax[0], palette='colorblind')\n",
                "sns.countplot(x='Competence', data=df_jobs, ax=ax[1], palette='colorblind')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "368511db",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Box plot of warmth and competence probabilities\n",
                "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
                "sns.boxplot(x='Warmth', y='Warmth_Probability', data=df_jobs, ax=ax[0], palette='colorblind')\n",
                "sns.boxplot(x='Competence', y='Competence_Probability', data=df_jobs, ax=ax[1], palette='colorblind')\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fd87577f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Specification curve analysis\n",
                "print(f'Running specification curve analysis with:\\nDEPENDENT VARIABLES = {dvs_prob}\\nINDEPENDENT VARIABLES = {ivs_perc}\\nCONTROLS = {controls}')\n",
                "sc = specy.SpecificationCurve(df=dj_jobs, y_endog=dvs_prob, x_exog=ivs_perc, controls=controls)\n",
                "sc.fit(estimator=sm.OLS)\n",
                "sc.plot(show_plot=True)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "adc3c701",
            "metadata": {},
            "source": [
                "### Save dataframe\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3057728d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "# df_jobs.to_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
                "# df_jobs.to_csv(f'{df_save_dir}df_jobs_for_analysis.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "de943922",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "study1_3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.10"
        },
        "varInspector": {
            "cols": {
                "lenName": 16,
                "lenType": 16,
                "lenVar": 40
            },
            "kernels_config": {
                "python": {
                    "delete_cmd_postfix": "",
                    "delete_cmd_prefix": "del ",
                    "library": "var_list.py",
                    "varRefreshCmd": "print(var_dic_list())"
                },
                "r": {
                    "delete_cmd_postfix": ") ",
                    "delete_cmd_prefix": "rm(",
                    "library": "var_list.r",
                    "varRefreshCmd": "cat(var_dic_list()) "
                }
            },
            "types_to_exclude": [
                "module",
                "function",
                "builtin_function_or_method",
                "instance",
                "_Feature"
            ],
            "window_display": false
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
