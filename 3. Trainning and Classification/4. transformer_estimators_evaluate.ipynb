{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50d4c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "if code_dir_name not in str(Path.cwd()).split('/')[-1]:\n",
    "    for _ in range(5):\n",
    "\n",
    "        parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "        if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "            code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "            if code_dir is not None:\n",
    "                break\n",
    "else:\n",
    "    code_dir = str(Path.cwd())\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3abbb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_module.imports import *  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module.estimators_get_pipe import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from setup_module.plot_metric_fork import functions as plot_metric_functions # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e858544b",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65134b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "method = 'Transformers'\n",
    "with open(f'{data_dir}{method}_results_save_path.txt', 'r') as f:\n",
    "    results_save_path = f.read().strip('\\n')\n",
    "with open(f'{data_dir}{method}_done_xy_save_path.txt', 'r') as f:\n",
    "    done_xy_save_path = f.read().strip('\\n')\n",
    "\n",
    "t = time.time()\n",
    "n_jobs = -1\n",
    "n_splits = 10\n",
    "n_repeats = 3\n",
    "random_state = 42\n",
    "refit = True\n",
    "class_weight = 'balanced'\n",
    "cv = RepeatedStratifiedKFold(\n",
    "    n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
    ")\n",
    "scoring = 'recall'\n",
    "scores = [\n",
    "    'recall', 'accuracy', 'f1', 'roc_auc',\n",
    "    'explained_variance', 'matthews_corrcoef'\n",
    "]\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score),\n",
    "}\n",
    "analysis_columns = ['Warmth', 'Competence']\n",
    "text_col = 'Job Description spacy_sentencized'\n",
    "metrics_dict = {\n",
    "    # f'{scoring.title()} Best Score': np.nan,\n",
    "    # f'{scoring.title()} Best Threshold': np.nan,\n",
    "    # 'Train - Mean Cross Validation Score': np.nan,\n",
    "    # f'Train - Mean Cross Validation - {scoring.title()}': np.nan,\n",
    "    # f'Train - Mean Explained Variance - {scoring.title()}': np.nan,\n",
    "    # 'Test - Mean Cross Validation Score': np.nan,\n",
    "    # f'Test - Mean Cross Validation - {scoring.title()}': np.nan,\n",
    "    # f'Test - Mean Explained Variance - {scoring.title()}': np.nan,\n",
    "    'Explained Variance': np.nan,\n",
    "    'Accuracy': np.nan,\n",
    "    'Balanced Accuracy': np.nan,\n",
    "    'Precision': np.nan,\n",
    "    'Average Precision': np.nan,\n",
    "    'Recall': np.nan,\n",
    "    'F1-score': np.nan,\n",
    "    'Matthews Correlation Coefficient': np.nan,\n",
    "    'Brier Score': np.nan,\n",
    "    'Fowlkes–Mallows Index': np.nan,\n",
    "    'R2 Score': np.nan,\n",
    "    'ROC': np.nan,\n",
    "    'AUC': np.nan,\n",
    "    'Log Loss/Cross Entropy': np.nan,\n",
    "    'Cohen’s Kappa': np.nan,\n",
    "    'Geometric Mean': np.nan,\n",
    "    'Classification Report': np.nan,\n",
    "    'Imbalanced Classification Report': np.nan,\n",
    "    'Confusion Matrix': np.nan,\n",
    "    'Normalized Confusion Matrix': np.nan,\n",
    "}\n",
    "\n",
    "# Set random seed\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Transformer variables\n",
    "max_length = 512\n",
    "returned_tensor = 'pt'\n",
    "cpu_counts = torch.multiprocessing.cpu_count()\n",
    "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available(\n",
    ") else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device_name = str(device.type)\n",
    "print(f'Using {device_name.upper()}')\n",
    "# Set random seed\n",
    "random_state = 42\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "cores = multiprocessing.cpu_count()\n",
    "torch.Generator(device_name).manual_seed(random_state)\n",
    "cores = multiprocessing.cpu_count()\n",
    "accelerator = Accelerator()\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "os.environ.get('TOKENIZERS_PARALLELISM')\n",
    "os.environ.get('PYTORCH_MPS_HIGH_WATERMARK_RATIO')\n",
    "os.environ.get('TRANSFORMERS_CACHE')\n",
    "openai_token = os.environ['OPENAI_API_KEY']\n",
    "huggingface_token = os.environ['HUGGINGFACE_API_KEY']\n",
    "# load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_quant_type='nf4'\n",
    "quantization_config_dict = {\n",
    "    'load_in_8bit': True,\n",
    "    'llm_int8_skip_modules': ['lm_head'],\n",
    "}\n",
    "skip_fitted_estimators = False\n",
    "evaluate_estimator_on_concat = False\n",
    "hyperparameter_tuning = False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55afc383",
   "metadata": {},
   "source": [
    "# Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee5f8d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_metrics(\n",
    "    vectorizers_pipe, classifiers_pipe, transformers_pipe, metrics_list,\n",
    "    col, vectorizer_name, classifier_name, protocol=None,\n",
    "    analysis_columns=analysis_columns,\n",
    "    table_save_path=table_save_path,\n",
    "    method=method, save_name=None,\n",
    "    compression=None, path_suffix=None,\n",
    "):\n",
    "    if save_name is None:\n",
    "        save_name = f'{method} Estimators Table'\n",
    "    if compression is None:\n",
    "        compression = False\n",
    "    if protocol is None:\n",
    "        protocol = pickle.HIGHEST_PROTOCOL\n",
    "    if isinstance(metrics_list, dict):\n",
    "        metrics_list = list(metrics_list.keys())\n",
    "\n",
    "    transformers_tokenizers_list = [\n",
    "        str(tranformer_dict['tokenizer']).split('.')[-1].split(\"'>\")[0]\n",
    "        for tranformer_dict in transformers_pipe.values()\n",
    "    ]\n",
    "    combined_classifiers_list = list(classifiers_pipe.keys()) + list(transformers_pipe.keys())\n",
    "    combined_vectorizers_list = list(vectorizers_pipe.keys()) + transformers_tokenizers_list\n",
    "\n",
    "    print('='*20)\n",
    "    if os.path.exists(f'{table_save_path}{save_name}.pkl') and os.path.getsize(f'{table_save_path}{save_name}.pkl') > 0:\n",
    "        print(f'Loading table from {save_name}.pkl')\n",
    "        df_metrics = pd.read_pickle(f'{table_save_path}{save_name}.pkl')\n",
    "        print('Done loading table!')\n",
    "    else:\n",
    "        print('Table does not exist, creating new table...')\n",
    "        if method == 'Transformers':\n",
    "            index = pd.MultiIndex.from_product(\n",
    "                [list(map(lambda classifier_name: classifier_name, list(transformers_pipe.keys())))],\n",
    "                names=['Classifiers'],\n",
    "            )\n",
    "            columns = pd.MultiIndex.from_product(\n",
    "                [\n",
    "                    analysis_columns,\n",
    "                    metrics_list,\n",
    "                ],\n",
    "                names=['Variable', 'Measures'],\n",
    "            )\n",
    "        elif method == 'Supervised':\n",
    "            index = pd.MultiIndex.from_product(\n",
    "                [list(map(lambda classifier_name: classifier_name, list(classifiers_pipe.keys())))],\n",
    "                names=['Classifiers'],\n",
    "            )\n",
    "            columns = pd.MultiIndex.from_product(\n",
    "                [\n",
    "                    analysis_columns,\n",
    "                    list(map(lambda vectorizer_name: vectorizer_name, list(vectorizers_pipe.keys()))),\n",
    "                    metrics_list,\n",
    "                ],\n",
    "                names=['Variable', 'Vectorizer', 'Measures'],\n",
    "            )\n",
    "        # Make df\n",
    "        df_metrics = pd.DataFrame(index=index, columns=columns)\n",
    "        print('Done creating new table!')\n",
    "    print('='*20)\n",
    "\n",
    "    return df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab49d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_existing_files(\n",
    "    results_save_path=results_save_path,\n",
    "    estimator_names_list=None,\n",
    "):\n",
    "    if estimator_names_list is None:\n",
    "        estimator_names_list = []\n",
    "\n",
    "    print(f'Searching for existing estimators in directory.')\n",
    "\n",
    "    for estimators_file in tqdm.tqdm(glob.glob(f'{results_save_path}*.*')):\n",
    "        if f'{method} Estimator - ' in estimators_file:\n",
    "\n",
    "            col=estimators_file.split(f'{method} Estimator - ')[-1].split(' - ')[0]\n",
    "            vectorizer_name=estimators_file.split(f'{col} - ')[-1].split(' + ')[0]\n",
    "            classifier_name=estimators_file.split(f'{vectorizer_name} + ')[-1].split(' (Save_protocol=')[0]\n",
    "\n",
    "            estimator_names_list.append(f'{col} - {vectorizer_name} + {classifier_name}')\n",
    "\n",
    "    return (\n",
    "        list(set(estimator_names_list))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.pos_weight = self._calculate_class_weights(self.train_dataset)\n",
    "\n",
    "    def _calculate_class_weights(self, dataset):\n",
    "        # Count the number of samples in each class\n",
    "        class_counts = torch.bincount(torch.tensor(dataset.labels, device=device))\n",
    "\n",
    "        # Calculate weight and pos_weight\n",
    "        num_negative = class_counts[0].item()\n",
    "        num_positive = class_counts[1].item()\n",
    "        # weight_neg = num_positive / (num_negative + 1e-5)\n",
    "        weight_pos = num_negative / (num_positive + 1e-5)\n",
    "        # weight = torch.tensor([weight_neg, weight_pos], device=device)\n",
    "        pos_weight = torch.tensor([weight_pos], device=device)\n",
    "\n",
    "        return pos_weight\n",
    "\n",
    "    def _calculate_calibration_loss(self, logits, labels):\n",
    "        return torch.nn.BCEWithLogitsLoss(pos_weight=self.pos_weight.to(device))(\n",
    "            logits.to(device), torch.nn.functional.one_hot(labels, logits.size(-1)).long().float().to(device)\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop('labels').to(device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits').to(device)\n",
    "        loss = self._calculate_calibration_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11d2c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Xy_estimator(\n",
    "    model, tokenizer, config,\n",
    "    col, vectorizer_name, classifier_name, protocol,\n",
    "    results_save_path=results_save_path,\n",
    "    done_xy_save_path=done_xy_save_path, method=method,\n",
    "    compression=None, saved_files_list=None,\n",
    "    path_suffix=None, data_dict=None,\n",
    "):\n",
    "    if compression is None:\n",
    "        compression = False\n",
    "    if protocol is None:\n",
    "        protocol = pickle.HIGHEST_PROTOCOL\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {str(col)} - {vectorizer_name} + {classifier_name} (Save_protocol={protocol})'\n",
    "    if data_dict is None:\n",
    "        data_dict = {}\n",
    "    if saved_files_list is None:\n",
    "        saved_files_list = []\n",
    "\n",
    "    print(f'Loading Xy from previous for {col}...')\n",
    "    # Read all dfs into\n",
    "    for file_path in glob.glob(f'{done_xy_save_path}{method}*{path_suffix}*'):\n",
    "        file_name = file_path.split(f'{done_xy_save_path}{method} ')[-1].split(path_suffix)[0]\n",
    "        print(f'Loading {file_name}')\n",
    "        if path_suffix in file_path and 'df_' in file_name or 'metrics_dict' in file_name:\n",
    "            data_dict[file_name] = pd.read_pickle(file_path)\n",
    "            saved_files_list.append(file_name)\n",
    "\n",
    "    # Load estimator and accelator\n",
    "    print('Loading Estimator.')\n",
    "    estimator_dir = f'{results_save_path}{method} Estimator{path_suffix}.model'\n",
    "    if os.path.exists(f'{estimator_dir}/checkpoint-500') and not os.listdir(f'{estimator_dir}/checkpoint-500') and training_args_dict['resume_from_checkpoint']:\n",
    "        saved_estimator = model.from_pretrained(f'{estimator_dir}/checkpoint-500', trust_remote_code=True)\n",
    "    else:\n",
    "        saved_estimator = model.from_pretrained(f'{estimator_dir}', trust_remote_code=True)\n",
    "    tokenizer = tokenizer.from_pretrained(estimator_dir, trust_remote_code=True)\n",
    "    config = config.from_pretrained(f'{estimator_dir}/config.json', trust_remote_code=True)\n",
    "    saved_files_list.extend(['Estimator', 'config'])#, 'accelerator'])\n",
    "\n",
    "    # Train data\n",
    "    df_train_data = data_dict['df_train_data']\n",
    "    X_train = df_train_data['X_train'].values\n",
    "    y_train = df_train_data['y_train'].values\n",
    "    train_dataset = df_train_data['train_dataset'].values\n",
    "    # Test data\n",
    "    df_test_data = data_dict['df_test_data']\n",
    "    X_test = df_test_data['X_test'].values\n",
    "    y_test = df_test_data['y_test'].values\n",
    "    test_dataset = df_test_data['test_dataset'].values\n",
    "    y_test_pred = df_test_data['y_test_pred'].values\n",
    "    y_test_pred_prob = df_test_data['y_test_pred_prob'].values\n",
    "    # Val data\n",
    "    df_val_data = data_dict['df_val_data']\n",
    "    X_val = df_val_data['X_val'].values\n",
    "    y_val = df_val_data['y_val'].values\n",
    "    val_dataset = df_val_data['val_dataset'].values\n",
    "    y_val_pred = df_val_data['y_val_pred'].values\n",
    "    y_val_pred_prob = df_val_data['y_val_pred_prob'].values\n",
    "\n",
    "    # Metrics dicts\n",
    "    for key, value in data_dict.items():\n",
    "        if 'metrics_dict' in key:\n",
    "            for key, value in metrics_dict.items():\n",
    "                if isinstance(value, str):\n",
    "                    metrics_dict[key] = np.fromstring(value[1:-1], sep=' ')\n",
    "    eval_metrics_dict = data_dict['eval_metrics_dict']\n",
    "    test_metrics_dict = data_dict['test_metrics_dict']\n",
    "    # for metrics_dict in [eval_metrics_dict, test_metrics_dict]:\n",
    "    #     for key, value in metrics_dict.items():\n",
    "    #         if isinstance(value, str):\n",
    "    #             metrics_dict[key] = np.fromstring(value[1:-1], sep=' ')\n",
    "\n",
    "    # Check predicted data\n",
    "    check_consistent_length(X_train, y_train)\n",
    "    check_consistent_length(X_test, y_test, y_test_pred, y_test_pred_prob)\n",
    "    check_consistent_length(X_val, y_val, y_val_pred, y_val_pred_prob)\n",
    "\n",
    "    # Get class weights\n",
    "    (\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "        val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "    ) = get_class_weights(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        X_val, y_val,\n",
    "    )\n",
    "\n",
    "    assert set(list(data_dict.keys())+['Estimator', 'config']) == set(saved_files_list), f'Not all files were loaded! Missing: {set(data_dict.keys()) ^ set(saved_files_list)}'\n",
    "    print(f'Done loading Xy and estimator!\\n{list(data_dict.keys())}')\n",
    "    print('='*20)\n",
    "\n",
    "    return (\n",
    "        X_train, y_train, train_dataset,\n",
    "        X_test, y_test, test_dataset, y_test_pred, y_test_pred_prob,\n",
    "        X_val, y_val, val_dataset, y_val_pred, y_val_pred_prob,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict,\n",
    "        saved_estimator, tokenizer, config, eval_metrics_dict, test_metrics_dict,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10ac5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    X_val, y_val,\n",
    "):\n",
    "    # Get train class weights\n",
    "    train_class_weights = compute_class_weight(class_weight = class_weight, classes = np.unique(y_train), y = y_train)\n",
    "    train_class_weights_ratio = train_class_weights[0]/train_class_weights[1]\n",
    "    train_class_weights_dict = dict(zip(np.unique(y_train), train_class_weights))\n",
    "\n",
    "    # Get train class weights\n",
    "    test_class_weights = compute_class_weight(class_weight = class_weight, classes = np.unique(y_test), y = y_test)\n",
    "    test_class_weights_ratio = test_class_weights[0]/test_class_weights[1]\n",
    "    test_class_weights_dict = dict(zip(np.unique(y_test), test_class_weights))\n",
    "\n",
    "    # Get val class weights\n",
    "    val_class_weights = compute_class_weight(class_weight = class_weight, classes = np.unique(y_val), y = y_val)\n",
    "    val_class_weights_ratio = val_class_weights[0]/val_class_weights[1]\n",
    "    val_class_weights_dict = dict(zip(np.unique(y_val), val_class_weights))\n",
    "\n",
    "    return (\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "        val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9aa05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_Xy(\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    X_val, y_val,\n",
    "    train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "    test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "    val_class_weights, val_class_weights_ratio, val_class_weights_dict,\n",
    "):\n",
    "    # Check for consistent length\n",
    "    check_consistent_length(X_train, y_train)\n",
    "    check_consistent_length(X_test, y_test)\n",
    "    check_consistent_length(X_val, y_val)\n",
    "\n",
    "    print('Done splitting data into training and testing sets.')\n",
    "    print('='*20)\n",
    "    print(f'Training set shape: {y_train.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Training set example:\\n{X_train[0]}')\n",
    "    print('~'*10)\n",
    "    print(f'Testing set shape: {y_test.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Testing set example:\\n{X_test[0]}')\n",
    "    print('~'*10)\n",
    "    print(f'Validation set shape: {y_val.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Validation set example:\\n{X_val[0]}')\n",
    "    print('~'*10)\n",
    "    print(f'Training data class weights:\\nRatio = {train_class_weights_ratio:.2f} (0 = {train_class_weights[0]:.2f}, 1 = {train_class_weights[1]:.2f})')\n",
    "    print('-'*10)\n",
    "    print(f'Testing data class weights:\\nRatio = {test_class_weights_ratio:.2f} (0 = {test_class_weights[0]:.2f}, 1 = {test_class_weights[1]:.2f})')\n",
    "    print('-'*10)\n",
    "    print(f'Validation data class weights:\\nRatio = {val_class_weights_ratio:.2f} (0 = {val_class_weights[0]:.2f}, 1 = {val_class_weights[1]:.2f})')\n",
    "    print('='*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9ccbd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # check is encodings and labels are tensors\n",
    "        for key, val in self.encodings.items():\n",
    "            if not torch.is_tensor(val[idx]):\n",
    "                self.encodings[key][idx] = torch.tensor(val[idx], dtype=torch.long, device=device)\n",
    "        if self.labels is not None and not torch.is_tensor(self.labels[idx]):\n",
    "            with contextlib.suppress(ValueError):\n",
    "                self.labels[idx] = torch.tensor(self.labels[idx], dtype=torch.long, device=device)\n",
    "        item = {key: val[idx].to(device) for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99d2740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_Xy_encodings(\n",
    "    X_train, y_train, train_dataset,\n",
    "    X_test, y_test, test_dataset,\n",
    "    X_val, y_val, val_dataset,\n",
    "):\n",
    "    # Check for consistent length\n",
    "    check_consistent_length(X_train, y_train, train_dataset)\n",
    "    check_consistent_length(X_test, y_test, test_dataset)\n",
    "    check_consistent_length(X_val, y_val, val_dataset)\n",
    "\n",
    "    # Check encodings\n",
    "    assert all(y_train == train_dataset.labels), 'y_train and train_dataset labels are not the same'\n",
    "    assert all(y_test == test_dataset.labels), 'y_test and test_dataset labels are not the same'\n",
    "\n",
    "    print('Done encoding training, testing, and validation sets.')\n",
    "    print('='*20)\n",
    "    print(f'Training set encodings example:\\n{\" \".join(train_dataset.encodings[0].tokens[:30])}')\n",
    "    print('-'*10)\n",
    "    print(f'Training set labels example: {set(train_dataset.labels)}')\n",
    "    print('~'*10)\n",
    "    print(f'Testing set encodings example:\\n{\" \".join(test_dataset.encodings[0].tokens[:30])}')\n",
    "    print('-'*10)\n",
    "    print(f'Testing set labels example: {set(test_dataset.labels)}')\n",
    "    print('~'*10)\n",
    "    print(f'Validation set encodings example:\\n{\" \".join(val_dataset.encodings[0].tokens[:30])}')\n",
    "    print('-'*10)\n",
    "    print(f'Validation labels after encoding: {set(val_dataset.labels)}')\n",
    "    print('='*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f3840ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    X_val, y_val,\n",
    "    tokenizer,\n",
    "):\n",
    "    print('='*20)\n",
    "    print(f'Encoding training, testing, and validation sets with {tokenizer.__class__.__name__}.from_pretrained using {tokenizer.name_or_path}.')\n",
    "\n",
    "    X_train_encodings = tokenizer(\n",
    "        X_train.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
    "    ).to(device)\n",
    "    train_dataset = ToDataset(X_train_encodings, y_train)\n",
    "\n",
    "    X_test_encodings = tokenizer(\n",
    "        X_test.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
    "    ).to(device)\n",
    "    test_dataset = ToDataset(X_test_encodings, y_test)\n",
    "\n",
    "    X_val_encodings = tokenizer(\n",
    "        X_val.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
    "    ).to(device)\n",
    "    val_dataset = ToDataset(X_val_encodings, y_val)\n",
    "\n",
    "    # Print info\n",
    "    print_Xy_encodings(\n",
    "        X_train, y_train, train_dataset,\n",
    "        X_test, y_test, test_dataset,\n",
    "        X_val, y_val, val_dataset,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        X_train_encodings, train_dataset,\n",
    "        X_test_encodings, test_dataset,\n",
    "        X_val_encodings, val_dataset,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7c888f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_with_y_pred(\n",
    "    y_labels, y_pred,\n",
    "    pos_label=None, labels=None, zero_division=None, alpha=None, print_enabled=None\n",
    "):\n",
    "    if pos_label is None:\n",
    "        pos_label = 1\n",
    "    if labels is None:\n",
    "        labels = np.unique(y_pred)\n",
    "    if zero_division is None:\n",
    "        zero_division = 0\n",
    "    if alpha is None:\n",
    "        alpha = 0.1\n",
    "    if print_enabled is None:\n",
    "        print_enabled = True\n",
    "\n",
    "    if print_enabled:\n",
    "        print('-'*20)\n",
    "        print('Computing metrics using y_pred.')\n",
    "    # Using y_pred\n",
    "    explained_variance = metrics.explained_variance_score(y_labels, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_labels, y_pred)\n",
    "    balanced_accuracy = metrics.balanced_accuracy_score(y_labels, y_pred)\n",
    "    precision = metrics.precision_score(y_labels, y_pred, pos_label=pos_label, labels=labels, zero_division=zero_division)\n",
    "    recall = metrics.recall_score(y_labels, y_pred, pos_label=pos_label, labels=labels, zero_division=zero_division)\n",
    "    f1 = metrics.f1_score(y_labels, y_pred, pos_label=pos_label,labels=labels, zero_division=zero_division)\n",
    "    mcc = metrics.matthews_corrcoef(y_labels, y_pred)\n",
    "    brier = metrics.brier_score_loss(y_labels, y_pred)\n",
    "    fm = metrics.fowlkes_mallows_score(y_labels, y_pred)\n",
    "    r2 = metrics.r2_score(y_labels, y_pred)\n",
    "    kappa = metrics.cohen_kappa_score(y_labels, y_pred, labels=labels)\n",
    "    gmean_iba = imblearn.metrics.make_index_balanced_accuracy(alpha=alpha, squared=True)(geometric_mean_score)\n",
    "    gmean = gmean_iba(y_labels, y_pred)\n",
    "    report = metrics.classification_report(y_labels, y_pred, labels=labels, zero_division=zero_division)\n",
    "    imblearn_report = classification_report_imbalanced(y_labels, y_pred, labels=labels, zero_division=zero_division)\n",
    "    cm = metrics.confusion_matrix(y_labels, y_pred, labels=labels)\n",
    "    cm_normalized = metrics.confusion_matrix(y_labels, y_pred, normalize='true', labels=labels)\n",
    "\n",
    "    return (\n",
    "        explained_variance, accuracy, balanced_accuracy, precision,\n",
    "        recall, f1, mcc, brier, fm, r2, kappa, gmean, report, imblearn_report, cm, cm_normalized\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82f234a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_with_y_pred(\n",
    "    y_labels, y_pred, col, vectorizer_name, classifier_name,\n",
    "    pos_label=None, labels=None, print_enabled=None\n",
    "):\n",
    "    if pos_label is None:\n",
    "        pos_label = 1\n",
    "    if labels is None:\n",
    "        labels = np.unique(y_pred)\n",
    "    if print_enabled is None:\n",
    "        print_enabled = True\n",
    "\n",
    "    # Displays\n",
    "    close_plots(plt)\n",
    "    cm_curve = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "        y_labels, y_pred, display_labels=labels, cmap=plt.cm.Grays, colorbar=True\n",
    "    )\n",
    "    cm_normalized_curve = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "        y_labels, y_pred, normalize='true', display_labels=labels, cmap=plt.cm.Grays, colorbar=True\n",
    "    )\n",
    "    roc_curve = metrics.RocCurveDisplay.from_predictions(\n",
    "        y_labels, y_pred, pos_label=pos_label, color='black'\n",
    "    )\n",
    "    pr_curve = metrics.PrecisionRecallDisplay.from_predictions(\n",
    "        y_labels, y_pred, pos_label=pos_label, color='black'\n",
    "    )\n",
    "    calibration_curve = CalibrationDisplay.from_predictions(\n",
    "        y_labels, y_pred, pos_label=pos_label, color='black'\n",
    "    )\n",
    "    if print_enabled: show_and_close_plots(plt)\n",
    "\n",
    "    # Plots\n",
    "    plots_dict = {\n",
    "        'Confusion Matrix': cm_curve,\n",
    "        'Normalized Confusion Matrix': cm_normalized_curve,\n",
    "        'ROC Curve': roc_curve,\n",
    "        'Precision-Recall Curve': pr_curve,\n",
    "        'Calibration Curve': calibration_curve,\n",
    "    }\n",
    "\n",
    "    print('=' * 20)\n",
    "    close_plots(plt)\n",
    "    print('Plotting metrics with y_pred:')\n",
    "    print('='*20)\n",
    "\n",
    "    for plot_name, plot_ in tqdm.tqdm(plots_dict.items()):\n",
    "        close_plots(plt)\n",
    "        print(f'Plotting {plot_name}:')\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(\n",
    "            f'{col} - {plot_name} - {vectorizer_name} + {classifier_name}'\n",
    "            )\n",
    "        if plot_name == 'ROC Curve':\n",
    "            ax.plot([0, 1], [0, 1], 'r--', lw=1)\n",
    "        try:\n",
    "            plot_.plot(ax=ax, cmap=plt.cm.Grays)\n",
    "        except Exception:\n",
    "            plot_.plot(ax=ax, color='black')\n",
    "        print('=' * 20)\n",
    "        fig = plt.gcf()\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # Save Plots\n",
    "        for image_save_format in tqdm.tqdm(['png', 'svg']):\n",
    "            save_path = f'{plot_save_path}{method} {col} - {plot_name} - {vectorizer_name} + {classifier_name}.{image_save_format}'\n",
    "            print(f'Saving {plot_name} as {image_save_format}')\n",
    "            try:\n",
    "                fig.savefig(\n",
    "                    save_path, format=image_save_format, dpi=3000, bbox_inches='tight'\n",
    "                )\n",
    "            except Exception:\n",
    "                print(f'Failed to save {plot_name}!')\n",
    "                print('=' * 20)\n",
    "            else:\n",
    "                print(f'Saved {plot_name}!')\n",
    "                print('=' * 20)\n",
    "        if print_enabled: show_and_close_plots(plt)\n",
    "\n",
    "    # with contextlib.suppress(AttributeError):\n",
    "    # Visualisation with plot_metric\n",
    "    bc = plot_metric_functions.BinaryClassification(y_labels, y_pred, labels=[0, 1], matplotlib_style='grayscale', seaborn_style='whitegrid')\n",
    "\n",
    "    # Figures\n",
    "    close_plots(plt)\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    fig.suptitle(f'{col} - {vectorizer_name} + {classifier_name}')\n",
    "    plt.subplot2grid((2, 6), (1, 1), colspan=2)\n",
    "    bc.plot_confusion_matrix(colorbar=True, cmap=plt.cm.Grays)\n",
    "    plt.subplot2grid((2, 6), (1, 3), colspan=2)\n",
    "    bc.plot_confusion_matrix(normalize=True, colorbar=True, cmap=plt.cm.Grays)\n",
    "    plt.subplot2grid(shape=(2, 6), loc=(0, 0), colspan=2)\n",
    "    bc.plot_roc_curve()\n",
    "    plt.subplot2grid((2, 6), (0, 2), colspan=2)\n",
    "    bc.plot_precision_recall_curve()\n",
    "    plt.subplot2grid((2, 6), (0, 4), colspan=2)\n",
    "    bc.plot_class_distribution()\n",
    "    bc.print_report()\n",
    "    fig = plt.gcf()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save Plots\n",
    "    for image_save_format in tqdm.tqdm(['png', 'svg']):\n",
    "        save_path = f'{plot_save_path}{method} {col} - plot_metric Curves - {vectorizer_name} + {classifier_name}.{image_save_format}'\n",
    "        print(f'Saving plot_metric Curves as {image_save_format}')\n",
    "        fig.savefig(\n",
    "            save_path, format=image_save_format, dpi=3000, bbox_inches='tight'\n",
    "        )\n",
    "    if print_enabled: show_and_close_plots(plt)\n",
    "\n",
    "    # Heatmap\n",
    "    print('Plotting Heatmap:')\n",
    "    close_plots(plt)\n",
    "    classifications_dict = defaultdict(int)\n",
    "    for _y_labels, _y_pred in zip(y_labels, y_pred):\n",
    "        if _y_labels != _y_pred:\n",
    "            classifications_dict[(_y_labels, _y_pred)] += 1\n",
    "\n",
    "    dicts_to_plot = [\n",
    "        {\n",
    "            f'True {col} value': _y_labels,\n",
    "            f'Predicted {col} value': _y_pred,\n",
    "            'Number of Classifications': _count,\n",
    "        }\n",
    "        for (_y_labels, _y_pred), _count in classifications_dict.items()\n",
    "    ]\n",
    "    df_to_plot = pd.DataFrame(dicts_to_plot)\n",
    "    df_wide = df_to_plot.pivot_table(\n",
    "        index=f'True {col} value',\n",
    "        columns=f'Predicted {col} value',\n",
    "        values='Number of Classifications'\n",
    "    )\n",
    "    plt.figure(figsize=(9,7))\n",
    "    sns.set(style='ticks', font_scale=1.2)\n",
    "    sns.heatmap(df_wide, linewidths=1, cmap=plt.cm.Grays, annot=True)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title(f'{col} Heatmap - {vectorizer_name} + {classifier_name}')\n",
    "    fig = plt.gcf()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save Heatmap\n",
    "    for image_save_format in tqdm.tqdm(['png', 'svg']):\n",
    "        save_path = f'{plot_save_path}{method} {col} - Heatmap - {vectorizer_name} + {classifier_name}.{image_save_format}'\n",
    "        print(f'Saving Heatmap as {image_save_format}')\n",
    "        fig.savefig(\n",
    "            save_path, format=image_save_format, dpi=3000, bbox_inches='tight'\n",
    "        )\n",
    "    print('Saved Heatmap!')\n",
    "    if print_enabled: show_and_close_plots(plt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e2dcb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_with_y_pred_prob(\n",
    "    y_labels, y_pred_prob,\n",
    "    pos_label=None,\n",
    "    print_enabled=None\n",
    "):\n",
    "    if pos_label is None:\n",
    "        pos_label = 1\n",
    "    if print_enabled is None:\n",
    "        print_enabled = True\n",
    "\n",
    "    if print_enabled:\n",
    "        print('-'*20)\n",
    "        print('Computing metrics using y_pred_prob.')\n",
    "    average_precision = metrics.average_precision_score(y_labels, y_pred_prob)\n",
    "    roc_auc = metrics.roc_auc_score(y_labels, y_pred_prob)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_labels, y_pred_prob, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    loss = metrics.log_loss(y_labels, y_pred_prob)\n",
    "    precision_pr, recall_pr, threshold_pr = metrics.precision_recall_curve(y_labels, y_pred_prob, pos_label=1)\n",
    "\n",
    "    return (\n",
    "        average_precision, roc_auc, auc,\n",
    "        fpr, tpr, threshold, loss,\n",
    "        precision_pr, recall_pr, threshold_pr\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "359e3293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_all(\n",
    "    y_labels, y_pred, y_pred_prob, print_enabled=None\n",
    "):\n",
    "    if print_enabled is None:\n",
    "        print_enabled = True\n",
    "    # Get metrics\n",
    "    # Using y_pred\n",
    "    if y_pred:\n",
    "        (\n",
    "            explained_variance, accuracy, balanced_accuracy, precision,\n",
    "            recall, f1, mcc, brier, fm, r2, kappa, gmean, report, imblearn_report, cm, cm_normalized\n",
    "        ) = compute_metrics_with_y_pred(\n",
    "            y_labels, y_pred, print_enabled=print_enabled\n",
    "        )\n",
    "    # Using y_pred_prob\n",
    "    if y_pred_prob:\n",
    "        (\n",
    "            average_precision, roc_auc, auc,\n",
    "            fpr, tpr, threshold, loss,\n",
    "            precision_pr, recall_pr, threshold_pr\n",
    "        ) = compute_metrics_with_y_pred_prob(\n",
    "            y_labels, y_pred_prob, print_enabled=print_enabled\n",
    "        )\n",
    "\n",
    "    # Place metrics into dict\n",
    "    if print_enabled:\n",
    "        print('='*20)\n",
    "        print('Appending metrics to dict.')\n",
    "    metrics_dict = {\n",
    "        # f'{scoring.title()} Best Score': float(best_train_score),\n",
    "        # f'{scoring.title()} Best Threshold': threshold,\n",
    "        # 'Train - Mean Cross Validation Score': float(cv_train_scores),\n",
    "        # f'Train - Mean Cross Validation - {scoring.title()}': float(cv_train_recall),\n",
    "        # f'Train - Mean Explained Variance - {scoring.title()}': float(cv_train_explained_variance_recall),\n",
    "        # 'Test - Mean Cross Validation Score': float(cv_test_scores),\n",
    "        # f'Test - Mean Cross Validation - {scoring.title()}': float(cv_test_recall),\n",
    "        # f'Test - Mean Explained Variance - {scoring.title()}': float(cv_test_explained_variance_recall),\n",
    "        'Explained Variance': float(explained_variance),\n",
    "        'Accuracy': float(accuracy),\n",
    "        'Balanced Accuracy': float(balanced_accuracy),\n",
    "        'Precision': float(precision),\n",
    "        'Average Precision': float(average_precision),\n",
    "        'Recall': float(recall),\n",
    "        'F1-score': float(f1),\n",
    "        'Matthews Correlation Coefficient': float(mcc),\n",
    "        'Brier Score': float(brier),\n",
    "        'Fowlkes–Mallows Index': float(fm),\n",
    "        'R2 Score': float(r2),\n",
    "        'ROC': float(roc_auc),\n",
    "        'AUC': float(auc),\n",
    "        'Log Loss/Cross Entropy': float(loss),\n",
    "        'Cohen’s Kappa': float(kappa),\n",
    "        'Geometric Mean': float(gmean),\n",
    "        'Classification Report': report,\n",
    "        'Imbalanced Classification Report': str(imblearn_report),\n",
    "        'Confusion Matrix': str(cm),\n",
    "        'Normalized Confusion Matrix': str(cm_normalized),\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_prob': y_pred_prob,\n",
    "    }\n",
    "    if print_enabled: print('Done appending metrics to dict.')\n",
    "\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53db240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_metrics_dict(metrics_dict, prefix_to_remove):\n",
    "    for metric_name in list(metrics_dict):\n",
    "        if metric_name.startswith(prefix_to_remove):\n",
    "            new_metric_name = ' '.join(metric_name.split(prefix_to_remove)[-1].split('_')).strip()\n",
    "        if not new_metric_name[0].isupper():\n",
    "            new_metric_name = new_metric_name.title()\n",
    "        if new_metric_name == 'Loss':\n",
    "            metrics_dict['Log Loss/Cross Entropy'] = metrics_dict.pop(metric_name)\n",
    "        else:\n",
    "            metrics_dict[new_metric_name] = metrics_dict.pop(metric_name)\n",
    "\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d15ac304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get y_pred and y_pred_prob\n",
    "def preprocess_logits_for_metrics_y_pred_prob(y_pred_logits, y_labels):\n",
    "\n",
    "    print('-'*20)\n",
    "    print(f'Preprocessing y_pred logits and labels for {col}:')\n",
    "    print('-'*20)\n",
    "\n",
    "    if isinstance(y_pred_logits, tuple):\n",
    "        y_pred_logits = y_pred_logits[0]\n",
    "\n",
    "    if not torch.is_tensor(y_pred_logits):\n",
    "        y_pred_logits_tensor = torch.tensor(y_pred_logits, device=device)\n",
    "    else:\n",
    "        y_pred_logits_tensor = y_pred_logits.to(device)\n",
    "\n",
    "    print(f'y_pred_logits shape: {y_pred_logits_tensor.shape}, {y_pred_logits_tensor.dtype}')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Get y_pred_prob\n",
    "    # https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop\n",
    "    print('-'*20)\n",
    "    print('Getting y_pred_prob through sigmoid of y_pred_logits.')\n",
    "    try:\n",
    "        y_pred_prob_array = torch.nn.functional.sigmoid(y_pred_logits_tensor)\n",
    "        print('Using torch.nn.functional.sigmoid.')\n",
    "    except Exception:\n",
    "        y_pred_prob_array = scipy.special.expit(y_pred_logits, axis=-1)\n",
    "        print('Using scipy.special.expit.')\n",
    "\n",
    "    print(f'y_pred_prob_array shape: {y_pred_prob_array.shape}, {y_pred_prob_array.dtype}')\n",
    "\n",
    "    return torch.tensor(y_pred_prob_array, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31ca2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get y_pred and y_pred_prob\n",
    "def preprocess_logits_for_metrics_y_pred(y_pred_prob_array):\n",
    "\n",
    "    # https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d\n",
    "    print('-'*20)\n",
    "    print(f'Getting y_pred from y_pred_prob for {col}:')\n",
    "    print('-'*20)\n",
    "\n",
    "    if isinstance(y_pred_prob_array, tuple):\n",
    "        y_pred_prob_array = y_pred_prob_array[0]\n",
    "\n",
    "    if not torch.is_tensor(y_pred_prob_array):\n",
    "        y_pred_prob_tensor = torch.tensor(y_pred_prob_array, device=device)\n",
    "    else:\n",
    "        y_pred_prob_tensor = y_pred_prob_array.to(device)\n",
    "\n",
    "    print(f'y_pred_prob_array shape: {y_pred_prob_tensor.shape}. {y_pred_prob_tensor.dtype}')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Get y_pred\n",
    "    print('-'*20)\n",
    "    print('Getting y_pred through argmax of y_pred_prob.')\n",
    "    try:\n",
    "        y_pred_array = torch.argmax(y_pred_prob_tensor, dim=-1)\n",
    "        print('Using torch.argmax.')\n",
    "    except Exception:\n",
    "        y_pred_array = y_pred_prob.argmax(axis=-1)\n",
    "        print('Using np.argmax.')\n",
    "\n",
    "    print(f'y_pred_array shape: {y_pred_array.shape}')\n",
    "\n",
    "    return y_pred_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34f4f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(\n",
    "    predicted_results_from_eval,\n",
    "):\n",
    "    y_pred_prob_array, y_labels_array = predicted_results_from_eval\n",
    "\n",
    "    # Get y_pred_prob\n",
    "    (\n",
    "        y_pred_array\n",
    "    ) = preprocess_logits_for_metrics_y_pred(y_pred_prob_array)\n",
    "\n",
    "    # Get the the whole of the last column, which is the  probability of 1, and flatten to list\n",
    "    print('-'*20)\n",
    "    print('Flattening y_labels , y_pred_array, and y_pred_prob_array, then extracting probabilities of 1.')\n",
    "    y_labels = y_labels_array.flatten().tolist()\n",
    "    y_pred = y_pred_array.flatten().tolist()\n",
    "    y_pred_prob = y_pred_prob_array[:, -1].flatten().tolist()\n",
    "    print(f'y_pred_prob length: {len(y_pred_prob)}')\n",
    "    print(f'y_labels length: {len(y_labels)}')\n",
    "    print('-'*20)\n",
    "\n",
    "    return compute_metrics_all(y_labels, y_pred, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe35a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get y_pred and y_pred_prob\n",
    "def preprocess_logits_for_metrics_from_logits(y_pred_logits, print_enabled=None):\n",
    "\n",
    "    if print_enabled is None:\n",
    "        print_enabled = True\n",
    "\n",
    "    # Get y_pred\n",
    "    if not torch.is_tensor(y_pred_logits):\n",
    "        y_pred_logits_tensor = torch.tensor(y_pred_logits, device=device)\n",
    "    if print_enabled:\n",
    "        print('-'*20)\n",
    "        print('Getting y_pred through argmax of y_pred_logits...')\n",
    "    try:\n",
    "        y_pred_array = torch.argmax(y_pred_logits_tensor, axis=-1)\n",
    "        if print_enabled: print('Using torch.argmax.')\n",
    "    except Exception:\n",
    "        y_pred_array = y_pred_logits.argmax(axis=-1)\n",
    "        if print_enabled: print('Using np.argmax.')\n",
    "    if print_enabled:\n",
    "        print(f'y_pred_array shape: {y_pred_array.shape}')\n",
    "        print('-'*20)\n",
    "        print('Flattening y_pred...')\n",
    "    y_pred = y_pred_array.flatten().tolist()\n",
    "    if print_enabled:\n",
    "        print(f'y_pred length: {len(y_pred)}')\n",
    "        print('-'*20)\n",
    "\n",
    "    # Get y_pred_prob\n",
    "    if print_enabled:\n",
    "        print('-'*20)\n",
    "        print('Getting y_pred_prob through sigmoid of y_pred_logits...')\n",
    "    try:\n",
    "        y_pred_prob_array = torch.nn.functional.sigmoid(y_pred_logits_tensor)\n",
    "        if print_enabled: print('Using torch.nn.functional.sigmoid.')\n",
    "    except Exception:\n",
    "        y_pred_prob_array = scipy.special.expit(y_pred_logits_tensor, axis=-1)\n",
    "        if print_enabled: print('Using scipy.special.expit.')\n",
    "    # from: https://discuss.huggingface.co/t/different-results-predicting-from-trainer-and-model/12922\n",
    "    assert all(y_pred_prob_array.argmax(axis=-1) == y_pred_array), 'Argmax of y_pred_prob_array does not match y_pred_array.'\n",
    "    y_pred_prob = y_pred_prob_array[:, -1].flatten().tolist()\n",
    "    if print_enabled:\n",
    "        print(f'y_pred_prob shape: {y_pred_prob_array.shape}')\n",
    "        print('-'*20)\n",
    "        print('Flattening y_pred_prob and extracting probabilities of 1...')\n",
    "        print(f'y_pred length: {len(y_pred_prob)}')\n",
    "        print('-'*20)\n",
    "\n",
    "    return (\n",
    "        y_pred_array, y_pred, y_pred_prob_array, y_pred_prob\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a1121fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_from_logits(\n",
    "    predicted_results_from_eval, print_enabled=None\n",
    "):\n",
    "    if print_enabled is None:\n",
    "        print_enabled = True\n",
    "    # Get predictions\n",
    "    y_pred_logits, y_labels = predicted_results_from_eval\n",
    "    if print_enabled:\n",
    "        print('-'*20)\n",
    "        print(f'Getting y_pred logits and ids for {col}:')\n",
    "        print(f'y_pred_logits shape: {y_pred_logits.shape}')\n",
    "        print(f'y shape: {y_labels.shape}')\n",
    "        print('-'*20)\n",
    "\n",
    "    # Get y_test_pred and y_test_pred_prob\n",
    "    (\n",
    "        y_pred_array, y_pred, y_pred_prob_array, y_pred_prob\n",
    "    ) = preprocess_logits_for_metrics_from_logits(y_pred_logits, print_enabled=print_enabled)\n",
    "\n",
    "    return compute_metrics_all(y_labels, y_pred, y_pred_prob, print_enabled=print_enabled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2d3da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(\n",
    "    y_labels, y_pred,\n",
    "    col, vectorizer_name, classifier_name,\n",
    "    with_y_pred=None, with_y_pred_prob=None, print_enabled=None\n",
    "):\n",
    "    if with_y_pred is None:\n",
    "        with_y_pred = True\n",
    "    if with_y_pred_prob is None:\n",
    "        with_y_pred_prob = True\n",
    "    if print_enabled is None:\n",
    "        print_enabled = True\n",
    "\n",
    "    # Plotting\n",
    "    # Using y_test_pred\n",
    "    if with_y_pred:\n",
    "        plot_metrics_with_y_pred(\n",
    "            y_labels, y_pred,\n",
    "            col, vectorizer_name, classifier_name, print_enabled=print_enabled\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6aeec3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def examine_predictions(\n",
    "    X_test, y_test, y_test_pred, col\n",
    "):\n",
    "    # Examine predictions\n",
    "    print('~'*20)\n",
    "    print(f'Examining predictions for {col}')\n",
    "    print('Incorrectly Classified Reviews:')\n",
    "    for _y_test, _y_test_pred, _X_test in random.sample(list(zip(y_test, y_test_pred, X_test)), 50):\n",
    "        if _y_test != _y_test_pred:\n",
    "            print('-'*20)\n",
    "            print(f'TRUE LABEL: {_y_test}')\n",
    "            print(f'PREDICTED LABEL: {_y_test_pred}')\n",
    "            print(f'REVIEW TEXT: {_X_test[:100]}')\n",
    "            print('-'*20)\n",
    "    print('~'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c44994c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(\n",
    "    y_labels, y_pred,\n",
    "    metrics_dict, df_metrics,\n",
    "    col, vectorizer_name, classifier_name,\n",
    "    plot_enabled=None, print_enabled=None\n",
    "):\n",
    "    if plot_enabled is None:\n",
    "        plot_enabled = True\n",
    "    if print_enabled is None:\n",
    "        print_enabled = True\n",
    "    # Print metrics\n",
    "    print('=' * 20)\n",
    "    print('~' * 20)\n",
    "    print(' Metrics:')\n",
    "    print('~' * 20)\n",
    "    print(f'Classification Report:\\n {test_metrics_dict[\"Classification Report\"]}')\n",
    "    print('-' * 20)\n",
    "    for metric_name, metric_value in metrics_dict.items():\n",
    "        if metric_name not in ['Runtime', 'Samples Per Second', 'Steps Per Second']:\n",
    "            with contextlib.suppress(TypeError, ValueError):\n",
    "                metric_value = float(metric_value)\n",
    "            if isinstance(metric_value, (int, float)):\n",
    "                df_metrics.loc[\n",
    "                    (classifier_name), (col, metric_name)\n",
    "                ] = metric_value\n",
    "                print(f'{metric_name}: {round(metric_value, 2)}')\n",
    "            else:\n",
    "                df_metrics.loc[\n",
    "                    (classifier_name), (col, metric_name)\n",
    "                ] = str(metric_value)\n",
    "                print(f'{metric_name}:\\n{metric_value}')\n",
    "            print('-' * 20)\n",
    "\n",
    "    print('=' * 20)\n",
    "\n",
    "    if plot_enabled:\n",
    "        # Plot Metrics\n",
    "        plot_metrics(\n",
    "            y_labels, y_pred,\n",
    "            col, vectorizer_name, classifier_name, print_enabled=print_enabled\n",
    "        )\n",
    "\n",
    "    return df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6552d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_confirmatory_tests(y_pred, y_pred_prob):\n",
    "\n",
    "    # Confirmatory Regression\n",
    "    print('+'*20)\n",
    "    print('Confirmatory Tests validating the linear relationship between y_pred and y_pred_prob')\n",
    "    print('-'*20)\n",
    "    print('T-Test y_pred_prob ~ y_pred:')\n",
    "    levene = scipy.stats.levene(y_pred_prob, y_pred)\n",
    "    equal_var_levene = levene.pvalue < 0.05\n",
    "    print(scipy.stats.ttest_ind(y_pred_prob, y_pred, equal_var=equal_var_levene))\n",
    "\n",
    "\n",
    "    print('\\n')\n",
    "    print('-'*20)\n",
    "    print('Logit y_pred ~ y_pred_prob:')\n",
    "    try:\n",
    "        logit_model = sm.Logit(endog=y_pred, exog=y_pred_prob)\n",
    "        logit_results = logit_model.fit()\n",
    "        std_coef = logit_results.params[0] / np.std(y_pred_prob)\n",
    "        std_err = logit_results.bse[0]\n",
    "        log_likelihood = logit_results.llf\n",
    "        print(logit_results.summary())\n",
    "        print('-'*20)\n",
    "        print(f'Std Coef: {std_coef}')\n",
    "        print(f'Std Err: {std_err}')\n",
    "        print(f'Log Likelihood: {log_likelihood}')\n",
    "    except Exception as e:\n",
    "        print(type(e).__name__)\n",
    "\n",
    "    print('-'*20)\n",
    "    print('\\n')\n",
    "    print('-'*20)\n",
    "    print('OLS y_pred_prob ~ y_pred:')\n",
    "    try:\n",
    "        ols_model = sm.OLS(endog=y_pred_prob, exog=y_pred)\n",
    "        ols_results = ols_model.fit()\n",
    "        std_coef = ols_results.params[0] / np.std(y_pred)\n",
    "        std_err = ols_results.bse[0]\n",
    "        print(ols_results.summary())\n",
    "        print('-'*20)\n",
    "        print(f'Std Coef: {std_coef}')\n",
    "        print(f'Std Err: {std_err}')\n",
    "    except Exception as e:\n",
    "        print(type(e).__name__)\n",
    "\n",
    "    print('-'*20)\n",
    "    print('+'*20)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "93960eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to place Xy data in df and save\n",
    "def save_Xy_estimator(\n",
    "    X_train, y_train, train_dataset,\n",
    "    X_test, y_test, y_test_pred, y_test_pred_prob, test_dataset,\n",
    "    X_val, y_val, y_val_pred, y_val_pred_prob, val_dataset,\n",
    "    estimator, accelerator, eval_metrics_dict, test_metrics_dict,\n",
    "    col, vectorizer_name, classifier_name,\n",
    "    results_save_path=results_save_path,\n",
    "    method=method, done_xy_save_path=done_xy_save_path,\n",
    "    path_suffix=None, data_dict=None,\n",
    "    compression=None, protocol=None,\n",
    "):\n",
    "    if data_dict is None:\n",
    "        data_dict = {}\n",
    "    if compression is None:\n",
    "        compression = False\n",
    "    if protocol is None:\n",
    "        protocol = pickle.HIGHEST_PROTOCOL\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {col} - {vectorizer_name} + {classifier_name} (Save_protocol={protocol}).pkl'\n",
    "\n",
    "    # Check predicted data\n",
    "    check_consistent_length(X_train, y_train, train_dataset)\n",
    "    check_consistent_length(X_test, y_test, y_test_pred, y_test_pred_prob, test_dataset)\n",
    "    check_consistent_length(X_val, y_val, y_val_pred, y_val_pred_prob, val_dataset)\n",
    "\n",
    "    # Make data dict\n",
    "    data_dict['Estimator'] = estimator\n",
    "    data_dict['accelerator'] = accelerator\n",
    "    data_dict['eval_metrics_dict'] = eval_metrics_dict\n",
    "    data_dict['test_metrics_dict'] = test_metrics_dict\n",
    "\n",
    "    # Make df_train_data\n",
    "    data_dict['df_train_data'] = pd.DataFrame(\n",
    "        {\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "            'train_dataset': train_dataset,\n",
    "        },\n",
    "    )\n",
    "    # Make df_test_data\n",
    "    data_dict['df_test_data'] = pd.DataFrame(\n",
    "        {\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'y_test_pred': y_test_pred,\n",
    "            'y_test_pred_prob': y_test_pred_prob,\n",
    "            'test_dataset': test_dataset,\n",
    "        },\n",
    "    )\n",
    "    # Make df_val_data\n",
    "    data_dict['df_val_data'] = pd.DataFrame(\n",
    "        {\n",
    "            'X_val': X_val,\n",
    "            'y_val': y_val,\n",
    "            'y_val_pred': y_val_pred,\n",
    "            'y_val_pred_prob': y_val_pred_prob,\n",
    "            'val_dataset': val_dataset,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Save files\n",
    "    print('='*20)\n",
    "    saved_files_list = []\n",
    "    for file_name, file_ in data_dict.items():\n",
    "        save_path = (\n",
    "            done_xy_save_path\n",
    "            if file_name not in ['Estimator', 'accelerator']\n",
    "            else results_save_path\n",
    "        )\n",
    "        print(f'Saving {file_name}')\n",
    "        if not isinstance(file_, pd.DataFrame) and file_name == 'Estimator' and 'df_' not in file_name and 'metrics_dict' not in file_name:\n",
    "            # Save as .model\n",
    "            file_.save_model(f'{save_path}{method} {file_name}{path_suffix.replace(\"pkl\", \"model\")}')\n",
    "            saved_files_list.append(file_name)\n",
    "        elif not isinstance(file_, pd.DataFrame) and file_name == 'accelerator' and 'df_' not in file_name and 'metrics_dict' not in file_name:\n",
    "            file_.save(estimator.state, f'{save_path}{method} Estimator{path_suffix.replace(\"pkl\", \"model\")}/accelerator')\n",
    "            saved_files_list.append(file_name)\n",
    "        elif isinstance(file_, dict) and file_name != 'Estimator' and file_name != 'accelerator' and 'df_' not in file_name and 'metrics_dict' in file_name:\n",
    "            with open(f'{save_path}{method} {file_name}{path_suffix}', 'wb') as f:\n",
    "                pickle.dump(file_, f, protocol=protocol)\n",
    "            saved_files_list.append(file_name)\n",
    "        elif isinstance(file_, pd.DataFrame) and file_name != 'Estimator' and file_name != 'accelerator' and 'df_' in file_name and 'metrics_dict' not in file_name:\n",
    "            file_.to_pickle(\n",
    "                f'{save_path}{method} {file_name}{path_suffix}', protocol=protocol\n",
    "            )\n",
    "            saved_files_list.append(file_name)\n",
    "\n",
    "    assert set(data_dict.keys()) == set(saved_files_list), f'Not all files were saved! Missing: {set(data_dict.keys()) ^ set(saved_files_list)}'\n",
    "    print(f'Done saving Xy, labels and estimator!\\n{list(data_dict.keys())}')\n",
    "    print('='*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "06545bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fitted_estimator(\n",
    "    estimator, metrics_dict,\n",
    "    col, vectorizer_name, classifier_name,\n",
    "    protocol=None,\n",
    "    results_save_path=results_save_path,\n",
    "    method=method, done_xy_save_path=done_xy_save_path,\n",
    "    path_suffix=None, data_dict=None,\n",
    "    compression=None,\n",
    "):\n",
    "    if protocol is None:\n",
    "        protocol = pickle.HIGHEST_PROTOCOL\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {col} - {vectorizer_name} + {classifier_name} (Save_protocol={protocol}).model'\n",
    "    if data_dict is None:\n",
    "        data_dict = {}\n",
    "    if compression is None:\n",
    "        compression = False\n",
    "\n",
    "    # Save fitted estimator\n",
    "    print('~'*20)\n",
    "    print(f'Saving fitted estimator {classifier_name}')\n",
    "    estimator.save_state()\n",
    "    estimator.save_model(f'{results_save_path}{method} Fitted Estimator{path_suffix}')\n",
    "    estimator.save_metrics('all', metrics_dict)\n",
    "    print('~'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b48de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table(\n",
    "    df_metrics,\n",
    "    col, vectorizer_name, classifier_name, protocol,\n",
    "    table_save_path=table_save_path,\n",
    "    method=method, save_name=None,\n",
    "    compression=None,\n",
    "    path_suffix=None,\n",
    "):\n",
    "    if save_name is None:\n",
    "        save_name = f'{method} Estimators Table'\n",
    "    if compression is None:\n",
    "        compression = False\n",
    "    if protocol is None:\n",
    "        protocol = pickle.HIGHEST_PROTOCOL\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {col} - {vectorizer_name} + {classifier_name} (Save_protocol={protocol}).pkl'\n",
    "\n",
    "    # Save metrics df\n",
    "    save_path = f'{table_save_path}{save_name}'\n",
    "    print(f'Saving fitted estimator and table')\n",
    "    df_metrics.to_csv(f'{save_path}.csv')\n",
    "    df_metrics.to_pickle(f'{save_path}.pkl')\n",
    "    df_metrics.to_excel(f'{save_path}.xlsx')\n",
    "    df_metrics.style.to_latex(f'{save_path}.tex', hrules=True)\n",
    "    df_metrics.to_markdown(f'{save_path}.md')\n",
    "    df_metrics.to_html(f'{save_path}.html')\n",
    "\n",
    "    print('Done saving fitted estimator and table!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29efbbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completed_estimators(results_save_path=results_save_path, method=method):\n",
    "\n",
    "    estimators_list = []\n",
    "\n",
    "    for estimator_path in glob.glob(f'{results_save_path}{method} Estimator - *.model'):\n",
    "        with open(estimator_path, 'rb') as f:\n",
    "            estimators_list.append(joblib.load(f))\n",
    "\n",
    "    return estimators_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34e44624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_plots(\n",
    "    estimators_list, X_test, y_test, col,\n",
    "    curves_dict=None, cmap=plt.cm.Grays\n",
    "):\n",
    "\n",
    "    curves_dict = {\n",
    "        'ROC Curve': metrics.RocCurveDisplay,\n",
    "        'Precision Recall Curve': metrics.PrecisionRecallDisplay,\n",
    "        # 'Calibration Curve': CalibrationDisplay,\n",
    "        # 'Validation Curve': ValidationCurveDisplay,\n",
    "        # 'Learning Curve': LearningCurveDisplay,\n",
    "    }\n",
    "\n",
    "    assert len(estimators_list) != 0\n",
    "\n",
    "    for curve_name, curve_package in curves_dict.items():\n",
    "        print('-' * 20)\n",
    "        print(f'{col} - {str(curve_name)}')\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(f'{col} - {str(curve_name)}')\n",
    "        for estimator in estimators_list:\n",
    "            try:\n",
    "                curve = curve_package.from_estimator(\n",
    "                    estimator, X_test, y_test, pos_label=1, ax=ax, cmap=cmap,\n",
    "                    name=f'{estimator.steps[0][0]} + {estimator.steps[1][0]} + {estimator.steps[-1][0]}'\n",
    "                )\n",
    "            except AttributeError:\n",
    "                curve = curve_package.from_estimator(\n",
    "                    estimator, X_test, y_test, pos_label=1, ax=ax, color='black',\n",
    "                    name=f'{estimator.steps[0][0]} + {estimator.steps[1][0]} + {estimator.steps[-1][0]}'\n",
    "                )\n",
    "        show_and_close_plots(plt)\n",
    "\n",
    "        # Save Plots\n",
    "        for image_save_format in tqdm.tqdm(['png', 'svg']):\n",
    "            save_path = f'{plot_save_path}{method} {col} - All {str(curve_name)}s.{image_save_format}'\n",
    "            print(f'Saving {curve_name} as {image_save_format}')\n",
    "            curve.figure_.savefig(\n",
    "                save_path, format=image_save_format, dpi=3000, bbox_inches='tight'\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dd9c3585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get example text for shap\n",
    "def get_example_text_for_shap(X_train, X_test, X_val, text: np.array = None, print_enabled: bool = None) -> np.array:\n",
    "    if text is None:\n",
    "        text = np.array([])\n",
    "    if print_enabled is None:\n",
    "        print_enabled = False\n",
    "\n",
    "    all_X = np.concatenate((X_train, X_test, X_val), axis=0)\n",
    "    # find example text by searching for values from dict example_sentences in all_X\n",
    "    for key, value in example_sentences.items():\n",
    "        matching_sentences = np.array([sentence for sentence in all_X if value in sentence])\n",
    "        if print_enabled:\n",
    "            print('-'*20)\n",
    "            print(f'Finding {key} in all_X:')\n",
    "            if matching_sentences.size != 0:\n",
    "                print(f'Found {key}:\\n{matching_sentences}')\n",
    "            else:\n",
    "                print(f'No {key} found in all_X')\n",
    "            print('-'*20)\n",
    "        text = np.append(text, matching_sentences)\n",
    "    if print_enabled: print('+'*20)\n",
    "    if print_enabled: print(f'{len(text)} unique text examples found in all_X:')\n",
    "    for (t), (k, v) in tqdm_product(text, example_sentences.items()):\n",
    "        if v == t and print_enabled:\n",
    "            print(f'{k}:\\n{t}')\n",
    "            print('-'*20)\n",
    "\n",
    "    return np.unique(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97eb6766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_score_and_visualize(col, X_train, X_test, X_val, estimator, tokenizer, vectorizer_name: str, classifier_name: str, shap_values_dict: dict, path_suffix: str = None, print_enabled: bool = None, shap_full: bool = None, make_new_explainer: bool = None, sample_size: int = None,):\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {str(col)} - {vectorizer_name} + {classifier_name}'\n",
    "    if print_enabled is None:\n",
    "        print_enabled = False\n",
    "    if shap_full is None:\n",
    "        shap_full = True\n",
    "    if make_new_explainer is None:\n",
    "        make_new_explainer = False\n",
    "    if sample_size is None or sample_size > len(X_test):\n",
    "        sample_size = len(X_test)\n",
    "\n",
    "    print('-'*20)\n",
    "    print(f'shap_full set to {shap_full}')\n",
    "    print('-'*20)\n",
    "    print(f'make_new_explainer set to {make_new_explainer}')\n",
    "    print('-'*20)\n",
    "    print(f'sample_size set to {sample_size}')\n",
    "    if sample_size == len(X_test):\n",
    "        print('-'*20)\n",
    "        print(f'Using full X_test')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Get logit scores\n",
    "    def f(x):\n",
    "        tv = torch.tensor(\n",
    "            [\n",
    "                tokenizer.encode(v, truncation=True, padding='max_length')\n",
    "                for v in x\n",
    "            ]\n",
    "        ).to(device)\n",
    "        attention_mask = (tv != 0).type(torch.int64).to(device)\n",
    "        outputs = estimator.to(device)(tv, attention_mask=attention_mask)[0].detach().cpu().numpy()\n",
    "        scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
    "        val = scipy.special.logit(scores)\n",
    "        return val\n",
    "\n",
    "    print('='*20)\n",
    "    print(f'Calculating SHAP values for {path_suffix}...')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Train SHAP explainer to get shap values\n",
    "    print('-'*20)\n",
    "    print(f'Training SHAP explainer for {path_suffix}...')\n",
    "    print('-'*20)\n",
    "    if shap_full:\n",
    "        explainer_path = f'{done_xy_save_path}{method} SHAP Explainer Full{path_suffix}'\n",
    "    else:\n",
    "        explainer_path = f'{done_xy_save_path}{method} SHAP Explainer{path_suffix}'\n",
    "\n",
    "    if os.path.exists(explainer_path) and os.path.getsize(explainer_path) != 0 and make_new_explainer is False:\n",
    "        print('Loading Existing SHAP explainer...')\n",
    "        with open(explainer_path, 'rb') as f:\n",
    "            explainer = shap.Explainer.load(f)\n",
    "    else:\n",
    "        print('Training New SHAP explainer...')\n",
    "        explainer = shap.Explainer(\n",
    "            model=f, masker=tokenizer, seed=random_state, output_names=[f'{col} Absent', f'{col} Present']#, link=shap.links.logit\n",
    "        )\n",
    "        with open(explainer_path, 'wb') as f:\n",
    "            explainer.save(f, model_saver='.save', masker_saver='.save')\n",
    "\n",
    "    # Get SHAP values\n",
    "    print('-'*20)\n",
    "    print(f'Getting SHAP values for {path_suffix}...')\n",
    "    print('-'*20)\n",
    "    if shap_full:\n",
    "        shap_values_path = f'{done_xy_save_path}{method} SHAP Values Full{path_suffix}.pkl'\n",
    "    else:\n",
    "        shap_values_path = f'{done_xy_save_path}{method} SHAP Values{path_suffix}.pkl'\n",
    "\n",
    "    if os.path.exists(shap_values_path) and os.path.getsize(shap_values_path) != 0 and make_new_explainer is False:\n",
    "        print('Loading Existing SHAP values...')\n",
    "        with open(shap_values_path, 'rb') as f:\n",
    "            shap_values = pickle.load(f)\n",
    "    else:\n",
    "        print('Calculating New SHAP values...')\n",
    "        if shap_full:\n",
    "            X_test = np.delete(X_test, np.argwhere(X_test[~pd.isnull(X_test)]=='CXD, e'))\n",
    "            if sample_size != len(X_test):\n",
    "                X = np.random.choice(X_test, sample_size, replace=False)\n",
    "        else:\n",
    "            X = get_example_text_for_shap(X_train, X_test, X_val, print_enabled=print_enabled)\n",
    "\n",
    "        # Get shap values from explainer\n",
    "        shap_values = explainer(X)\n",
    "        with open(shap_values_path, 'wb') as f:\n",
    "            pickle.dump(shap_values, f)\n",
    "    print('-'*20)\n",
    "    print(f'Done calculating SHAP values for {path_suffix}!')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Save\n",
    "    print(f'Saving SHAP values for {path_suffix}...')\n",
    "    print('-'*20)\n",
    "    if not shap_full:\n",
    "        save_path = f'{plot_save_path}{method} {col} - SHAP Plot - {vectorizer_name} + {classifier_name}.html'\n",
    "        with open(save_path, 'w') as f:\n",
    "            f.write(shap.plots.text(shap_values, display=False))\n",
    "\n",
    "    # Save SHAP values dict\n",
    "    shap_values_dict[col][classifier_name] = shap_values\n",
    "\n",
    "    # Save SHAP values dict\n",
    "    print(f'Saving SHAP values dict for {path_suffix}...')\n",
    "    print('='*20)\n",
    "    if shap_full:\n",
    "        shap_values_dict_path = f'{done_xy_save_path}{method} SHAP Values Dict Full{path_suffix}.pkl'\n",
    "    else:\n",
    "        shap_values_dict_path = f'{done_xy_save_path}{method} SHAP Values Dict{path_suffix}.pkl'\n",
    "\n",
    "    with open(shap_values_dict_path, 'wb') as f:\n",
    "        pickle.dump(shap_values_dict, f)\n",
    "\n",
    "    return shap_values, explainer, shap_values_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e938050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_shap_values_and_features(col, vectorizer_name, classifier_name, path_suffix: str = None, print_enabled: bool = None, shap_full: bool = None, remove_stopwords: bool = None, make_new_df_shap_values_and_features: bool = None):\n",
    "\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {str(col)} - {vectorizer_name} + {classifier_name}'\n",
    "    if print_enabled is None:\n",
    "        print_enabled = False\n",
    "    if shap_full is None:\n",
    "        shap_full = True\n",
    "    if remove_stopwords is None:\n",
    "        remove_stopwords = False\n",
    "    if make_new_df_shap_values_and_features is None:\n",
    "        make_new_df_shap_values_and_features = False\n",
    "\n",
    "    print('-'*20)\n",
    "    print(f'shap_full set to {shap_full}')\n",
    "    print('-'*20)\n",
    "    print(f'remove_stopwords set to {remove_stopwords}')\n",
    "    print('-'*20)\n",
    "    print(f'make_new_df_shap_values_and_features set to {make_new_df_shap_values_and_features}')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Get SHAP values dict\n",
    "    print(f'Getting SHAP values dict for {path_suffix}...')\n",
    "    print('='*20)\n",
    "    if shap_full:\n",
    "        shap_values_dict_path = f'{done_xy_save_path}{method} SHAP Values Dict Full{path_suffix}.pkl'\n",
    "        df_shap_values_and_features_path = f'{done_xy_save_path}{method} df_shap_values_and_features Full{path_suffix}'\n",
    "    else:\n",
    "        shap_values_dict_path = f'{done_xy_save_path}{method} SHAP Values Dict{path_suffix}.pkl'\n",
    "        df_shap_values_and_features_path = f'{done_xy_save_path}{method} df_shap_values_and_features{path_suffix}'\n",
    "\n",
    "    if not os.path.exists(f'{df_shap_values_and_features_path}.pkl') or make_new_df_shap_values_and_features:\n",
    "\n",
    "        print(f'Loading SHAP values dict from {path_suffix}...')\n",
    "        print('-'*20)\n",
    "        with open(shap_values_dict_path, 'rb') as f:\n",
    "            shap_values_dict = pickle.load(f)\n",
    "\n",
    "        shap_values = shap_values_dict[col][classifier_name]\n",
    "\n",
    "        print(f'Making df_shap_values_and_features for {path_suffix}...')\n",
    "        print('-'*20)\n",
    "\n",
    "        df_shap_values_and_features = pd.DataFrame(columns=[f'{col} Features', f'{classifier_name} SHAP Values'])\n",
    "\n",
    "        for i in range(len(shap_values)):\n",
    "            df_shap_values_and_features = pd.concat(\n",
    "                [\n",
    "                    df_shap_values_and_features,\n",
    "                    pd.DataFrame(\n",
    "                        {\n",
    "                            f'{col} Features': shap_values.data[i],\n",
    "                            f'{classifier_name} SHAP Values': shap_values.values[i][:, -1],\n",
    "                        }\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        df_shap_values_and_features = df_shap_values_and_features.groupby(f'{col} Features').mean().reset_index().sort_values(by=f'{classifier_name} SHAP Values', ascending=False).rename(columns={'Features': f'{col} Features'}).reset_index(drop=True)\n",
    "\n",
    "        if remove_stopwords:\n",
    "            print(f'Removing stopwords and punctuations from {col} Features...')\n",
    "            print('-'*20)\n",
    "            df_shap_values_and_features = df_shap_values_and_features.loc[\n",
    "                ~df_shap_values_and_features[f'{col} Features'].str.strip().isin(list(stop_words))\n",
    "                & ~df_shap_values_and_features[f'{col} Features'].str.strip().isin(punctuations)\n",
    "                & ~df_shap_values_and_features[f'{col} Features'].isin(['', ' '])\n",
    "                & df_shap_values_and_features[f'{col} Features'].str.strip().str.isalpha()\n",
    "                & df_shap_values_and_features[f'{col} Features'].str.strip().str.len() != 0\n",
    "            ]\n",
    "\n",
    "        print(f'Done making df_shap_values_and_features for {path_suffix}!')\n",
    "        print('-'*20)\n",
    "\n",
    "        print(f'Saving df_shap_values_and_features for {path_suffix}...')\n",
    "        df_shap_values_and_features.to_pickle(f'{df_shap_values_and_features_path}.pkl')\n",
    "        df_shap_values_and_features.to_csv(f'{df_shap_values_and_features_path}.csv')\n",
    "        print('='*20)\n",
    "\n",
    "    else:\n",
    "        print(f'df_shap_values_and_features already exists. Loading df_shap_values_and_features for {path_suffix}...')\n",
    "        print('-'*20)\n",
    "        df_shap_values_and_features = pd.read_pickle(f'{df_shap_values_and_features_path}.pkl')\n",
    "        print(f'Done loading df_shap_values_and_features for {path_suffix}!')\n",
    "        print('='*20)\n",
    "\n",
    "    return df_shap_values_and_features\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "707bd733",
   "metadata": {},
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe77e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print('#'*40)\n",
    "print('Starting!')\n",
    "print('#'*40)\n",
    "\n",
    "analysis_columns = ['Warmth', 'Competence']\n",
    "text_col = 'Job Description spacy_sentencized'\n",
    "\n",
    "# Get existing estimators\n",
    "estimator_names_list = get_existing_files()\n",
    "done_estimators = glob.glob(f'{done_xy_save_path}*')\n",
    "done_files = [\n",
    "    'df_train_data', 'df_test_data', 'df_val_data', 'eval_metrics_dict', 'test_metrics_dict'\n",
    "]\n",
    "\n",
    "# Identify cols, vectorizers and classifiers\n",
    "for estimators_file in tqdm.tqdm(glob.glob(f'{results_save_path}{method} Estimator - *.model')):\n",
    "    assert f'{method} Estimator - ' in estimators_file, f'Estimators file name {estimators_file} does not contain {method} Estimator - '\n",
    "    estimate_file_name = estimators_file.split(f'{method} Estimator - ')[-1]\n",
    "\n",
    "    # Skip fitted estimators\n",
    "    fitted_estimators = [fitted_estimators_file.split(f'{method} Fitted Estimator - ')[-1] for fitted_estimators_file in tqdm.tqdm(glob.glob(f'{results_save_path}{method} Fitted Estimator - *.pkl'))]\n",
    "    if estimate_file_name in fitted_estimators and skip_fitted_estimators is True:\n",
    "        print(f'Estimator {estimate_file_name} already fitted! Skipping...')\n",
    "        continue\n",
    "\n",
    "    # Specify col, vectorizer and classifier\n",
    "    col = estimators_file.split(f'{method} Estimator - ')[-1].split(' - ')[0]\n",
    "    vectorizer_name = estimators_file.split(f'{col} - ')[-1].split(' + ')[0]\n",
    "    classifier_name = estimators_file.split(f'{vectorizer_name} + ')[-1].split(' (Save_protocol=')[0]\n",
    "\n",
    "    if classifier_name in transformers_pipe.keys():\n",
    "        model = transformers_pipe[classifier_name]['model']\n",
    "        tokenizer = transformers_pipe[classifier_name]['tokenizer']\n",
    "        config = transformers_pipe[classifier_name]['config']\n",
    "        protocol = int(estimators_file.split(f'{vectorizer_name} + ')[-1].split(' (Save_protocol=')[-1].split(').model')[0])\n",
    "        with open(f'{done_xy_save_path}{method} training_args_dict - {col} - {vectorizer_name} + {classifier_name}.json', 'r') as f:\n",
    "            training_args_dict = json.load(f)\n",
    "        output_dir = training_args_dict['output_dir'] = estimators_file\n",
    "\n",
    "        # Load Table DF\n",
    "        df_metrics = make_df_metrics(\n",
    "            vectorizers_pipe=vectorizers_pipe, classifiers_pipe=classifiers_pipe, transformers_pipe=transformers_pipe,\n",
    "            metrics_list=metrics_dict,\n",
    "            col=col, vectorizer_name=vectorizer_name, classifier_name=classifier_name, protocol=protocol\n",
    "        )\n",
    "        print('~'*20)\n",
    "        print(f'Loading data for {col} - {vectorizer_name} + {classifier_name}')\n",
    "        print('~'*20)\n",
    "        # Load X, y and estimator\n",
    "        (\n",
    "            X_train, y_train, train_dataset,\n",
    "            X_test, y_test, test_dataset, y_test_pred, y_test_pred_prob,\n",
    "            X_val, y_val, val_dataset, y_val_pred, y_val_pred_prob,\n",
    "            train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "            test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict,\n",
    "            saved_estimator, tokenizer, config, eval_metrics_dict, test_metrics_dict,\n",
    "        ) = load_Xy_estimator(\n",
    "            model, tokenizer, config,\n",
    "            col, vectorizer_name, classifier_name, protocol,\n",
    "        )\n",
    "\n",
    "        if hasattr(saved_estimator, 'to'):\n",
    "            saved_estimator = saved_estimator.to(device)\n",
    "\n",
    "        print('-'*20)\n",
    "        print(f'{\"=\"*30} EVALUATING DATASET OF LENGTH {len(X_train)+len(X_test)+len(X_val)} ON {col.upper()} {\"=\"*30}')\n",
    "        print('-'*20)\n",
    "        print(\n",
    "            f'Testing Classification Report:\\n{(train_report:=metrics.classification_report(y_test, y_test_pred, labels=np.unique(y_test_pred), zero_division=0))}\\n'\n",
    "        )\n",
    "\n",
    "        # Examine predictions\n",
    "        examine_predictions(\n",
    "            X_test, y_test, y_test_pred, col\n",
    "        )\n",
    "        print('='*20)\n",
    "\n",
    "        # Train and Test Confusion Matrix\n",
    "        print('='*20)\n",
    "        print('Evaluation and Test Confusion Matrix:\\n')\n",
    "        close_plots(plt)\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        fig.suptitle(f'{col} - Evaluation and Test Confusion Matrix - {vectorizer_name} + {classifier_name}')\n",
    "        for ax in axs:\n",
    "            ax.set_aspect('equal')\n",
    "        val_cm = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "            y_val, y_val_pred, normalize='true', ax=axs[0], cmap=plt.cm.Grays, colorbar=False\n",
    "        )\n",
    "        val_cm.ax_.set_title('Evaluation Data')\n",
    "        test_cm = metrics.ConfusionMatrixDisplay.from_predictions(\n",
    "            y_test, y_test_pred, normalize='true', ax=axs[1], cmap=plt.cm.Grays, colorbar=False\n",
    "        )\n",
    "        test_cm.ax_.set_title('Testing Data')\n",
    "        plt.tight_layout()\n",
    "        for image_save_format in tqdm.tqdm(['png', 'svg']):\n",
    "            save_path = f'{plot_save_path}{method} {col} - Evaluation and Test Confusion Matrix - {vectorizer_name} + {classifier_name}.{image_save_format}'\n",
    "            try:\n",
    "                print(f'Evaluation and Test Confusion Matrix plot as {image_save_format}')\n",
    "                fig.savefig(\n",
    "                    save_path, format=image_save_format, dpi=3000, bbox_inches='tight'\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "        show_and_close_plots(plt)\n",
    "        print('='*20)\n",
    "\n",
    "        if evaluate_estimator_on_concat:\n",
    "            # Fit estimator\n",
    "            print('~'*20)\n",
    "            print('Fitting best params to estimator')\n",
    "            X = np.concatenate((X_test, X_val), axis=0)\n",
    "            y = np.concatenate((y_test, y_val), axis=0)\n",
    "        else:\n",
    "            X = X_test\n",
    "            y = y_test\n",
    "\n",
    "        X_encodings = tokenizer(\n",
    "            X.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
    "        ).to(device)\n",
    "        dataset = ToDataset(X_encodings, y)\n",
    "\n",
    "        # Accelerate model\n",
    "        (\n",
    "            saved_estimator, tokenizer, dataset\n",
    "        ) = accelerator.prepare(\n",
    "            saved_estimator, tokenizer, dataset\n",
    "        )\n",
    "        saved_estimator.eval()\n",
    "\n",
    "        # Initalize trainer\n",
    "        estimator = Trainer(\n",
    "            model=saved_estimator,\n",
    "            tokenizer=tokenizer,\n",
    "            args=TrainingArguments(**training_args_dict),\n",
    "            preprocess_logits_for_metrics=preprocess_logits_for_metrics_y_pred_prob,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)], # [TensorBoardCallback()]\n",
    "            data_collator=transformers.DataCollatorWithPadding(tokenizer),\n",
    "        )\n",
    "\n",
    "        # Get prediction results\n",
    "        if estimator.place_model_on_device:\n",
    "            estimator.model.to(device)\n",
    "        y_pred_logits, y_labels, metrics_dict = estimator.predict(dataset)\n",
    "        y_pred = metrics_dict.pop('test_y_pred')\n",
    "        y_pred_prob = metrics_dict.pop('test_y_pred_prob')\n",
    "        metrics_dict = clean_metrics_dict(metrics_dict, list(metrics_dict.keys())[0].split('_')[0])\n",
    "        print('Done predicting!')\n",
    "        print('Saving fitted estimator')\n",
    "        save_fitted_estimator(estimator, metrics_dict, col, vectorizer_name, classifier_name, protocol)\n",
    "        print('Fitted estimator saved')\n",
    "        print('~'*20)\n",
    "\n",
    "        # Evaluate Model\n",
    "        df_metrics = evaluation(\n",
    "            y_labels, y_pred,\n",
    "            metrics_dict, df_metrics,\n",
    "            col, vectorizer_name, classifier_name, plot_enabled=True, print_enabled=True\n",
    "        )\n",
    "\n",
    "        # Confirmatory Regression\n",
    "        prob_confirmatory_tests(y_labels, y_pred)\n",
    "        prob_confirmatory_tests(y_pred, y_pred_prob)\n",
    "\n",
    "        # Save Vectorizer, Selector, and Classifier\n",
    "        save_table(df_metrics, col, vectorizer_name, classifier_name, protocol)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fda781",
   "metadata": {},
   "source": [
    "## Evaluate df_metrics and get final estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f29616",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aeabc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tqdm.tqdm(analysis_columns):\n",
    "    print('='*20)\n",
    "    print(f'Metrics for {col}:')\n",
    "    for metric in metrics_dict.keys():\n",
    "        if metric in df_metrics[col].columns and not is_string_dtype(df_metrics[col][metric]):\n",
    "            print(f'Highest {metric} for {col} is {df_metrics[col][metric].idxmax()[0]}: {df_metrics[col][metric].max():.3f}')\n",
    "            print('-'*20)\n",
    "    print('='*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5305d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmth_classifier = 'GPT2ForSequenceClassification'\n",
    "competence_classifier = 'BertForSequenceClassification'\n",
    "\n",
    "final_estimators_dict = {\n",
    "    'Warmth': {\n",
    "        'classifier_name': warmth_classifier,\n",
    "        'vectorizer_name': ''.join(transformers_pipe[warmth_classifier][\"model_name\"].split('-')).upper(),\n",
    "    },\n",
    "    'Competence': {\n",
    "        'classifier_name': competence_classifier,\n",
    "        'vectorizer_name': ''.join(transformers_pipe[competence_classifier][\"model_name\"].split('-')).upper(),\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(f'{done_xy_save_path}{method} final_estimators_dict.json', 'w') as f:\n",
    "    json.dump(final_estimators_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a7aaa0",
   "metadata": {},
   "source": [
    "## SHAP Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "accfb0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fitted Transformer BertForSequenceClassification from pretrained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading Fitted Transformer BertForSequenceClassification from pretrained!\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Loading data for Competence - BERTBASEUNCASED + BertForSequenceClassification\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Loading Xy from previous for Competence...\n",
      "Loading eval_metrics_dict\n",
      "Loading df_test_data\n",
      "Loading test_metrics_dict\n",
      "Loading df_val_data\n",
      "Loading df_train_data\n",
      "Loading Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading Xy and estimator!\n",
      "['eval_metrics_dict', 'df_test_data', 'test_metrics_dict', 'df_val_data', 'df_train_data']\n",
      "====================\n",
      "--------------------\n",
      "shap_full set to True\n",
      "--------------------\n",
      "make_new_explainer set to True\n",
      "--------------------\n",
      "sample_size set to 100\n",
      "--------------------\n",
      "====================\n",
      "Calculating SHAP values for  - Competence - BERTBASEUNCASED + BertForSequenceClassification...\n",
      "--------------------\n",
      "--------------------\n",
      "Training SHAP explainer for  - Competence - BERTBASEUNCASED + BertForSequenceClassification...\n",
      "--------------------\n",
      "Training New SHAP explainer...\n",
      "--------------------\n",
      "Getting SHAP values for  - Competence - BERTBASEUNCASED + BertForSequenceClassification...\n",
      "--------------------\n",
      "Calculating New SHAP values...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fed70a941fb4530a836c58b5b9464ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c433f4107a437e8e3c6bf8c4edaa68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65660abc2fa4d598224a5dc09d590e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295169599a3a43b5934cd924e92998ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e302d11b144e4a57801f2daa3563b277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b92758e3ca472ab7057f166dc68734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24147bb052ee4d3795ab9f8b089b94a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f75178a832d4cf593d24174bb8a8107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d040396cb64d63a82ef74e5fee396b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315f41afe19d41c29cc1e8fff4287232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba0bd7f64f7459cb4ab0b2cb8797cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967bd376f277454fa69a486cff698c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee8feb1eaa74fb493ec4560ef3b4271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b627bfc2db4103b201164a31ee943c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fa434262924819a0a90b339d292ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87943fe5a63468fa9eaa3f77739ea92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2274f257c74109a8a877d2f2f8cff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45194926c1245d991b5dca8ddf4ff51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de287d2027f4f36ae02c616313b8ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9c82a09e164f8680114b4a416e53a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccfdf1648f3b4438a6b173460c51d327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cbfa71e9f441648ef3f7fa05c109a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b428302eca4858903dcbbfa021decb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3b91a8a3dc4a38b2b92ec102ded746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e58fa7cc74421781063d3f6d40df6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df150bc62ac47538d00f7f1eeb8ff7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7f656178684f4b9d56d0e76b466640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9c6f0628e54fdb8a18b3b688e4e332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c2c7f610fd479f96a9ec6feef7fd7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cf7ec2cc0946aab0f3ac840952d130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4510eef28bbc4099bc1485de1827d586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0289b2cb3a45419789b33400dbc07939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491f95bd3ec94e5bbb4ec2e144bd3861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61eecf34c1fe4b57b645359cf03589f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530a3c8ce1684bfbb170b38b5a70f17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83071bfafb8d417bb46486d2c9650497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16d2f5f17c94ff7ad559045f642dd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b58eb0f12441bfbae4d093be22a8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8ddfc19f2a485bb640a1066f378236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46018552f28041d099705e20617239cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b36ac812bd49559175dae0302bad46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d323f1cc4c4844728cdc200791729db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d539b9d2cc0f4ed980328df34afb57c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e32964782f54340b2f758e537451050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620962fbde0a4837834e2c009b4ae218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2128d07621fd44efba16f7ad4625658c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816614a7c71f4b808ece74fc135f1a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89e604f81a64aef8092d0e2dbbf940c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/210 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24dbe06449b8416cb1b1d292c427ce94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63fccfafa4446f5878ee3bd74ecf35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5b5132917845048dd64e0184b24851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d404c9ba6d74a22a6c205cf9d466586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e4540ef52c4f4e8f95217291b3f31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9f927ae708415688070d66bbf4cf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875124da6dc74d718e5139522f63c6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bee43260c4420fb234e3034f4a3686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f60f8a5a8564051954e1b113030653c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd8c0d505c74497b8df1c50773cca7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b703a767c542e3a1e87ba3056764d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b6a8016d5c4620be0542467de35756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639ac89078134b8db99d8ad51445e6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5626a60c7cad4f22b1f9a4c13a522589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968dcf7d72de4ea29e796cbc620d1454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e8d71703c8487e9f9711a5e8dc9325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17d3b4494734db7aade46c29aaf0384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db2b416f7854342a83ee72d7e73048d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b0fc0f45544a5e8173585c4a7d4498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88994f76e602496a82dbb743417e58ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e371112738d401c88eed9b08b334f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a3db174e534bffb57d28ac06c479da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5706b6e94ee249e5bf7415e8167fab46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6805b6c634ec410fb398be75a0547b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d6564436e2489984713a6d38114292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5d4fb1823a4986b99a8b9f0f5bb4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0be9a0ae7a44beb047e251691335e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8577e09a64f40709a10428e1ac774ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fd1499370a44b8974c240ada149383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1837fb8f9516408085095e7c0e38944e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752b0579cce747f1bd8ae8e132941132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ada2c560264f7997691f2b86b5ac7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c310edf2004bd49bb5cbf3b37ad259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33df405909114969b4d92ab6a47e38af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf2dfba0fc545c7b84eb23380111799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7792a0fdbf4144e88e0df41db78e18e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fece117b17c4790ae8ad50bbe6e31de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3893f8bd1a6447a97689d05996fd253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30eba5b88bd4c9b9fc8e6456c4de7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f438deff61754296b57a602becd5f684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PartitionExplainer explainer: 101it [54:32, 32.73s/it]\n",
      " 50%|█████     | 1/2 [54:35<54:35, 3275.71s/it]The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Done calculating SHAP values for  - Competence - BERTBASEUNCASED + BertForSequenceClassification!\n",
      "--------------------\n",
      "Saving SHAP values for  - Competence - BERTBASEUNCASED + BertForSequenceClassification...\n",
      "--------------------\n",
      "Saving SHAP values dict for  - Competence - BERTBASEUNCASED + BertForSequenceClassification...\n",
      "====================\n",
      "--------------------\n",
      "shap_full set to True\n",
      "--------------------\n",
      "remove_stopwords set to True\n",
      "--------------------\n",
      "make_new_df_shap_values_and_features set to True\n",
      "--------------------\n",
      "Getting SHAP values dict for  - Competence - BERTBASEUNCASED + BertForSequenceClassification...\n",
      "====================\n",
      "Loading SHAP values dict from  - Competence - BERTBASEUNCASED + BertForSequenceClassification...\n",
      "--------------------\n",
      "Making df_shap_values_and_features for  - Competence - BERTBASEUNCASED + BertForSequenceClassification...\n",
      "--------------------\n",
      "Removing stopwords and punctuations from Competence Features...\n",
      "--------------------\n",
      "Done making df_shap_values_and_features for  - Competence - BERTBASEUNCASED + BertForSequenceClassification!\n",
      "--------------------\n",
      "Saving df_shap_values_and_features for  - Competence - BERTBASEUNCASED + BertForSequenceClassification...\n",
      "====================\n",
      "10 Highest SHAP Values and Features for Competence - BERTBASEUNCASED + BertForSequenceClassification:\n",
      "--------------------\n",
      "   Competence Features  BertForSequenceClassification SHAP Values\n",
      "0             Excel                      4.225                   \n",
      "2       initiatives                      3.848                   \n",
      "3           fastest                      3.847                   \n",
      "6             rapid                      3.002                   \n",
      "7           Ability                      2.953                   \n",
      "8           designs                      2.933                   \n",
      "9     comprehensive                      2.929                   \n",
      "11            Serve                      2.833                   \n",
      "12            style                      2.723                   \n",
      "13          Develop                      2.718                   \n",
      "--------------------\n",
      "Loading Fitted Transformer GPT2ForSequenceClassification from pretrained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading Fitted Transformer GPT2ForSequenceClassification from pretrained!\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Loading data for Warmth - GPT2 + GPT2ForSequenceClassification\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "Loading Xy from previous for Warmth...\n",
      "Loading eval_metrics_dict\n",
      "Loading df_test_data\n",
      "Loading df_val_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading df_train_data\n",
      "Loading test_metrics_dict\n",
      "Loading Estimator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading Xy and estimator!\n",
      "['eval_metrics_dict', 'df_test_data', 'df_val_data', 'df_train_data', 'test_metrics_dict']\n",
      "====================\n",
      "--------------------\n",
      "shap_full set to True\n",
      "--------------------\n",
      "make_new_explainer set to True\n",
      "--------------------\n",
      "sample_size set to 100\n",
      "--------------------\n",
      "====================\n",
      "Calculating SHAP values for  - Warmth - GPT2 + GPT2ForSequenceClassification...\n",
      "--------------------\n",
      "--------------------\n",
      "Training SHAP explainer for  - Warmth - GPT2 + GPT2ForSequenceClassification...\n",
      "--------------------\n",
      "Training New SHAP explainer...\n",
      "--------------------\n",
      "Getting SHAP values for  - Warmth - GPT2 + GPT2ForSequenceClassification...\n",
      "--------------------\n",
      "Calculating New SHAP values...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83ed2aba99d414d850fff13123d34c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a635f39e6e9f4c87816933755e11c5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f52645b3d8b451398f2551c4ae33da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6703f2ce02344d7883d0a1b59e1d962a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333bcc57ac4d4963a02c614c5019453e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d300d9ed45194fde8b822ada797e0fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bacab55f044075a4c5b5906d82280a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e3a02ed07a4a65b22766fe39fee867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f4d986ae804391a6ab6b8a6122d488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2604a01fef4cf5ae06d98e5192c3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b75b86187d4e6eb8507ecceb42f149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c3b3d1ed534806b02f93b5e4fac7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e0c7fa1d23406fb1f82aba0bb69fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ebbdfee6b248f59f457ae5918e8490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cb9466d36f4f14a637c68b754e1cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8637d4616164b8b9b324effa60ca84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e9167b8dfe4367ac9060248558a41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0a1d653e9f4842860b0c33e2fde860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "shap_values_dict = defaultdict(dict)\n",
    "shap_full = True\n",
    "\n",
    "for col in tqdm.tqdm(analysis_columns):\n",
    "    final_estimators_dict[col]['path_suffix'] = path_suffix = f' - {col} - {(vectorizer_name := final_estimators_dict[col][\"vectorizer_name\"])} + {(classifier_name := final_estimators_dict[col][\"classifier_name\"])} (Save_protocol={protocol})'\n",
    "    model = transformers_pipe[classifier_name]['model']\n",
    "    tokenizer = transformers_pipe[classifier_name]['tokenizer']\n",
    "    config = transformers_pipe[classifier_name]['config']\n",
    "\n",
    "    print(f'Loading Fitted Transformer {classifier_name} from pretrained.')\n",
    "    estimator_dir = f'{results_save_path}{method} Fitted Estimator{path_suffix}.model'\n",
    "    fitted_estimator = model.from_pretrained(estimator_dir, trust_remote_code=True)\n",
    "    if hasattr(fitted_estimator, 'to'):\n",
    "        fitted_estimator = fitted_estimator.to(device)\n",
    "    tokenizer = tokenizer.from_pretrained(estimator_dir, trust_remote_code=True)\n",
    "    config = config.from_pretrained(f'{estimator_dir}/config.json', trust_remote_code=True)\n",
    "    print(f'Done loading Fitted Transformer {classifier_name} from pretrained!')\n",
    "\n",
    "    print('~'*20)\n",
    "    print(f'Loading data for {col} - {vectorizer_name} + {classifier_name}')\n",
    "    print('~'*20)\n",
    "    # Load X, y and estimator\n",
    "    (\n",
    "        X_train, y_train, train_dataset,\n",
    "        X_test, y_test, test_dataset, y_test_pred, y_test_pred_prob,\n",
    "        X_val, y_val, val_dataset, y_val_pred, y_val_pred_prob,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict,\n",
    "        saved_estimator, tokenizer, config, eval_metrics_dict, test_metrics_dict,\n",
    "    ) = load_Xy_estimator(\n",
    "        model, tokenizer, config,\n",
    "        col, vectorizer_name, classifier_name, protocol,\n",
    "    )\n",
    "\n",
    "    if hasattr(saved_estimator, 'to'):\n",
    "        saved_estimator = saved_estimator.to(device)\n",
    "\n",
    "    # Get SHAP values\n",
    "    shap_values, explainer, shap_values_dict = shap_score_and_visualize(\n",
    "        col, X_train, X_test, X_val, fitted_estimator, tokenizer, vectorizer_name, classifier_name, shap_values_dict, print_enabled=True, shap_full=shap_full, make_new_explainer=True, sample_size=100\n",
    "    )\n",
    "\n",
    "    # Get SHAP dict\n",
    "    df_shap_values_and_features = get_df_shap_values_and_features(col, vectorizer_name, classifier_name, shap_full=shap_full, remove_stopwords=True, make_new_df_shap_values_and_features=True)\n",
    "\n",
    "    print(f'10 Highest SHAP Values and Features for {col} - {vectorizer_name} + {classifier_name}:')\n",
    "    print('-'*20)\n",
    "    print(df_shap_values_and_features.head(10))\n",
    "    print('-'*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b20c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Automating_Equity1_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
