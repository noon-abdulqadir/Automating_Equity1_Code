{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "50d4c434",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "if code_dir_name not in str(Path.cwd()).split('/')[-1]:\n",
                "    for _ in range(5):\n",
                "\n",
                "        parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "        if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "            code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "            if code_dir is not None:\n",
                "                break\n",
                "else:\n",
                "    code_dir = str(Path.cwd())\n",
                "sys.path.append(code_dir)\n",
                "\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fef3f604",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from setup_module.estimators_get_pipe import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from setup_module.forestIV import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e3936e59",
            "metadata": {},
            "source": [
                "### Set variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3b9d1a7b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Variables\n",
                "method = 'Supervised'\n",
                "classifiers_type = 'all'\n",
                "if classifiers_type == 'nonlinear':\n",
                "    classifiers_pipe = classifiers_pipe_nonlinear\n",
                "elif classifiers_type == 'linear':\n",
                "    classifiers_pipe = classifiers_pipe_linear\n",
                "elif classifiers_type == 'ensemble':\n",
                "    classifiers_pipe = classifiers_pipe_ensemble\n",
                "elif classifiers_type == 'all':\n",
                "    classifiers_pipe = classifiers_pipe\n",
                "\n",
                "results_save_path = f'{models_save_path}{method} Results/'\n",
                "with open(f'{data_dir}{method}_results_save_path.txt', 'w') as f:\n",
                "    f.write(results_save_path)\n",
                "if not os.path.exists(results_save_path):\n",
                "    os.makedirs(results_save_path)\n",
                "done_xy_save_path = f'{results_save_path}Search+Xy/'\n",
                "with open(f'{data_dir}{method}_done_xy_save_path.txt', 'w') as f:\n",
                "    f.write(done_xy_save_path)\n",
                "if not os.path.exists(done_xy_save_path):\n",
                "    os.makedirs(done_xy_save_path)\n",
                "\n",
                "t = time.time()\n",
                "n_jobs = -1\n",
                "n_splits = 10\n",
                "n_repeats = 3\n",
                "random_state = 42\n",
                "refit = True\n",
                "class_weight = 'balanced'\n",
                "cv = RepeatedStratifiedKFold(\n",
                "    n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
                ")\n",
                "scoring = 'recall'\n",
                "scores = [\n",
                "    'recall', 'accuracy', 'f1', 'roc_auc',\n",
                "    'explained_variance', 'matthews_corrcoef'\n",
                "]\n",
                "scorers = {\n",
                "    'precision_score': make_scorer(precision_score, zero_division=0),\n",
                "    'recall_score': make_scorer(recall_score, zero_division=0),\n",
                "    'accuracy_score': make_scorer(accuracy_score, zero_division=0),\n",
                "}\n",
                "analysis_columns = ['Warmth', 'Competence']\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "metrics_dict = {\n",
                "    f'{scoring.title()} Best Score': np.nan,\n",
                "    f'{scoring.title()} Best Threshold': np.nan,\n",
                "    'Train - Mean Cross Validation Score': np.nan,\n",
                "    f'Train - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    f'Train - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Test - Mean Cross Validation Score': np.nan,\n",
                "    f'Test - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    f'Test - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Explained Variance': np.nan,\n",
                "    'Accuracy': np.nan,\n",
                "    'Balanced Accuracy': np.nan,\n",
                "    'Precision': np.nan,\n",
                "    'Average Precision': np.nan,\n",
                "    'Recall': np.nan,\n",
                "    'F1-score': np.nan,\n",
                "    'Matthews Correlation Coefficient': np.nan,\n",
                "    'Brier Score': np.nan,\n",
                "    'Fowlkes–Mallows Index': np.nan,\n",
                "    'R2 Score': np.nan,\n",
                "    'ROC': np.nan,\n",
                "    'AUC': np.nan,\n",
                "    'Log Loss/Cross Entropy': np.nan,\n",
                "    'Cohen’s Kappa': np.nan,\n",
                "    'Geometric Mean': np.nan,\n",
                "    'Classification Report': np.nan,\n",
                "    'Imbalanced Classification Report': np.nan,\n",
                "    'Confusion Matrix': np.nan,\n",
                "    'Normalized Confusion Matrix': np.nan,\n",
                "}\n",
                "\n",
                "# Transformer variables\n",
                "max_length = 512\n",
                "returned_tensor = 'pt'\n",
                "cpu_counts = torch.multiprocessing.cpu_count()\n",
                "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available(\n",
                ") else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "device_name = str(device.type)\n",
                "print(f'Using {device_name.upper()}')\n",
                "# Set random seed\n",
                "random_state = 42\n",
                "random.seed(random_state)\n",
                "np.random.seed(random_state)\n",
                "torch.manual_seed(random_state)\n",
                "cores = multiprocessing.cpu_count()\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "55afc383",
            "metadata": {},
            "source": [
                "### Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f15e44f8",
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_df_full_summary_excel(\n",
                "    df_full_summary,\n",
                "    title,\n",
                "    text_to_add_list,\n",
                "    file_save_path,\n",
                "    sheet_name=None,\n",
                "    startrow=None,\n",
                "    startcol=None,\n",
                "):\n",
                "    if sheet_name is None:\n",
                "        sheet_name = 'All'\n",
                "    if startrow is None:\n",
                "        startrow = 1\n",
                "    if startcol is None:\n",
                "        startcol = 1\n",
                "\n",
                "    # Define last rows and cols locs\n",
                "    header_range = 1\n",
                "    endrow = startrow + header_range + df_full_summary.shape[0]\n",
                "    endcol = startcol + df_full_summary.shape[1]\n",
                "\n",
                "    # Remove NAs\n",
                "    df_full_summary = df_full_summary.fillna('')\n",
                "\n",
                "    # Write\n",
                "    writer = pd.ExcelWriter(f'{file_save_path}.xlsx')\n",
                "    df_full_summary.to_excel(writer, sheet_name=sheet_name, merge_cells=True, startrow=startrow, startcol=startcol)\n",
                "    workbook  = writer.book\n",
                "    worksheet = writer.sheets[sheet_name]\n",
                "    worksheet.set_column(startrow, 1, None, None, {'hidden': True}) # hide the index column\n",
                "\n",
                "    # Title\n",
                "    worksheet.merge_range(1, startcol, 1, endcol, title, workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'left', 'top': True, 'bottom': True, 'left': False, 'right': False}))\n",
                "\n",
                "    # Main body\n",
                "    body_max_row_idx, body_max_col_idx = df_full_summary.shape\n",
                "\n",
                "    for c, r in tqdm_product(range(body_max_col_idx), range(body_max_row_idx)):\n",
                "        row_to_write = startrow + header_range + r\n",
                "        col_to_write = startcol + 1 + c # 1 is for index\n",
                "        body_formats = {'num_format': '0.00', 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'text_wrap': True, 'left': False, 'right': False}\n",
                "\n",
                "        if r == 0:\n",
                "            body_formats |= {'top': True, 'bottom': True, 'left': False, 'right': False}\n",
                "            worksheet.set_column(col_to_write, col_to_write, 10)\n",
                "\n",
                "        if r == body_max_row_idx-1:\n",
                "            body_formats |= {'bottom': True}\n",
                "\n",
                "        if c == 0:\n",
                "            body_formats |= {'align': 'left'}\n",
                "            worksheet.set_column(col_to_write, col_to_write, 15)\n",
                "\n",
                "        worksheet.write(row_to_write, col_to_write, df_full_summary.iloc[r, c], workbook.add_format(body_formats))\n",
                "\n",
                "    # Add Note\n",
                "    note_format = {'italic': True, 'font_name': 'Times New Roman', 'font_size': 10, 'font_color': 'black', 'align': 'left', 'left': False, 'right': False}\n",
                "    worksheet.merge_range(endrow, startcol, endrow, endcol, 'Note.', workbook.add_format(note_format))\n",
                "    # Add text\n",
                "    for i, text in enumerate(text_to_add_list):\n",
                "        worksheet.merge_range(endrow + 1 + i , startcol, endrow + 1 + i, endcol, text, workbook.add_format(note_format))\n",
                "\n",
                "    writer.close()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96e6d325",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_full_report(\n",
                "    results, dv, dvs_name, dv_type,\n",
                "    regression_info_dict=None, regressor_order=None, text_to_add_list=None, title=None, model_names=None\n",
                "):\n",
                "    '''\n",
                "    Make a full report for a regression analysis.\n",
                "    results: statsmodels regression results object or list of results objects\n",
                "    dv: str, dependent variable name\n",
                "    '''\n",
                "\n",
                "    if regression_info_dict is None:\n",
                "        # Regression info dict\n",
                "        regression_info_dict = {\n",
                "            'Model Name': lambda x: f'{x.model.__class__.__name__}',\n",
                "            'N': lambda x: f'{int(x.nobs):d}',\n",
                "            'R-squared': lambda x: f'{x.rsquared:.5f}',\n",
                "            'R-squared Adj.': lambda x: f'{x.rsquared_adj:.5f}',\n",
                "            'Log-Likelihood': lambda x: f'{x.llf:.5f}',\n",
                "            'Pseudo R2': lambda x: f'{x.prsquared:.5f}',\n",
                "            'F': lambda x: f'{x.fvalue:.5f}',\n",
                "            'F (p-value)': lambda x: f'{x.f_pvalue:.5f}',\n",
                "            'df_model': lambda x: f'{x.df_model:.0f}',\n",
                "            'df_total': lambda x: f'{x.df_resid + x.df_model + 1:.0f}',\n",
                "            'df_resid': lambda x: f'{x.df_resid:.0f}',\n",
                "            'AIC': lambda x: f'{x.aic:.5f}',\n",
                "            'BIC': lambda x: f'{x.bic:.5f}',\n",
                "            'ICC': lambda x: f'{x.rsquared / (x.rsquared + (x.nobs - 1) * x.mse_resid):.5f}',\n",
                "            'RMSE': lambda x: f'{x.mse_resid ** 0.5:.5f}',\n",
                "            'RMSE (std)': lambda x: f'{x.mse_resid ** 0.5 / x.model.endog.std():.5f}',\n",
                "            'Omnibus': lambda x: f'{sms.omni_normtest(x.resid).statistic:.5f}',\n",
                "            'Omnibus (p-value)': lambda x: f'{sms.omni_normtest(x.resid).pvalue:.5f}',\n",
                "            'Skew': lambda x: f'{sms.jarque_bera(x.resid)[-2]:.5f}',\n",
                "            'Kurtosis': lambda x: f'{sms.jarque_bera(x.resid)[-1]:.5f}',\n",
                "            'Jarque-Bera (JB)': lambda x: f'{sms.jarque_bera(x.resid)[0]:.5f}',\n",
                "            'Jarque-Bera (p-value)': lambda x: f'{sms.jarque_bera(x.resid)[1]:.5f}',\n",
                "            'Intercept': lambda x: f'{x.params[\"const\"]:.5f}',\n",
                "            'Intercept (std)': lambda x: f'{x.bse[\"const\"]:.5f}',\n",
                "            'Intercept t': lambda x: f'{x.tvalues[\"const\"]:.5f}',\n",
                "            'Intercept t (p-value)': lambda x: f'{x.pvalues[\"const\"]:.5f}',\n",
                "            'Intercept (95% CI)': lambda x: f'{x.conf_int().loc[\"const\"][0]:.5f} - {x.conf_int().loc[\"const\"][1]:.5f}',\n",
                "            'Unstandardized Coefficent B (b)': lambda x: f'{x.params[0]:.5f}',\n",
                "            'Standard Error (SE)': lambda x: f'{x.bse[0]:.5f}',\n",
                "            'Standardized Coefficient b* (β)': lambda x: f'{x.params[0] / x.model.endog.std():.5f}',\n",
                "            't': lambda x: f'{x.tvalues[0]:.5f}',\n",
                "            't (p-value)': lambda x: f'{x.pvalues[0]:.5f}',\n",
                "            '95% CI': lambda x: f'{x.conf_int().iloc[0, 1]:.5f} - {x.conf_int().iloc[0, 1]:.5f}',\n",
                "            # 'Summary': lambda x: f'{x.summary()}',\n",
                "            # 'F (p-value - FDR)': lambda x: f'{x.f_pvalue_fdr:.5f}',\n",
                "            # 'F (p-value - Bonferroni)': lambda x: f'{x.f_pvalue_bonf:.5f}',\n",
                "            # 't (p-value - FDR)': lambda x: f'{x.pvalues_fdr[1]:.5f}',\n",
                "            # 't (p-value - Bonferroni)': lambda x: f'{x.pvalues_bonf[1]:.5f}',\n",
                "        }\n",
                "    if model_names is None:\n",
                "        if isinstance(results, list):\n",
                "            model_names = [\n",
                "                f'{results[0].model.endog_names.split(\"_\")[0] if \"_\" in results[0].model.endog_names else results[0].model.endog_names} Model {i}'\n",
                "                for i in range(len(results[0].model.endog_names))\n",
                "            ]\n",
                "            model_names[0] = model_names[0].replace('Model 0', 'Full Model')\n",
                "        else:\n",
                "            model_names = [\n",
                "                f'{results.model.endog_names.split(\"_\")[0] if \"_\" in results.model.endog_names else results.model.endog_names}'\n",
                "            ]\n",
                "\n",
                "    order_type = 'unordered' if regressor_order is None else 'ordered'\n",
                "    if text_to_add_list is None:\n",
                "        text_to_add_list = []\n",
                "        if regressor_order is not None:\n",
                "            text_to_add_list.append('Models are ordered by independent variable type.')\n",
                "\n",
                "        else:\n",
                "            text_to_add_list.append('Models are ordered by coefficient size, largest to smallest.')\n",
                "\n",
                "    if title is None:\n",
                "        title = f'{dv_type} OLS Regression {dv}'\n",
                "\n",
                "    try:\n",
                "        # Statsmodels summary_col\n",
                "        full_summary = summary_col(\n",
                "            results,\n",
                "            stars=True,\n",
                "            info_dict=regression_info_dict,\n",
                "            regressor_order=regressor_order,\n",
                "            float_format='%0.3f',\n",
                "            model_names=model_names,\n",
                "        )\n",
                "        if isinstance(results, list) and len(results) > 4:\n",
                "            full_summary.tables[0][full_summary.tables[0].filter(regex='Full Model').columns[0]].loc['Unstandardized Coefficent B (b)': '95% CI'] = ''\n",
                "\n",
                "        # Add title and notes\n",
                "        full_summary.add_title(title)\n",
                "        text_to_add_list.extend(full_summary.extra_txt)\n",
                "        for text in text_to_add_list:\n",
                "            full_summary.add_text(text)\n",
                "        # Save\n",
                "        save_name = f'{table_save_path}{title}'\n",
                "        print(f'Saving {save_name}...')\n",
                "        df_full_summary = pd.read_html(full_summary.as_html())[0]\n",
                "        df_full_summary.to_csv(f'{save_name}.csv')\n",
                "        df_full_summary.style.to_latex(f'{save_name}.tex', hrules=True)\n",
                "        save_df_full_summary_excel(df_full_summary, title, text_to_add_list, save_name)\n",
                "\n",
                "        return full_summary\n",
                "    except IndexError:\n",
                "        return None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ad45ea49",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_standardized_coefficients(results):\n",
                "\n",
                "    # # Get standardized regression coefficients\n",
                "    # std = np.asarray(constant.std(0))\n",
                "\n",
                "    # if 'const' in results.params and 'const' in constant:\n",
                "    #     std[0] = 1\n",
                "    # tt = results.t_test(np.diag(std))\n",
                "    # tt.c_names = results.model.exog_names\n",
                "\n",
                "    # t-test\n",
                "    std = results.model.exog.std(0)\n",
                "    if 'const' in results.params:\n",
                "        std[0] = 1\n",
                "    tt = results.t_test(np.diag(std))\n",
                "    if results.model.__class__.__name__ == 'MixedLM' or 'Group Var' in results.model.exog_names:\n",
                "        offset = slice(None, -1)\n",
                "        tt.c_names = results.model.exog_names[offset]\n",
                "    else:\n",
                "        offset = slice(None, None)\n",
                "        tt.c_names = results.model.exog_names\n",
                "\n",
                "    # Make df with standardized and unstandardized coefficients\n",
                "    df_std_coef = pd.DataFrame(\n",
                "        {\n",
                "            'coef': results.params[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'std err': results.bse[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'std coef': (results.params[offset] / results.model.exog[offset].std(axis=0)).apply(lambda x: f'{x:.5f}'),\n",
                "            't': results.tvalues[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'P>|t|': results.pvalues[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            '[0.025': results.conf_int()[0][offset].apply(lambda x: f'{x:.5f}'),\n",
                "            '0.975]': results.conf_int()[1][offset].apply(lambda x: f'{x:.5f}'),\n",
                "        }\n",
                "    )\n",
                "    # if 'Group Var' in df_std_coef.index:\n",
                "    #     df_std_coef = df_std_coef.drop('Group Var', axis='index')\n",
                "    # # Add standardized coefficients and other data from t-test\n",
                "    # df_std_coef['std coef'] = tt.effect\n",
                "    # df_std_coef['std err'] = tt.sd\n",
                "    # df_std_coef['t'] = tt.statistic\n",
                "    # df_std_coef['P>|t|'] = tt.pvalue\n",
                "    # df_std_coef['[0.025'] = tt.conf_int()[:, 0]\n",
                "    # df_std_coef['0.975]'] = tt.conf_int()[:, 1]\n",
                "    # df_std_coef['var'] = [names[i] for i in range(len(results.model.exog_names))]\n",
                "    # df_std_coef = df_std_coef.sort_values('std coef', ascending=False)\n",
                "    df_std_coef = df_std_coef.reset_index().rename(columns={'index': 'var'})\n",
                "    df_std_coef = df_std_coef.rename(\n",
                "        columns={\n",
                "            'var': 'Variable',\n",
                "            'coef': 'Unstandardized Coefficent B (b)',\n",
                "            'std err': 'Standard Error',\n",
                "            'std coef':'Standardized Coefficient b* (β)',\n",
                "            't': 't-value',\n",
                "            'P>|t|': 'p-value',\n",
                "            '[0.025': '95% CI Lower',\n",
                "            '0.975]': '95% CI Upper'\n",
                "        }\n",
                "    )\n",
                "    # Reorder columns\n",
                "    df_std_coef = df_std_coef[[\n",
                "        'Variable',\n",
                "        'Unstandardized Coefficent B (b)',\n",
                "        'Standard Error',\n",
                "        'Standardized Coefficient b* (β)',\n",
                "        't-value',\n",
                "        'p-value',\n",
                "        '95% CI Lower',\n",
                "        '95% CI Upper'\n",
                "    ]]\n",
                "\n",
                "    return tt, df_std_coef\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bbe40924",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to compare and produce Unbiased and Biased OLS Models\n",
                "def compare_actual_and_predicted(df, analysis_type, iv_names=None, print_enabled=None):\n",
                "    if print_enabled is None:\n",
                "        print_enabled = True\n",
                "    dv_names_dict = defaultdict(lambda: defaultdict())\n",
                "\n",
                "    for dv in tqdm.tqdm(dvs):\n",
                "        if analysis_type == 'pre_classification':\n",
                "            if iv_names is None:\n",
                "                iv_names = ivs_dummy_perc_and_perc_interactions + controls[:2]\n",
                "            dv_names_dict[dv] = {\n",
                "                'Unbiased': {'dv_names': f'{dv}_actual'},\n",
                "                'Biased': {'dv_names': f'{dv}_predicted'}\n",
                "            }\n",
                "            df = df.loc[\n",
                "                (~df[dv_names_dict[dv]['Unbiased']['dv_names']].isna())\n",
                "                & (~df[dv_names_dict[dv]['Biased']['dv_names']].isna())\n",
                "            ]\n",
                "            print(f'Processing dataframe of length {len(df)}')\n",
                "\n",
                "        elif analysis_type == 'post_classification':\n",
                "            if iv_names is None:\n",
                "                iv_names = ivs_dummy_perc_and_perc_interactions[0]\n",
                "            if f'{dv}_aggr_unlabeled_predicted' in df.columns:\n",
                "                dv_names_dict[dv] = {\n",
                "                    'Biased': {'dv_names': [f'{dv}_aggr_unlabeled_predicted']},# HACK + controls[:2]\n",
                "                }\n",
                "                df = df.loc[\n",
                "                    (~df[dv_names_dict[dv]['Biased']['dv_names'][0]].isna())\n",
                "                ]\n",
                "                print(f'Processing dataframe of length {len(df)}')\n",
                "            elif f'{dv}_actual' in df.columns:\n",
                "                dv_names_dict[dv] = {\n",
                "                    'Unbiased': {'dv_names': [f'{dv}_actual']},# HACK + controls[:2]\n",
                "                }\n",
                "                df = df.loc[\n",
                "                    (~df[dv_names_dict[dv]['Unbiased']['dv_names'][0]].isna())\n",
                "                ]\n",
                "                print(f'Processing dataframe of length {len(df)}')\n",
                "\n",
                "        print(f'Analyzing {dv} {dv_names_dict[dv].keys()} Models')\n",
                "\n",
                "        for dv_type, dv_names in tqdm.tqdm(dv_names_dict[dv].items()):\n",
                "            if analysis_type == 'pre_classification':\n",
                "                endog = df[dv_names['dv_names']]\n",
                "                exog = df[iv_names]\n",
                "            elif analysis_type == 'post_classification':\n",
                "                endog = df[iv_names]\n",
                "                exog = df[dv_names['dv_names']]\n",
                "\n",
                "            constant = sm.add_constant(exog)\n",
                "            model = sm.OLS(endog=endog, exog=constant, data=df)\n",
                "            results = model.fit()\n",
                "            tt, df_std_coef = get_standardized_coefficients(results)\n",
                "            title = f'{analysis_type} {dv_type} OLS Regression {dv_names[\"dv_names\"]} x {iv_names[:3]} etc.'\n",
                "            full_summary = make_full_report(\n",
                "                results, dv, dvs_name=dv, dv_type=dv_type, title=title\n",
                "            )\n",
                "            dv_names_dict[dv][dv_type]['R-squared'] = results.rsquared\n",
                "            dv_names_dict[dv][dv_type]['Results'] = results\n",
                "\n",
                "            if print_enabled:\n",
                "                print('\\n')\n",
                "                print('-'*20)\n",
                "                print(f'{dv_type.upper()} {dv}\\n')\n",
                "                print('-'*20)\n",
                "                print('\\n')\n",
                "                print(f'{dv_type.upper()} SUMMARY RESULTS:')\n",
                "                print(results.summary())\n",
                "                print(full_summary)\n",
                "                print('\\n')\n",
                "                print('-'*20)\n",
                "                print(f'{dv_type.upper()} STANDARDIZED BETA REGRESSION COEFFICIENTS FOR {dv}:\\n{df_std_coef}')\n",
                "                print('\\n')\n",
                "                print('-'*20)\n",
                "\n",
                "            df_summary_results = pd.DataFrame(csv.reader(results.summary().as_csv().split('\\n'), delimiter=','))\n",
                "            save_name = f'{table_save_path}{title}'\n",
                "            df_summary_results.to_csv(f'{save_name}.csv')\n",
                "            df_summary_results.style.to_latex(f'{save_name}.tex', hrules=True)\n",
                "            df_std_coef.to_csv(f'{save_name} - standardized coefficients.csv')\n",
                "            df_std_coef.style.to_latex(f'{save_name} - standardized coefficients.tex', hrules=True)\n",
                "\n",
                "        if dv_names_dict[dv][list(dv_names_dict[dv])[0]]['R-squared'] != dv_names_dict[dv][list(dv_names_dict[dv])[-1]]['R-squared']:\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "            print(f'{dv} {list(dv_names_dict[dv])[0]} R-Squared does not equal {list(dv_names_dict[dv])[-1]} R-Squared:')\n",
                "            print(f'{dv} {list(dv_names_dict[dv])[0]} = {dv_names_dict[dv][list(dv_names_dict[dv])[0]][\"R-squared\"]:.3f}')\n",
                "            print(f'{dv} {list(dv_names_dict[dv])[-1]} = {dv_names_dict[dv][list(dv_names_dict[dv])[-1]][\"R-squared\"]:.3f}')\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "\n",
                "    return dict(dv_names_dict)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "fd32c435",
            "metadata": {},
            "source": [
                "### READ DATA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "923fee85",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'r') as f:\n",
                "    df_jobs_len = int(f.read())\n",
                "\n",
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
                "assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_jobs)}'\n",
                "print(f'Dataframe df_jobs_for_analysis loaded with shape: {df_jobs.shape}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aee1fd3d",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Warmth'].equals(df_jobs['Warmth_predicted'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a183fc9d",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Competence'].equals(df_jobs['Competence_predicted'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a761f93",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs[['Warmth', 'Warmth_actual']].isna().sum()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2ebecb79",
            "metadata": {},
            "source": [
                "## Check biased and unbiased regressions models using human annotated and classifier predicted Warmth and Competence\n",
                "Source: https://mochenyang.github.io/mochenyangblog/research/2022/01/10/ForestIV.html"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5499a77b",
            "metadata": {},
            "source": [
                "### Unbiased and Biased Warmth and CompetenceOLS regression with human annotated actual values as DV and all IVs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "08d54a15",
            "metadata": {},
            "outputs": [],
            "source": [
                "dv_names_dict_pre_classification = compare_actual_and_predicted(df_jobs, analysis_type='pre_classification', print_enabled=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "33e3488f",
            "metadata": {},
            "outputs": [],
            "source": [
                "dv_names_dict_pre_classification\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b9202851",
            "metadata": {},
            "source": [
                "## Make RandomForestRegressor Classifier\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dcf1e9cb",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_final_indiv_and_aggr_preds(estimator, X):\n",
                "    pred = estimator.predict(X)\n",
                "    indiv_pred = [tree.predict(X) for tree in estimator.estimators_]\n",
                "    aggr_pred = np.mean(indiv_pred, axis=0)\n",
                "\n",
                "    return pred, indiv_pred, aggr_pred\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "50385c5e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_randomforest_instrumental_variable_estimator(df_jobs, cols_to_compare=None, text_col=None, n_trees=None):\n",
                "\n",
                "    if cols_to_compare is None:\n",
                "        cols_to_compare = ['Warmth_actual', 'Warmth_predicted', 'Competence_actual', 'Competence_predicted']\n",
                "    if text_col is None:\n",
                "        text_col = 'Job Description spacy_sentencized'\n",
                "    if n_trees is None:\n",
                "        n_trees = 100\n",
                "    cols_dict = defaultdict()\n",
                "    train_ratio = 0.75\n",
                "    test_ratio = 0.10\n",
                "    validation_ratio = 0.15\n",
                "    test_split = test_size = 1 - train_ratio\n",
                "    validation_split = test_ratio / (test_ratio + validation_ratio)\n",
                "\n",
                "    # Make df_jobs_unlabeled\n",
                "    df_jobs_unlabeled = df_jobs.loc[\n",
                "        (df_jobs[cols_to_compare].isna()).all(axis='columns')\n",
                "    ]\n",
                "\n",
                "    if all(df_jobs_unlabeled.isna().sum()) != 0:\n",
                "        raise IndexError('Missing data in df_jobs_labeled.')\n",
                "\n",
                "    df_jobs_unlabeled = df_jobs_unlabeled.dropna(subset=analysis_columns, how='any')\n",
                "    print(f'Dataframe df_jobs_unlabeled of length: {len(df_jobs_unlabeled)}')\n",
                "\n",
                "    # Make df_jobs_labeled\n",
                "    df_jobs_labeled = df_jobs.loc[\n",
                "        (~df_jobs[cols_to_compare].isna()).all(axis='columns')\n",
                "    ]\n",
                "\n",
                "    if all(df_jobs_labeled.isna().sum()) != 0:\n",
                "        raise IndexError('Missing data in df_jobs_labeled.')\n",
                "\n",
                "    df_jobs_labeled = df_jobs_labeled.dropna(subset=analysis_columns, how='any')\n",
                "    print(f'Dataframe df_jobs_labeled of length: {len(df_jobs_labeled)}')\n",
                "\n",
                "    # Make df labels dict\n",
                "    df_add_preds_dict = {\n",
                "        'labeled': df_jobs_labeled,\n",
                "        'unlabeled': df_jobs_unlabeled\n",
                "    }\n",
                "\n",
                "    # Split data\n",
                "    print('Splitting data...')\n",
                "    train, test = train_test_split(\n",
                "        df_jobs_labeled, train_size=1-test_split, test_size=test_split, random_state=random_state\n",
                "    )\n",
                "    print(f'Length of train dataset: {len(train)}')\n",
                "    print(f'Length of test dataset: {len(test)}')\n",
                "    cols_dict = {\n",
                "        'train': train, 'test': test,\n",
                "    }\n",
                "\n",
                "    for col in tqdm.tqdm(analysis_columns):\n",
                "        assert col in df_jobs_labeled.columns, f'{col} column not found in df_jobs_labeled'\n",
                "        print('='*20)\n",
                "        print(f'Training on {col}...')\n",
                "\n",
                "        X_train = np.array(list(train[text_col].astype('str').values))\n",
                "        y_train = column_or_1d(train[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_test = np.array(list(test[text_col].astype('str').values))\n",
                "        y_test = column_or_1d(test[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_labeled = np.array(list(df_jobs_labeled[text_col].astype('str').values))\n",
                "        y_labeled = column_or_1d(df_jobs_labeled[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_unlabeled = np.array(list(df_jobs_unlabeled[text_col].astype('str').values))\n",
                "        y_unlabeled = column_or_1d(df_jobs_unlabeled[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        # Vectorize using FeatueUnion\n",
                "        print(f'Vectorizing using {vectorizers_list[-1].__class__.__name__}...')\n",
                "        vectorizer = vectorizers_list[-1]\n",
                "        X_train = vectorizer.fit_transform(X_train)\n",
                "        X_test = vectorizer.transform(X_test)\n",
                "        X_labeled = vectorizer.transform(X_labeled)\n",
                "        X_unlabeled = vectorizer.transform(X_unlabeled)\n",
                "\n",
                "        # Train using RandomForestRegressor\n",
                "        print('Training using RandomForestRegressor...')\n",
                "        estimator = RandomForestRegressor(n_estimators=n_trees, random_state=random_state, n_jobs=n_jobs)\n",
                "        estimator.fit(X_train, y_train)\n",
                "\n",
                "        # Get predictions\n",
                "        print('Getting predictions...')\n",
                "        y_train_pred, indiv_y_train_pred, aggr_y_train_pred = make_final_indiv_and_aggr_preds(estimator, X_train)\n",
                "        y_test_pred, indiv_y_test_pred, aggr_y_test_pred = make_final_indiv_and_aggr_preds(estimator, X_test)\n",
                "        y_labeled_pred, indiv_y_labeled_pred, aggr_y_labeled_pred = make_final_indiv_and_aggr_preds(estimator, X_labeled)\n",
                "        y_unlabeled_pred, indiv_y_unlabeled_pred, aggr_y_unlabeled_pred = make_final_indiv_and_aggr_preds(estimator, X_unlabeled)\n",
                "\n",
                "        # Make col dict\n",
                "        cols_dict[col] = {\n",
                "            'estimator': estimator, 'vectorizer': vectorizer,\n",
                "            'X_train': X_train, 'y_train': y_train, 'y_train_pred': y_train_pred,\n",
                "            'indiv_y_train_pred': indiv_y_train_pred, 'aggr_y_train_pred': aggr_y_train_pred,\n",
                "            'X_test': X_test, 'y_test': y_test, 'y_test_pred': y_test_pred,\n",
                "            'indiv_y_test_pred': indiv_y_test_pred, 'aggr_y_test_pred': aggr_y_test_pred,\n",
                "            'X_labeled': X_labeled, 'y_labeled': y_labeled, 'y_labeled_pred': y_labeled_pred,\n",
                "            'indiv_y_labeled_pred': indiv_y_labeled_pred, 'aggr_y_labeled_pred': aggr_y_labeled_pred,\n",
                "            'X_unlabeled': X_unlabeled, 'y_unlabeled': y_unlabeled, 'y_unlabeled_pred': y_unlabeled_pred,\n",
                "            'indiv_y_unlabeled_pred': indiv_y_unlabeled_pred, 'aggr_y_unlabeled_pred': aggr_y_unlabeled_pred,\n",
                "        }\n",
                "\n",
                "        # Add columns to df\n",
                "        for df_lab, df in tqdm.tqdm(df_add_preds_dict.items()):\n",
                "            df = pd.concat(\n",
                "                [\n",
                "                    df.reset_index(drop=True),\n",
                "                    pd.DataFrame(\n",
                "                        {\n",
                "                            f'{col}_{df_lab}_predicted': cols_dict[col][f'y_{df_lab}_pred'],\n",
                "                            f'{col}_aggr_{df_lab}_predicted': cols_dict[col][f'aggr_y_{df_lab}_pred'],\n",
                "                        }\n",
                "                    ).reset_index(drop=True),\n",
                "                    pd.DataFrame(cols_dict[col][f'indiv_y_{df_lab}_pred']).transpose().add_prefix(f'{col}_tree_').reset_index(drop=True)\n",
                "                ],\n",
                "                axis='columns'\n",
                "            )\n",
                "            cols_dict[col][f'df_jobs_{df_lab}'] = df\n",
                "\n",
                "        # Evaluate\n",
                "        print('Evaluating...')\n",
                "        score = estimator.score(X_test, y_test)\n",
                "        mae = mean_absolute_error(y_test, y_test_pred)\n",
                "        mse = mean_squared_error(y_test, y_test_pred)\n",
                "        rmse = np.sqrt(mse)\n",
                "        r2 = r2_score(y_test, y_test_pred)\n",
                "\n",
                "        print('-'*20)\n",
                "        print(f'Mean Absolute Error: {mae:3f}')\n",
                "        print(f'Mean Squared Error: {mse:3f}')\n",
                "        print(f'Root Mean Squared Error: {rmse:3f}')\n",
                "        print(f'R-squared (R^2) Score: {r2:3f}')\n",
                "        print('-'*20)\n",
                "\n",
                "    return n_trees, dict(cols_dict)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14cc0d13",
            "metadata": {},
            "outputs": [],
            "source": [
                "n_trees, cols_dict = get_randomforest_instrumental_variable_estimator(df_jobs, n_trees=100)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59b7ec3b",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict.keys()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b3221c1c",
            "metadata": {},
            "outputs": [],
            "source": [
                "list_columns = [c for c in df_jobs.columns if df_jobs[c].apply(lambda x: isinstance(x, list)).any()]\n",
                "non_list_columns = [c for c in df_jobs.columns if not df_jobs[c].apply(lambda x: isinstance(x, list)).any()]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a993ee38",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Warmth']['df_jobs_labeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12167868",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Competence']['df_jobs_labeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2e23e857",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled = cols_dict['Warmth']['df_jobs_labeled']\\\n",
                "    .drop(columns=list_columns)\\\n",
                "    .merge(\n",
                "        cols_dict['Competence']['df_jobs_labeled'],\n",
                "        how='outer',\n",
                "        on=non_list_columns\n",
                "    ).dropna(axis='columns', how='all')\\\n",
                "        .reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a3b9868a",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fa150d05",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "25567198",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Warmth']['df_jobs_unlabeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eff0ccb5",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Competence']['df_jobs_unlabeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e8597d57",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled = cols_dict['Warmth']['df_jobs_unlabeled']\\\n",
                "    .drop(columns=list_columns)\\\n",
                "        .merge(\n",
                "            cols_dict['Competence']['df_jobs_unlabeled'],\n",
                "            how='outer',\n",
                "            on=non_list_columns\n",
                "        ).dropna(axis='columns', how='all')\\\n",
                "            .reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "57fd9028",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cb3b5c70",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4fa26dae",
            "metadata": {},
            "outputs": [],
            "source": [
                "train = cols_dict['train']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19353659",
            "metadata": {},
            "outputs": [],
            "source": [
                "train.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "09a72253",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_train = train.copy()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2adff07d",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_train.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "615db4ea",
            "metadata": {},
            "outputs": [],
            "source": [
                "test = cols_dict['test']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7a7cfb3f",
            "metadata": {},
            "outputs": [],
            "source": [
                "test.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9dbf219e",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test = test\\\n",
                "    .drop(columns=list_columns)\\\n",
                "    .merge(\n",
                "        df_jobs_labeled,\n",
                "        how='inner',\n",
                "        on=non_list_columns\n",
                "    ).reset_index(drop=True)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6b76d98f",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "47f90db7",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a1a9e627",
            "metadata": {},
            "source": [
                "# Make instrumental Variable"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "48060e42",
            "metadata": {},
            "source": [
                "### Make unbiased and biased models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0707e44c",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction = pd.concat([df_jobs_labeled, df_jobs_unlabeled], axis='index')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c8c27cbc",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1235f58a",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "68f95899",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Biased model\n",
                "biased_post_classification_dict = defaultdict()\n",
                "for iv in tqdm.tqdm(ivs_dummy_perc_and_perc_interactions):\n",
                "    dv_names_dict_unlabeled_post_classification = compare_actual_and_predicted(\n",
                "        df_jobs_unlabeled, analysis_type='post_classification', iv_names=iv, print_enabled=False\n",
                "    )\n",
                "    biased_post_classification_dict[iv] = dv_names_dict_unlabeled_post_classification\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "894c6225",
            "metadata": {},
            "outputs": [],
            "source": [
                "biased_post_classification_dict.keys()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ae3352a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uniased model\n",
                "unbiased_post_classification_dict = defaultdict()\n",
                "for iv in tqdm.tqdm(ivs_dummy_perc_and_perc_interactions):\n",
                "    dv_names_dict_labeled_post_classification = compare_actual_and_predicted(\n",
                "        df_jobs_labeled, analysis_type='post_classification', iv_names=iv, print_enabled=False\n",
                "    )\n",
                "    unbiased_post_classification_dict[iv] = dv_names_dict_labeled_post_classification\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1454b793",
            "metadata": {},
            "outputs": [],
            "source": [
                "unbiased_post_classification_dict.keys()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4fa12799",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get forest_iv results\n",
                "forest_iv_results_dict = defaultdict(lambda: defaultdict())\n",
                "forest_iv_params = {\n",
                "    # 'col': dv,\n",
                "    # 'var': iv,\n",
                "    # 'model_unbias': model_unbias,\n",
                "    'data_test': df_jobs_test,\n",
                "    'data_unlabel': df_jobs_for_correction,\n",
                "    # 'control': controls[:2],\n",
                "    'ntree': n_trees,\n",
                "    'iterative': True\n",
                "    # 'diagnostic': True,\n",
                "    # 'family': sm.families.Gaussian(link=sm.families.links.Identity()),\n",
                "    # 'select_method': 'optimal',\n",
                "    # 'method': 'Lasso',\n",
                "}\n",
                "\n",
                "for dv, iv in tqdm_product(dvs, ivs_dummy_perc_and_perc_interactions):\n",
                "    print('-'*20)\n",
                "    print(f'Analyzing {dv} with {iv}...')\n",
                "    forest_iv_params['col'] = dv\n",
                "    forest_iv_params['var'] = iv\n",
                "    forest_iv_params['model_unbias'] = unbiased_post_classification_dict[iv][dv]['Unbiased']['Results']\n",
                "\n",
                "    forest_iv_results_dict[dv][iv] = defaultdict()\n",
                "\n",
                "    results_IV, output, results  = forest_iv(**forest_iv_params)\n",
                "\n",
                "    forest_iv_results_dict[dv][iv]['Results_IV'] = results_IV\n",
                "    forest_iv_results_dict[dv][iv]['Output'] = output\n",
                "    forest_iv_results_dict[dv][iv]['Results'] = results\n",
                "\n",
                "# result = forest_iv(\n",
                "#     col=dv,\n",
                "#     data_test=df_jobs_test,\n",
                "#     data_unlabel=df_jobs_unlabeled,\n",
                "#     var=iv,\n",
                "#     control=controls[:2],\n",
                "#     ntree=n_trees,\n",
                "#     model_unbias=model_unbias,\n",
                "#     diagnostic=True,\n",
                "#     family=sm.families.Gaussian(link=sm.families.links.Identity()),\n",
                "#     select_method='optimal',\n",
                "#     method='Lasso',\n",
                "#     iterative=False\n",
                "# )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a63c9a57",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the critical value for a chi-squared distribution\n",
                "H_critical = scipy.stats.chi2.ppf(0.95, df=4)\n",
                "\n",
                "for dv, iv in tqdm_product(dvs, ivs_dummy_perc_and_perc_interactions):\n",
                "    # Get unbiased model\n",
                "    model_unbias = unbiased_post_classification_dict[iv][dv]['Unbiased']['Results']\n",
                "\n",
                "    # Get the unbiased coefficients\n",
                "    coef_unbiased = model_unbias.params\n",
                "\n",
                "    # Get results\n",
                "    results = forest_iv_results_dict[dv][iv]['Results']\n",
                "\n",
                "    # Calculate the squared bias for each beta\n",
                "    results['bias2'] = ((results[[beta for beta in results.columns if 'beta' in beta ]] - coef_unbiased) ** 2).sum(axis=1)\n",
                "\n",
                "    # Calculate the total variance\n",
                "    results['variance'] = (results[[se for se in results.columns if 'se' in se]] ** 2).sum(axis=1)\n",
                "\n",
                "    # Calculate the mean squared error (MSE)\n",
                "    results['mse'] = results['bias2'] + results['variance']\n",
                "\n",
                "    # Sort the DataFrame by MSE\n",
                "    results = results.sort_values(by='mse')\n",
                "\n",
                "    # Filter rows where Hotelling is less than H_critical and only keep the first row\n",
                "    filtered_results = results[(results['Hotelling'] < H_critical) & (results.index == results.index[0])]\n",
                "\n",
                "    # Display the filtered results\n",
                "    print(filtered_results[[beta for beta in results.columns if 'beta' in beta ]])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a50be1b0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get valid instrumental variables from forest_iv_results_dict\n",
                "instrumental_variables = list(\n",
                "    {\n",
                "        instrument\n",
                "        for dv, iv in forest_iv_results_dict.items()\n",
                "        for k, v in iv.items()\n",
                "        for instrument in v['Output']['IVs']\n",
                "    }\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "instrumental_variables\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b60b30c",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = df_jobs_for_correction.loc[:,\n",
                "    (~df_jobs_for_correction.columns.str.contains('_tree_'))\n",
                "    | (df_jobs_for_correction.columns.isin(instrumental_variables))\n",
                "].reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9e5f3c1b",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "37533128",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a30d6c5b",
            "metadata": {},
            "outputs": [],
            "source": [
                "iv = ivs_perc[0]\n",
                "col = dvs[0]\n",
                "for dv in dvs:\n",
                "    print(dv, iv)\n",
                "    results_IV = forest_iv_results_dict[dv][iv]['Results_IV']\n",
                "    print(results_IV.summary())\n",
                "    corrected_var = results_IV.predict(df_jobs[col])\n",
                "    print(corrected_var)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "efec800f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "# df_jobs.to_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
                "# df_jobs.to_csv(f'{df_save_dir}df_jobs_for_analysis.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0ac17152",
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(f'Saving corrected df_jobs length {len(df_jobs)} to txt file.')\n",
                "# with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'w') as f:\n",
                "#     f.write(str(len(df_jobs)))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1b50e19e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# # Calculate the critical value of Hotelling's T-squared test\n",
                "# H_critical = chi2.ppf(0.95, df=4)\n",
                "\n",
                "# # Get the unbiased coefficients\n",
                "# coef_unbiased = model_unbias.coef\n",
                "\n",
                "# # Calculate the bias squared, variance, and mean squared error (MSE)\n",
                "# bias2 = np.sum((coef_unbiased - [beta_1, beta_2, beta_3, beta_4])**2)\n",
                "# variance = se_1**2 + se_2**2 + se_3**2 + se_4**2\n",
                "# mse = bias2 + variance\n",
                "\n",
                "# # Add these columns to the `result` DataFrame\n",
                "# result = result.assign(\n",
                "#     bias2=bias2,\n",
                "#     variance=variance,\n",
                "#     mse=mse,\n",
                "# )\n",
                "\n",
                "# # Sort the DataFrame by MSE and filter to the top row\n",
                "# result = result.sort_values(\"mse\").iloc[:1]\n",
                "\n",
                "# # Filter to the rows where Hotelling's T-squared test is less than the critical value\n",
                "# result = result.query(\"Hotelling < {}\".format(H_critical))\n",
                "\n",
                "# # Print the results\n",
                "# print(result)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fa9fb434",
            "metadata": {},
            "outputs": [],
            "source": [
                "# HACK\n",
                "# def compute_embeddings(model, input_ids):\n",
                "#     outputs = model(input_ids)\n",
                "#     hidden_states = outputs.hidden_states\n",
                "#     embeddings = hidden_states[-1]  # Extract embeddings from the last layer\n",
                "#     return embeddings\n",
                "\n",
                "# train_data = estimator.get_train_dataloader()\n",
                "# eval_data = estimator.get_eval_dataloader()\n",
                "\n",
                "# # Compute embeddings for your train and eval data\n",
                "# train_embeddings = compute_embeddings(model, next(iter(train_data))[0])\n",
                "# eval_embeddings = compute_embeddings(model, next(iter(eval_data))[0])\n",
                "\n",
                "# TODO: get train, test, datasets from transformers save folder, X = np.concatenate((X_test, X_val), axis=0) and y = np.concatenate((y_test, y_val), axis=0) so X_test, y_test will be both of these. Get these to become df_jobs_test and df_jobs_train, then df_jobs_unlabeled will be the same.\n",
                "\n",
                "# from transformers import BertModel, Trainer\n",
                "\n",
                "# model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
                "# trainer = Trainer(model)\n",
                "\n",
                "# trainer.train()\n",
                "\n",
                "# # Get the embeddings from the model\n",
                "# embeddings = model.get_input_embeddings()\n",
                "\n",
                "# print(embeddings.shape)\n",
                "\n",
                "# from transformers import BertModel, Trainer\n",
                "\n",
                "# model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
                "# trainer = Trainer(model)\n",
                "\n",
                "# trainer.train()\n",
                "\n",
                "# # Get the hidden states from the model\n",
                "# hidden_states = model.get_hidden_states()\n",
                "\n",
                "# # Get the embeddings from the last layer\n",
                "# embeddings = hidden_states[-1]\n",
                "\n",
                "# print(embeddings.shape)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Automating_Equity1_3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        },
        "varInspector": {
            "cols": {
                "lenName": 16,
                "lenType": 16,
                "lenVar": 40
            },
            "kernels_config": {
                "python": {
                    "delete_cmd_postfix": "",
                    "delete_cmd_prefix": "del ",
                    "library": "var_list.py",
                    "varRefreshCmd": "print(var_dic_list())"
                },
                "r": {
                    "delete_cmd_postfix": ") ",
                    "delete_cmd_prefix": "rm(",
                    "library": "var_list.r",
                    "varRefreshCmd": "cat(var_dic_list()) "
                }
            },
            "types_to_exclude": [
                "module",
                "function",
                "builtin_function_or_method",
                "instance",
                "_Feature"
            ],
            "window_display": false
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
