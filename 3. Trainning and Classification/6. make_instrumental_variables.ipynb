{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "50d4c434",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "if code_dir_name not in str(Path.cwd()).split('/')[-1]:\n",
                "    for _ in range(5):\n",
                "\n",
                "        parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "        if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "            code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "            if code_dir is not None:\n",
                "                break\n",
                "else:\n",
                "    code_dir = str(Path.cwd())\n",
                "sys.path.append(code_dir)\n",
                "\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fef3f604",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from estimators_get_pipe import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e3936e59",
            "metadata": {},
            "source": [
                "### Set variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3b9d1a7b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Variables\n",
                "method = 'Supervised'\n",
                "classifiers_type = 'all'\n",
                "if classifiers_type == 'nonlinear':\n",
                "    classifiers_pipe = classifiers_pipe_nonlinear\n",
                "elif classifiers_type == 'linear':\n",
                "    classifiers_pipe = classifiers_pipe_linear\n",
                "elif classifiers_type == 'ensemble':\n",
                "    classifiers_pipe = classifiers_pipe_ensemble\n",
                "elif classifiers_type == 'all':\n",
                "    classifiers_pipe = classifiers_pipe\n",
                "\n",
                "results_save_path = f'{models_save_path}{method} Results/'\n",
                "with open(f'{data_dir}{method}_results_save_path.txt', 'w') as f:\n",
                "    f.write(results_save_path)\n",
                "if not os.path.exists(results_save_path):\n",
                "    os.makedirs(results_save_path)\n",
                "done_xy_save_path = f'{results_save_path}Search+Xy/'\n",
                "with open(f'{data_dir}{method}_done_xy_save_path.txt', 'w') as f:\n",
                "    f.write(done_xy_save_path)\n",
                "if not os.path.exists(done_xy_save_path):\n",
                "    os.makedirs(done_xy_save_path)\n",
                "\n",
                "t = time.time()\n",
                "n_jobs = -1\n",
                "n_splits = 10\n",
                "n_repeats = 3\n",
                "random_state = 42\n",
                "refit = True\n",
                "class_weight = 'balanced'\n",
                "cv = RepeatedStratifiedKFold(\n",
                "    n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
                ")\n",
                "scoring = 'recall'\n",
                "scores = [\n",
                "    'recall', 'accuracy', 'f1', 'roc_auc',\n",
                "    'explained_variance', 'matthews_corrcoef'\n",
                "]\n",
                "scorers = {\n",
                "    'precision_score': make_scorer(precision_score, zero_division=0),\n",
                "    'recall_score': make_scorer(recall_score, zero_division=0),\n",
                "    'accuracy_score': make_scorer(accuracy_score, zero_division=0),\n",
                "}\n",
                "analysis_columns = ['Warmth', 'Competence']\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "metrics_dict = {\n",
                "    f'{scoring.title()} Best Score': np.nan,\n",
                "    f'{scoring.title()} Best Threshold': np.nan,\n",
                "    'Train - Mean Cross Validation Score': np.nan,\n",
                "    f'Train - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    f'Train - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Test - Mean Cross Validation Score': np.nan,\n",
                "    f'Test - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    f'Test - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Explained Variance': np.nan,\n",
                "    'Accuracy': np.nan,\n",
                "    'Balanced Accuracy': np.nan,\n",
                "    'Precision': np.nan,\n",
                "    'Average Precision': np.nan,\n",
                "    'Recall': np.nan,\n",
                "    'F1-score': np.nan,\n",
                "    'Matthews Correlation Coefficient': np.nan,\n",
                "    'Brier Score': np.nan,\n",
                "    'Fowlkes–Mallows Index': np.nan,\n",
                "    'R2 Score': np.nan,\n",
                "    'ROC': np.nan,\n",
                "    'AUC': np.nan,\n",
                "    'Log Loss/Cross Entropy': np.nan,\n",
                "    'Cohen’s Kappa': np.nan,\n",
                "    'Geometric Mean': np.nan,\n",
                "    'Classification Report': np.nan,\n",
                "    'Imbalanced Classification Report': np.nan,\n",
                "    'Confusion Matrix': np.nan,\n",
                "    'Normalized Confusion Matrix': np.nan,\n",
                "}\n",
                "\n",
                "# Transformer variables\n",
                "max_length = 512\n",
                "returned_tensor = 'pt'\n",
                "cpu_counts = torch.multiprocessing.cpu_count()\n",
                "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available(\n",
                ") else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "device_name = str(device.type)\n",
                "print(f'Using {device_name.upper()}')\n",
                "# Set random seed\n",
                "random_state = 42\n",
                "random.seed(random_state)\n",
                "np.random.seed(random_state)\n",
                "torch.manual_seed(random_state)\n",
                "cores = multiprocessing.cpu_count()\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "55afc383",
            "metadata": {},
            "source": [
                "### Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f15e44f8",
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_df_full_summary_excel(\n",
                "    df_full_summary,\n",
                "    title,\n",
                "    text_to_add_list,\n",
                "    file_save_path,\n",
                "    sheet_name=None,\n",
                "    startrow=None,\n",
                "    startcol=None,\n",
                "):\n",
                "    if sheet_name is None:\n",
                "        sheet_name = 'All'\n",
                "    if startrow is None:\n",
                "        startrow = 1\n",
                "    if startcol is None:\n",
                "        startcol = 1\n",
                "\n",
                "    # Define last rows and cols locs\n",
                "    header_range = 1\n",
                "    endrow = startrow + header_range + df_full_summary.shape[0]\n",
                "    endcol = startcol + df_full_summary.shape[1]\n",
                "\n",
                "    # Remove NAs\n",
                "    df_full_summary = df_full_summary.fillna('')\n",
                "\n",
                "    # Write\n",
                "    writer = pd.ExcelWriter(f'{file_save_path}.xlsx')\n",
                "    df_full_summary.to_excel(writer, sheet_name=sheet_name, merge_cells=True, startrow=startrow, startcol=startcol)\n",
                "    workbook  = writer.book\n",
                "    worksheet = writer.sheets[sheet_name]\n",
                "    worksheet.set_column(startrow, 1, None, None, {'hidden': True}) # hide the index column\n",
                "\n",
                "    # Title\n",
                "    worksheet.merge_range(1, startcol, 1, endcol, title, workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'left', 'top': True, 'bottom': True, 'left': False, 'right': False}))\n",
                "\n",
                "    # Main body\n",
                "    body_max_row_idx, body_max_col_idx = df_full_summary.shape\n",
                "\n",
                "    for c, r in tqdm_product(range(body_max_col_idx), range(body_max_row_idx)):\n",
                "        row_to_write = startrow + header_range + r\n",
                "        col_to_write = startcol + 1 + c # 1 is for index\n",
                "        body_formats = {'num_format': '0.00', 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'text_wrap': True, 'left': False, 'right': False}\n",
                "\n",
                "        if r == 0:\n",
                "            body_formats |= {'top': True, 'bottom': True, 'left': False, 'right': False}\n",
                "            worksheet.set_column(col_to_write, col_to_write, 10)\n",
                "\n",
                "        if r == body_max_row_idx-1:\n",
                "            body_formats |= {'bottom': True}\n",
                "\n",
                "        if c == 0:\n",
                "            body_formats |= {'align': 'left'}\n",
                "            worksheet.set_column(col_to_write, col_to_write, 15)\n",
                "\n",
                "        worksheet.write(row_to_write, col_to_write, df_full_summary.iloc[r, c], workbook.add_format(body_formats))\n",
                "\n",
                "    # Add Note\n",
                "    note_format = {'italic': True, 'font_name': 'Times New Roman', 'font_size': 10, 'font_color': 'black', 'align': 'left', 'left': False, 'right': False}\n",
                "    worksheet.merge_range(endrow, startcol, endrow, endcol, 'Note.', workbook.add_format(note_format))\n",
                "    # Add text\n",
                "    for i, text in enumerate(text_to_add_list):\n",
                "        worksheet.merge_range(endrow + 1 + i , startcol, endrow + 1 + i, endcol, text, workbook.add_format(note_format))\n",
                "\n",
                "    writer.close()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96e6d325",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_full_report(\n",
                "    results, dv, dvs_name, dv_type,\n",
                "    regression_info_dict=None, regressor_order=None, text_to_add_list=None, title=None, model_names=None\n",
                "):\n",
                "    '''\n",
                "    Make a full report for a regression analysis.\n",
                "    results: statsmodels regression results object or list of results objects\n",
                "    dv: str, dependent variable name\n",
                "    '''\n",
                "\n",
                "    if regression_info_dict is None:\n",
                "        # Regression info dict\n",
                "        regression_info_dict = {\n",
                "            'Model Name': lambda x: f'{x.model.__class__.__name__}',\n",
                "            'N': lambda x: f'{int(x.nobs):d}',\n",
                "            'R-squared': lambda x: f'{x.rsquared:.5f}',\n",
                "            'R-squared Adj.': lambda x: f'{x.rsquared_adj:.5f}',\n",
                "            'Log-Likelihood': lambda x: f'{x.llf:.5f}',\n",
                "            'Pseudo R2': lambda x: f'{x.prsquared:.5f}',\n",
                "            'F': lambda x: f'{x.fvalue:.5f}',\n",
                "            'F (p-value)': lambda x: f'{x.f_pvalue:.5f}',\n",
                "            'df_model': lambda x: f'{x.df_model:.0f}',\n",
                "            'df_total': lambda x: f'{x.df_resid + x.df_model + 1:.0f}',\n",
                "            'df_resid': lambda x: f'{x.df_resid:.0f}',\n",
                "            'AIC': lambda x: f'{x.aic:.5f}',\n",
                "            'BIC': lambda x: f'{x.bic:.5f}',\n",
                "            'ICC': lambda x: f'{x.rsquared / (x.rsquared + (x.nobs - 1) * x.mse_resid):.5f}',\n",
                "            'RMSE': lambda x: f'{x.mse_resid ** 0.5:.5f}',\n",
                "            'RMSE (std)': lambda x: f'{x.mse_resid ** 0.5 / x.model.endog.std():.5f}',\n",
                "            'Omnibus': lambda x: f'{sms.omni_normtest(x.resid).statistic:.5f}',\n",
                "            'Omnibus (p-value)': lambda x: f'{sms.omni_normtest(x.resid).pvalue:.5f}',\n",
                "            'Skew': lambda x: f'{sms.jarque_bera(x.resid)[-2]:.5f}',\n",
                "            'Kurtosis': lambda x: f'{sms.jarque_bera(x.resid)[-1]:.5f}',\n",
                "            'Jarque-Bera (JB)': lambda x: f'{sms.jarque_bera(x.resid)[0]:.5f}',\n",
                "            'Jarque-Bera (p-value)': lambda x: f'{sms.jarque_bera(x.resid)[1]:.5f}',\n",
                "            'Intercept': lambda x: f'{x.params[\"const\"]:.5f}',\n",
                "            'Intercept (std)': lambda x: f'{x.bse[\"const\"]:.5f}',\n",
                "            'Intercept t': lambda x: f'{x.tvalues[\"const\"]:.5f}',\n",
                "            'Intercept t (p-value)': lambda x: f'{x.pvalues[\"const\"]:.5f}',\n",
                "            'Intercept (95% CI)': lambda x: f'{x.conf_int().loc[\"const\"][0]:.5f} - {x.conf_int().loc[\"const\"][1]:.5f}',\n",
                "            'Unstandardized Coefficent B (b)': lambda x: f'{x.params[0]:.5f}',\n",
                "            'Standard Error (SE)': lambda x: f'{x.bse[0]:.5f}',\n",
                "            'Standardized Coefficient b* (β)': lambda x: f'{x.params[0] / x.model.endog.std():.5f}',\n",
                "            't': lambda x: f'{x.tvalues[0]:.5f}',\n",
                "            't (p-value)': lambda x: f'{x.pvalues[0]:.5f}',\n",
                "            '95% CI': lambda x: f'{x.conf_int().iloc[0, 1]:.5f} - {x.conf_int().iloc[0, 1]:.5f}',\n",
                "            # 'Summary': lambda x: f'{x.summary()}',\n",
                "            # 'F (p-value - FDR)': lambda x: f'{x.f_pvalue_fdr:.5f}',\n",
                "            # 'F (p-value - Bonferroni)': lambda x: f'{x.f_pvalue_bonf:.5f}',\n",
                "            # 't (p-value - FDR)': lambda x: f'{x.pvalues_fdr[1]:.5f}',\n",
                "            # 't (p-value - Bonferroni)': lambda x: f'{x.pvalues_bonf[1]:.5f}',\n",
                "        }\n",
                "    if model_names is None:\n",
                "        if isinstance(results, list):\n",
                "            model_names = [\n",
                "                f'{results[0].model.endog_names.split(\"_\")[0] if \"_\" in results[0].model.endog_names else results[0].model.endog_names} Model {i}'\n",
                "                for i in range(len(results[0].model.endog_names))\n",
                "            ]\n",
                "            model_names[0] = model_names[0].replace('Model 0', 'Full Model')\n",
                "        else:\n",
                "            model_names = [\n",
                "                f'{results.model.endog_names.split(\"_\")[0] if \"_\" in results.model.endog_names else results.model.endog_names}'\n",
                "            ]\n",
                "\n",
                "    order_type = 'unordered' if regressor_order is None else 'ordered'\n",
                "    if text_to_add_list is None:\n",
                "        text_to_add_list = []\n",
                "        if regressor_order is not None:\n",
                "            text_to_add_list.append('Models are ordered by independent variable type.')\n",
                "\n",
                "        else:\n",
                "            text_to_add_list.append('Models are ordered by coefficient size, largest to smallest.')\n",
                "\n",
                "    if title is None:\n",
                "        title = f'{dv_type} OLS Regression {dv}'\n",
                "\n",
                "    try:\n",
                "        # Statsmodels summary_col\n",
                "        full_summary = summary_col(\n",
                "            results,\n",
                "            stars=True,\n",
                "            info_dict=regression_info_dict,\n",
                "            regressor_order=regressor_order,\n",
                "            float_format='%0.3f',\n",
                "            model_names=model_names,\n",
                "        )\n",
                "        if isinstance(results, list) and len(results) > 4:\n",
                "            full_summary.tables[0][full_summary.tables[0].filter(regex='Full Model').columns[0]].loc['Unstandardized Coefficent B (b)': '95% CI'] = ''\n",
                "\n",
                "        # Add title and notes\n",
                "        full_summary.add_title(title)\n",
                "        text_to_add_list.extend(full_summary.extra_txt)\n",
                "        for text in text_to_add_list:\n",
                "            full_summary.add_text(text)\n",
                "        # Save\n",
                "        save_name = f'{table_save_path}{dv_type} OLS Regression {dv}'\n",
                "        print(f'Saving {save_name}...')\n",
                "        df_full_summary = pd.read_html(full_summary.as_html())[0]\n",
                "        df_full_summary.to_csv(f'{save_name}.csv')\n",
                "        df_full_summary.style.to_latex(f'{save_name}.tex', hrules=True)\n",
                "        save_df_full_summary_excel(df_full_summary, title, text_to_add_list, save_name)\n",
                "\n",
                "        return full_summary\n",
                "    except IndexError:\n",
                "        return None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ad45ea49",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_standardized_coefficients(results):\n",
                "\n",
                "    # # Get standardized regression coefficients\n",
                "    # std = np.asarray(constant.std(0))\n",
                "\n",
                "    # if 'const' in results.params and 'const' in constant:\n",
                "    #     std[0] = 1\n",
                "    # tt = results.t_test(np.diag(std))\n",
                "    # tt.c_names = results.model.exog_names\n",
                "\n",
                "    # t-test\n",
                "    std = results.model.exog.std(0)\n",
                "    if 'const' in results.params:\n",
                "        std[0] = 1\n",
                "    tt = results.t_test(np.diag(std))\n",
                "    if results.model.__class__.__name__ == 'MixedLM' or 'Group Var' in results.model.exog_names:\n",
                "        offset = slice(None, -1)\n",
                "        tt.c_names = results.model.exog_names[offset]\n",
                "    else:\n",
                "        offset = slice(None, None)\n",
                "        tt.c_names = results.model.exog_names\n",
                "\n",
                "    # Make df with standardized and unstandardized coefficients\n",
                "    df_std_coef = pd.DataFrame(\n",
                "        {\n",
                "            'coef': results.params[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'std err': results.bse[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'std coef': (results.params[offset] / results.model.exog[offset].std(axis=0)).apply(lambda x: f'{x:.5f}'),\n",
                "            't': results.tvalues[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'P>|t|': results.pvalues[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            '[0.025': results.conf_int()[0][offset].apply(lambda x: f'{x:.5f}'),\n",
                "            '0.975]': results.conf_int()[1][offset].apply(lambda x: f'{x:.5f}'),\n",
                "        }\n",
                "    )\n",
                "    # if 'Group Var' in df_std_coef.index:\n",
                "    #     df_std_coef = df_std_coef.drop('Group Var', axis='index')\n",
                "    # # Add standardized coefficients and other data from t-test\n",
                "    # df_std_coef['std coef'] = tt.effect\n",
                "    # df_std_coef['std err'] = tt.sd\n",
                "    # df_std_coef['t'] = tt.statistic\n",
                "    # df_std_coef['P>|t|'] = tt.pvalue\n",
                "    # df_std_coef['[0.025'] = tt.conf_int()[:, 0]\n",
                "    # df_std_coef['0.975]'] = tt.conf_int()[:, 1]\n",
                "    # df_std_coef['var'] = [names[i] for i in range(len(results.model.exog_names))]\n",
                "    # df_std_coef = df_std_coef.sort_values('std coef', ascending=False)\n",
                "    df_std_coef = df_std_coef.reset_index().rename(columns={'index': 'var'})\n",
                "    df_std_coef = df_std_coef.rename(\n",
                "        columns={\n",
                "            'var': 'Variable',\n",
                "            'coef': 'Unstandardized Coefficent B (b)',\n",
                "            'std err': 'Standard Error',\n",
                "            'std coef':'Standardized Coefficient b* (β)',\n",
                "            't': 't-value',\n",
                "            'P>|t|': 'p-value',\n",
                "            '[0.025': '95% CI Lower',\n",
                "            '0.975]': '95% CI Upper'\n",
                "        }\n",
                "    )\n",
                "    # Reorder columns\n",
                "    df_std_coef = df_std_coef[[\n",
                "        'Variable',\n",
                "        'Unstandardized Coefficent B (b)',\n",
                "        'Standard Error',\n",
                "        'Standardized Coefficient b* (β)',\n",
                "        't-value',\n",
                "        'p-value',\n",
                "        '95% CI Lower',\n",
                "        '95% CI Upper'\n",
                "    ]]\n",
                "\n",
                "    return tt, df_std_coef\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "fd32c435",
            "metadata": {},
            "source": [
                "### READ DATA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "41f33a6e",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(f'{data_dir}df_manual_len.txt', 'r') as f:\n",
                "    df_manual_len = int(f.read())\n",
                "# HACK\n",
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_training.pkl')\n",
                "assert len(df_manual) == df_manual_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_manual_len} BUT IS OF LENGTH {len(df_manual)}'\n",
                "print(f'Dataframe df_manual_for_training loaded with shape: {df_manual.shape}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2ebecb79",
            "metadata": {},
            "source": [
                "## Check biased and unbiased regressions models using human annotated and classifier predicted Warmth and Competence\n",
                "Source: https://mochenyang.github.io/mochenyangblog/research/2022/01/10/ForestIV.html"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "908bc3df",
            "metadata": {},
            "outputs": [],
            "source": [
                "# HACK\n",
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
                "df_manual = pd.merge(\n",
                "    df_manual[['Job ID', 'Job Description spacy_sentencized', 'Warmth', 'Competence']],\n",
                "    df_jobs[['Job ID', 'Job Description spacy_sentencized', 'Warmth', 'Competence'] + ivs_dummy_perc_and_perc_interactions + controls[:2]],\n",
                "    how='inner', on=['Job ID', 'Job Description spacy_sentencized'], suffixes=('', '_predicted')\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fef6a1ad",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b31c2ef4",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual.describe()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4617c4d7",
            "metadata": {},
            "source": [
                "#### Check that actual human annotated and classifier predicted warmth and competence are different"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual['Warmth'].equals(df_manual['Warmth_predicted'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e869c471",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual['Competence'].equals(df_manual['Competence_predicted'])\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5499a77b",
            "metadata": {},
            "source": [
                "### Unbiased and Biased Warmth and CompetenceOLS regression with human annotated actual values as DV and all IVs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "769c4726",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compare_actual_and_predicted(df, endog_names_dict=None):\n",
                "    if endog_names_dict is None:\n",
                "        endog_names_dict = defaultdict(lambda: defaultdict())\n",
                "    exog_names = ivs_dummy_perc_and_perc_interactions + controls[:2]\n",
                "    exog = df[exog_names]\n",
                "    constant = sm.add_constant(exog)\n",
                "\n",
                "    for dv in dvs:\n",
                "        endog_names_dict[dv] = {\n",
                "            'Unbiased': {'endog_names': dv},\n",
                "            'Biased': {'endog_names': f'{dv}_predicted'}\n",
                "        }\n",
                "\n",
                "        for dv_type, endog_names in endog_names_dict[dv].items():\n",
                "            endog = df[endog_names['endog_names']]\n",
                "            model = sm.OLS(endog=endog, exog=constant, data=df)\n",
                "            results = model.fit()\n",
                "            tt, df_std_coef = get_standardized_coefficients(results)\n",
                "            full_summary = make_full_report(\n",
                "                results, dv, dvs_name=dv, dv_type=dv_type, title=f'{dv_type} OLS Regression {dv}'\n",
                "            )\n",
                "            endog_names_dict[dv][dv_type]['R-squared'] = results.rsquared\n",
                "            endog_names_dict[dv][dv_type]['Results'] = results\n",
                "\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "            print(f'{dv_type.upper()} {dv}\\n')\n",
                "            print('-'*20)\n",
                "            print('\\n')\n",
                "            print(f'{dv_type.upper()} SUMMARY RESULTS:')\n",
                "            print(results.summary())\n",
                "            print(full_summary)\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "            print(f'{dv_type.upper()} STANDARDIZED BETA REGRESSION COEFFICIENTS FOR {dv}:\\n{df_std_coef}')\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "\n",
                "            save_name = f'{table_save_path}{dv_type} OLS Regression {dv}'\n",
                "            df_summary_results = pd.DataFrame(csv.reader(results.summary().as_csv().split('\\n'), delimiter=','))\n",
                "            df_summary_results.to_csv(f'{save_name}.csv')\n",
                "            df_summary_results.style.to_latex(f'{save_name}.tex', hrules=True)\n",
                "            df_std_coef.to_csv(f'{save_name} - standardized coefficients.csv')\n",
                "            df_std_coef.style.to_latex(f'{save_name} - standardized coefficients.tex', hrules=True)\n",
                "\n",
                "        if endog_names_dict[dv][list(endog_names_dict[dv])[0]]['R-squared'] != endog_names_dict[dv][list(endog_names_dict[dv])[-1]]['R-squared']:\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "            print(f'{dv} {list(endog_names_dict[dv])[0]} R-Squared does not equal {list(endog_names_dict[dv])[-1]} R-Squared:')\n",
                "            print(f'{dv} {list(endog_names_dict[dv])[0]} = {endog_names_dict[dv][list(endog_names_dict[dv])[0]][\"R-squared\"]:.3f}')\n",
                "            print(f'{dv} {list(endog_names_dict[dv])[-1]} = {endog_names_dict[dv][list(endog_names_dict[dv])[-1]][\"R-squared\"]:.3f}')\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "\n",
                "    return dict(endog_names_dict)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "08d54a15",
            "metadata": {},
            "outputs": [],
            "source": [
                "endog_names_dict = compare_actual_and_predicted(df_manual)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "33e3488f",
            "metadata": {},
            "outputs": [],
            "source": [
                "endog_names_dict\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b9202851",
            "metadata": {},
            "source": [
                "# Make Instrumental Variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "37761293",
            "metadata": {},
            "outputs": [],
            "source": [
                "n_trees = 100\n",
                "train_ratio = 0.75\n",
                "test_ratio = 0.10\n",
                "validation_ratio = 0.15\n",
                "test_split = test_size = 1 - train_ratio\n",
                "validation_split = test_ratio / (test_ratio + validation_ratio)\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "col = 'Warmth'\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f2788aab",
            "metadata": {},
            "outputs": [],
            "source": [
                "train, test = train_test_split(df_manual, train_size=1-test_split, test_size=test_split, random_state=random_state)\n",
                "val, test = train_test_split(test, test_size=validation_split, random_state=random_state)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a1e98392",
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train = np.array(list(train[text_col].astype('str').values))\n",
                "y_train = column_or_1d(train[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "X_test = np.array(list(test[text_col].astype('str').values))\n",
                "y_test = column_or_1d(test[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "X_val = np.array(list(val[text_col].astype('str').values))\n",
                "y_val = column_or_1d(val[col].astype('int64').values.tolist(), warn=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bb10001b",
            "metadata": {},
            "outputs": [],
            "source": [
                "bow_\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "653547a7",
            "metadata": {},
            "outputs": [],
            "source": [
                "bow_params\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f65590b3",
            "metadata": {},
            "outputs": [],
            "source": [
                "rfr_ = RandomForestRegressor()\n",
                "rfr_params = {\n",
                "    'max_depth': [2, 5, 10],\n",
                "    'n_estimators': [50, 100, 150],\n",
                "    'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
                "    'random_state': [random_state],\n",
                "}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7b871ce8",
            "metadata": {},
            "outputs": [],
            "source": [
                "steps = [\n",
                "    (bow_.__class__.__name__, bow_),\n",
                "    (rfr_.__class__.__name__, rfr)\n",
                "]\n",
                "param_grid = {\n",
                "    **bow_params,\n",
                "    **rfr_params,\n",
                "}\n",
                "pipe = Pipeline(steps=steps)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6e80376f",
            "metadata": {},
            "outputs": [],
            "source": [
                "grid_search = GridSearchCV(\n",
                "    estimator=pipe,\n",
                "    param_grid=param_grid,\n",
                "    cv=cv,\n",
                "    n_jobs=n_jobs,\n",
                "    return_train_score=True,\n",
                "    verbose=1,\n",
                "    error_score='raise',\n",
                "    refit=refit,\n",
                "    random_state=random_state,\n",
                "    scoring=scorers['recall_score'],\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "551e1d2b",
            "metadata": {},
            "outputs": [],
            "source": [
                "with joblib.parallel_backend(backend='loky', n_jobs=n_jobs):\n",
                "    # Fit SearchCV\n",
                "    print('Fitting GridSearchCV')\n",
                "    searchcv = grid_search.fit(np.concatenate((X_train, X_val), axis=0), np.concatenate((y_train, y_val), axis=0))\n",
                "\n",
                "# Reidentify and name best estimator and params\n",
                "estimator = searchcv.best_estimator_\n",
                "cv_results = searchcv.cv_results_\n",
                "vectorizer = estimator[0]\n",
                "vectorizer_params = vectorizer.get_params()\n",
                "vectorizer_name = vectorizer.__class__.__name__\n",
                "selector = estimator[1]\n",
                "selector_params = selector.get_params()\n",
                "selector_name = selector.__class__.__name__\n",
                "classifier = estimator[-1]\n",
                "classifier_params = classifier.get_params()\n",
                "classifier_name = classifier.__class__.__name__\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a3cfe9b5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vecotrize X_train and X_test using TfidfVectorizer\n",
                "vecotorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), lowercase=True)\n",
                "X_train = vecotorizer.fit_transform(X_train).toarray()\n",
                "X_test = vecotorizer.fit_transform(X_test).toarray()\n",
                "X_val = vecotorizer.fit_transform(X_val).toarray()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c8e65b07",
            "metadata": {},
            "outputs": [],
            "source": [
                "estimator = RandomForestRegressor(n_estimators=n_trees, random_state=random_state)\n",
                "estimator.fit(X_train, y_train)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9cab0962",
            "metadata": {},
            "outputs": [],
            "source": [
                "actual = y_val\n",
                "pred_unlabel = estimator.predict(X_train)\n",
                "indiv_pred_unlabel = [tree.predict(X_train) for tree in estimator.estimators_]\n",
                "aggr_pred_unlabel = np.mean(indiv_pred_unlabel, axis=0)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "51453190",
            "metadata": {},
            "outputs": [],
            "source": [
                "pred_test = estimator.predict(X_test)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4bfe84df",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Automating_Equity1_3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        },
        "varInspector": {
            "cols": {
                "lenName": 16,
                "lenType": 16,
                "lenVar": 40
            },
            "kernels_config": {
                "python": {
                    "delete_cmd_postfix": "",
                    "delete_cmd_prefix": "del ",
                    "library": "var_list.py",
                    "varRefreshCmd": "print(var_dic_list())"
                },
                "r": {
                    "delete_cmd_postfix": ") ",
                    "delete_cmd_prefix": "rm(",
                    "library": "var_list.r",
                    "varRefreshCmd": "cat(var_dic_list()) "
                }
            },
            "types_to_exclude": [
                "module",
                "function",
                "builtin_function_or_method",
                "instance",
                "_Feature"
            ],
            "window_display": false
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
