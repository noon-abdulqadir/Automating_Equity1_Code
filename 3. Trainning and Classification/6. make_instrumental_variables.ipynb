{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "50d4c434",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "if code_dir_name not in str(Path.cwd()).split('/')[-1]:\n",
                "    for _ in range(5):\n",
                "\n",
                "        parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "        if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "            code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "            if code_dir is not None:\n",
                "                break\n",
                "else:\n",
                "    code_dir = str(Path.cwd())\n",
                "sys.path.append(code_dir)\n",
                "\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fef3f604",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from estimators_get_pipe import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from setup_module.forestIV import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e3936e59",
            "metadata": {},
            "source": [
                "### Set variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3b9d1a7b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Variables\n",
                "method = 'Supervised'\n",
                "classifiers_type = 'all'\n",
                "if classifiers_type == 'nonlinear':\n",
                "    classifiers_pipe = classifiers_pipe_nonlinear\n",
                "elif classifiers_type == 'linear':\n",
                "    classifiers_pipe = classifiers_pipe_linear\n",
                "elif classifiers_type == 'ensemble':\n",
                "    classifiers_pipe = classifiers_pipe_ensemble\n",
                "elif classifiers_type == 'all':\n",
                "    classifiers_pipe = classifiers_pipe\n",
                "\n",
                "results_save_path = f'{models_save_path}{method} Results/'\n",
                "with open(f'{data_dir}{method}_results_save_path.txt', 'w') as f:\n",
                "    f.write(results_save_path)\n",
                "if not os.path.exists(results_save_path):\n",
                "    os.makedirs(results_save_path)\n",
                "done_xy_save_path = f'{results_save_path}Search+Xy/'\n",
                "with open(f'{data_dir}{method}_done_xy_save_path.txt', 'w') as f:\n",
                "    f.write(done_xy_save_path)\n",
                "if not os.path.exists(done_xy_save_path):\n",
                "    os.makedirs(done_xy_save_path)\n",
                "\n",
                "t = time.time()\n",
                "n_jobs = -1\n",
                "n_splits = 10\n",
                "n_repeats = 3\n",
                "random_state = 42\n",
                "refit = True\n",
                "class_weight = 'balanced'\n",
                "cv = RepeatedStratifiedKFold(\n",
                "    n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
                ")\n",
                "scoring = 'recall'\n",
                "scores = [\n",
                "    'recall', 'accuracy', 'f1', 'roc_auc',\n",
                "    'explained_variance', 'matthews_corrcoef'\n",
                "]\n",
                "scorers = {\n",
                "    'precision_score': make_scorer(precision_score, zero_division=0),\n",
                "    'recall_score': make_scorer(recall_score, zero_division=0),\n",
                "    'accuracy_score': make_scorer(accuracy_score, zero_division=0),\n",
                "}\n",
                "analysis_columns = ['Warmth', 'Competence']\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "metrics_dict = {\n",
                "    f'{scoring.title()} Best Score': np.nan,\n",
                "    f'{scoring.title()} Best Threshold': np.nan,\n",
                "    'Train - Mean Cross Validation Score': np.nan,\n",
                "    f'Train - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    f'Train - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Test - Mean Cross Validation Score': np.nan,\n",
                "    f'Test - Mean Cross Validation - {scoring.title()}': np.nan,\n",
                "    f'Test - Mean Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Explained Variance': np.nan,\n",
                "    'Accuracy': np.nan,\n",
                "    'Balanced Accuracy': np.nan,\n",
                "    'Precision': np.nan,\n",
                "    'Average Precision': np.nan,\n",
                "    'Recall': np.nan,\n",
                "    'F1-score': np.nan,\n",
                "    'Matthews Correlation Coefficient': np.nan,\n",
                "    'Brier Score': np.nan,\n",
                "    'Fowlkes–Mallows Index': np.nan,\n",
                "    'R2 Score': np.nan,\n",
                "    'ROC': np.nan,\n",
                "    'AUC': np.nan,\n",
                "    'Log Loss/Cross Entropy': np.nan,\n",
                "    'Cohen’s Kappa': np.nan,\n",
                "    'Geometric Mean': np.nan,\n",
                "    'Classification Report': np.nan,\n",
                "    'Imbalanced Classification Report': np.nan,\n",
                "    'Confusion Matrix': np.nan,\n",
                "    'Normalized Confusion Matrix': np.nan,\n",
                "}\n",
                "\n",
                "# Transformer variables\n",
                "max_length = 512\n",
                "returned_tensor = 'pt'\n",
                "cpu_counts = torch.multiprocessing.cpu_count()\n",
                "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available(\n",
                ") else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "device_name = str(device.type)\n",
                "print(f'Using {device_name.upper()}')\n",
                "# Set random seed\n",
                "random_state = 42\n",
                "random.seed(random_state)\n",
                "np.random.seed(random_state)\n",
                "torch.manual_seed(random_state)\n",
                "cores = multiprocessing.cpu_count()\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "55afc383",
            "metadata": {},
            "source": [
                "### Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f15e44f8",
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_df_full_summary_excel(\n",
                "    df_full_summary,\n",
                "    title,\n",
                "    text_to_add_list,\n",
                "    file_save_path,\n",
                "    sheet_name=None,\n",
                "    startrow=None,\n",
                "    startcol=None,\n",
                "):\n",
                "    if sheet_name is None:\n",
                "        sheet_name = 'All'\n",
                "    if startrow is None:\n",
                "        startrow = 1\n",
                "    if startcol is None:\n",
                "        startcol = 1\n",
                "\n",
                "    # Define last rows and cols locs\n",
                "    header_range = 1\n",
                "    endrow = startrow + header_range + df_full_summary.shape[0]\n",
                "    endcol = startcol + df_full_summary.shape[1]\n",
                "\n",
                "    # Remove NAs\n",
                "    df_full_summary = df_full_summary.fillna('')\n",
                "\n",
                "    # Write\n",
                "    writer = pd.ExcelWriter(f'{file_save_path}.xlsx')\n",
                "    df_full_summary.to_excel(writer, sheet_name=sheet_name, merge_cells=True, startrow=startrow, startcol=startcol)\n",
                "    workbook  = writer.book\n",
                "    worksheet = writer.sheets[sheet_name]\n",
                "    worksheet.set_column(startrow, 1, None, None, {'hidden': True}) # hide the index column\n",
                "\n",
                "    # Title\n",
                "    worksheet.merge_range(1, startcol, 1, endcol, title, workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'left', 'top': True, 'bottom': True, 'left': False, 'right': False}))\n",
                "\n",
                "    # Main body\n",
                "    body_max_row_idx, body_max_col_idx = df_full_summary.shape\n",
                "\n",
                "    for c, r in tqdm_product(range(body_max_col_idx), range(body_max_row_idx)):\n",
                "        row_to_write = startrow + header_range + r\n",
                "        col_to_write = startcol + 1 + c # 1 is for index\n",
                "        body_formats = {'num_format': '0.00', 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'text_wrap': True, 'left': False, 'right': False}\n",
                "\n",
                "        if r == 0:\n",
                "            body_formats |= {'top': True, 'bottom': True, 'left': False, 'right': False}\n",
                "            worksheet.set_column(col_to_write, col_to_write, 10)\n",
                "\n",
                "        if r == body_max_row_idx-1:\n",
                "            body_formats |= {'bottom': True}\n",
                "\n",
                "        if c == 0:\n",
                "            body_formats |= {'align': 'left'}\n",
                "            worksheet.set_column(col_to_write, col_to_write, 15)\n",
                "\n",
                "        worksheet.write(row_to_write, col_to_write, df_full_summary.iloc[r, c], workbook.add_format(body_formats))\n",
                "\n",
                "    # Add Note\n",
                "    note_format = {'italic': True, 'font_name': 'Times New Roman', 'font_size': 10, 'font_color': 'black', 'align': 'left', 'left': False, 'right': False}\n",
                "    worksheet.merge_range(endrow, startcol, endrow, endcol, 'Note.', workbook.add_format(note_format))\n",
                "    # Add text\n",
                "    for i, text in enumerate(text_to_add_list):\n",
                "        worksheet.merge_range(endrow + 1 + i , startcol, endrow + 1 + i, endcol, text, workbook.add_format(note_format))\n",
                "\n",
                "    writer.close()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96e6d325",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_full_report(\n",
                "    results, dv, dvs_name, dv_type,\n",
                "    regression_info_dict=None, regressor_order=None, text_to_add_list=None, title=None, model_names=None\n",
                "):\n",
                "    '''\n",
                "    Make a full report for a regression analysis.\n",
                "    results: statsmodels regression results object or list of results objects\n",
                "    dv: str, dependent variable name\n",
                "    '''\n",
                "\n",
                "    if regression_info_dict is None:\n",
                "        # Regression info dict\n",
                "        regression_info_dict = {\n",
                "            'Model Name': lambda x: f'{x.model.__class__.__name__}',\n",
                "            'N': lambda x: f'{int(x.nobs):d}',\n",
                "            'R-squared': lambda x: f'{x.rsquared:.5f}',\n",
                "            'R-squared Adj.': lambda x: f'{x.rsquared_adj:.5f}',\n",
                "            'Log-Likelihood': lambda x: f'{x.llf:.5f}',\n",
                "            'Pseudo R2': lambda x: f'{x.prsquared:.5f}',\n",
                "            'F': lambda x: f'{x.fvalue:.5f}',\n",
                "            'F (p-value)': lambda x: f'{x.f_pvalue:.5f}',\n",
                "            'df_model': lambda x: f'{x.df_model:.0f}',\n",
                "            'df_total': lambda x: f'{x.df_resid + x.df_model + 1:.0f}',\n",
                "            'df_resid': lambda x: f'{x.df_resid:.0f}',\n",
                "            'AIC': lambda x: f'{x.aic:.5f}',\n",
                "            'BIC': lambda x: f'{x.bic:.5f}',\n",
                "            'ICC': lambda x: f'{x.rsquared / (x.rsquared + (x.nobs - 1) * x.mse_resid):.5f}',\n",
                "            'RMSE': lambda x: f'{x.mse_resid ** 0.5:.5f}',\n",
                "            'RMSE (std)': lambda x: f'{x.mse_resid ** 0.5 / x.model.endog.std():.5f}',\n",
                "            'Omnibus': lambda x: f'{sms.omni_normtest(x.resid).statistic:.5f}',\n",
                "            'Omnibus (p-value)': lambda x: f'{sms.omni_normtest(x.resid).pvalue:.5f}',\n",
                "            'Skew': lambda x: f'{sms.jarque_bera(x.resid)[-2]:.5f}',\n",
                "            'Kurtosis': lambda x: f'{sms.jarque_bera(x.resid)[-1]:.5f}',\n",
                "            'Jarque-Bera (JB)': lambda x: f'{sms.jarque_bera(x.resid)[0]:.5f}',\n",
                "            'Jarque-Bera (p-value)': lambda x: f'{sms.jarque_bera(x.resid)[1]:.5f}',\n",
                "            'Intercept': lambda x: f'{x.params[\"const\"]:.5f}',\n",
                "            'Intercept (std)': lambda x: f'{x.bse[\"const\"]:.5f}',\n",
                "            'Intercept t': lambda x: f'{x.tvalues[\"const\"]:.5f}',\n",
                "            'Intercept t (p-value)': lambda x: f'{x.pvalues[\"const\"]:.5f}',\n",
                "            'Intercept (95% CI)': lambda x: f'{x.conf_int().loc[\"const\"][0]:.5f} - {x.conf_int().loc[\"const\"][1]:.5f}',\n",
                "            'Unstandardized Coefficent B (b)': lambda x: f'{x.params[0]:.5f}',\n",
                "            'Standard Error (SE)': lambda x: f'{x.bse[0]:.5f}',\n",
                "            'Standardized Coefficient b* (β)': lambda x: f'{x.params[0] / x.model.endog.std():.5f}',\n",
                "            't': lambda x: f'{x.tvalues[0]:.5f}',\n",
                "            't (p-value)': lambda x: f'{x.pvalues[0]:.5f}',\n",
                "            '95% CI': lambda x: f'{x.conf_int().iloc[0, 1]:.5f} - {x.conf_int().iloc[0, 1]:.5f}',\n",
                "            # 'Summary': lambda x: f'{x.summary()}',\n",
                "            # 'F (p-value - FDR)': lambda x: f'{x.f_pvalue_fdr:.5f}',\n",
                "            # 'F (p-value - Bonferroni)': lambda x: f'{x.f_pvalue_bonf:.5f}',\n",
                "            # 't (p-value - FDR)': lambda x: f'{x.pvalues_fdr[1]:.5f}',\n",
                "            # 't (p-value - Bonferroni)': lambda x: f'{x.pvalues_bonf[1]:.5f}',\n",
                "        }\n",
                "    if model_names is None:\n",
                "        if isinstance(results, list):\n",
                "            model_names = [\n",
                "                f'{results[0].model.endog_names.split(\"_\")[0] if \"_\" in results[0].model.endog_names else results[0].model.endog_names} Model {i}'\n",
                "                for i in range(len(results[0].model.endog_names))\n",
                "            ]\n",
                "            model_names[0] = model_names[0].replace('Model 0', 'Full Model')\n",
                "        else:\n",
                "            model_names = [\n",
                "                f'{results.model.endog_names.split(\"_\")[0] if \"_\" in results.model.endog_names else results.model.endog_names}'\n",
                "            ]\n",
                "\n",
                "    order_type = 'unordered' if regressor_order is None else 'ordered'\n",
                "    if text_to_add_list is None:\n",
                "        text_to_add_list = []\n",
                "        if regressor_order is not None:\n",
                "            text_to_add_list.append('Models are ordered by independent variable type.')\n",
                "\n",
                "        else:\n",
                "            text_to_add_list.append('Models are ordered by coefficient size, largest to smallest.')\n",
                "\n",
                "    if title is None:\n",
                "        title = f'{dv_type} OLS Regression {dv}'\n",
                "\n",
                "    try:\n",
                "        # Statsmodels summary_col\n",
                "        full_summary = summary_col(\n",
                "            results,\n",
                "            stars=True,\n",
                "            info_dict=regression_info_dict,\n",
                "            regressor_order=regressor_order,\n",
                "            float_format='%0.3f',\n",
                "            model_names=model_names,\n",
                "        )\n",
                "        if isinstance(results, list) and len(results) > 4:\n",
                "            full_summary.tables[0][full_summary.tables[0].filter(regex='Full Model').columns[0]].loc['Unstandardized Coefficent B (b)': '95% CI'] = ''\n",
                "\n",
                "        # Add title and notes\n",
                "        full_summary.add_title(title)\n",
                "        text_to_add_list.extend(full_summary.extra_txt)\n",
                "        for text in text_to_add_list:\n",
                "            full_summary.add_text(text)\n",
                "        # Save\n",
                "        save_name = f'{table_save_path}{title}'\n",
                "        print(f'Saving {save_name}...')\n",
                "        df_full_summary = pd.read_html(full_summary.as_html())[0]\n",
                "        df_full_summary.to_csv(f'{save_name}.csv')\n",
                "        df_full_summary.style.to_latex(f'{save_name}.tex', hrules=True)\n",
                "        save_df_full_summary_excel(df_full_summary, title, text_to_add_list, save_name)\n",
                "\n",
                "        return full_summary\n",
                "    except IndexError:\n",
                "        return None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ad45ea49",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_standardized_coefficients(results):\n",
                "\n",
                "    # # Get standardized regression coefficients\n",
                "    # std = np.asarray(constant.std(0))\n",
                "\n",
                "    # if 'const' in results.params and 'const' in constant:\n",
                "    #     std[0] = 1\n",
                "    # tt = results.t_test(np.diag(std))\n",
                "    # tt.c_names = results.model.exog_names\n",
                "\n",
                "    # t-test\n",
                "    std = results.model.exog.std(0)\n",
                "    if 'const' in results.params:\n",
                "        std[0] = 1\n",
                "    tt = results.t_test(np.diag(std))\n",
                "    if results.model.__class__.__name__ == 'MixedLM' or 'Group Var' in results.model.exog_names:\n",
                "        offset = slice(None, -1)\n",
                "        tt.c_names = results.model.exog_names[offset]\n",
                "    else:\n",
                "        offset = slice(None, None)\n",
                "        tt.c_names = results.model.exog_names\n",
                "\n",
                "    # Make df with standardized and unstandardized coefficients\n",
                "    df_std_coef = pd.DataFrame(\n",
                "        {\n",
                "            'coef': results.params[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'std err': results.bse[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'std coef': (results.params[offset] / results.model.exog[offset].std(axis=0)).apply(lambda x: f'{x:.5f}'),\n",
                "            't': results.tvalues[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            'P>|t|': results.pvalues[offset].apply(lambda x: f'{x:.5f}'),\n",
                "            '[0.025': results.conf_int()[0][offset].apply(lambda x: f'{x:.5f}'),\n",
                "            '0.975]': results.conf_int()[1][offset].apply(lambda x: f'{x:.5f}'),\n",
                "        }\n",
                "    )\n",
                "    # if 'Group Var' in df_std_coef.index:\n",
                "    #     df_std_coef = df_std_coef.drop('Group Var', axis='index')\n",
                "    # # Add standardized coefficients and other data from t-test\n",
                "    # df_std_coef['std coef'] = tt.effect\n",
                "    # df_std_coef['std err'] = tt.sd\n",
                "    # df_std_coef['t'] = tt.statistic\n",
                "    # df_std_coef['P>|t|'] = tt.pvalue\n",
                "    # df_std_coef['[0.025'] = tt.conf_int()[:, 0]\n",
                "    # df_std_coef['0.975]'] = tt.conf_int()[:, 1]\n",
                "    # df_std_coef['var'] = [names[i] for i in range(len(results.model.exog_names))]\n",
                "    # df_std_coef = df_std_coef.sort_values('std coef', ascending=False)\n",
                "    df_std_coef = df_std_coef.reset_index().rename(columns={'index': 'var'})\n",
                "    df_std_coef = df_std_coef.rename(\n",
                "        columns={\n",
                "            'var': 'Variable',\n",
                "            'coef': 'Unstandardized Coefficent B (b)',\n",
                "            'std err': 'Standard Error',\n",
                "            'std coef':'Standardized Coefficient b* (β)',\n",
                "            't': 't-value',\n",
                "            'P>|t|': 'p-value',\n",
                "            '[0.025': '95% CI Lower',\n",
                "            '0.975]': '95% CI Upper'\n",
                "        }\n",
                "    )\n",
                "    # Reorder columns\n",
                "    df_std_coef = df_std_coef[[\n",
                "        'Variable',\n",
                "        'Unstandardized Coefficent B (b)',\n",
                "        'Standard Error',\n",
                "        'Standardized Coefficient b* (β)',\n",
                "        't-value',\n",
                "        'p-value',\n",
                "        '95% CI Lower',\n",
                "        '95% CI Upper'\n",
                "    ]]\n",
                "\n",
                "    return tt, df_std_coef\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "fd32c435",
            "metadata": {},
            "source": [
                "### READ DATA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "923fee85",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open(f'{data_dir}df_jobs_for_analysis_len.txt', 'r') as f:\n",
                "    df_jobs_len = int(f.read())\n",
                "\n",
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_for_analysis.pkl')\n",
                "assert len(df_jobs) == df_jobs_len, f'DATAFRAME MISSING DATA! DF SHOULD BE OF LENGTH {df_jobs_len} BUT IS OF LENGTH {len(df_jobs)}'\n",
                "print(f'Dataframe df_jobs_for_analysis loaded with shape: {df_jobs.shape}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aee1fd3d",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Warmth'].equals(df_jobs['Warmth_predicted'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a183fc9d",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Competence'].equals(df_jobs['Competence_predicted'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a761f93",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs[['Warmth', 'Warmth_actual']].isna().sum()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2ebecb79",
            "metadata": {},
            "source": [
                "## Check biased and unbiased regressions models using human annotated and classifier predicted Warmth and Competence\n",
                "Source: https://mochenyang.github.io/mochenyangblog/research/2022/01/10/ForestIV.html"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5499a77b",
            "metadata": {},
            "source": [
                "### Unbiased and Biased Warmth and CompetenceOLS regression with human annotated actual values as DV and all IVs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "769c4726",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compare_actual_and_predicted(df, endog_type):\n",
                "    endog_names_dict = defaultdict(lambda: defaultdict())\n",
                "    exog_names = ivs_dummy_perc_and_perc_interactions + controls[:2]\n",
                "\n",
                "    for dv in dvs:\n",
                "        if endog_type == 'pre_classification':\n",
                "            endog_names_dict[dv] = {\n",
                "                'Unbiased': {'endog_names': f'{dv}_actual'},\n",
                "                'Biased': {'endog_names': f'{dv}_predicted'}\n",
                "            }\n",
                "            df = df.loc[\n",
                "                (~df[endog_names_dict[dv]['Unbiased']['endog_names']].isna())\n",
                "                & (~df[endog_names_dict[dv]['Biased']['endog_names']].isna())\n",
                "            ]\n",
                "            print(f'Processing dataframe of length {len(df)}')\n",
                "        elif endog_type == 'post_classification':\n",
                "            if f'{dv}_aggr_unlabeled_predicted' in df.columns:\n",
                "                endog_names_dict[dv] = {\n",
                "                    'Biased': {'endog_names': f'{dv}_aggr_unlabeled_predicted'}\n",
                "                }\n",
                "                df = df.loc[\n",
                "                    (~df[endog_names_dict[dv]['Biased']['endog_names']].isna())\n",
                "                ]\n",
                "                print(f'Processing dataframe of length {len(df)}')\n",
                "            elif f'{dv}_actual' in df.columns:\n",
                "                endog_names_dict[dv] = {\n",
                "                    'Unbiased': {'endog_names': f'{dv}_actual'},\n",
                "                }\n",
                "                df = df.loc[\n",
                "                    (~df[endog_names_dict[dv]['Unbiased']['endog_names']].isna())\n",
                "                ]\n",
                "                print(f'Processing dataframe of length {len(df)}')\n",
                "\n",
                "        print(f'Analyzing {dv} {endog_names_dict[dv].keys()} Models')\n",
                "\n",
                "        exog = df[exog_names]\n",
                "        constant = sm.add_constant(exog)\n",
                "\n",
                "        for dv_type, endog_names in endog_names_dict[dv].items():\n",
                "            endog = df[endog_names['endog_names']]\n",
                "            model = sm.OLS(endog=endog, exog=constant, data=df)\n",
                "            results = model.fit()\n",
                "            tt, df_std_coef = get_standardized_coefficients(results)\n",
                "            title = f'{endog_type} {dv_type} OLS Regression {dv}'\n",
                "            full_summary = make_full_report(\n",
                "                results, dv, dvs_name=dv, dv_type=dv_type, title=title\n",
                "            )\n",
                "            endog_names_dict[dv][dv_type]['R-squared'] = results.rsquared\n",
                "            endog_names_dict[dv][dv_type]['Results'] = results\n",
                "\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "            print(f'{dv_type.upper()} {dv}\\n')\n",
                "            print('-'*20)\n",
                "            print('\\n')\n",
                "            print(f'{dv_type.upper()} SUMMARY RESULTS:')\n",
                "            print(results.summary())\n",
                "            print(full_summary)\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "            print(f'{dv_type.upper()} STANDARDIZED BETA REGRESSION COEFFICIENTS FOR {dv}:\\n{df_std_coef}')\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "\n",
                "            save_name = f'{table_save_path}{title}'\n",
                "            df_summary_results = pd.DataFrame(csv.reader(results.summary().as_csv().split('\\n'), delimiter=','))\n",
                "            df_summary_results.to_csv(f'{save_name}.csv')\n",
                "            df_summary_results.style.to_latex(f'{save_name}.tex', hrules=True)\n",
                "            df_std_coef.to_csv(f'{save_name} - standardized coefficients.csv')\n",
                "            df_std_coef.style.to_latex(f'{save_name} - standardized coefficients.tex', hrules=True)\n",
                "\n",
                "        if endog_names_dict[dv][list(endog_names_dict[dv])[0]]['R-squared'] != endog_names_dict[dv][list(endog_names_dict[dv])[-1]]['R-squared']:\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "            print(f'{dv} {list(endog_names_dict[dv])[0]} R-Squared does not equal {list(endog_names_dict[dv])[-1]} R-Squared:')\n",
                "            print(f'{dv} {list(endog_names_dict[dv])[0]} = {endog_names_dict[dv][list(endog_names_dict[dv])[0]][\"R-squared\"]:.3f}')\n",
                "            print(f'{dv} {list(endog_names_dict[dv])[-1]} = {endog_names_dict[dv][list(endog_names_dict[dv])[-1]][\"R-squared\"]:.3f}')\n",
                "            print('\\n')\n",
                "            print('-'*20)\n",
                "\n",
                "    return dict(endog_names_dict)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "08d54a15",
            "metadata": {},
            "outputs": [],
            "source": [
                "endog_names_dict_pre_classification = compare_actual_and_predicted(df_jobs, endog_type='pre_classification')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "33e3488f",
            "metadata": {},
            "outputs": [],
            "source": [
                "endog_names_dict_pre_classification\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b9202851",
            "metadata": {},
            "source": [
                "## Make RandomForestRegressor Classifier\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dcf1e9cb",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_final_indiv_and_aggr_preds(estimator, X):\n",
                "    pred = estimator.predict(X)\n",
                "    indiv_pred = [tree.predict(X) for tree in estimator.estimators_]\n",
                "    aggr_pred = np.mean(indiv_pred, axis=0)\n",
                "\n",
                "    return pred, indiv_pred, aggr_pred\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "50385c5e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_randomforest_instrumental_variable_estimator(df_jobs, cols_to_compare=None, text_col=None, n_trees=None):\n",
                "\n",
                "    if cols_to_compare is None:\n",
                "        cols_to_compare = ['Warmth_actual', 'Warmth_predicted', 'Competence_actual', 'Competence_predicted']\n",
                "    if text_col is None:\n",
                "        text_col = 'Job Description spacy_sentencized'\n",
                "    if n_trees is None:\n",
                "        n_trees = 100\n",
                "    cols_dict = defaultdict()\n",
                "    train_ratio = 0.75\n",
                "    test_ratio = 0.10\n",
                "    validation_ratio = 0.15\n",
                "    test_split = test_size = 1 - train_ratio\n",
                "    validation_split = test_ratio / (test_ratio + validation_ratio)\n",
                "\n",
                "    # Make df_jobs_unlabeled\n",
                "    df_jobs_unlabeled = df_jobs.loc[\n",
                "        (df_jobs[cols_to_compare].isna()).all(axis='columns')\n",
                "    ]\n",
                "\n",
                "    if all(df_jobs_unlabeled.isna().sum()) != 0:\n",
                "        raise IndexError('Missing data in df_jobs_labeled.')\n",
                "\n",
                "    df_jobs_unlabeled = df_jobs_unlabeled.dropna(subset=analysis_columns, how='any')\n",
                "    print(f'Dataframe df_jobs_unlabeled of length: {len(df_jobs_unlabeled)}')\n",
                "\n",
                "    # Make df_jobs_labeled\n",
                "    df_jobs_labeled = df_jobs.loc[\n",
                "        (~df_jobs[cols_to_compare].isna()).all(axis='columns')\n",
                "    ]\n",
                "\n",
                "    if all(df_jobs_labeled.isna().sum()) != 0:\n",
                "        raise IndexError('Missing data in df_jobs_labeled.')\n",
                "\n",
                "    df_jobs_labeled = df_jobs_labeled.dropna(subset=analysis_columns, how='any')\n",
                "    print(f'Dataframe df_jobs_labeled of length: {len(df_jobs_labeled)}')\n",
                "\n",
                "    # Make df labels dict\n",
                "    df_add_preds_dict = {\n",
                "        'labeled': df_jobs_labeled,\n",
                "        'unlabeled': df_jobs_unlabeled\n",
                "    }\n",
                "\n",
                "    # Split data\n",
                "    print('Splitting data...')\n",
                "    train, test = train_test_split(\n",
                "        df_jobs_labeled, train_size=1-test_split, test_size=test_split, random_state=random_state\n",
                "    )\n",
                "    print(f'Length of train dataset: {len(train)}')\n",
                "    print(f'Length of test dataset: {len(test)}')\n",
                "    cols_dict = {\n",
                "        'train': train, 'test': test,\n",
                "    }\n",
                "\n",
                "    for col in analysis_columns:\n",
                "        assert col in df_jobs_labeled.columns, f'{col} column not found in df_jobs_labeled'\n",
                "        print('='*20)\n",
                "        print(f'Training on {col}...')\n",
                "\n",
                "        X_train = np.array(list(train[text_col].astype('str').values))\n",
                "        y_train = column_or_1d(train[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_test = np.array(list(test[text_col].astype('str').values))\n",
                "        y_test = column_or_1d(test[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_labeled = np.array(list(df_jobs_labeled[text_col].astype('str').values))\n",
                "        y_labeled = column_or_1d(df_jobs_labeled[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        X_unlabeled = np.array(list(df_jobs_unlabeled[text_col].astype('str').values))\n",
                "        y_unlabeled = column_or_1d(df_jobs_unlabeled[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "        # Vectorize using FeatueUnion\n",
                "        print(f'Vectorizing using {vectorizers_list[-1].__class__.__name__}...')\n",
                "        vectorizer = vectorizers_list[-1]\n",
                "        X_train = vectorizer.fit_transform(X_train)\n",
                "        X_test = vectorizer.transform(X_test)\n",
                "        X_labeled = vectorizer.transform(X_labeled)\n",
                "        X_unlabeled = vectorizer.transform(X_unlabeled)\n",
                "\n",
                "        # Train using RandomForestRegressor\n",
                "        print('Training using RandomForestRegressor...')\n",
                "        estimator = RandomForestRegressor(n_estimators=n_trees, random_state=random_state, n_jobs=n_jobs)\n",
                "        estimator.fit(X_train, y_train)\n",
                "\n",
                "        # Get predictions\n",
                "        print('Getting predictions...')\n",
                "        y_train_pred, indiv_y_train_pred, aggr_y_train_pred = make_final_indiv_and_aggr_preds(estimator, X_train)\n",
                "        y_test_pred, indiv_y_test_pred, aggr_y_test_pred = make_final_indiv_and_aggr_preds(estimator, X_test)\n",
                "        y_labeled_pred, indiv_y_labeled_pred, aggr_y_labeled_pred = make_final_indiv_and_aggr_preds(estimator, X_labeled)\n",
                "        y_unlabeled_pred, indiv_y_unlabeled_pred, aggr_y_unlabeled_pred = make_final_indiv_and_aggr_preds(estimator, X_unlabeled)\n",
                "\n",
                "        # Make col dict\n",
                "        cols_dict[col] = {\n",
                "            'estimator': estimator, 'vectorizer': vectorizer,\n",
                "            'X_train': X_train, 'y_train': y_train, 'y_train_pred': y_train_pred,\n",
                "            'indiv_y_train_pred': indiv_y_train_pred, 'aggr_y_train_pred': aggr_y_train_pred,\n",
                "            'X_test': X_test, 'y_test': y_test, 'y_test_pred': y_test_pred,\n",
                "            'indiv_y_test_pred': indiv_y_test_pred, 'aggr_y_test_pred': aggr_y_test_pred,\n",
                "            'X_labeled': X_labeled, 'y_labeled': y_labeled, 'y_labeled_pred': y_labeled_pred,\n",
                "            'indiv_y_labeled_pred': indiv_y_labeled_pred, 'aggr_y_labeled_pred': aggr_y_labeled_pred,\n",
                "            'X_unlabeled': X_unlabeled, 'y_unlabeled': y_unlabeled, 'y_unlabeled_pred': y_unlabeled_pred,\n",
                "            'indiv_y_unlabeled_pred': indiv_y_unlabeled_pred, 'aggr_y_unlabeled_pred': aggr_y_unlabeled_pred,\n",
                "        }\n",
                "\n",
                "        # Add columns to df\n",
                "        for df_lab, df in df_add_preds_dict.items():\n",
                "            df = pd.concat(\n",
                "                [\n",
                "                    df.reset_index(drop=True),\n",
                "                    pd.DataFrame(\n",
                "                        {\n",
                "                            f'{col}_{df_lab}_predicted': cols_dict[col][f'y_{df_lab}_pred'],\n",
                "                            f'{col}_aggr_{df_lab}_predicted': cols_dict[col][f'aggr_y_{df_lab}_pred'],\n",
                "                        }\n",
                "                    ).reset_index(drop=True),\n",
                "                    pd.DataFrame(cols_dict[col][f'indiv_y_{df_lab}_pred']).transpose().add_prefix(f'{col}_tree_').reset_index(drop=True)\n",
                "                ],\n",
                "                axis='columns'\n",
                "            )\n",
                "            cols_dict[col][f'df_jobs_{df_lab}'] = df\n",
                "\n",
                "        # Evaluate\n",
                "        print('Evaluating...')\n",
                "        score = estimator.score(X_test, y_test)\n",
                "        mae = mean_absolute_error(y_test, y_test_pred)\n",
                "        mse = mean_squared_error(y_test, y_test_pred)\n",
                "        rmse = np.sqrt(mse)\n",
                "        r2 = r2_score(y_test, y_test_pred)\n",
                "\n",
                "        print('-'*20)\n",
                "        print(f'Mean Absolute Error: {mae:3f}')\n",
                "        print(f'Mean Squared Error: {mse:3f}')\n",
                "        print(f'Root Mean Squared Error: {rmse:3f}')\n",
                "        print(f'R-squared (R^2) Score: {r2:3f}')\n",
                "        print('-'*20)\n",
                "\n",
                "    return n_trees, dict(cols_dict)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14cc0d13",
            "metadata": {},
            "outputs": [],
            "source": [
                "n_trees, cols_dict = get_randomforest_instrumental_variable_estimator(df_jobs)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59b7ec3b",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict.keys()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b3221c1c",
            "metadata": {},
            "outputs": [],
            "source": [
                "list_columns = [c for c in df_jobs.columns if df_jobs[c].apply(lambda x: isinstance(x, list)).any()]\n",
                "non_list_columns = [c for c in df_jobs.columns if not df_jobs[c].apply(lambda x: isinstance(x, list)).any()]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a993ee38",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Warmth']['df_jobs_labeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "12167868",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Competence']['df_jobs_labeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2e23e857",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled = cols_dict['Warmth']['df_jobs_labeled']\\\n",
                "    .drop(columns=list_columns)\\\n",
                "    .merge(\n",
                "        cols_dict['Competence']['df_jobs_labeled'],\n",
                "        how='outer',\n",
                "        on=non_list_columns\n",
                "    ).dropna(axis='columns', how='all')\\\n",
                "        .reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a3b9868a",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fa150d05",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_labeled.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "25567198",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Warmth']['df_jobs_unlabeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "eff0ccb5",
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_dict['Competence']['df_jobs_unlabeled'].info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e8597d57",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled = cols_dict['Warmth']['df_jobs_unlabeled']\\\n",
                "    .drop(columns=list_columns)\\\n",
                "        .merge(\n",
                "            cols_dict['Competence']['df_jobs_unlabeled'],\n",
                "            how='outer',\n",
                "            on=non_list_columns\n",
                "        ).dropna(axis='columns', how='all')\\\n",
                "            .reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "57fd9028",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cb3b5c70",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_unlabeled.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4fa26dae",
            "metadata": {},
            "outputs": [],
            "source": [
                "train = cols_dict['train']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19353659",
            "metadata": {},
            "outputs": [],
            "source": [
                "train.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "09a72253",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_train = train.copy()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2adff07d",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_train.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "615db4ea",
            "metadata": {},
            "outputs": [],
            "source": [
                "test = cols_dict['test']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7a7cfb3f",
            "metadata": {},
            "outputs": [],
            "source": [
                "test.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9dbf219e",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test = test\\\n",
                "    .drop(columns=list_columns)\\\n",
                "    .merge(\n",
                "        df_jobs_labeled,\n",
                "        how='inner',\n",
                "        on=non_list_columns\n",
                "    ).reset_index(drop=True)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6b76d98f",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "47f90db7",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_test.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "48060e42",
            "metadata": {},
            "source": [
                "### Make unbiased and biased models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ae3352a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uniased model\n",
                "endog_names_dict_post_labeled_classification = compare_actual_and_predicted(df_jobs_labeled, endog_type='post_classification')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "68f95899",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Biased model\n",
                "endog_names_dict_post_unlabeled_classification = compare_actual_and_predicted(df_jobs_unlabeled, endog_type='post_classification')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1454b793",
            "metadata": {},
            "outputs": [],
            "source": [
                "endog_names_dict_post_labeled_classification\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "15ca3e62",
            "metadata": {},
            "outputs": [],
            "source": [
                "endog_names_dict_post_unlabeled_classification\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a1a9e627",
            "metadata": {},
            "source": [
                "# Make instrumental Variable"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0707e44c",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction = pd.concat([df_jobs_labeled, df_jobs_unlabeled], axis='index')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c8c27cbc",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1235f58a",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs_for_correction.head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b0b1d321",
            "metadata": {},
            "outputs": [],
            "source": [
                "def hotelling(beta_IV, vcov_IV, model_unbias):\n",
                "    b_diff = beta_IV - model_unbias.params\n",
                "    var_diff = vcov_IV + model_unbias.cov_params()\n",
                "    return float(np.dot(b_diff, np.dot(np.linalg.inv(var_diff), b_diff)))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f32a9c65",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_corrs(lhs, rhs):\n",
                "    return np.abs(np.corrcoef(lhs, rhs).mean())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a230d09b",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_formula_endog_exog_instrument(regressor, control, IVs, var, type, data):\n",
                "    regressor_ = regressor.replace('%', '').replace(' ', '_')\n",
                "    control_ = [c.replace('%', '').replace(' ', '_') for c in control]\n",
                "    IVs_ = [i.replace('%', '').replace(' ', '_') for i in IVs]\n",
                "    var_ = var.replace('%', '').replace(' ', '_')\n",
                "\n",
                "    if control:\n",
                "        if type == 'XZ':\n",
                "            formula_str = f'{regressor_} ~ {\" + \".join(IVs_)}'\n",
                "            endog_names = regressor\n",
                "            exog_names = IVs\n",
                "            instrument_names = None\n",
                "        elif type == 'YX':\n",
                "            formula_str = f'{var_} ~ {regressor_} + {\" + \".join(control_)}'\n",
                "            endog_names = var\n",
                "            exog_names = [regressor] + control\n",
                "            instrument_names = None\n",
                "        elif type == 'all':\n",
                "            formula_str = f'{var_} ~ {regressor_} + {\" + \".join(control_)} | {\" + \".join(IVs_)} + {\" + \".join(control_)}'\n",
                "            endog_names = var\n",
                "            exog_names = [regressor] + control\n",
                "            instrument_names = IVs + control\n",
                "    elif type == 'XZ':\n",
                "        formula_str = f'{regressor_} ~ {\" + \".join(IVs_)}'\n",
                "        endog_names = regressor\n",
                "        exog_names = IVs\n",
                "        instrument_names = None\n",
                "    elif type == 'YX':\n",
                "        formula_str = f'{var_} ~ {regressor_}'\n",
                "        endog_names = var\n",
                "        exog_names = regressor\n",
                "    elif type == 'all':\n",
                "        formula_str = f'{var_} ~ {regressor_} | {\" + \".join(IVs_)}'\n",
                "        endog_names = var\n",
                "        exog_names = regressor\n",
                "        instrument_names = IVs\n",
                "\n",
                "    endog = data[endog_names]\n",
                "    exog = data[exog_names]\n",
                "    instrument = data[instrument_names]\n",
                "    constant = sm.add_constant(exog)\n",
                "\n",
                "    formula_data = data.copy()\n",
                "    formula_data.columns = formula_data.columns.str.replace('%', '').str.replace(' ', '_')\n",
                "\n",
                "    try:\n",
                "        ols_model = smf.ols(formula=formula_str, data=formula_data)\n",
                "    except:\n",
                "        ols_model = sm.OLS(endog=endog, exog=exog, data=data)\n",
                "\n",
                "    return formula_data, formula_str, ols_model, endog_names, endog, exog_names, exog, instrument_names, instrument, constant\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b01bf3de",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to select strong IVs using Lasso\n",
                "def lasso_select_strong(data_unlabel, regressor, candidates):\n",
                "    formula_data = data_unlabel.copy()\n",
                "    formula_data.columns = formula_data.columns.str.replace('%', '').str.replace(' ', '_')\n",
                "    if len(candidates) != 0:\n",
                "        formula_str = f'{regressor.replace(\"%\", \"\").replace(\" \", \"_\")} ~ {\" + \".join([c.replace(\"%\", \"\").replace(\" \", \"_\") for c in candidates])}'\n",
                "        y = formula_data[regressor]\n",
                "        X = formula_data[candidates]\n",
                "\n",
                "        lasso = LassoCV(cv=5)\n",
                "        lasso.fit(X, y)\n",
                "        selection = lasso.coef_ != 0\n",
                "        return np.array(candidates)[selection]\n",
                "    else:\n",
                "        return candidates\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e1df672e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to select valid IVs using Lasso\n",
                "def lasso_select_valid(col, data_test, regressor, candidates):\n",
                "    if len(data_test) == 0 or len(candidates) == 0:\n",
                "        return candidates\n",
                "    focal_pred = data_test[regressor]\n",
                "    others_pred = data_test[candidates]\n",
                "    actual = data_test[f'{col}_actual']\n",
                "    focal_error = focal_pred - actual\n",
                "\n",
                "    lasso = LassoCV(cv=5)\n",
                "    lasso.fit(others_pred, focal_error)\n",
                "    invalid = lasso.coef_ == 0\n",
                "    return np.array(candidates)[~invalid]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5bb39123",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to perform Lasso selection for validity and strength\n",
                "def lasso_select(col, data_test, data_unlabel, ntree, regressor, iterative):\n",
                "    candidates = [f'{col}_tree_{i}' for i in range(0, ntree) if f'{col}_tree_{i}' != regressor]\n",
                "\n",
                "    def get_corrs(lhs, rhs):\n",
                "        return np.abs(np.corrcoef(lhs.values, rhs.values.transpose()).mean())\n",
                "\n",
                "    pp_abs_before = get_corrs(data_unlabel[regressor], data_unlabel[candidates])\n",
                "    pe_abs_before = get_corrs((data_test[regressor] - data_test[f'{col}_actual']), data_test[candidates])\n",
                "\n",
                "    if iterative:\n",
                "        IV_valid = lasso_select_valid(col, data_test, regressor, candidates)\n",
                "        IVs = lasso_select_strong(data_unlabel, regressor, IV_valid)\n",
                "        while len(IVs) != len(candidates):\n",
                "            candidates = IVs\n",
                "            IV_valid = lasso_select_valid(col, data_test, regressor, candidates)\n",
                "            IVs = lasso_select_strong(data_unlabel, regressor, IV_valid)\n",
                "    else:\n",
                "        IV_valid = lasso_select_valid(col, data_test, regressor, candidates)\n",
                "        IVs = lasso_select_strong(data_unlabel, regressor, IV_valid)\n",
                "\n",
                "    if len(IVs) != 0:\n",
                "        pp_abs_after = get_corrs(data_unlabel[regressor], data_unlabel[IVs])\n",
                "        pe_abs_after = get_corrs(data_test[regressor] - data_test[f'{col}_actual'], data_test[IVs])\n",
                "    else:\n",
                "        pp_abs_after = np.nan\n",
                "        pe_abs_after = np.nan\n",
                "\n",
                "    return {\n",
                "        \"IVs\": IVs,\n",
                "        \"correlations\": [pp_abs_before, pe_abs_before, pp_abs_after, pe_abs_after]\n",
                "    }\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cfca9c9e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to perform 2SLS estimation\n",
                "def perform_2sls_estimation(data_unlabel_new, regressor, var, control, IVs, family):\n",
                "    if family.__class__.__name__ == 'Gaussian' and family.link.__class__.__name__ == 'Identity':\n",
                "        (\n",
                "            formula_data, formula_str, ols_model, endog_names, endog, exog_names, exog, instrument_names, instrument, constant\n",
                "        ) = make_formula_endog_exog_instrument(\n",
                "            regressor, controls, IVs, var, 'all', data_unlabel_new\n",
                "        )\n",
                "        model_IV = IV2SLS(endog=endog, exog=constant, instrument=instrument).fit()\n",
                "    else:\n",
                "        print('Only Gaussian family implemented.')\n",
                "    return model_IV\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ecfd7d7a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ForestIV Main Function (Python implementation)\n",
                "def forest_iv(col, data_test, data_unlabel, var, control, method, ntree, model_unbias, diagnostic, select_method, family, iterative=True):\n",
                "    \"\"\"ForestIV Main Function\n",
                "    This function implements the main ForestIV approach.\n",
                "\n",
                "    Args:\n",
                "        col: Name of classified variable\n",
                "        data_test: Testing dataframe for random forest, must have a column named \"{col}_actual\" that contains the ground truth, and all trees' predictions. data_test = pd.DataFrame(test[f'{col}_indiv_pred_test'], test[f'{col}_aggr_pred_test'], f'test[f'{col}_actual])\n",
                "        data_unlabel: Unlabel dataframe for random forest, must have all trees' predictions. data_unlabel = pd.DataFrame(df_unlabeled, df_unlabeled[f'{col}_indiv_pred_unlabel], df_unlabeled[f'{col}_aggr_pred_unlabel'])\n",
                "        control: A character vector of control variable names. Pass an empty vector if there are no control variables\n",
                "        method: \"Lasso\" for ForestIV method and \"IIV\" for EnsembleIV method.\n",
                "        iterative: Whether to perform iterative IV selection or not, default to TRUE. Only relevant when method = \"Lasso\"\n",
                "        ntree: Number of trees in the random forest.\n",
                "        model_unbias: Unbiased estimation.\n",
                "        family: Model specification, same as in the family parameter in glm.\n",
                "        diagnostic: Whether to output diagnostic correlations for instrument validity and strength, default to TRUE.\n",
                "        select_method: method of IV selection. One of \"optimal\" (LASSO based), \"top3\", and \"PCA\".\n",
                "    Returns:\n",
                "        ForestIV estimation results\n",
                "    \"\"\"\n",
                "\n",
                "    result = []\n",
                "\n",
                "    for i in range(0, ntree):\n",
                "        regressor = f'{col}_tree_{i}'\n",
                "        print(f'Analyzing {regressor}/{ntree-1} trees')\n",
                "\n",
                "        if method == 'Lasso':\n",
                "            output = lasso_select(col, data_test, data_unlabel, ntree, regressor, iterative)\n",
                "            IVs = output['IVs'].tolist()\n",
                "            data_unlabel_new = data_unlabel.copy()\n",
                "\n",
                "        if method == 'IIV':\n",
                "            output = iiv_select(data_test, data_unlabel, ntree, regressor, select_method)\n",
                "            IVs = output['IVs'].tolist()\n",
                "            data_unlabel_new = output['data_unlabel_new']\n",
                "        print(f'Candidates IVs length: {len(IVs)}')\n",
                "\n",
                "        if len(IVs) != 0:\n",
                "            model_IV = perform_2sls_estimation(data_unlabel_new, regressor, var, control, IVs, family)\n",
                "            beta_IV = model_IV.params\n",
                "            vcov_IV = model_IV.cov_params()\n",
                "            se_IV = np.sqrt(np.diag(vcov_IV))\n",
                "            convergence = 0\n",
                "\n",
                "            H_stats = hotelling(beta_IV, vcov_IV, model_unbias)\n",
                "            correlations = output['correlations']\n",
                "            result.append([*beta_IV, *se_IV, H_stats, convergence, *correlations])\n",
                "\n",
                "    result = pd.DataFrame(result, columns=[f'beta_{i}' for i in range(1, len(beta_IV) + 1)] +\n",
                "                                            [f'se_{i}' for i in range(1, len(se_IV) + 1)] +\n",
                "                                            ['Hotelling', 'Convergence', 'pp_abs_before', 'pe_abs_before', 'pp_abs_after', 'pe_abs_after'])\n",
                "\n",
                "    return beta_IV, vcov_IV, model_unbias, result if diagnostic else result.iloc[:, :-4]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4fa12799",
            "metadata": {},
            "outputs": [],
            "source": [
                "beta_IV, vcov_IV, model_unbias, result = forest_iv(col='Warmth', data_test=df_jobs_test, data_unlabel=df_jobs_unlabeled, var=ivs_perc[0], control=controls[:2], method='Lasso', ntree=3, model_unbias=endog_names_dict_post_labeled_classification['Warmth']['Unbiased']['Results'], diagnostic=True, select_method='optimal', family=sm.families.Gaussian(link=sm.families.links.Identity()), iterative=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "62a37c28",
            "metadata": {},
            "outputs": [],
            "source": [
                "result\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6cce3c63",
            "metadata": {},
            "outputs": [],
            "source": [
                "# import numpy as np\n",
                "# import pandas as pd\n",
                "# from statsmodels.formula.api import ivreg\n",
                "# from statsmodels.formula.api import glm\n",
                "# from OneSampleMR import tsri\n",
                "# from ivtools import ivglm\n",
                "\n",
                "# def forest_iv(data_test, data_unlabel, control, method, iterative=True, ntree, model_unbias, family, diagnostic, select_method):\n",
                "    # \"\"\"ForestIV Main Function\n",
                "\n",
                "    # This function implements the main ForestIV approach.\n",
                "\n",
                "    # Args:\n",
                "    #     data_test: Testing dataframe for random forest, must have a column named \"actual\" that contains the ground truth, and all trees' predictions.\n",
                "    #     data_unlabel: Unlabel dataframe for random forest, must have all trees' predictions.\n",
                "    #     control: A character vector of control variable names. Pass an empty vector if there are no control variables\n",
                "    #     method: \"Lasso\" for ForestIV method and \"IIV\" for EnsembleIV method.\n",
                "    #     iterative: Whether to perform iterative IV selection or not, default to TRUE. Only relevant when method = \"Lasso\"\n",
                "    #     ntree: Number of trees in the random forest.\n",
                "    #     model_unbias: Unbiased estimation.\n",
                "    #     family: Model specification, same as in the family parameter in glm.\n",
                "    #     diagnostic: Whether to output diagnostic correlations for instrument validity and strength, default to TRUE.\n",
                "    #     select_method: method of IV selection. One of \"optimal\" (LASSO based), \"top3\", and \"PCA\".\n",
                "\n",
                "    # Returns:\n",
                "    #     ForestIV estimation results\n",
                "    # \"\"\"\n",
                "\n",
                "#     result = []\n",
                "#     for i in range(1, ntree + 1):\n",
                "#         # use i-th tree as the endogenous covariate\n",
                "#         regressor = f'X{i}'\n",
                "\n",
                "#         # IV selection\n",
                "#         if method == \"Lasso\":\n",
                "#             ivs = lasso_select(data_test, data_unlabel, iterative, ntree, regressor)\n",
                "#             data_unlabel_new = data_unlabel.copy()\n",
                "#         elif method == \"IIV\":\n",
                "#             ivs = iiv_select(data_test, data_unlabel, ntree, regressor, select_method)\n",
                "#             data_unlabel_new = ivs['data_unlabel_new']\n",
                "\n",
                "#         # 2SLS estimation\n",
                "#         if len(ivs) > 0:\n",
                "#             if family.family == \"gaussian\" and family.link == \"identity\":\n",
                "#                 model_IV = ivreg(f'{regressor} ~ {\" + \".join(ivs + control)}', data=data_unlabel_new)\n",
                "#                 beta_IV = model_IV.params\n",
                "#                 vcov_IV = model_IV.cov_params()\n",
                "#                 se_IV = np.sqrt(np.diag(vcov_IV))\n",
                "#                 convergence = 0\n",
                "#             else:\n",
                "#                 link = 'logit' if family.family == 'binomial' else 'logadd'\n",
                "#                 model_IV = tsri(f'{regressor} ~ {\" + \".join(ivs + control)}', data=data_unlabel_new, link=link)\n",
                "#                 beta_IV = model_IV.fit.params[1:-1]\n",
                "#                 vcov_IV = model_IV.fit.cov_params()[1:-1, 1:-1]\n",
                "#                 se_IV = np.sqrt(np.diag(vcov_IV))\n",
                "#                 convergence = model_IV.fit.algoInfo['convergence']\n",
                "\n",
                "#             H_stats = hotelling(beta_IV, vcov_IV, model_unbias)\n",
                "#             correlations = ivs['correlations']\n",
                "#             result.append([*beta_IV, *se_IV, H_stats, convergence, *correlations])\n",
                "\n",
                "#     if diagnostic:\n",
                "#         result = pd.DataFrame(result)\n",
                "#         result.columns = [f'beta_{i}' for i in range(1, len(beta_IV) + 1)] + [f'se_{i}' for i in range(1, len(se_IV) + 1)] + ['Hotelling', 'Convergence', 'pp_abs_before', 'pe_abs_before', 'pp_abs_after', 'pe_abs_after']\n",
                "#         return result\n",
                "#     else:\n",
                "#         result = pd.DataFrame(result)\n",
                "#         result.columns = [f'beta_{i}' for i in range(1, len(beta_IV) + 1)] + [f'se_{i}' for i in range(1, len(se_IV) + 1)] + ['Hotelling', 'Convergence']\n",
                "#         return result\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Automating_Equity1_3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        },
        "varInspector": {
            "cols": {
                "lenName": 16,
                "lenType": 16,
                "lenVar": 40
            },
            "kernels_config": {
                "python": {
                    "delete_cmd_postfix": "",
                    "delete_cmd_prefix": "del ",
                    "library": "var_list.py",
                    "varRefreshCmd": "print(var_dic_list())"
                },
                "r": {
                    "delete_cmd_postfix": ") ",
                    "delete_cmd_prefix": "rm(",
                    "library": "var_list.r",
                    "varRefreshCmd": "cat(var_dic_list()) "
                }
            },
            "types_to_exclude": [
                "module",
                "function",
                "builtin_function_or_method",
                "instance",
                "_Feature"
            ],
            "window_display": false
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
