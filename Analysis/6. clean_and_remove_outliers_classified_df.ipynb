{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26fa756",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 02:43:52.428389: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-14 02:43:52.429446: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Warning: Cannot change to a different GUI toolkit: widget. Using notebook instead.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# %%\n",
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %% [markdown]\n",
    "# ### Install packages and import\n",
    "# %%\n",
    "# #################################### PLEASE INSTALL LATEST CHROME WEBDRIVER #####################################\n",
    "# Uncomment to run as required\n",
    "# #     --install-option=\"--chromedriver-version= *.**\" \\\n",
    "#   --install-option=\"--chromedriver-checksums=4fecc99b066cb1a346035bf022607104,058cd8b7b4b9688507701b5e648fd821\"\n",
    "# %%\n",
    "# ##### COPY THE LINES IN THIS COMMENT TO THE TOP OF NEW SCRIPTS #####\n",
    "# # Function to import this package to other files\n",
    "# import os\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# code_dir = None\n",
    "# code_dir_name = 'Code'\n",
    "# unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "# for _ in range(5):\n",
    "\n",
    "#     parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "#     if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "#         code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "#         if code_dir is not None:\n",
    "#             break\n",
    "\n",
    "# main_dir = str(Path(code_dir).parents[0])\n",
    "# scraped_data = f'{code_dir}/scraped_data'\n",
    "# sys.path.append(code_dir)\n",
    "\n",
    "# from setup_module.imports import *\n",
    "# from setup_module.params import *\n",
    "# from setup_module.scraping import *\n",
    "# from setup_module.classification import *\n",
    "# from setup_module.vectorizers_classifiers import *\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "main_dir = str(Path(code_dir).parents[0])\n",
    "scraped_data = f'{code_dir}/scraped_data'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "from setup_module.imports import *\n",
    "from setup_module.params import *\n",
    "from setup_module.scraping import *\n",
    "from setup_module.classification import *\n",
    "from setup_module.vectorizers_classifiers import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib notebook\n",
    "%matplotlib widget\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da64901d",
   "metadata": {},
   "source": [
    "# Manually-annotated Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bf5158",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db72d2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing DF from MANUAL Content Analysis.\n"
     ]
    }
   ],
   "source": [
    "if analysis_df_from_manual is False:\n",
    "    print('Analyzing DF from AUTOMATED Content Analysis.')\n",
    "    df = pd.read_pickle(\n",
    "        f'{df_dir}df_classified_age_limit-{age_limit}_age_ratio-{age_ratio}_gender_ratio-{gender_ratio}.{file_save_format}'\n",
    "    )\n",
    "    df.dropna(subset=dv_cols, inplace=True)\n",
    "\n",
    "elif analysis_df_from_manual is True:\n",
    "    print('Analyzing DF from MANUAL Content Analysis.')\n",
    "    df = df_jobs_labeled\n",
    "\n",
    "    try:\n",
    "        df.drop(\n",
    "            ['Task_Mentioned', 'Task_Warmth', 'Task_Competence'],\n",
    "            axis=1,\n",
    "            inplace=True,\n",
    "        )\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "\n",
    "    # Set Age, Gender, Sectors and Language Requirements\n",
    "    if ('Gender' not in df.columns) or ('Age' not in df.columns):\n",
    "        df = set_gender_age_sects_lang(df)\n",
    "\n",
    "    # df.dropna(subset=dv_cols, inplace=True)\n",
    "\n",
    "    df.to_csv(f'{df_dir}df_manual.{file_save_format_backup}', index=False)\n",
    "\n",
    "    df.to_pickle(f'{df_dir}df_manual.{file_save_format}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1434b68e",
   "metadata": {},
   "source": [
    "### Correct dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7f2378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if analysis_df_from_manual is False:\n",
    "    df['Collection Date'] = pd.to_datetime(df['Collection Date'])\n",
    "    df = df.loc[df['Collection Date'] < '2021-05-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c80d021",
   "metadata": {},
   "source": [
    "### Clean DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83db1fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DF INFO:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6401 entries, 0 to 6400\n",
      "Data columns (total 76 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Unnamed: 0                           6401 non-null   int64  \n",
      " 1   123grams_gensim                      6401 non-null   object \n",
      " 2   123grams_gensim_abs_word_freq        6296 non-null   object \n",
      " 3   123grams_gensim_abs_word_perc        6296 non-null   object \n",
      " 4   123grams_gensim_abs_word_perc_cum    6296 non-null   object \n",
      " 5   123grams_nltk                        6401 non-null   object \n",
      " 6   123grams_nltk_abs_word_freq          6296 non-null   object \n",
      " 7   123grams_nltk_abs_word_perc          6296 non-null   object \n",
      " 8   123grams_nltk_abs_word_perc_cum      6296 non-null   object \n",
      " 9   1grams_all                           6401 non-null   object \n",
      " 10  1grams_all_abs_word_freq             6296 non-null   object \n",
      " 11  1grams_all_abs_word_perc             6296 non-null   object \n",
      " 12  1grams_all_abs_word_perc_cum         6296 non-null   object \n",
      " 13  1grams_bert                          6401 non-null   object \n",
      " 14  2grams_gensim                        6401 non-null   object \n",
      " 15  2grams_gensim_abs_word_freq          6296 non-null   object \n",
      " 16  2grams_gensim_abs_word_perc          6296 non-null   object \n",
      " 17  2grams_gensim_abs_word_perc_cum      6296 non-null   object \n",
      " 18  2grams_nltk                          6401 non-null   object \n",
      " 19  2grams_nltk_abs_word_freq            5821 non-null   object \n",
      " 20  2grams_nltk_abs_word_perc            5821 non-null   object \n",
      " 21  2grams_nltk_abs_word_perc_cum        5821 non-null   object \n",
      " 22  3grams_gensim                        6401 non-null   object \n",
      " 23  3grams_gensim_abs_word_freq          6296 non-null   object \n",
      " 24  3grams_gensim_abs_word_perc          6296 non-null   object \n",
      " 25  3grams_gensim_abs_word_perc_cum      6296 non-null   object \n",
      " 26  3grams_nltk                          6401 non-null   object \n",
      " 27  3grams_nltk_abs_word_freq            5278 non-null   object \n",
      " 28  3grams_nltk_abs_word_perc            5278 non-null   object \n",
      " 29  3grams_nltk_abs_word_perc_cum        5278 non-null   object \n",
      " 30  Age                                  6401 non-null   object \n",
      " 31  Age_Mixed                            6401 non-null   float64\n",
      " 32  Age_Num                              6401 non-null   float64\n",
      " 33  Age_Older                            6401 non-null   float64\n",
      " 34  Age_Younger                          6401 non-null   float64\n",
      " 35  Competence                           6401 non-null   int64  \n",
      " 36  Dutch Requirement                    6401 non-null   object \n",
      " 37  English Requirement                  6401 non-null   object \n",
      " 38  Gender                               6401 non-null   object \n",
      " 39  Gender_Female                        6401 non-null   float64\n",
      " 40  Gender_Male                          6401 non-null   float64\n",
      " 41  Gender_Mixed                         6401 non-null   float64\n",
      " 42  Gender_Num                           6401 non-null   float64\n",
      " 43  Job Description                      6401 non-null   object \n",
      " 44  Job Description_cleaned              6300 non-null   object \n",
      " 45  Job ID                               6401 non-null   object \n",
      " 46  Warmth                               6401 non-null   int64  \n",
      " 47  num_chars                            6401 non-null   int64  \n",
      " 48  num_punctuations                     6401 non-null   int64  \n",
      " 49  num_unique_words                     6401 non-null   int64  \n",
      " 50  num_words                            6401 non-null   int64  \n",
      " 51  sentiment                            6401 non-null   float64\n",
      " 52  2grams_gensim_dictionary             6401 non-null   object \n",
      " 53  2grams_gensim_corpus                 6401 non-null   object \n",
      " 54  2grams_gensim_tfidf                  6401 non-null   object \n",
      " 55  3grams_gensim_dictionary             6401 non-null   object \n",
      " 56  3grams_gensim_corpus                 6401 non-null   object \n",
      " 57  3grams_gensim_tfidf                  6401 non-null   object \n",
      " 58  123grams_gensim_dictionary           6401 non-null   object \n",
      " 59  123grams_gensim_corpus               6401 non-null   object \n",
      " 60  123grams_gensim_tfidf                6401 non-null   object \n",
      " 61  1grams_all_mean_w2v_embeddings       6401 non-null   object \n",
      " 62  1grams_all_mean_ft_embeddings        6401 non-null   object \n",
      " 63  2grams_nltk_mean_w2v_embeddings      6401 non-null   object \n",
      " 64  2grams_nltk_mean_ft_embeddings       6401 non-null   object \n",
      " 65  3grams_nltk_mean_w2v_embeddings      6401 non-null   object \n",
      " 66  3grams_nltk_mean_ft_embeddings       6401 non-null   object \n",
      " 67  123grams_nltk_mean_w2v_embeddings    6401 non-null   object \n",
      " 68  123grams_nltk_mean_ft_embeddings     6401 non-null   object \n",
      " 69  2grams_gensim_mean_w2v_embeddings    6401 non-null   object \n",
      " 70  2grams_gensim_mean_ft_embeddings     6401 non-null   object \n",
      " 71  3grams_gensim_mean_w2v_embeddings    6401 non-null   object \n",
      " 72  3grams_gensim_mean_ft_embeddings     6401 non-null   object \n",
      " 73  123grams_gensim_mean_w2v_embeddings  6401 non-null   object \n",
      " 74  123grams_gensim_mean_ft_embeddings   6401 non-null   object \n",
      " 75  123grams_gensim_sent2vec_embeddings  6401 non-null   object \n",
      "dtypes: float64(9), int64(7), object(60)\n",
      "memory usage: 3.7+ MB\n",
      "====================\n",
      "Gender:\n",
      "--------------------\n",
      "Gender Counts:\n",
      "Mixed Gender    5271\n",
      "Male             629\n",
      "Female           501\n",
      "Name: Gender, dtype: int64\n",
      "--------------------\n",
      "Gender Percentages:\n",
      "Mixed Gender   82.300\n",
      "Male            9.800\n",
      "Female          7.800\n",
      "Name: Gender, dtype: float64\n",
      "--------------------\n",
      "====================\n",
      "Gender_Num:\n",
      "--------------------\n",
      "Gender_Num Counts:\n",
      "2.000    5271\n",
      "3.000     629\n",
      "1.000     501\n",
      "Name: Gender_Num, dtype: int64\n",
      "--------------------\n",
      "Gender_Num Percentages:\n",
      "2.000   82.300\n",
      "3.000    9.800\n",
      "1.000    7.800\n",
      "Name: Gender_Num, dtype: float64\n",
      "--------------------\n",
      "Gender_Num Mean: 2.02\n",
      "--------------------\n",
      "Gender_Num Standard Deviation: 0.42\n",
      "====================\n",
      "Gender_Female:\n",
      "--------------------\n",
      "Gender_Female Counts:\n",
      "0.000    5900\n",
      "1.000     501\n",
      "Name: Gender_Female, dtype: int64\n",
      "--------------------\n",
      "Gender_Female Percentages:\n",
      "0.000   92.200\n",
      "1.000    7.800\n",
      "Name: Gender_Female, dtype: float64\n",
      "--------------------\n",
      "Gender_Female Mean: 0.08\n",
      "--------------------\n",
      "Gender_Female Standard Deviation: 0.27\n",
      "====================\n",
      "Gender_Mixed:\n",
      "--------------------\n",
      "Gender_Mixed Counts:\n",
      "1.000    5271\n",
      "0.000    1130\n",
      "Name: Gender_Mixed, dtype: int64\n",
      "--------------------\n",
      "Gender_Mixed Percentages:\n",
      "1.000   82.300\n",
      "0.000   17.700\n",
      "Name: Gender_Mixed, dtype: float64\n",
      "--------------------\n",
      "Gender_Mixed Mean: 0.82\n",
      "--------------------\n",
      "Gender_Mixed Standard Deviation: 0.38\n",
      "====================\n",
      "Gender_Male:\n",
      "--------------------\n",
      "Gender_Male Counts:\n",
      "0.000    5772\n",
      "1.000     629\n",
      "Name: Gender_Male, dtype: int64\n",
      "--------------------\n",
      "Gender_Male Percentages:\n",
      "0.000   90.200\n",
      "1.000    9.800\n",
      "Name: Gender_Male, dtype: float64\n",
      "--------------------\n",
      "Gender_Male Mean: 0.1\n",
      "--------------------\n",
      "Gender_Male Standard Deviation: 0.3\n",
      "====================\n",
      "Age:\n",
      "--------------------\n",
      "Age Counts:\n",
      "Mixed Age         5512\n",
      "Older Worker       580\n",
      "Younger     309\n",
      "Name: Age, dtype: int64\n",
      "--------------------\n",
      "Age Percentages:\n",
      "Mixed Age        86.100\n",
      "Older Worker      9.100\n",
      "Younger    4.800\n",
      "Name: Age, dtype: float64\n",
      "--------------------\n",
      "====================\n",
      "Age_Num:\n",
      "--------------------\n",
      "Age_Num Counts:\n",
      "2.000    5512\n",
      "1.000     580\n",
      "3.000     309\n",
      "Name: Age_Num, dtype: int64\n",
      "--------------------\n",
      "Age_Num Percentages:\n",
      "2.000   86.100\n",
      "1.000    9.100\n",
      "3.000    4.800\n",
      "Name: Age_Num, dtype: float64\n",
      "--------------------\n",
      "Age_Num Mean: 1.96\n",
      "--------------------\n",
      "Age_Num Standard Deviation: 0.37\n",
      "====================\n",
      "Age_Older:\n",
      "--------------------\n",
      "Age_Older Counts:\n",
      "0.000    5821\n",
      "1.000     580\n",
      "Name: Age_Older, dtype: int64\n",
      "--------------------\n",
      "Age_Older Percentages:\n",
      "0.000   90.900\n",
      "1.000    9.100\n",
      "Name: Age_Older, dtype: float64\n",
      "--------------------\n",
      "Age_Older Mean: 0.09\n",
      "--------------------\n",
      "Age_Older Standard Deviation: 0.29\n",
      "====================\n",
      "Age_Mixed:\n",
      "--------------------\n",
      "Age_Mixed Counts:\n",
      "1.000    5512\n",
      "0.000     889\n",
      "Name: Age_Mixed, dtype: int64\n",
      "--------------------\n",
      "Age_Mixed Percentages:\n",
      "1.000   86.100\n",
      "0.000   13.900\n",
      "Name: Age_Mixed, dtype: float64\n",
      "--------------------\n",
      "Age_Mixed Mean: 0.86\n",
      "--------------------\n",
      "Age_Mixed Standard Deviation: 0.35\n",
      "====================\n",
      "Age_Younger:\n",
      "--------------------\n",
      "Age_Younger Counts:\n",
      "0.000    6092\n",
      "1.000     309\n",
      "Name: Age_Younger, dtype: int64\n",
      "--------------------\n",
      "Age_Younger Percentages:\n",
      "0.000   95.200\n",
      "1.000    4.800\n",
      "Name: Age_Younger, dtype: float64\n",
      "--------------------\n",
      "Age_Younger Mean: 0.05\n",
      "--------------------\n",
      "Age_Younger Standard Deviation: 0.21\n",
      "\n",
      "\n",
      "\n",
      "DF INFO:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6401 entries, 0 to 6400\n",
      "Data columns (total 76 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Unnamed: 0                           6401 non-null   int64  \n",
      " 1   123grams_gensim                      6401 non-null   object \n",
      " 2   123grams_gensim_abs_word_freq        6296 non-null   object \n",
      " 3   123grams_gensim_abs_word_perc        6296 non-null   object \n",
      " 4   123grams_gensim_abs_word_perc_cum    6296 non-null   object \n",
      " 5   123grams_nltk                        6401 non-null   object \n",
      " 6   123grams_nltk_abs_word_freq          6296 non-null   object \n",
      " 7   123grams_nltk_abs_word_perc          6296 non-null   object \n",
      " 8   123grams_nltk_abs_word_perc_cum      6296 non-null   object \n",
      " 9   1grams_all                           6401 non-null   object \n",
      " 10  1grams_all_abs_word_freq             6296 non-null   object \n",
      " 11  1grams_all_abs_word_perc             6296 non-null   object \n",
      " 12  1grams_all_abs_word_perc_cum         6296 non-null   object \n",
      " 13  1grams_bert                          6401 non-null   object \n",
      " 14  2grams_gensim                        6401 non-null   object \n",
      " 15  2grams_gensim_abs_word_freq          6296 non-null   object \n",
      " 16  2grams_gensim_abs_word_perc          6296 non-null   object \n",
      " 17  2grams_gensim_abs_word_perc_cum      6296 non-null   object \n",
      " 18  2grams_nltk                          6401 non-null   object \n",
      " 19  2grams_nltk_abs_word_freq            5821 non-null   object \n",
      " 20  2grams_nltk_abs_word_perc            5821 non-null   object \n",
      " 21  2grams_nltk_abs_word_perc_cum        5821 non-null   object \n",
      " 22  3grams_gensim                        6401 non-null   object \n",
      " 23  3grams_gensim_abs_word_freq          6296 non-null   object \n",
      " 24  3grams_gensim_abs_word_perc          6296 non-null   object \n",
      " 25  3grams_gensim_abs_word_perc_cum      6296 non-null   object \n",
      " 26  3grams_nltk                          6401 non-null   object \n",
      " 27  3grams_nltk_abs_word_freq            5278 non-null   object \n",
      " 28  3grams_nltk_abs_word_perc            5278 non-null   object \n",
      " 29  3grams_nltk_abs_word_perc_cum        5278 non-null   object \n",
      " 30  Age                                  6401 non-null   object \n",
      " 31  Age_Mixed                            6401 non-null   float64\n",
      " 32  Age_Num                              6401 non-null   float64\n",
      " 33  Age_Older                            6401 non-null   float64\n",
      " 34  Age_Younger                          6401 non-null   float64\n",
      " 35  Competence                           6401 non-null   int64  \n",
      " 36  Dutch Requirement                    6401 non-null   object \n",
      " 37  English Requirement                  6401 non-null   object \n",
      " 38  Gender                               6401 non-null   object \n",
      " 39  Gender_Female                        6401 non-null   float64\n",
      " 40  Gender_Male                          6401 non-null   float64\n",
      " 41  Gender_Mixed                         6401 non-null   float64\n",
      " 42  Gender_Num                           6401 non-null   float64\n",
      " 43  Job Description                      6401 non-null   object \n",
      " 44  Job Description_cleaned              6300 non-null   object \n",
      " 45  Job ID                               6401 non-null   object \n",
      " 46  Warmth                               6401 non-null   int64  \n",
      " 47  num_chars                            6401 non-null   int64  \n",
      " 48  num_punctuations                     6401 non-null   int64  \n",
      " 49  num_unique_words                     6401 non-null   int64  \n",
      " 50  num_words                            6401 non-null   int64  \n",
      " 51  sentiment                            6401 non-null   float64\n",
      " 52  2grams_gensim_dictionary             6401 non-null   object \n",
      " 53  2grams_gensim_corpus                 6401 non-null   object \n",
      " 54  2grams_gensim_tfidf                  6401 non-null   object \n",
      " 55  3grams_gensim_dictionary             6401 non-null   object \n",
      " 56  3grams_gensim_corpus                 6401 non-null   object \n",
      " 57  3grams_gensim_tfidf                  6401 non-null   object \n",
      " 58  123grams_gensim_dictionary           6401 non-null   object \n",
      " 59  123grams_gensim_corpus               6401 non-null   object \n",
      " 60  123grams_gensim_tfidf                6401 non-null   object \n",
      " 61  1grams_all_mean_w2v_embeddings       6401 non-null   object \n",
      " 62  1grams_all_mean_ft_embeddings        6401 non-null   object \n",
      " 63  2grams_nltk_mean_w2v_embeddings      6401 non-null   object \n",
      " 64  2grams_nltk_mean_ft_embeddings       6401 non-null   object \n",
      " 65  3grams_nltk_mean_w2v_embeddings      6401 non-null   object \n",
      " 66  3grams_nltk_mean_ft_embeddings       6401 non-null   object \n",
      " 67  123grams_nltk_mean_w2v_embeddings    6401 non-null   object \n",
      " 68  123grams_nltk_mean_ft_embeddings     6401 non-null   object \n",
      " 69  2grams_gensim_mean_w2v_embeddings    6401 non-null   object \n",
      " 70  2grams_gensim_mean_ft_embeddings     6401 non-null   object \n",
      " 71  3grams_gensim_mean_w2v_embeddings    6401 non-null   object \n",
      " 72  3grams_gensim_mean_ft_embeddings     6401 non-null   object \n",
      " 73  123grams_gensim_mean_w2v_embeddings  6401 non-null   object \n",
      " 74  123grams_gensim_mean_ft_embeddings   6401 non-null   object \n",
      " 75  123grams_gensim_sent2vec_embeddings  6401 non-null   object \n",
      "dtypes: float64(9), int64(7), object(60)\n",
      "memory usage: 3.7+ MB\n",
      "====================\n",
      "Gender:\n",
      "--------------------\n",
      "Gender Counts:\n",
      "Mixed Gender    5271\n",
      "Male             629\n",
      "Female           501\n",
      "Name: Gender, dtype: int64\n",
      "--------------------\n",
      "Gender Percentages:\n",
      "Mixed Gender   82.300\n",
      "Male            9.800\n",
      "Female          7.800\n",
      "Name: Gender, dtype: float64\n",
      "--------------------\n",
      "====================\n",
      "Gender_Num:\n",
      "--------------------\n",
      "Gender_Num Counts:\n",
      "2.000    5271\n",
      "3.000     629\n",
      "1.000     501\n",
      "Name: Gender_Num, dtype: int64\n",
      "--------------------\n",
      "Gender_Num Percentages:\n",
      "2.000   82.300\n",
      "3.000    9.800\n",
      "1.000    7.800\n",
      "Name: Gender_Num, dtype: float64\n",
      "--------------------\n",
      "Gender_Num Mean: 2.02\n",
      "--------------------\n",
      "Gender_Num Standard Deviation: 0.42\n",
      "====================\n",
      "Gender_Female:\n",
      "--------------------\n",
      "Gender_Female Counts:\n",
      "0.000    5900\n",
      "1.000     501\n",
      "Name: Gender_Female, dtype: int64\n",
      "--------------------\n",
      "Gender_Female Percentages:\n",
      "0.000   92.200\n",
      "1.000    7.800\n",
      "Name: Gender_Female, dtype: float64\n",
      "--------------------\n",
      "Gender_Female Mean: 0.08\n",
      "--------------------\n",
      "Gender_Female Standard Deviation: 0.27\n",
      "====================\n",
      "Gender_Mixed:\n",
      "--------------------\n",
      "Gender_Mixed Counts:\n",
      "1.000    5271\n",
      "0.000    1130\n",
      "Name: Gender_Mixed, dtype: int64\n",
      "--------------------\n",
      "Gender_Mixed Percentages:\n",
      "1.000   82.300\n",
      "0.000   17.700\n",
      "Name: Gender_Mixed, dtype: float64\n",
      "--------------------\n",
      "Gender_Mixed Mean: 0.82\n",
      "--------------------\n",
      "Gender_Mixed Standard Deviation: 0.38\n",
      "====================\n",
      "Gender_Male:\n",
      "--------------------\n",
      "Gender_Male Counts:\n",
      "0.000    5772\n",
      "1.000     629\n",
      "Name: Gender_Male, dtype: int64\n",
      "--------------------\n",
      "Gender_Male Percentages:\n",
      "0.000   90.200\n",
      "1.000    9.800\n",
      "Name: Gender_Male, dtype: float64\n",
      "--------------------\n",
      "Gender_Male Mean: 0.1\n",
      "--------------------\n",
      "Gender_Male Standard Deviation: 0.3\n",
      "====================\n",
      "Age:\n",
      "--------------------\n",
      "Age Counts:\n",
      "Mixed Age         5512\n",
      "Older Worker       580\n",
      "Younger     309\n",
      "Name: Age, dtype: int64\n",
      "--------------------\n",
      "Age Percentages:\n",
      "Mixed Age        86.100\n",
      "Older Worker      9.100\n",
      "Younger    4.800\n",
      "Name: Age, dtype: float64\n",
      "--------------------\n",
      "====================\n",
      "Age_Num:\n",
      "--------------------\n",
      "Age_Num Counts:\n",
      "2.000    5512\n",
      "1.000     580\n",
      "3.000     309\n",
      "Name: Age_Num, dtype: int64\n",
      "--------------------\n",
      "Age_Num Percentages:\n",
      "2.000   86.100\n",
      "1.000    9.100\n",
      "3.000    4.800\n",
      "Name: Age_Num, dtype: float64\n",
      "--------------------\n",
      "Age_Num Mean: 1.96\n",
      "--------------------\n",
      "Age_Num Standard Deviation: 0.37\n",
      "====================\n",
      "Age_Older:\n",
      "--------------------\n",
      "Age_Older Counts:\n",
      "0.000    5821\n",
      "1.000     580\n",
      "Name: Age_Older, dtype: int64\n",
      "--------------------\n",
      "Age_Older Percentages:\n",
      "0.000   90.900\n",
      "1.000    9.100\n",
      "Name: Age_Older, dtype: float64\n",
      "--------------------\n",
      "Age_Older Mean: 0.09\n",
      "--------------------\n",
      "Age_Older Standard Deviation: 0.29\n",
      "====================\n",
      "Age_Mixed:\n",
      "--------------------\n",
      "Age_Mixed Counts:\n",
      "1.000    5512\n",
      "0.000     889\n",
      "Name: Age_Mixed, dtype: int64\n",
      "--------------------\n",
      "Age_Mixed Percentages:\n",
      "1.000   86.100\n",
      "0.000   13.900\n",
      "Name: Age_Mixed, dtype: float64\n",
      "--------------------\n",
      "Age_Mixed Mean: 0.86\n",
      "--------------------\n",
      "Age_Mixed Standard Deviation: 0.35\n",
      "====================\n",
      "Age_Younger:\n",
      "--------------------\n",
      "Age_Younger Counts:\n",
      "0.000    6092\n",
      "1.000     309\n",
      "Name: Age_Younger, dtype: int64\n",
      "--------------------\n",
      "Age_Younger Percentages:\n",
      "0.000   95.200\n",
      "1.000    4.800\n",
      "Name: Age_Younger, dtype: float64\n",
      "--------------------\n",
      "Age_Younger Mean: 0.05\n",
      "--------------------\n",
      "Age_Younger Standard Deviation: 0.21\n",
      "\n",
      "\n",
      "\n",
      "DF INFO:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6401 entries, 0 to 6400\n",
      "Data columns (total 76 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Unnamed: 0                           6401 non-null   int64  \n",
      " 1   123grams_gensim                      6401 non-null   object \n",
      " 2   123grams_gensim_abs_word_freq        6296 non-null   object \n",
      " 3   123grams_gensim_abs_word_perc        6296 non-null   object \n",
      " 4   123grams_gensim_abs_word_perc_cum    6296 non-null   object \n",
      " 5   123grams_nltk                        6401 non-null   object \n",
      " 6   123grams_nltk_abs_word_freq          6296 non-null   object \n",
      " 7   123grams_nltk_abs_word_perc          6296 non-null   object \n",
      " 8   123grams_nltk_abs_word_perc_cum      6296 non-null   object \n",
      " 9   1grams_all                           6401 non-null   object \n",
      " 10  1grams_all_abs_word_freq             6296 non-null   object \n",
      " 11  1grams_all_abs_word_perc             6296 non-null   object \n",
      " 12  1grams_all_abs_word_perc_cum         6296 non-null   object \n",
      " 13  1grams_bert                          6401 non-null   object \n",
      " 14  2grams_gensim                        6401 non-null   object \n",
      " 15  2grams_gensim_abs_word_freq          6296 non-null   object \n",
      " 16  2grams_gensim_abs_word_perc          6296 non-null   object \n",
      " 17  2grams_gensim_abs_word_perc_cum      6296 non-null   object \n",
      " 18  2grams_nltk                          6401 non-null   object \n",
      " 19  2grams_nltk_abs_word_freq            5821 non-null   object \n",
      " 20  2grams_nltk_abs_word_perc            5821 non-null   object \n",
      " 21  2grams_nltk_abs_word_perc_cum        5821 non-null   object \n",
      " 22  3grams_gensim                        6401 non-null   object \n",
      " 23  3grams_gensim_abs_word_freq          6296 non-null   object \n",
      " 24  3grams_gensim_abs_word_perc          6296 non-null   object \n",
      " 25  3grams_gensim_abs_word_perc_cum      6296 non-null   object \n",
      " 26  3grams_nltk                          6401 non-null   object \n",
      " 27  3grams_nltk_abs_word_freq            5278 non-null   object \n",
      " 28  3grams_nltk_abs_word_perc            5278 non-null   object \n",
      " 29  3grams_nltk_abs_word_perc_cum        5278 non-null   object \n",
      " 30  Age                                  6401 non-null   object \n",
      " 31  Age_Mixed                            6401 non-null   float64\n",
      " 32  Age_Num                              6401 non-null   float64\n",
      " 33  Age_Older                            6401 non-null   float64\n",
      " 34  Age_Younger                          6401 non-null   float64\n",
      " 35  Competence                           6401 non-null   int64  \n",
      " 36  Dutch Requirement                    6401 non-null   object \n",
      " 37  English Requirement                  6401 non-null   object \n",
      " 38  Gender                               6401 non-null   object \n",
      " 39  Gender_Female                        6401 non-null   float64\n",
      " 40  Gender_Male                          6401 non-null   float64\n",
      " 41  Gender_Mixed                         6401 non-null   float64\n",
      " 42  Gender_Num                           6401 non-null   float64\n",
      " 43  Job Description                      6401 non-null   object \n",
      " 44  Job Description_cleaned              6300 non-null   object \n",
      " 45  Job ID                               6401 non-null   object \n",
      " 46  Warmth                               6401 non-null   int64  \n",
      " 47  num_chars                            6401 non-null   int64  \n",
      " 48  num_punctuations                     6401 non-null   int64  \n",
      " 49  num_unique_words                     6401 non-null   int64  \n",
      " 50  num_words                            6401 non-null   int64  \n",
      " 51  sentiment                            6401 non-null   float64\n",
      " 52  2grams_gensim_dictionary             6401 non-null   object \n",
      " 53  2grams_gensim_corpus                 6401 non-null   object \n",
      " 54  2grams_gensim_tfidf                  6401 non-null   object \n",
      " 55  3grams_gensim_dictionary             6401 non-null   object \n",
      " 56  3grams_gensim_corpus                 6401 non-null   object \n",
      " 57  3grams_gensim_tfidf                  6401 non-null   object \n",
      " 58  123grams_gensim_dictionary           6401 non-null   object \n",
      " 59  123grams_gensim_corpus               6401 non-null   object \n",
      " 60  123grams_gensim_tfidf                6401 non-null   object \n",
      " 61  1grams_all_mean_w2v_embeddings       6401 non-null   object \n",
      " 62  1grams_all_mean_ft_embeddings        6401 non-null   object \n",
      " 63  2grams_nltk_mean_w2v_embeddings      6401 non-null   object \n",
      " 64  2grams_nltk_mean_ft_embeddings       6401 non-null   object \n",
      " 65  3grams_nltk_mean_w2v_embeddings      6401 non-null   object \n",
      " 66  3grams_nltk_mean_ft_embeddings       6401 non-null   object \n",
      " 67  123grams_nltk_mean_w2v_embeddings    6401 non-null   object \n",
      " 68  123grams_nltk_mean_ft_embeddings     6401 non-null   object \n",
      " 69  2grams_gensim_mean_w2v_embeddings    6401 non-null   object \n",
      " 70  2grams_gensim_mean_ft_embeddings     6401 non-null   object \n",
      " 71  3grams_gensim_mean_w2v_embeddings    6401 non-null   object \n",
      " 72  3grams_gensim_mean_ft_embeddings     6401 non-null   object \n",
      " 73  123grams_gensim_mean_w2v_embeddings  6401 non-null   object \n",
      " 74  123grams_gensim_mean_ft_embeddings   6401 non-null   object \n",
      " 75  123grams_gensim_sent2vec_embeddings  6401 non-null   object \n",
      "dtypes: float64(9), int64(7), object(60)\n",
      "memory usage: 3.7+ MB\n",
      "====================\n",
      "Warmth:\n",
      "--------------------\n",
      "Warmth Counts:\n",
      "0    4776\n",
      "1    1625\n",
      "Name: Warmth, dtype: int64\n",
      "--------------------\n",
      "Warmth Percentages:\n",
      "0   74.600\n",
      "1   25.400\n",
      "Name: Warmth, dtype: float64\n",
      "--------------------\n",
      "Warmth Means: 0.25\n",
      "--------------------\n",
      "Warmth Standard Deviation: 0.44\n",
      "====================\n",
      "Competence:\n",
      "--------------------\n",
      "Competence Counts:\n",
      "0    3511\n",
      "1    2890\n",
      "Name: Competence, dtype: int64\n",
      "--------------------\n",
      "Competence Percentages:\n",
      "0   54.900\n",
      "1   45.100\n",
      "Name: Competence, dtype: float64\n",
      "--------------------\n",
      "Competence Means: 0.45\n",
      "--------------------\n",
      "Competence Standard Deviation: 0.5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "df.dropna(subset=dv_cols, inplace=True)\n",
    "\n",
    "df = dummy_code_df_gender_age(df)\n",
    "\n",
    "df_gender_age_info(df, print_info=True)\n",
    "df_warm_comp_info(df, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "962018e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if analysis_df_from_manual is False:\n",
    "\n",
    "    df.to_pickle(\n",
    "        f'{df_dir}df_classified_clean_age_limit-{age_limit}_age_ratio-{age_ratio}_gender_ratio-{gender_ratio}.{file_save_format}'\n",
    "    )\n",
    "\n",
    "    df.to_csv(\n",
    "        f'{df_dir}df_classified_clean_age_limit-{age_limit}_age_ratio-{age_ratio}_gender_ratio-{gender_ratio}.{file_save_format_backup}',\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "elif analysis_df_from_manual is True:\n",
    "\n",
    "    df.to_pickle(\n",
    "        f'{df_dir}df_manual_clean.{file_save_format}'\n",
    "    )\n",
    "\n",
    "    df.to_csv(\n",
    "        f'{df_dir}df_manual_clean.{file_save_format_backup}',\n",
    "        index=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a76daf3",
   "metadata": {},
   "source": [
    "### Aggregate on mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f70a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Gender and Age astype object\n",
    "df[['Gender', 'Age']] = df[['Gender', 'Age']].astype(str)\n",
    "\n",
    "# Speoify cols that will be aggregated by first\n",
    "all_cols = [col for col in df.columns if col not in dv_cols]\n",
    "\n",
    "# Create df_mean\n",
    "df_mean = df.groupby(['Job ID'], as_index=False).agg({**dict.fromkeys(all_cols, 'first'), **dict.fromkeys(dv_cols, 'mean')})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac673c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 133 entries, 0 to 132\n",
      "Data columns (total 76 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Unnamed: 0                           133 non-null    int64  \n",
      " 1   123grams_gensim                      133 non-null    object \n",
      " 2   123grams_gensim_abs_word_freq        133 non-null    object \n",
      " 3   123grams_gensim_abs_word_perc        133 non-null    object \n",
      " 4   123grams_gensim_abs_word_perc_cum    133 non-null    object \n",
      " 5   123grams_nltk                        133 non-null    object \n",
      " 6   123grams_nltk_abs_word_freq          133 non-null    object \n",
      " 7   123grams_nltk_abs_word_perc          133 non-null    object \n",
      " 8   123grams_nltk_abs_word_perc_cum      133 non-null    object \n",
      " 9   1grams_all                           133 non-null    object \n",
      " 10  1grams_all_abs_word_freq             133 non-null    object \n",
      " 11  1grams_all_abs_word_perc             133 non-null    object \n",
      " 12  1grams_all_abs_word_perc_cum         133 non-null    object \n",
      " 13  1grams_bert                          133 non-null    object \n",
      " 14  2grams_gensim                        133 non-null    object \n",
      " 15  2grams_gensim_abs_word_freq          133 non-null    object \n",
      " 16  2grams_gensim_abs_word_perc          133 non-null    object \n",
      " 17  2grams_gensim_abs_word_perc_cum      133 non-null    object \n",
      " 18  2grams_nltk                          133 non-null    object \n",
      " 19  2grams_nltk_abs_word_freq            133 non-null    object \n",
      " 20  2grams_nltk_abs_word_perc            133 non-null    object \n",
      " 21  2grams_nltk_abs_word_perc_cum        133 non-null    object \n",
      " 22  3grams_gensim                        133 non-null    object \n",
      " 23  3grams_gensim_abs_word_freq          133 non-null    object \n",
      " 24  3grams_gensim_abs_word_perc          133 non-null    object \n",
      " 25  3grams_gensim_abs_word_perc_cum      133 non-null    object \n",
      " 26  3grams_nltk                          133 non-null    object \n",
      " 27  3grams_nltk_abs_word_freq            133 non-null    object \n",
      " 28  3grams_nltk_abs_word_perc            133 non-null    object \n",
      " 29  3grams_nltk_abs_word_perc_cum        133 non-null    object \n",
      " 30  Age                                  133 non-null    object \n",
      " 31  Age_Mixed                            133 non-null    float64\n",
      " 32  Age_Num                              133 non-null    float64\n",
      " 33  Age_Older                            133 non-null    float64\n",
      " 34  Age_Younger                          133 non-null    float64\n",
      " 35  Dutch Requirement                    133 non-null    object \n",
      " 36  English Requirement                  133 non-null    object \n",
      " 37  Gender                               133 non-null    object \n",
      " 38  Gender_Female                        133 non-null    float64\n",
      " 39  Gender_Male                          133 non-null    float64\n",
      " 40  Gender_Mixed                         133 non-null    float64\n",
      " 41  Gender_Num                           133 non-null    float64\n",
      " 42  Job Description                      133 non-null    object \n",
      " 43  Job Description_cleaned              133 non-null    object \n",
      " 44  Job ID                               133 non-null    object \n",
      " 45  num_chars                            133 non-null    int64  \n",
      " 46  num_punctuations                     133 non-null    int64  \n",
      " 47  num_unique_words                     133 non-null    int64  \n",
      " 48  num_words                            133 non-null    int64  \n",
      " 49  sentiment                            133 non-null    float64\n",
      " 50  2grams_gensim_dictionary             133 non-null    object \n",
      " 51  2grams_gensim_corpus                 133 non-null    object \n",
      " 52  2grams_gensim_tfidf                  133 non-null    object \n",
      " 53  3grams_gensim_dictionary             133 non-null    object \n",
      " 54  3grams_gensim_corpus                 133 non-null    object \n",
      " 55  3grams_gensim_tfidf                  133 non-null    object \n",
      " 56  123grams_gensim_dictionary           133 non-null    object \n",
      " 57  123grams_gensim_corpus               133 non-null    object \n",
      " 58  123grams_gensim_tfidf                133 non-null    object \n",
      " 59  1grams_all_mean_w2v_embeddings       133 non-null    object \n",
      " 60  1grams_all_mean_ft_embeddings        133 non-null    object \n",
      " 61  2grams_nltk_mean_w2v_embeddings      133 non-null    object \n",
      " 62  2grams_nltk_mean_ft_embeddings       133 non-null    object \n",
      " 63  3grams_nltk_mean_w2v_embeddings      133 non-null    object \n",
      " 64  3grams_nltk_mean_ft_embeddings       133 non-null    object \n",
      " 65  123grams_nltk_mean_w2v_embeddings    133 non-null    object \n",
      " 66  123grams_nltk_mean_ft_embeddings     133 non-null    object \n",
      " 67  2grams_gensim_mean_w2v_embeddings    133 non-null    object \n",
      " 68  2grams_gensim_mean_ft_embeddings     133 non-null    object \n",
      " 69  3grams_gensim_mean_w2v_embeddings    133 non-null    object \n",
      " 70  3grams_gensim_mean_ft_embeddings     133 non-null    object \n",
      " 71  123grams_gensim_mean_w2v_embeddings  133 non-null    object \n",
      " 72  123grams_gensim_mean_ft_embeddings   133 non-null    object \n",
      " 73  123grams_gensim_sent2vec_embeddings  133 non-null    object \n",
      " 74  Warmth                               133 non-null    float64\n",
      " 75  Competence                           133 non-null    float64\n",
      "dtypes: float64(11), int64(5), object(60)\n",
      "memory usage: 79.1+ KB\n",
      "====================\n",
      "Gender:\n",
      "Gender Counts:\n",
      "Mixed Gender    109\n",
      "Male             15\n",
      "Female            9\n",
      "Name: Gender, dtype: int64\n",
      "--------------------\n",
      "Gender Percentages:\n",
      "Mixed Gender   82.300\n",
      "Male            9.800\n",
      "Female          7.800\n",
      "Name: Gender, dtype: float64\n",
      "====================\n",
      "Age:\n",
      "Age Counts:\n",
      "Mixed Age         111\n",
      "Older Worker       16\n",
      "Younger      6\n",
      "Name: Age, dtype: int64\n",
      "--------------------\n",
      "Age Percentages:\n",
      "Mixed Age        86.100\n",
      "Older Worker      9.100\n",
      "Younger    4.800\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_mean.info()\n",
    "\n",
    "for iv in ivs:\n",
    "    print('='*20)\n",
    "    print(f'{iv}:')\n",
    "    print(f'{iv} Counts:\\n{df_mean[f\"{iv}\"].value_counts()}')\n",
    "    print('-'*20)\n",
    "    print(f'{iv} Percentages:\\n{df[f\"{iv}\"].value_counts(normalize=True).mul(100).round(1).astype(float)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ec78cd",
   "metadata": {},
   "source": [
    "## Make dfs dict and save df and df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c25e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if analysis_df_from_manual is False:\n",
    "    dataframes = {'df': df, 'df_mean': df_mean}\n",
    "\n",
    "elif analysis_df_from_manual is True:\n",
    "    dataframes = {'df_manual': df, 'df_manual_mean': df_mean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "329511b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Saving df_manual in /Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating Equity/Study 1/Study1_Code/data/final dfs/:\n",
      "====================\n",
      "====================\n",
      "Saving df_manual_mean in /Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating Equity/Study 1/Study1_Code/data/final dfs/:\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "for df_name, df_df in dataframes.items():\n",
    "\n",
    "    print('=' * 20)\n",
    "    print(f'Saving {df_name} in {df_dir}:')\n",
    "    print('=' * 20)\n",
    "\n",
    "    # Arrange Categories\n",
    "    df_df = categorize_df_gender_age(df_df)\n",
    "\n",
    "    if analysis_df_from_manual is False:\n",
    "\n",
    "        df_df.to_pickle(\n",
    "            f'{df_dir}{df_name}_for_analysis_age_limit-{age_limit}_age_ratio-{age_ratio}_gender_ratio-{gender_ratio}.{file_save_format}'\n",
    "        )\n",
    "\n",
    "        df_df.to_csv(\n",
    "            f'{df_dir}{df_name}_for_analysis_age_limit-{age_limit}_age_ratio-{age_ratio}_gender_ratio-{gender_ratio}.{file_save_format_backup}',\n",
    "            index=False,\n",
    "        )\n",
    "\n",
    "    elif analysis_df_from_manual is True:\n",
    "\n",
    "        df_df.to_pickle(\n",
    "            f'{df_dir}{df_name}_for_analysis.{file_save_format}'\n",
    "        )\n",
    "\n",
    "        df_df.to_csv(\n",
    "            f'{df_dir}{df_name}_for_analysis.{file_save_format_backup}',\n",
    "            index=False,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48cfc9a",
   "metadata": {},
   "source": [
    "## Outliers check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea88a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Analysing df_manual:\n",
      "====================\n",
      "--------------------\n",
      "Warmth\n",
      "--------------------\n",
      "Minimum: 0\n",
      "Maximum: 1\n",
      "--------------------\n",
      "Competence\n",
      "--------------------\n",
      "Minimum: 0\n",
      "Maximum: 1\n",
      "====================\n",
      "Analysing df_manual_mean:\n",
      "====================\n",
      "--------------------\n",
      "Warmth\n",
      "--------------------\n",
      "Minimum: 0.03333333333333333\n",
      "Maximum: 0.6785714285714286\n",
      "--------------------\n",
      "Competence\n",
      "--------------------\n",
      "Minimum: 0.07526881720430108\n",
      "Maximum: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "for df_name, df_df in dataframes.items():\n",
    "\n",
    "    print('=' * 20)\n",
    "    print(f'Analysing {df_name}:')\n",
    "    print('=' * 20)\n",
    "\n",
    "    for dv in dv_cols:\n",
    "\n",
    "        print('-' * 20)\n",
    "        print(f'{dv}')\n",
    "        print('-' * 20)\n",
    "        print(f\"Minimum: {df_df[f'{dv}'].min()}\")\n",
    "        print(f\"Maximum: {df_df[f'{dv}'].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b5014",
   "metadata": {},
   "source": [
    "### Specify sample/outliers based on z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc8cd485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Analysing df_manual:\n",
      "====================\n",
      "--------------------\n",
      "Warmth_Zscore\n",
      "--------------------\n",
      "Minimum: -0.5833034211043399\n",
      "Maximum: 1.714373624119586\n",
      "====================\n",
      "Removing outliers on Zscore: 0\n",
      "====================\n",
      "--------------------\n",
      "Zscore 0: Warmth_Outliers_Removed_Zscore0\n",
      "--------------------\n",
      "Minimum: 0\n",
      "Maximum: 1\n",
      "====================\n",
      "Removing outliers on Zscore: 1.96\n",
      "====================\n",
      "--------------------\n",
      "Zscore 1.96: Warmth_Outliers_Removed_Zscore1.96\n",
      "--------------------\n",
      "Minimum: 0.0\n",
      "Maximum: 1.0\n",
      "====================\n",
      "Removing outliers on Zscore: 2.58\n",
      "====================\n",
      "--------------------\n",
      "Zscore 2.58: Warmth_Outliers_Removed_Zscore2.58\n",
      "--------------------\n",
      "Minimum: 0.0\n",
      "Maximum: 1.0\n",
      "====================\n",
      "Removing outliers on Zscore: 3.29\n",
      "====================\n",
      "--------------------\n",
      "Zscore 3.29: Warmth_Outliers_Removed_Zscore3.29\n",
      "--------------------\n",
      "Minimum: 0.0\n",
      "Maximum: 1.0\n",
      "Saving df_manual with outliers removed.\n",
      "--------------------\n",
      "Competence_Zscore\n",
      "--------------------\n",
      "Minimum: -0.9072636409310755\n",
      "Maximum: 1.1022154475117667\n",
      "====================\n",
      "Removing outliers on Zscore: 0\n",
      "====================\n",
      "--------------------\n",
      "Zscore 0: Competence_Outliers_Removed_Zscore0\n",
      "--------------------\n",
      "Minimum: 0\n",
      "Maximum: 1\n",
      "====================\n",
      "Removing outliers on Zscore: 1.96\n",
      "====================\n",
      "--------------------\n",
      "Zscore 1.96: Competence_Outliers_Removed_Zscore1.96\n",
      "--------------------\n",
      "Minimum: 0.0\n",
      "Maximum: 1.0\n",
      "====================\n",
      "Removing outliers on Zscore: 2.58\n",
      "====================\n",
      "--------------------\n",
      "Zscore 2.58: Competence_Outliers_Removed_Zscore2.58\n",
      "--------------------\n",
      "Minimum: 0.0\n",
      "Maximum: 1.0\n",
      "====================\n",
      "Removing outliers on Zscore: 3.29\n",
      "====================\n",
      "--------------------\n",
      "Zscore 3.29: Competence_Outliers_Removed_Zscore3.29\n",
      "--------------------\n",
      "Minimum: 0.0\n",
      "Maximum: 1.0\n",
      "Saving df_manual with outliers removed.\n",
      "====================\n",
      "Analysing df_manual_mean:\n",
      "====================\n",
      "--------------------\n",
      "Warmth_Zscore\n",
      "--------------------\n",
      "Minimum: -1.7916955430761932\n",
      "Maximum: 3.294464511497264\n",
      "====================\n",
      "Removing outliers on Zscore: 0\n",
      "====================\n",
      "--------------------\n",
      "Zscore 0: Warmth_Outliers_Removed_Zscore0\n",
      "--------------------\n",
      "Minimum: 0.03333333333333333\n",
      "Maximum: 0.6785714285714286\n",
      "====================\n",
      "Removing outliers on Zscore: 1.96\n",
      "====================\n",
      "--------------------\n",
      "Zscore 1.96: Warmth_Outliers_Removed_Zscore1.96\n",
      "--------------------\n",
      "Minimum: 0.03333333333333333\n",
      "Maximum: 0.5\n",
      "====================\n",
      "Removing outliers on Zscore: 2.58\n",
      "====================\n",
      "--------------------\n",
      "Zscore 2.58: Warmth_Outliers_Removed_Zscore2.58\n",
      "--------------------\n",
      "Minimum: 0.03333333333333333\n",
      "Maximum: 0.5581395348837209\n",
      "====================\n",
      "Removing outliers on Zscore: 3.29\n",
      "====================\n",
      "--------------------\n",
      "Zscore 3.29: Warmth_Outliers_Removed_Zscore3.29\n",
      "--------------------\n",
      "Minimum: 0.03333333333333333\n",
      "Maximum: 0.6071428571428571\n",
      "Saving df_manual_mean with outliers removed.\n",
      "--------------------\n",
      "Competence_Zscore\n",
      "--------------------\n",
      "Minimum: -2.273045471125972\n",
      "Maximum: 2.488678960086491\n",
      "====================\n",
      "Removing outliers on Zscore: 0\n",
      "====================\n",
      "--------------------\n",
      "Zscore 0: Competence_Outliers_Removed_Zscore0\n",
      "--------------------\n",
      "Minimum: 0.07526881720430108\n",
      "Maximum: 0.8666666666666667\n",
      "====================\n",
      "Removing outliers on Zscore: 1.96\n",
      "====================\n",
      "--------------------\n",
      "Zscore 1.96: Competence_Outliers_Removed_Zscore1.96\n",
      "--------------------\n",
      "Minimum: 0.13333333333333333\n",
      "Maximum: 0.7297297297297297\n",
      "====================\n",
      "Removing outliers on Zscore: 2.58\n",
      "====================\n",
      "--------------------\n",
      "Zscore 2.58: Competence_Outliers_Removed_Zscore2.58\n",
      "--------------------\n",
      "Minimum: 0.07526881720430108\n",
      "Maximum: 0.8666666666666667\n",
      "====================\n",
      "Removing outliers on Zscore: 3.29\n",
      "====================\n",
      "--------------------\n",
      "Zscore 3.29: Competence_Outliers_Removed_Zscore3.29\n",
      "--------------------\n",
      "Minimum: 0.07526881720430108\n",
      "Maximum: 0.8666666666666667\n",
      "Saving df_manual_mean with outliers removed.\n"
     ]
    }
   ],
   "source": [
    "for df_name, df_df in dataframes.items():\n",
    "\n",
    "    print('=' * 20)\n",
    "    print(f'Analysing {df_name}:')\n",
    "    print('=' * 20)\n",
    "\n",
    "    for dv in dv_cols:\n",
    "\n",
    "        df_df[f'{dv}_Zscore'] = stats.zscore(df_df[f'{dv}'])\n",
    "\n",
    "        print('-' * 20)\n",
    "        print(f'{dv}_Zscore')\n",
    "        print('-' * 20)\n",
    "        print(f\"Minimum: {df_df[f'{dv}_Zscore'].min()}\")\n",
    "        print(f\"Maximum: {df_df[f'{dv}_Zscore'].max()}\")\n",
    "\n",
    "        for zscores in zscores_list:\n",
    "\n",
    "            print('=' * 20)\n",
    "            print(f'Removing outliers on Zscore: {zscores}')\n",
    "            print('=' * 20)\n",
    "\n",
    "            if zscores == 0:\n",
    "                df_df[f'{dv}_Outliers_Removed_Zscore{zscores}'] = df_df[f'{dv}']\n",
    "\n",
    "            elif zscores != 0:\n",
    "                df_df.loc[abs(df_df[f'{dv}_Zscore']) < zscores, [f'{dv}_Outliers_Removed_Zscore{zscores}']] = df_df[f'{dv}']\n",
    "\n",
    "            print('-' * 20)\n",
    "            print(f'Zscore {zscores}: {dv}_Outliers_Removed_Zscore{zscores}')\n",
    "            print('-' * 20)\n",
    "            print(f\"Minimum: {df_df[f'{dv}_Outliers_Removed_Zscore{zscores}'].min()}\")\n",
    "            print(f\"Maximum: {df_df[f'{dv}_Outliers_Removed_Zscore{zscores}'].max()}\")\n",
    "\n",
    "        print(f'Saving {df_name} with outliers removed.')\n",
    "\n",
    "        if analysis_df_from_manual is False:\n",
    "\n",
    "            df_df.to_pickle(\n",
    "                f'{df_dir}{df_name}_outliers_age_limit-{age_limit}_age_ratio-{age_ratio}_gender_ratio-{gender_ratio}.{file_save_format}'\n",
    "            )\n",
    "\n",
    "            df_df.to_csv(\n",
    "                f'{df_dir}{df_name}_outliers_age_limit-{age_limit}_age_ratio-{age_ratio}_gender_ratio-{gender_ratio}.{file_save_format_backup}',\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        elif analysis_df_from_manual is True:\n",
    "\n",
    "            df_df.to_pickle(\n",
    "                f'{df_dir}{df_name}_outliers.{file_save_format}'\n",
    "                )\n",
    "\n",
    "            df_df.to_csv(\n",
    "                f'{df_dir}{df_name}_outliers.{file_save_format_backup}',\n",
    "                index=False,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe097e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 | packaged by conda-forge | (main, Nov 21 2022, 13:22:15) [Clang 14.0.6 ]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e64b55c31e662d3b8ca165241f15a246a93354fe580fc7a1249b2f351dbc5a06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
