{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9bfda79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.11.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.11.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Printing keywords not enabled.\n",
      "Warning: Cannot change to a different GUI toolkit: widget. Using notebook instead.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# %%\n",
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %% [markdown]\n",
    "# ### Install packages and import\n",
    "# %%\n",
    "# #################################### PLEASE INSTALL LATEST CHROME WEBDRIVER #####################################\n",
    "# Uncomment to run as required\n",
    "# #     --install-option=\"--chromedriver-version= *.**\" \\\n",
    "#   --install-option=\"--chromedriver-checksums=4fecc99b066cb1a346035bf022607104,058cd8b7b4b9688507701b5e648fd821\"\n",
    "# %%\n",
    "# ##### COPY THE LINES IN THIS COMMENT TO THE TOP OF NEW SCRIPTS #####\n",
    "# # Function to import this package to other files\n",
    "# import os\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# code_dir = None\n",
    "# code_dir_name = 'Code'\n",
    "# unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "# for _ in range(5):\n",
    "\n",
    "#     parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "#     if (code_dir_name in parent_path) and (\n",
    "#         unwanted_subdir_name not in parent_path):\n",
    "\n",
    "#         code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "#         if code_dir is not None:\n",
    "#             break\n",
    "\n",
    "# main_dir = str(Path(code_dir).parents[0])\n",
    "# sys.path.append(code_dir)\n",
    "\n",
    "# from setup_module.imports import *\n",
    "# from setup_module.params import *\n",
    "# from setup_module.scraping import *\n",
    "# from setup_module.classification import *\n",
    "# from setup_module.vectorizers_classifiers import *\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (\n",
    "        unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "main_dir = str(Path(code_dir).parents[0])\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "from setup_module.imports import *\n",
    "from setup_module.params import *\n",
    "from setup_module.scraping import *\n",
    "from setup_module.classification import *\n",
    "from setup_module.vectorizers_classifiers import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib widget\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4cc7116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lux.core.frame.LuxDataFrame'>\n",
      "RangeIndex: 6106 entries, 0 to 6105\n",
      "Data columns (total 29 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   Job ID                   6106 non-null   object  \n",
      " 1   Job Description          6106 non-null   object  \n",
      " 2   Gender                   6106 non-null   category\n",
      " 3   Age                      6106 non-null   category\n",
      " 4   Warmth                   6106 non-null   int8    \n",
      " 5   Competence               6106 non-null   int8    \n",
      " 6   Task_Mentioned           6106 non-null   int8    \n",
      " 7   Task_Warmth              6106 non-null   int8    \n",
      " 8   Task_Competence          6106 non-null   int8    \n",
      " 9   Gender_Female            6106 non-null   float64 \n",
      " 10  Gender_Mixed             6106 non-null   float64 \n",
      " 11  Gender_Male              6106 non-null   float64 \n",
      " 12  Age_Older                6106 non-null   float64 \n",
      " 13  Age_Mixed                6106 non-null   float64 \n",
      " 14  Age_Younger              6106 non-null   float64 \n",
      " 15  Gender_Num               6106 non-null   float64 \n",
      " 16  Age_Num                  6106 non-null   float64 \n",
      " 17  Dutch Requirement        6106 non-null   object  \n",
      " 18  English Requirement      6106 non-null   object  \n",
      " 19  Job Description_cleaned  6106 non-null   object  \n",
      " 20  num_words                6106 non-null   int64   \n",
      " 21  num_unique_words         6106 non-null   int64   \n",
      " 22  num_chars                6106 non-null   int64   \n",
      " 23  num_punctuations         6106 non-null   int64   \n",
      " 24  1gram                    6106 non-null   object  \n",
      " 25  2grams_gensim            6106 non-null   object  \n",
      " 26  3grams_gensim            6106 non-null   object  \n",
      " 27  2grams_nltk              6106 non-null   object  \n",
      " 28  3grams_nltk              6106 non-null   object  \n",
      "dtypes: category(2), float64(8), int64(4), int8(5), object(10)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c51296e63041d9b7c630b3572317ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326168038ebb4752bb5dfb7abdb6d1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2701af5f53c14df9b6bf059677a19711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Toggle Pandas/Lux', layout=Layout(top='5px', width='140px'), style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8826c21d180b46e7ac6dbb08922eb0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Training Dataset: Warmth and Competence Sentence Counts')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"476.07pt\" height=\"275.258045pt\" viewBox=\"0 0 476.07 275.258045\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-04-24T22:03:47.942987</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 275.258045 \nL 476.07 275.258045 \nL 476.07 0 \nL 0 0 \nL 0 275.258045 \nz\n\" style=\"fill: none\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 76.035 253.44 \nL 410.835 253.44 \nL 410.835 36 \nL 76.035 36 \nz\n\" style=\"fill: #e5e5e5\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 76.035 253.44 \nL 76.035 36 \n\" clip-path=\"url(#p20ce8145e2)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g style=\"fill: #555555\" transform=\"translate(73.71887 266.402458)scale(0.0833 -0.0833)\">\n       <defs>\n        <path id=\"ArialMT-30\" d=\"M 266 2259 \nQ 266 3072 433 3567 \nQ 600 4063 929 4331 \nQ 1259 4600 1759 4600 \nQ 2128 4600 2406 4451 \nQ 2684 4303 2865 4023 \nQ 3047 3744 3150 3342 \nQ 3253 2941 3253 2259 \nQ 3253 1453 3087 958 \nQ 2922 463 2592 192 \nQ 2263 -78 1759 -78 \nQ 1097 -78 719 397 \nQ 266 969 266 2259 \nz\nM 844 2259 \nQ 844 1131 1108 757 \nQ 1372 384 1759 384 \nQ 2147 384 2411 759 \nQ 2675 1134 2675 2259 \nQ 2675 3391 2411 3762 \nQ 2147 4134 1753 4134 \nQ 1366 4134 1134 3806 \nQ 844 3388 844 2259 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path d=\"M 131.835 253.44 \nL 131.835 36 \n\" clip-path=\"url(#p20ce8145e2)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- 500 -->\n      <g style=\"fill: #555555\" transform=\"translate(124.886609 266.402458)scale(0.0833 -0.0833)\">\n       <defs>\n        <path id=\"ArialMT-35\" d=\"M 266 1200 \nL 856 1250 \nQ 922 819 1161 601 \nQ 1400 384 1738 384 \nQ 2144 384 2425 690 \nQ 2706 997 2706 1503 \nQ 2706 1984 2436 2262 \nQ 2166 2541 1728 2541 \nQ 1456 2541 1237 2417 \nQ 1019 2294 894 2097 \nL 366 2166 \nL 809 4519 \nL 3088 4519 \nL 3088 3981 \nL 1259 3981 \nL 1013 2750 \nQ 1425 3038 1878 3038 \nQ 2478 3038 2890 2622 \nQ 3303 2206 3303 1553 \nQ 3303 931 2941 478 \nQ 2500 -78 1738 -78 \nQ 1113 -78 717 272 \nQ 322 622 266 1200 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-35\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path d=\"M 187.635 253.44 \nL 187.635 36 \n\" clip-path=\"url(#p20ce8145e2)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- 1000 -->\n      <g style=\"fill: #555555\" transform=\"translate(178.370478 266.402458)scale(0.0833 -0.0833)\">\n       <defs>\n        <path id=\"ArialMT-31\" d=\"M 2384 0 \nL 1822 0 \nL 1822 3584 \nQ 1619 3391 1289 3197 \nQ 959 3003 697 2906 \nL 697 3450 \nQ 1169 3672 1522 3987 \nQ 1875 4303 2022 4600 \nL 2384 4600 \nL 2384 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path d=\"M 243.435 253.44 \nL 243.435 36 \n\" clip-path=\"url(#p20ce8145e2)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- 1500 -->\n      <g style=\"fill: #555555\" transform=\"translate(234.170478 266.402458)scale(0.0833 -0.0833)\">\n       <use xlink:href=\"#ArialMT-31\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path d=\"M 299.235 253.44 \nL 299.235 36 \n\" clip-path=\"url(#p20ce8145e2)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- 2000 -->\n      <g style=\"fill: #555555\" transform=\"translate(289.970478 266.402458)scale(0.0833 -0.0833)\">\n       <defs>\n        <path id=\"ArialMT-32\" d=\"M 3222 541 \nL 3222 0 \nL 194 0 \nQ 188 203 259 391 \nQ 375 700 629 1000 \nQ 884 1300 1366 1694 \nQ 2113 2306 2375 2664 \nQ 2638 3022 2638 3341 \nQ 2638 3675 2398 3904 \nQ 2159 4134 1775 4134 \nQ 1369 4134 1125 3890 \nQ 881 3647 878 3216 \nL 300 3275 \nQ 359 3922 746 4261 \nQ 1134 4600 1788 4600 \nQ 2447 4600 2831 4234 \nQ 3216 3869 3216 3328 \nQ 3216 3053 3103 2787 \nQ 2991 2522 2730 2228 \nQ 2469 1934 1863 1422 \nQ 1356 997 1212 845 \nQ 1069 694 975 541 \nL 3222 541 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-32\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path d=\"M 355.035 253.44 \nL 355.035 36 \n\" clip-path=\"url(#p20ce8145e2)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- 2500 -->\n      <g style=\"fill: #555555\" transform=\"translate(345.770478 266.402458)scale(0.0833 -0.0833)\">\n       <use xlink:href=\"#ArialMT-32\"/>\n       <use xlink:href=\"#ArialMT-35\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 410.835 253.44 \nL 410.835 36 \n\" clip-path=\"url(#p20ce8145e2)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_7\">\n      <!-- 3000 -->\n      <g style=\"fill: #555555\" transform=\"translate(401.570478 266.402458)scale(0.0833 -0.0833)\">\n       <defs>\n        <path id=\"ArialMT-33\" d=\"M 269 1209 \nL 831 1284 \nQ 928 806 1161 595 \nQ 1394 384 1728 384 \nQ 2125 384 2398 659 \nQ 2672 934 2672 1341 \nQ 2672 1728 2419 1979 \nQ 2166 2231 1775 2231 \nQ 1616 2231 1378 2169 \nL 1441 2663 \nQ 1497 2656 1531 2656 \nQ 1891 2656 2178 2843 \nQ 2466 3031 2466 3422 \nQ 2466 3731 2256 3934 \nQ 2047 4138 1716 4138 \nQ 1388 4138 1169 3931 \nQ 950 3725 888 3313 \nL 325 3413 \nQ 428 3978 793 4289 \nQ 1159 4600 1703 4600 \nQ 2078 4600 2393 4439 \nQ 2709 4278 2876 4000 \nQ 3044 3722 3044 3409 \nQ 3044 3113 2884 2869 \nQ 2725 2625 2413 2481 \nQ 2819 2388 3044 2092 \nQ 3269 1797 3269 1353 \nQ 3269 753 2831 336 \nQ 2394 -81 1725 -81 \nQ 1122 -81 723 278 \nQ 325 638 269 1209 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-33\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"55.615234\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"111.230469\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"166.845703\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_15\"/>\n     <g id=\"text_8\">\n      <!-- (1, 1) -->\n      <g style=\"fill: #555555\" transform=\"translate(49.594863 229.29199)scale(0.0833 -0.0833)\">\n       <defs>\n        <path id=\"ArialMT-28\" d=\"M 1497 -1347 \nQ 1031 -759 709 28 \nQ 388 816 388 1659 \nQ 388 2403 628 3084 \nQ 909 3875 1497 4659 \nL 1900 4659 \nQ 1522 4009 1400 3731 \nQ 1209 3300 1100 2831 \nQ 966 2247 966 1656 \nQ 966 153 1900 -1347 \nL 1497 -1347 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-2c\" d=\"M 569 0 \nL 569 641 \nL 1209 641 \nL 1209 0 \nQ 1209 -353 1084 -570 \nQ 959 -788 688 -906 \nL 531 -666 \nQ 709 -588 793 -436 \nQ 878 -284 888 0 \nL 569 0 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n        <path id=\"ArialMT-29\" d=\"M 791 -1347 \nL 388 -1347 \nQ 1322 153 1322 1656 \nQ 1322 2244 1188 2822 \nQ 1081 3291 891 3722 \nQ 769 4003 388 4659 \nL 791 4659 \nQ 1378 3875 1659 3084 \nQ 1900 2403 1900 1659 \nQ 1900 816 1576 28 \nQ 1253 -759 791 -1347 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#ArialMT-28\"/>\n       <use xlink:href=\"#ArialMT-31\" x=\"33.300781\"/>\n       <use xlink:href=\"#ArialMT-2c\" x=\"88.916016\"/>\n       <use xlink:href=\"#ArialMT-20\" x=\"116.699219\"/>\n       <use xlink:href=\"#ArialMT-31\" x=\"144.482422\"/>\n       <use xlink:href=\"#ArialMT-29\" x=\"200.097656\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_16\"/>\n     <g id=\"text_9\">\n      <!-- (1, 0) -->\n      <g style=\"fill: #555555\" transform=\"translate(49.594863 174.93199)scale(0.0833 -0.0833)\">\n       <use xlink:href=\"#ArialMT-28\"/>\n       <use xlink:href=\"#ArialMT-31\" x=\"33.300781\"/>\n       <use xlink:href=\"#ArialMT-2c\" x=\"88.916016\"/>\n       <use xlink:href=\"#ArialMT-20\" x=\"116.699219\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"144.482422\"/>\n       <use xlink:href=\"#ArialMT-29\" x=\"200.097656\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\"/>\n     <g id=\"text_10\">\n      <!-- (0, 1) -->\n      <g style=\"fill: #555555\" transform=\"translate(49.594863 120.57199)scale(0.0833 -0.0833)\">\n       <use xlink:href=\"#ArialMT-28\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"33.300781\"/>\n       <use xlink:href=\"#ArialMT-2c\" x=\"88.916016\"/>\n       <use xlink:href=\"#ArialMT-20\" x=\"116.699219\"/>\n       <use xlink:href=\"#ArialMT-31\" x=\"144.482422\"/>\n       <use xlink:href=\"#ArialMT-29\" x=\"200.097656\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_18\"/>\n     <g id=\"text_11\">\n      <!-- (0, 0) -->\n      <g style=\"fill: #555555\" transform=\"translate(49.594863 66.21199)scale(0.0833 -0.0833)\">\n       <use xlink:href=\"#ArialMT-28\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"33.300781\"/>\n       <use xlink:href=\"#ArialMT-2c\" x=\"88.916016\"/>\n       <use xlink:href=\"#ArialMT-20\" x=\"116.699219\"/>\n       <use xlink:href=\"#ArialMT-30\" x=\"144.482422\"/>\n       <use xlink:href=\"#ArialMT-29\" x=\"200.097656\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_12\">\n     <!-- Warmth,Competence -->\n     <g style=\"fill: #555555\" transform=\"translate(42.226738 204.501562)rotate(-90)scale(0.12 -0.12)\">\n      <defs>\n       <path id=\"Arial-BoldMT-57\" d=\"M 1116 0 \nL 22 4581 \nL 969 4581 \nL 1659 1434 \nL 2497 4581 \nL 3597 4581 \nL 4400 1381 \nL 5103 4581 \nL 6034 4581 \nL 4922 0 \nL 3941 0 \nL 3028 3425 \nL 2119 0 \nL 1116 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-61\" d=\"M 1116 2306 \nL 319 2450 \nQ 453 2931 781 3162 \nQ 1109 3394 1756 3394 \nQ 2344 3394 2631 3255 \nQ 2919 3116 3036 2902 \nQ 3153 2688 3153 2116 \nL 3144 1091 \nQ 3144 653 3186 445 \nQ 3228 238 3344 0 \nL 2475 0 \nQ 2441 88 2391 259 \nQ 2369 338 2359 363 \nQ 2134 144 1878 34 \nQ 1622 -75 1331 -75 \nQ 819 -75 523 203 \nQ 228 481 228 906 \nQ 228 1188 362 1408 \nQ 497 1628 739 1745 \nQ 981 1863 1438 1950 \nQ 2053 2066 2291 2166 \nL 2291 2253 \nQ 2291 2506 2166 2614 \nQ 2041 2722 1694 2722 \nQ 1459 2722 1328 2630 \nQ 1197 2538 1116 2306 \nz\nM 2291 1594 \nQ 2122 1538 1756 1459 \nQ 1391 1381 1278 1306 \nQ 1106 1184 1106 997 \nQ 1106 813 1243 678 \nQ 1381 544 1594 544 \nQ 1831 544 2047 700 \nQ 2206 819 2256 991 \nQ 2291 1103 2291 1419 \nL 2291 1594 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-72\" d=\"M 1300 0 \nL 422 0 \nL 422 3319 \nL 1238 3319 \nL 1238 2847 \nQ 1447 3181 1614 3287 \nQ 1781 3394 1994 3394 \nQ 2294 3394 2572 3228 \nL 2300 2463 \nQ 2078 2606 1888 2606 \nQ 1703 2606 1575 2504 \nQ 1447 2403 1373 2137 \nQ 1300 1872 1300 1025 \nL 1300 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-6d\" d=\"M 394 3319 \nL 1203 3319 \nL 1203 2866 \nQ 1638 3394 2238 3394 \nQ 2556 3394 2790 3262 \nQ 3025 3131 3175 2866 \nQ 3394 3131 3647 3262 \nQ 3900 3394 4188 3394 \nQ 4553 3394 4806 3245 \nQ 5059 3097 5184 2809 \nQ 5275 2597 5275 2122 \nL 5275 0 \nL 4397 0 \nL 4397 1897 \nQ 4397 2391 4306 2534 \nQ 4184 2722 3931 2722 \nQ 3747 2722 3584 2609 \nQ 3422 2497 3350 2280 \nQ 3278 2063 3278 1594 \nL 3278 0 \nL 2400 0 \nL 2400 1819 \nQ 2400 2303 2353 2443 \nQ 2306 2584 2207 2653 \nQ 2109 2722 1941 2722 \nQ 1738 2722 1575 2612 \nQ 1413 2503 1342 2297 \nQ 1272 2091 1272 1613 \nL 1272 0 \nL 394 0 \nL 394 3319 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-74\" d=\"M 1981 3319 \nL 1981 2619 \nL 1381 2619 \nL 1381 1281 \nQ 1381 875 1398 808 \nQ 1416 741 1477 697 \nQ 1538 653 1625 653 \nQ 1747 653 1978 738 \nL 2053 56 \nQ 1747 -75 1359 -75 \nQ 1122 -75 931 4 \nQ 741 84 652 211 \nQ 563 338 528 553 \nQ 500 706 500 1172 \nL 500 2619 \nL 97 2619 \nL 97 3319 \nL 500 3319 \nL 500 3978 \nL 1381 4491 \nL 1381 3319 \nL 1981 3319 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-68\" d=\"M 1334 4581 \nL 1334 2897 \nQ 1759 3394 2350 3394 \nQ 2653 3394 2897 3281 \nQ 3141 3169 3264 2994 \nQ 3388 2819 3433 2606 \nQ 3478 2394 3478 1947 \nL 3478 0 \nL 2600 0 \nL 2600 1753 \nQ 2600 2275 2550 2415 \nQ 2500 2556 2373 2639 \nQ 2247 2722 2056 2722 \nQ 1838 2722 1666 2615 \nQ 1494 2509 1414 2295 \nQ 1334 2081 1334 1663 \nL 1334 0 \nL 456 0 \nL 456 4581 \nL 1334 4581 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-2c\" d=\"M 438 878 \nL 1316 878 \nL 1316 250 \nQ 1316 -131 1250 -351 \nQ 1184 -572 1001 -747 \nQ 819 -922 538 -1022 \nL 366 -659 \nQ 631 -572 743 -419 \nQ 856 -266 863 0 \nL 438 0 \nL 438 878 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-43\" d=\"M 3397 1684 \nL 4294 1400 \nQ 4088 650 3608 286 \nQ 3128 -78 2391 -78 \nQ 1478 -78 890 545 \nQ 303 1169 303 2250 \nQ 303 3394 893 4026 \nQ 1484 4659 2447 4659 \nQ 3288 4659 3813 4163 \nQ 4125 3869 4281 3319 \nL 3366 3100 \nQ 3284 3456 3026 3662 \nQ 2769 3869 2400 3869 \nQ 1891 3869 1573 3503 \nQ 1256 3138 1256 2319 \nQ 1256 1450 1568 1081 \nQ 1881 713 2381 713 \nQ 2750 713 3015 947 \nQ 3281 1181 3397 1684 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-6f\" d=\"M 256 1706 \nQ 256 2144 472 2553 \nQ 688 2963 1083 3178 \nQ 1478 3394 1966 3394 \nQ 2719 3394 3200 2905 \nQ 3681 2416 3681 1669 \nQ 3681 916 3195 420 \nQ 2709 -75 1972 -75 \nQ 1516 -75 1102 131 \nQ 688 338 472 736 \nQ 256 1134 256 1706 \nz\nM 1156 1659 \nQ 1156 1166 1390 903 \nQ 1625 641 1969 641 \nQ 2313 641 2545 903 \nQ 2778 1166 2778 1666 \nQ 2778 2153 2545 2415 \nQ 2313 2678 1969 2678 \nQ 1625 2678 1390 2415 \nQ 1156 2153 1156 1659 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-70\" d=\"M 434 3319 \nL 1253 3319 \nL 1253 2831 \nQ 1413 3081 1684 3237 \nQ 1956 3394 2288 3394 \nQ 2866 3394 3269 2941 \nQ 3672 2488 3672 1678 \nQ 3672 847 3265 386 \nQ 2859 -75 2281 -75 \nQ 2006 -75 1782 34 \nQ 1559 144 1313 409 \nL 1313 -1263 \nL 434 -1263 \nL 434 3319 \nz\nM 1303 1716 \nQ 1303 1156 1525 889 \nQ 1747 622 2066 622 \nQ 2372 622 2575 867 \nQ 2778 1113 2778 1672 \nQ 2778 2194 2568 2447 \nQ 2359 2700 2050 2700 \nQ 1728 2700 1515 2451 \nQ 1303 2203 1303 1716 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-65\" d=\"M 2381 1056 \nL 3256 909 \nQ 3088 428 2723 176 \nQ 2359 -75 1813 -75 \nQ 947 -75 531 491 \nQ 203 944 203 1634 \nQ 203 2459 634 2926 \nQ 1066 3394 1725 3394 \nQ 2466 3394 2894 2905 \nQ 3322 2416 3303 1406 \nL 1103 1406 \nQ 1113 1016 1316 798 \nQ 1519 581 1822 581 \nQ 2028 581 2168 693 \nQ 2309 806 2381 1056 \nz\nM 2431 1944 \nQ 2422 2325 2234 2523 \nQ 2047 2722 1778 2722 \nQ 1491 2722 1303 2513 \nQ 1116 2303 1119 1944 \nL 2431 1944 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-6e\" d=\"M 3478 0 \nL 2600 0 \nL 2600 1694 \nQ 2600 2231 2544 2389 \nQ 2488 2547 2361 2634 \nQ 2234 2722 2056 2722 \nQ 1828 2722 1647 2597 \nQ 1466 2472 1398 2265 \nQ 1331 2059 1331 1503 \nL 1331 0 \nL 453 0 \nL 453 3319 \nL 1269 3319 \nL 1269 2831 \nQ 1703 3394 2363 3394 \nQ 2653 3394 2893 3289 \nQ 3134 3184 3257 3021 \nQ 3381 2859 3429 2653 \nQ 3478 2447 3478 2063 \nL 3478 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"Arial-BoldMT-63\" d=\"M 3353 2338 \nL 2488 2181 \nQ 2444 2441 2289 2572 \nQ 2134 2703 1888 2703 \nQ 1559 2703 1364 2476 \nQ 1169 2250 1169 1719 \nQ 1169 1128 1367 884 \nQ 1566 641 1900 641 \nQ 2150 641 2309 783 \nQ 2469 925 2534 1272 \nL 3397 1125 \nQ 3263 531 2881 228 \nQ 2500 -75 1859 -75 \nQ 1131 -75 698 384 \nQ 266 844 266 1656 \nQ 266 2478 700 2936 \nQ 1134 3394 1875 3394 \nQ 2481 3394 2839 3133 \nQ 3197 2872 3353 2338 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#Arial-BoldMT-57\"/>\n      <use xlink:href=\"#Arial-BoldMT-61\" x=\"90.634766\"/>\n      <use xlink:href=\"#Arial-BoldMT-72\" x=\"146.25\"/>\n      <use xlink:href=\"#Arial-BoldMT-6d\" x=\"185.166016\"/>\n      <use xlink:href=\"#Arial-BoldMT-74\" x=\"274.082031\"/>\n      <use xlink:href=\"#Arial-BoldMT-68\" x=\"307.382812\"/>\n      <use xlink:href=\"#Arial-BoldMT-2c\" x=\"368.466797\"/>\n      <use xlink:href=\"#Arial-BoldMT-43\" x=\"396.25\"/>\n      <use xlink:href=\"#Arial-BoldMT-6f\" x=\"468.466797\"/>\n      <use xlink:href=\"#Arial-BoldMT-6d\" x=\"529.550781\"/>\n      <use xlink:href=\"#Arial-BoldMT-70\" x=\"618.466797\"/>\n      <use xlink:href=\"#Arial-BoldMT-65\" x=\"679.550781\"/>\n      <use xlink:href=\"#Arial-BoldMT-74\" x=\"735.166016\"/>\n      <use xlink:href=\"#Arial-BoldMT-65\" x=\"768.466797\"/>\n      <use xlink:href=\"#Arial-BoldMT-6e\" x=\"824.082031\"/>\n      <use xlink:href=\"#Arial-BoldMT-63\" x=\"885.166016\"/>\n      <use xlink:href=\"#Arial-BoldMT-65\" x=\"940.78125\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 76.035 239.85 \nL 153.1506 239.85 \nL 153.1506 212.67 \nL 76.035 212.67 \nz\n\" clip-path=\"url(#p20ce8145e2)\" style=\"fill: #0000ff\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 76.035 185.49 \nL 171.6762 185.49 \nL 171.6762 158.31 \nL 76.035 158.31 \nz\n\" clip-path=\"url(#p20ce8145e2)\" style=\"fill: #0000ff\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 76.035 131.13 \nL 307.4934 131.13 \nL 307.4934 103.95 \nL 76.035 103.95 \nz\n\" clip-path=\"url(#p20ce8145e2)\" style=\"fill: #0000ff\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 76.035 76.77 \nL 353.2494 76.77 \nL 353.2494 49.59 \nL 76.035 49.59 \nz\n\" clip-path=\"url(#p20ce8145e2)\" style=\"fill: #0000ff\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 76.035 253.44 \nL 76.035 36 \n\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 76.035 253.44 \nL 410.835 253.44 \n\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_9\">\n     <path d=\"M 349.930313 242.4525 \nL 369.930313 242.4525 \nL 369.930313 235.4525 \nL 349.930313 235.4525 \nz\n\" style=\"fill: #0000ff\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- index -->\n     <g style=\"fill: #262626\" transform=\"translate(377.930313 242.4525)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"ArialMT-69\" d=\"M 425 3934 \nL 425 4581 \nL 988 4581 \nL 988 3934 \nL 425 3934 \nz\nM 425 0 \nL 425 3319 \nL 988 3319 \nL 988 0 \nL 425 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-6e\" d=\"M 422 0 \nL 422 3319 \nL 928 3319 \nL 928 2847 \nQ 1294 3394 1984 3394 \nQ 2284 3394 2536 3286 \nQ 2788 3178 2913 3003 \nQ 3038 2828 3088 2588 \nQ 3119 2431 3119 2041 \nL 3119 0 \nL 2556 0 \nL 2556 2019 \nQ 2556 2363 2490 2533 \nQ 2425 2703 2258 2804 \nQ 2091 2906 1866 2906 \nQ 1506 2906 1245 2678 \nQ 984 2450 984 1813 \nL 984 0 \nL 422 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-64\" d=\"M 2575 0 \nL 2575 419 \nQ 2259 -75 1647 -75 \nQ 1250 -75 917 144 \nQ 584 363 401 755 \nQ 219 1147 219 1656 \nQ 219 2153 384 2558 \nQ 550 2963 881 3178 \nQ 1213 3394 1622 3394 \nQ 1922 3394 2156 3267 \nQ 2391 3141 2538 2938 \nL 2538 4581 \nL 3097 4581 \nL 3097 0 \nL 2575 0 \nz\nM 797 1656 \nQ 797 1019 1065 703 \nQ 1334 388 1700 388 \nQ 2069 388 2326 689 \nQ 2584 991 2584 1609 \nQ 2584 2291 2321 2609 \nQ 2059 2928 1675 2928 \nQ 1300 2928 1048 2622 \nQ 797 2316 797 1656 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-65\" d=\"M 2694 1069 \nL 3275 997 \nQ 3138 488 2766 206 \nQ 2394 -75 1816 -75 \nQ 1088 -75 661 373 \nQ 234 822 234 1631 \nQ 234 2469 665 2931 \nQ 1097 3394 1784 3394 \nQ 2450 3394 2872 2941 \nQ 3294 2488 3294 1666 \nQ 3294 1616 3291 1516 \nL 816 1516 \nQ 847 969 1125 678 \nQ 1403 388 1819 388 \nQ 2128 388 2347 550 \nQ 2566 713 2694 1069 \nz\nM 847 1978 \nL 2700 1978 \nQ 2663 2397 2488 2606 \nQ 2219 2931 1791 2931 \nQ 1403 2931 1139 2672 \nQ 875 2413 847 1978 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"ArialMT-78\" d=\"M 47 0 \nL 1259 1725 \nL 138 3319 \nL 841 3319 \nL 1350 2541 \nQ 1494 2319 1581 2169 \nQ 1719 2375 1834 2534 \nL 2394 3319 \nL 3066 3319 \nL 1919 1756 \nL 3153 0 \nL 2463 0 \nL 1781 1031 \nL 1600 1309 \nL 728 0 \nL 47 0 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#ArialMT-69\"/>\n      <use xlink:href=\"#ArialMT-6e\" x=\"22.216797\"/>\n      <use xlink:href=\"#ArialMT-64\" x=\"77.832031\"/>\n      <use xlink:href=\"#ArialMT-65\" x=\"133.447266\"/>\n      <use xlink:href=\"#ArialMT-78\" x=\"189.0625\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"text_14\">\n   <!-- Training Dataset: Warmth and Competence Sentence Counts -->\n   <g style=\"fill: #262626\" transform=\"translate(7.2 18.8475)scale(0.16 -0.16)\">\n    <defs>\n     <path id=\"Arial-BoldMT-54\" d=\"M 1497 0 \nL 1497 3806 \nL 138 3806 \nL 138 4581 \nL 3778 4581 \nL 3778 3806 \nL 2422 3806 \nL 2422 0 \nL 1497 0 \nz\n\" transform=\"scale(0.015625)\"/>\n     <path id=\"Arial-BoldMT-69\" d=\"M 459 3769 \nL 459 4581 \nL 1338 4581 \nL 1338 3769 \nL 459 3769 \nz\nM 459 0 \nL 459 3319 \nL 1338 3319 \nL 1338 0 \nL 459 0 \nz\n\" transform=\"scale(0.015625)\"/>\n     <path id=\"Arial-BoldMT-67\" d=\"M 378 -219 \nL 1381 -341 \nQ 1406 -516 1497 -581 \nQ 1622 -675 1891 -675 \nQ 2234 -675 2406 -572 \nQ 2522 -503 2581 -350 \nQ 2622 -241 2622 53 \nL 2622 538 \nQ 2228 0 1628 0 \nQ 959 0 569 566 \nQ 263 1013 263 1678 \nQ 263 2513 664 2953 \nQ 1066 3394 1663 3394 \nQ 2278 3394 2678 2853 \nL 2678 3319 \nL 3500 3319 \nL 3500 341 \nQ 3500 -247 3403 -537 \nQ 3306 -828 3131 -993 \nQ 2956 -1159 2664 -1253 \nQ 2372 -1347 1925 -1347 \nQ 1081 -1347 728 -1058 \nQ 375 -769 375 -325 \nQ 375 -281 378 -219 \nz\nM 1163 1728 \nQ 1163 1200 1367 954 \nQ 1572 709 1872 709 \nQ 2194 709 2416 961 \nQ 2638 1213 2638 1706 \nQ 2638 2222 2425 2472 \nQ 2213 2722 1888 2722 \nQ 1572 2722 1367 2476 \nQ 1163 2231 1163 1728 \nz\n\" transform=\"scale(0.015625)\"/>\n     <path id=\"Arial-BoldMT-20\" transform=\"scale(0.015625)\"/>\n     <path id=\"Arial-BoldMT-44\" d=\"M 463 4581 \nL 2153 4581 \nQ 2725 4581 3025 4494 \nQ 3428 4375 3715 4072 \nQ 4003 3769 4153 3330 \nQ 4303 2891 4303 2247 \nQ 4303 1681 4163 1272 \nQ 3991 772 3672 463 \nQ 3431 228 3022 97 \nQ 2716 0 2203 0 \nL 463 0 \nL 463 4581 \nz\nM 1388 3806 \nL 1388 772 \nL 2078 772 \nQ 2466 772 2638 816 \nQ 2863 872 3011 1006 \nQ 3159 1141 3253 1448 \nQ 3347 1756 3347 2288 \nQ 3347 2819 3253 3103 \nQ 3159 3388 2990 3547 \nQ 2822 3706 2563 3763 \nQ 2369 3806 1803 3806 \nL 1388 3806 \nz\n\" transform=\"scale(0.015625)\"/>\n     <path id=\"Arial-BoldMT-73\" d=\"M 150 947 \nL 1031 1081 \nQ 1088 825 1259 692 \nQ 1431 559 1741 559 \nQ 2081 559 2253 684 \nQ 2369 772 2369 919 \nQ 2369 1019 2306 1084 \nQ 2241 1147 2013 1200 \nQ 950 1434 666 1628 \nQ 272 1897 272 2375 \nQ 272 2806 612 3100 \nQ 953 3394 1669 3394 \nQ 2350 3394 2681 3172 \nQ 3013 2950 3138 2516 \nL 2309 2363 \nQ 2256 2556 2107 2659 \nQ 1959 2763 1684 2763 \nQ 1338 2763 1188 2666 \nQ 1088 2597 1088 2488 \nQ 1088 2394 1175 2328 \nQ 1294 2241 1995 2081 \nQ 2697 1922 2975 1691 \nQ 3250 1456 3250 1038 \nQ 3250 581 2869 253 \nQ 2488 -75 1741 -75 \nQ 1063 -75 667 200 \nQ 272 475 150 947 \nz\n\" transform=\"scale(0.015625)\"/>\n     <path id=\"Arial-BoldMT-3a\" d=\"M 628 2441 \nL 628 3319 \nL 1506 3319 \nL 1506 2441 \nL 628 2441 \nz\nM 628 0 \nL 628 878 \nL 1506 878 \nL 1506 0 \nL 628 0 \nz\n\" transform=\"scale(0.015625)\"/>\n     <path id=\"Arial-BoldMT-64\" d=\"M 3503 0 \nL 2688 0 \nL 2688 488 \nQ 2484 203 2207 64 \nQ 1931 -75 1650 -75 \nQ 1078 -75 670 386 \nQ 263 847 263 1672 \nQ 263 2516 659 2955 \nQ 1056 3394 1663 3394 \nQ 2219 3394 2625 2931 \nL 2625 4581 \nL 3503 4581 \nL 3503 0 \nz\nM 1159 1731 \nQ 1159 1200 1306 963 \nQ 1519 619 1900 619 \nQ 2203 619 2415 876 \nQ 2628 1134 2628 1647 \nQ 2628 2219 2422 2470 \nQ 2216 2722 1894 2722 \nQ 1581 2722 1370 2473 \nQ 1159 2225 1159 1731 \nz\n\" transform=\"scale(0.015625)\"/>\n     <path id=\"Arial-BoldMT-53\" d=\"M 231 1491 \nL 1131 1578 \nQ 1213 1125 1461 912 \nQ 1709 700 2131 700 \nQ 2578 700 2804 889 \nQ 3031 1078 3031 1331 \nQ 3031 1494 2936 1608 \nQ 2841 1722 2603 1806 \nQ 2441 1863 1863 2006 \nQ 1119 2191 819 2459 \nQ 397 2838 397 3381 \nQ 397 3731 595 4036 \nQ 794 4341 1167 4500 \nQ 1541 4659 2069 4659 \nQ 2931 4659 3367 4281 \nQ 3803 3903 3825 3272 \nL 2900 3231 \nQ 2841 3584 2645 3739 \nQ 2450 3894 2059 3894 \nQ 1656 3894 1428 3728 \nQ 1281 3622 1281 3444 \nQ 1281 3281 1419 3166 \nQ 1594 3019 2269 2859 \nQ 2944 2700 3267 2529 \nQ 3591 2359 3773 2064 \nQ 3956 1769 3956 1334 \nQ 3956 941 3737 597 \nQ 3519 253 3119 86 \nQ 2719 -81 2122 -81 \nQ 1253 -81 787 320 \nQ 322 722 231 1491 \nz\n\" transform=\"scale(0.015625)\"/>\n     <path id=\"Arial-BoldMT-75\" d=\"M 2644 0 \nL 2644 497 \nQ 2463 231 2167 78 \nQ 1872 -75 1544 -75 \nQ 1209 -75 943 72 \nQ 678 219 559 484 \nQ 441 750 441 1219 \nL 441 3319 \nL 1319 3319 \nL 1319 1794 \nQ 1319 1094 1367 936 \nQ 1416 778 1544 686 \nQ 1672 594 1869 594 \nQ 2094 594 2272 717 \nQ 2450 841 2515 1023 \nQ 2581 1206 2581 1919 \nL 2581 3319 \nL 3459 3319 \nL 3459 0 \nL 2644 0 \nz\n\" transform=\"scale(0.015625)\"/>\n    </defs>\n    <use xlink:href=\"#Arial-BoldMT-54\"/>\n    <use xlink:href=\"#Arial-BoldMT-72\" x=\"55.583984\"/>\n    <use xlink:href=\"#Arial-BoldMT-61\" x=\"94.5\"/>\n    <use xlink:href=\"#Arial-BoldMT-69\" x=\"150.115234\"/>\n    <use xlink:href=\"#Arial-BoldMT-6e\" x=\"177.898438\"/>\n    <use xlink:href=\"#Arial-BoldMT-69\" x=\"238.982422\"/>\n    <use xlink:href=\"#Arial-BoldMT-6e\" x=\"266.765625\"/>\n    <use xlink:href=\"#Arial-BoldMT-67\" x=\"327.849609\"/>\n    <use xlink:href=\"#Arial-BoldMT-20\" x=\"388.933594\"/>\n    <use xlink:href=\"#Arial-BoldMT-44\" x=\"416.716797\"/>\n    <use xlink:href=\"#Arial-BoldMT-61\" x=\"488.933594\"/>\n    <use xlink:href=\"#Arial-BoldMT-74\" x=\"544.548828\"/>\n    <use xlink:href=\"#Arial-BoldMT-61\" x=\"577.849609\"/>\n    <use xlink:href=\"#Arial-BoldMT-73\" x=\"633.464844\"/>\n    <use xlink:href=\"#Arial-BoldMT-65\" x=\"689.080078\"/>\n    <use xlink:href=\"#Arial-BoldMT-74\" x=\"744.695312\"/>\n    <use xlink:href=\"#Arial-BoldMT-3a\" x=\"777.996094\"/>\n    <use xlink:href=\"#Arial-BoldMT-20\" x=\"811.296875\"/>\n    <use xlink:href=\"#Arial-BoldMT-57\" x=\"839.080078\"/>\n    <use xlink:href=\"#Arial-BoldMT-61\" x=\"929.714844\"/>\n    <use xlink:href=\"#Arial-BoldMT-72\" x=\"985.330078\"/>\n    <use xlink:href=\"#Arial-BoldMT-6d\" x=\"1024.246094\"/>\n    <use xlink:href=\"#Arial-BoldMT-74\" x=\"1113.162109\"/>\n    <use xlink:href=\"#Arial-BoldMT-68\" x=\"1146.462891\"/>\n    <use xlink:href=\"#Arial-BoldMT-20\" x=\"1207.546875\"/>\n    <use xlink:href=\"#Arial-BoldMT-61\" x=\"1235.330078\"/>\n    <use xlink:href=\"#Arial-BoldMT-6e\" x=\"1290.945312\"/>\n    <use xlink:href=\"#Arial-BoldMT-64\" x=\"1352.029297\"/>\n    <use xlink:href=\"#Arial-BoldMT-20\" x=\"1413.113281\"/>\n    <use xlink:href=\"#Arial-BoldMT-43\" x=\"1440.896484\"/>\n    <use xlink:href=\"#Arial-BoldMT-6f\" x=\"1513.113281\"/>\n    <use xlink:href=\"#Arial-BoldMT-6d\" x=\"1574.197266\"/>\n    <use xlink:href=\"#Arial-BoldMT-70\" x=\"1663.113281\"/>\n    <use xlink:href=\"#Arial-BoldMT-65\" x=\"1724.197266\"/>\n    <use xlink:href=\"#Arial-BoldMT-74\" x=\"1779.8125\"/>\n    <use xlink:href=\"#Arial-BoldMT-65\" x=\"1813.113281\"/>\n    <use xlink:href=\"#Arial-BoldMT-6e\" x=\"1868.728516\"/>\n    <use xlink:href=\"#Arial-BoldMT-63\" x=\"1929.8125\"/>\n    <use xlink:href=\"#Arial-BoldMT-65\" x=\"1985.427734\"/>\n    <use xlink:href=\"#Arial-BoldMT-20\" x=\"2041.042969\"/>\n    <use xlink:href=\"#Arial-BoldMT-53\" x=\"2068.826172\"/>\n    <use xlink:href=\"#Arial-BoldMT-65\" x=\"2135.525391\"/>\n    <use xlink:href=\"#Arial-BoldMT-6e\" x=\"2191.140625\"/>\n    <use xlink:href=\"#Arial-BoldMT-74\" x=\"2252.224609\"/>\n    <use xlink:href=\"#Arial-BoldMT-65\" x=\"2285.525391\"/>\n    <use xlink:href=\"#Arial-BoldMT-6e\" x=\"2341.140625\"/>\n    <use xlink:href=\"#Arial-BoldMT-63\" x=\"2402.224609\"/>\n    <use xlink:href=\"#Arial-BoldMT-65\" x=\"2457.839844\"/>\n    <use xlink:href=\"#Arial-BoldMT-20\" x=\"2513.455078\"/>\n    <use xlink:href=\"#Arial-BoldMT-43\" x=\"2541.238281\"/>\n    <use xlink:href=\"#Arial-BoldMT-6f\" x=\"2613.455078\"/>\n    <use xlink:href=\"#Arial-BoldMT-75\" x=\"2674.539062\"/>\n    <use xlink:href=\"#Arial-BoldMT-6e\" x=\"2735.623047\"/>\n    <use xlink:href=\"#Arial-BoldMT-74\" x=\"2796.707031\"/>\n    <use xlink:href=\"#Arial-BoldMT-73\" x=\"2830.007812\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p20ce8145e2\">\n   <rect x=\"76.035\" y=\"36\" width=\"334.8\" height=\"217.44\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize data balance\n",
    "df_jobs_labeled.info()\n",
    "df_jobs_labeled['Warmth'].value_counts()\n",
    "df_jobs_labeled['Competence'].value_counts()\n",
    "warm_comp_count = (\n",
    "    df_jobs_labeled[analysis_columns]\n",
    "    .reset_index()\n",
    "    .groupby(analysis_columns)\n",
    "    .count()\n",
    "    .sort_values(by='index')\n",
    ")\n",
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('Training Dataset: Warmth and Competence Sentence Counts', fontsize=16.0)\n",
    "warm_comp_count.plot(kind='barh', stacked=True, legend=True, color='blue', ax=ax).grid(\n",
    "    axis='y'\n",
    ")\n",
    "if save_enabled == True:\n",
    "    fig.savefig(f'{plot_save_path}Warmth and Competence Sentence Counts.{image_save_format}', format=image_save_format, dpi=3000)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97861e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = 'Job Description_w2v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366c0125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_jobs_labeled, vectorizer, col, text_col):\n",
    "    # BOW Split\n",
    "    print('Splitting data into training and test sets.')\n",
    "    df_jobs_labeled.dropna(subset=['Warmth', 'Competence', text_col], how='any', inplace=True)\n",
    "\n",
    "    train, test = train_test_split(\n",
    "        df_jobs_labeled, test_size=test_split, train_size = 1-test_split, random_state=random_state\n",
    "    )\n",
    "\n",
    "    validate, test = train_test_split(\n",
    "        test, test_size=validation_split, random_state=random_state\n",
    "    )\n",
    "\n",
    "    X_train = np.array([sent2vec(x) for x in train[f'{str(text_col)}'].astype('str').values])\n",
    "    prepared_X_train = X_train.to_list()\n",
    "\n",
    "    y_train = column_or_1d(train[str(col)].astype('int64').values, warn=True)\n",
    "    prepared_y_train = y_train.to_list()\n",
    "\n",
    "    X_test = np.array([sent2vec(x) for x in test[f'{str(text_col)}'].astype('str').values])\n",
    "    prepared_X_test = X_test.to_list()\n",
    "\n",
    "    y_test = column_or_1d(test[str(col)].astype('int64').values, warn=True)\n",
    "    prepared_y_test = y_test.to_list()\n",
    "\n",
    "    X_validate = np.array([sent2vec(x) for x in validate[f'{str(text_col)}'].astype('str').values])\n",
    "    prepared_X_validate = X_validate.to_list()\n",
    "\n",
    "    y_validate = column_or_1d(validate[str(col)].astype('int64').values, warn=True)\n",
    "    prepared_y_validate = y_validate.to_list()\n",
    "\n",
    "    prepared_text = vectorizer.fit_transform(prepared_X_train+prepared_X_test+prepared_X_validate)\n",
    "\n",
    "    return train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, prepared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f9c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding with Fasttext\n",
    "def word_embedding(df_jobs, X_train, feature_names):\n",
    "\n",
    "    sentences = df_jobs['2grams_gensim']\n",
    "\n",
    "    fasttext_model = FastText(sentences, window=3, min_count=1, sorted_vocab=1)\n",
    "\n",
    "    row=0\n",
    "    errors=0\n",
    "    for sent in tqdm.tqdm(sentences):\n",
    "        sent_vec = np.zeros(100)\n",
    "        weight_sum =0\n",
    "        for word in sent:\n",
    "            try:\n",
    "                # weight = fasttext_model.wv.get_vector(word)\n",
    "                # weight_sum += weight\n",
    "                # sent_vec += weight\n",
    "                vec = fasttext_model.wv[word]\n",
    "                feat = X_train[row, feature_names.index(word)]\n",
    "                sent_vec += (vec * feat)\n",
    "                weight_sum += feat\n",
    "            except Exception:\n",
    "                errors += 1\n",
    "        sent_vec /= weight_sum\n",
    "                # print(np.isnan(np.sum(sent_vec)))\n",
    "    sent_vectors = [sent_vec]\n",
    "    row += 1\n",
    "    print(f'errors noted: {str(errors)}')\n",
    "\n",
    "    return fasttext_model, sent_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1af0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_poed(vectorizer, X_train, y_train, X_test, y_test, X_validate, y_validate, feature_names):\n",
    "\n",
    "    # Get words and offsets\n",
    "    train_words, train_offsets = train_offset(X_train, 'train')\n",
    "    test_words, test_offsets = train_offset(X_test, 'test')\n",
    "    validate_words, validate_offsets = train_offset(X_validate, 'validate')\n",
    "\n",
    "    if hasattr(vectorizer, 'vocabulary_'):\n",
    "        vocabulary_map = vectorizer.vocabulary_\n",
    "        if plots_enabled:\n",
    "            sns.heatmap(X_train.todense()[:,np.random.randint(0,X.shape[1],100)]==0, vmin=0, vmax=1, cbar=False).set_title('Sparse Matrix Sample')\n",
    "\n",
    "        embs = load_glove_with_vocabulary(vocabulary_map, feature_names, print_enabled=print_enabled)\n",
    "        emb_model = BagOfEmbeddings(embs, dropout=0.1, hidden_dim=75, embedding_mode='mean')\n",
    "        print(f'Embedding Model: {emb_model}')\n",
    "\n",
    "        loss = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(emb_model.parameters(), lr = 0.001)\n",
    "        torch.manual_seed(random_state)\n",
    "        losses = run_training(epochs=1, emb_model=emb_model, optimizer=optimizer, loss_fn=loss,\n",
    "                            all_words=train_words, all_offsets=train_offsets, all_targets=y_train,\n",
    "                            batch_size=32)\n",
    "        print(\"Training avg emb_model complete!\")\n",
    "\n",
    "        print(\"Evaluating test set\")\n",
    "        batch_losses, outputs = run_test(emb_model=emb_model, loss_fn=loss,\n",
    "                            all_words=test_words, all_offsets=test_offsets, all_targets=y_train,\n",
    "                            batch_size=256)\n",
    "\n",
    "        print(\"outputs.shape\", outputs.shape)\n",
    "\n",
    "        boe_pred = outputs.detach().numpy()\n",
    "\n",
    "        best_threshold_boe, best_score_boe = calculate_best_threshold(y_test[:300], boe_pred[:300], scoring, print_enabled)\n",
    "\n",
    "        print(\"boe_pred:\\n\", boe_pred[10])\n",
    "\n",
    "        print(\"Evaluating validate outputs\")\n",
    "        _, validate_outputs = run_test(emb_model=emb_model, loss_fn=None,\n",
    "                            all_words=validate_words, all_offsets=validate_offsets, all_targets=None,\n",
    "                            batch_size=256)\n",
    "\n",
    "        boe_validate_pred = validate_outputs.detach().numpy()\n",
    "        print(\"boe_validate_pred:\\n\", boe_validate_pred[10])\n",
    "        print(\"Validate outputs done\")\n",
    "\n",
    "    else:\n",
    "        vocabulary_map = None\n",
    "        boe_pred = None\n",
    "        boe_validate_pred = None\n",
    "        best_threshold_boe = None\n",
    "        best_score_boe = None\n",
    "\n",
    "    return vocabulary_map, boe_pred, boe_validate_pred, best_threshold_boe, best_score_boe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0beed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and target arrays\n",
    "def vectorize(vectorizer, vectorizer_name, selector, df_jobs_labeled, col, text_col):\n",
    "    print(\n",
    "        f'============================ {str(col)}: {vectorizer_name} passed ============================'\n",
    "    )\n",
    "\n",
    "    refit_vectorizer = vectorizer\n",
    "\n",
    "    # BOW Split\n",
    "    train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, prepared_text = split_data(df_jobs_labeled, vectorizer, col, text_col)\n",
    "\n",
    "    # BOW fit transform\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    # Selecting best features\n",
    "    if select_best_enabled == True:\n",
    "        X_train = selector.fit_transform(X_train, y_train)\n",
    "    # Oversampling to fix imbalance\n",
    "    if (resampling_enabled == True) and (col == 'Warmth'):\n",
    "        X_train, y_train = resample_data(X_train, y_train, col, resampling_enabled, resampling_method)\n",
    "\n",
    "    # Get feature names\n",
    "    X_train, vectorizer, dtf_features, X_names, feature_names = get_feature_name_and_refit_X_train_on_chi_test(train, X_train, vectorizer, refit_vectorizer)\n",
    "    unique_features = set(feature_names)\n",
    "\n",
    "    # BOW fit\n",
    "    print('Fitting and transforming data.')\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    X_validate = vectorizer.transform(X_validate)\n",
    "    # Selecting best features\n",
    "    if select_best_enabled == True:\n",
    "        X_test = selector.transform(X_test)\n",
    "        X_validate = selector.transform(X_validate)\n",
    "        # Get feature names\n",
    "        feature_names = selector.get_feature_names_out(vocabulary=X_names)\n",
    "        unique_features = set(feature_names)\n",
    "\n",
    "    # y to numpy array\n",
    "    y_train = torch.from_numpy(np.array(y_train)).float()\n",
    "    y_test = torch.from_numpy(np.array(y_test)).float()\n",
    "    if print_enabled:\n",
    "        print(f'Train targets: {y_train}')\n",
    "        print(f'Test targets: {y_test}')\n",
    "\n",
    "    vocabulary_map, boe_pred, boe_validate_pred, best_threshold_boe, best_score_boe = emb_poed(vectorizer, X_train, y_train, X_test, y_test, X_validate, y_validate, feature_names)\n",
    "\n",
    "    # fasttext_model, sent_vectors = word_embedding(df_jobs, X_train, feature_names)\n",
    "\n",
    "    return df_jobs_labeled, vectorizer, selector, train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, feature_names, unique_features, vocabulary_map, best_threshold_boe, best_score_boe, boe_pred, boe_validate_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bd1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_preds(best_threshold, y_final_validate_prob_pred, test, col, vectorizer_name, classifier_name, save_enabled=save_enabled):\n",
    "\n",
    "    # Save DF of predictions\n",
    "    labels = (y_final_validate_prob_pred > best_threshold).astype(int)\n",
    "    df_preds = pd.DataFrame({f'{str(text_col)}': test[f'{str(text_col)}'], \"prediction\": labels})\n",
    "    if save_enabled:\n",
    "        df_preds.to_csv(f'{df_dir}df_preds_{str(col)} - {vectorizer_name} + {classifier_name}.{file_save_format}', index=False)\n",
    "\n",
    "    return df_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e0b8914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(classifier, classifier_name, vectorizer, vectorizer_name, final_classifier, test, y_test, y_test_prob_pred, validate, y_validate, y_validate_prob_pred, boe_pred, boe_validate_pred, scoring, print_enabled):\n",
    "\n",
    "    num = len(test) // 2\n",
    "\n",
    "    best_threshold, best_score = calculate_best_threshold(y_test[:num], y_test_prob_pred[:num], scoring, print_enabled)\n",
    "\n",
    "    if (boe_pred is not None) and (boe_validate_pred is not None):\n",
    "        num = len(boe_pred) // 2\n",
    "\n",
    "        X_final_augmented_train = pd.DataFrame({\n",
    "            \"y_test_prob_pred\": y_test_prob_pred[:num],\n",
    "            \"boe_pred\": boe_pred[:num].squeeze(),\n",
    "            \"num_words\": test[\"num_words\"].values[:num],\n",
    "            \"num_chars\": test[\"num_chars\"].values[:num]})\n",
    "        y_final_augmented_train = y_test[:num]\n",
    "\n",
    "        X_final_augmented_test = pd.DataFrame({\n",
    "            \"y_test_prob_pred\": y_test_prob_pred[num:],\n",
    "            \"boe_pred\": boe_pred[num:].squeeze(),\n",
    "            \"num_words\": test[\"num_words\"].values[num:],\n",
    "            \"num_chars\": test[\"num_chars\"].values[num:]})\n",
    "        y_final_augmented_test = y_test[num:]\n",
    "\n",
    "        final_classifier = final_classifier.fit(X_final_augmented_train, y_final_augmented_train)\n",
    "\n",
    "        if hasattr(final_classifier, 'predict_proba'):\n",
    "            y_final_test_prob_pred = final_classifier.predict_proba(X_final_augmented_test)[:, 1]\n",
    "        elif hasattr(final_classifier, '_predict_proba_lr'):\n",
    "            y_final_test_prob_pred = final_classifier._predict_proba_lr(X_final_augmented_test)[:, 1]\n",
    "\n",
    "        best_threshold_final, best_score_final = calculate_best_threshold(y_final_augmented_test, y_final_test_prob_pred, scoring, print_enabled)\n",
    "\n",
    "        X_final_augmented_validate = pd.DataFrame({\n",
    "            \"y_validate_prob_pred\": y_validate_prob_pred,\n",
    "            \"boe_validate_pred\": boe_validate_pred.squeeze(),\n",
    "            \"num_words\": validate[\"num_words\"].values,\n",
    "            \"num_chars\": validate[\"num_chars\"].values})\n",
    "        y_final_augmented_validate = y_validate\n",
    "\n",
    "        y_final_validate_prob_pred = final_classifier.predict_proba(X_final_augmented_validate)[:,1]\n",
    "\n",
    "        df_preds = get_df_preds(best_threshold_final, y_final_validate_prob_pred, validate, col, vectorizer_name, classifier_name)\n",
    "\n",
    "    elif (boe_pred is None) and (boe_validate_pred is None):\n",
    "        final_classifier = classifier\n",
    "        X_final_augmented_validate = X_test\n",
    "        y_final_augmented_validate = y_test\n",
    "        y_final_validate_prob_pred = y_test_prob_pred\n",
    "        df_preds = get_df_preds(best_threshold, y_final_validate_prob_pred, test, col, vectorizer_name, classifier_name)\n",
    "\n",
    "    return final_classifier, X_final_augmented_validate, y_final_augmented_validate, y_final_validate_prob_pred, best_threshold, best_score, df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a69ae3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit classifier\n",
    "def classify(train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, classifier, classifier_name, vectorizer, vectorizer_name, boe_pred, boe_validate_pred):\n",
    "    print('\\n')\n",
    "    print(\n",
    "        f'============================ {str(col)}: {vectorizer_name} + {classifier_name} passed ============================'\n",
    "    )\n",
    "    num = len(test) // 2\n",
    "\n",
    "    # BOW model\n",
    "    if classifier_name == 'GaussianNB':\n",
    "        X_train = X_train.todense()\n",
    "        X_test = X_test.todense()\n",
    "        X_validate = X_validate.todense()\n",
    "\n",
    "    if classifier_name == 'Sequential':\n",
    "        classifier.compile(loss='categorical_crossentropy')\n",
    "    if hasattr(classifier, 'decision_function') and not hasattr(classifier, 'predict_proba'):\n",
    "        classifier = CalibratedClassifierCV(classifier, cv = cv, method = 'sigmoid')\n",
    "\n",
    "    final_classifier = classifier\n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "    classifier = SelectFromModel(estimator=classifier, prefit=True).fit(X_train, y_train)\n",
    "\n",
    "    if hasattr(classifier, 'predict_proba'):\n",
    "        y_test_prob_pred = classifier.predict_proba(X_test)\n",
    "        y_validate_prob_pred = classifier.predict_proba(X_validate)\n",
    "    elif hasattr(classifier, '_predict_proba_lr'):\n",
    "        y_test_prob_pred = classifier._predict_proba_lr(X_test)\n",
    "        y_validate_prob_pred = classifier._predict_proba_lr(X_validate)\n",
    "    else:\n",
    "        raise(f'{classifier_name} has neither predict_proba nor _predict_proba_lr attributes.')\n",
    "\n",
    "    final_classifier, X_test, y_test, y_test_prob_pred, best_threshold, best_score, df_preds = augment(classifier, classifier_name, vectorizer, vectorizer_name, final_classifier, test, y_test, y_test_prob_pred, validate, y_validate, y_validate_prob_pred, boe_pred, boe_validate_pred, scoring, print_enabled)\n",
    "\n",
    "    return final_classifier, X_test, y_test, y_test_prob_pred, best_threshold, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c2107c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, table_df, classifier, classifier_name, vectorizer, vectorizer_name, col, text_col, scoring):\n",
    "\n",
    "    # Evaluate\n",
    "    print('\\n')\n",
    "    print('-' * 20)\n",
    "    print(\n",
    "        f'EVALUATING FITTED MODEL - {vectorizer_name} + {classifier_name}: ',\n",
    "        has_fit_parameter(classifier, 'sample_weight'),\n",
    "    )\n",
    "    # 5 cross_validation score\n",
    "    print(f'Cross Validating - {vectorizer_name} + {classifier_name}.')\n",
    "    cross_validate_score = cross_validate(\n",
    "        classifier,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        cv=cv,\n",
    "        return_train_score=True,\n",
    "        scoring=scores,\n",
    "    )\n",
    "\n",
    "    cross_validate_score_noscoring = cross_validate(\n",
    "        classifier,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        cv=cv,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f'Mean cross_validate scores - {vectorizer_name} + {classifier_name}: {cross_validate_score_noscoring.get(\"test_score\").mean()}'\n",
    "    )\n",
    "    numberoflabels = len(set((str(e) for e in y_test.to_list())))\n",
    "\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, 'Mean Validation Score')\n",
    "    ] = float(cross_validate_score_noscoring.get('test_score').mean())\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, 'Explained Variance')\n",
    "    ] = float(\n",
    "        cross_validate_score.get('test_explained_variance').mean()\n",
    "    )\n",
    "\n",
    "    print('-' * 20)\n",
    "    for key, values in cross_validate_score.items():\n",
    "        if 'test' in key:\n",
    "            print(key, ' mean ', values.mean())\n",
    "    print('-' * 20)\n",
    "    print('\\n')\n",
    "\n",
    "    # Predictions\n",
    "    print('-' * 20)\n",
    "    print(\n",
    "        f'============================ {str(col)} PREDICTIONS FOR {vectorizer_name.upper()} WITH {classifier_name.upper()} ============================'\n",
    "    )\n",
    "    print('\\n')\n",
    "    print(f'y_test_pred - {str(col)} - {vectorizer_name} + {classifier_name}:')\n",
    "    dic_y_mapping = {n: label for n, label in enumerate(np.unique(y_train))}\n",
    "    inverse_dic = {v:k for k,v in dic_y_mapping.items()}\n",
    "    y_train = np.array([inverse_dic[y] for y in y_train])\n",
    "\n",
    "    y_test_pred = classifier.predict(X_test)\n",
    "    if classifier_name == 'GaussianNB':\n",
    "        # y_test_pred = y_test_pred.to_list()\n",
    "        y_test_pred = classifier.predict(X_test.todense())\n",
    "    predicted = [dic_y_mapping[np.argmax(pred)] for pred in y_test_pred]\n",
    "    acc_roc_f1 = evaluate_print(classifier_name + '   |   ', y_test, y_test_pred)\n",
    "    cm, precision, recall, accuracy, f1, mcc, best_threshold, best_score, report = evaluation(\n",
    "        y_test, y_test_pred, scoring, print_enabled\n",
    "    )\n",
    "\n",
    "    true_negative = cm[0][0]\n",
    "    false_positives = cm[0][1]\n",
    "    false_negatives = cm[1][0]\n",
    "    true_positives = cm[1][1]\n",
    "\n",
    "    report_test = predict(\n",
    "        X_test,\n",
    "        y_test,\n",
    "        classifier,\n",
    "        classifier_name,\n",
    "        col,\n",
    "        scoring,\n",
    "        df_jobs_labeled,\n",
    "        print_enabled,\n",
    "    )\n",
    "\n",
    "    print(f'REPORT TEST {str(col)} - {vectorizer_name} + {classifier_name}:\\n', report_test)\n",
    "    print('-' * 20)\n",
    "\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, 'Accuracy')\n",
    "    ] = float(accuracy)\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, 'Precision')\n",
    "    ] = float(precision)\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, 'Recall')\n",
    "    ] = float(recall)\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, 'F1-score')\n",
    "    ] = float(f1)\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, 'Matthews Correlation Coefficient'),\n",
    "    ] = float(mcc)\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, f'{scoring.title()} Best Threshold'),\n",
    "    ] = float(best_threshold)\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, f'{scoring.title()} Best Score'),\n",
    "    ] = float(best_score)\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, 'Classification Report')\n",
    "    ] = report\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, 'Confusion Matrix')\n",
    "    ] = str(cm)\n",
    "\n",
    "    # Plot\n",
    "    heatmap = plot_confusion_matrix_percentage(col, cm, classifier_name, vectorizer_name)\n",
    "    plt.show()\n",
    "    if save_enabled == True:\n",
    "        heatmap.figure.savefig(\n",
    "            f'{plot_save_path}Confusion Matrix {str(col)} - {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
    "            format=image_save_format,\n",
    "            dpi=3000,\n",
    "            )\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n",
    "\n",
    "    # Log Loss Cross Entropy\n",
    "    if hasattr(classifier, 'predict_proba'):\n",
    "        y_test_prob_pred = classifier.predict_proba(X_test)[:, 1]\n",
    "        probability_of_1 = y_test_prob_pred#[:, 1]\n",
    "\n",
    "        loss = log_loss(y_test, y_test_prob_pred)\n",
    "        print('\\n')\n",
    "        print('=' * 20)\n",
    "        print(f'Log Loss / Cross Entropy = {loss}')\n",
    "        print('=' * 20)\n",
    "        print('\\n')\n",
    "        table_df.loc[\n",
    "            (classifier_name),\n",
    "            (col, vectorizer_name, 'Log Loss/Cross Entropy'),\n",
    "        ] = float(loss)\n",
    "\n",
    "        # Explain Model\n",
    "        explained = explain_model(test, y_test, y_test_pred, y_test_prob_pred, y_train)\n",
    "        if plots_enabled:\n",
    "            explained.show_in_notebook(text=txt_instance, predict_proba=False)\n",
    "\n",
    "        # ROC Curve\n",
    "        table_df, fpr, tpr, thresholds, auc, roc_curve, roc_auc = get_roc_curve(classifier, X_test, y_test, y_test_pred, probability_of_1, vectorizer_name, classifier_name, col)\n",
    "\n",
    "        # Precision Recall Curve\n",
    "        get_pr_curve(X_test, y_test, recall, precision, auc, vectorizer_name, classifier_name, col)\n",
    "\n",
    "    # Optimization\n",
    "    if optimization_enabled == True and hasattr(classifier, 'predict_log_proba'):\n",
    "        classifier, table_df, y_test_prob_log_pred, y_test_pred_new, cm_opt, precision_opt, recall_opt, accuracy_opt, f1_opt, mcc_opt, report_opt = optimize_model(\n",
    "            classifier,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            probability_of_1,\n",
    "            vectorizer_name,\n",
    "            classifier_name,\n",
    "            table_df,\n",
    "            score)\n",
    "\n",
    "        # ROC Curve\n",
    "        table_df, fpr, tpr, thresholds, auc, roc_curve, roc_auc = get_roc_curve(classifier, X_test, y_test, y_test_pred_new, probability_of_1, vectorizer_name, classifier_name, col)\n",
    "\n",
    "        # Precision Recall Curve\n",
    "        print(f'Precision Recall Curve AFTER OPTIMIZATION - {str(col)} - {vectorizer_name} + {classifier_name}')\n",
    "        get_pr_curve(X_test, y_test, recall_opt, precision_opt, auc, vectorizer_name, classifier_name, col)\n",
    "\n",
    "    if hasattr(classifier, 'best_estimator_'):\n",
    "        ohe_cols = list(\n",
    "            classifier.best_estimator_.named_steps['vectorizer']\n",
    "            .named_transformers_['cat']\n",
    "            .named_steps['ohe']\n",
    "            .get_feature_names(input_features=categorical)\n",
    "        )\n",
    "        num_feats = list(numerical)\n",
    "        num_feats.extend(ohe_cols)\n",
    "        feat_imp = eli5.explain_weights_df(\n",
    "            classifier.best_estimator_.named_steps['classifier'],\n",
    "            top=10,\n",
    "            feature_names=num_feats,\n",
    "        )\n",
    "        print(\n",
    "            f'feat_imp - {str(col)} - {vectorizer_name} + {classifier_name}: ',\n",
    "            feat_imp,\n",
    "        )\n",
    "        print('-' * 20)\n",
    "        print('\\n')\n",
    "\n",
    "    report_test = predict(\n",
    "        X_test,\n",
    "        y_test,\n",
    "        classifier,\n",
    "        classifier_name,\n",
    "        col,\n",
    "        scoring,\n",
    "        df_jobs_labeled,\n",
    "        print_enabled,\n",
    "    )\n",
    "    print(f'REPORT TEST {str(col)} - {vectorizer_name} + {classifier_name}:\\n', report_test)\n",
    "    print('-' * 20)\n",
    "\n",
    "    return classifier, table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11cc66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "def get_roc_curve(classifier, X_test, y_test, y_test_pred, probability_of_1, vectorizer_name, classifier_name, col):\n",
    "    roc_curve = metrics.plot_roc_curve(classifier, X_test, y_test)\n",
    "    plt.title(\n",
    "        f'ROC Curve {str(col)} - {vectorizer_name} + {classifier_name}',\n",
    "        fontsize=16,\n",
    "    )\n",
    "    if save_enabled == True:\n",
    "        roc_curve.figure_.savefig(\n",
    "            plot_save_path\n",
    "            + f'ROC {str(col)} - {classifier_name} - {vectorizer_name}.{image_save_format}',\n",
    "            format=image_save_format,\n",
    "            dpi=3000,\n",
    "        )\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(\n",
    "        y_test, probability_of_1, pos_label=1\n",
    "    )\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, 'ROC')\n",
    "    ] = float(roc_auc)\n",
    "    table_df.loc[\n",
    "        (classifier_name), (col, vectorizer_name, 'AUC')\n",
    "    ] = float(auc)\n",
    "\n",
    "    print('\\n')\n",
    "    print('-' * 20)\n",
    "    print(f'AUC {str(col)} - {vectorizer_name} + {classifier_name}:\\n', auc)\n",
    "\n",
    "    print('ROC CURVE FOR PREDICTED PROBABILITIES')\n",
    "    bc = BinaryClassification(y_test, y_test_pred, labels=['0', '1'])\n",
    "    # Figures\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    bc.plot_roc_curve()\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test_array[:,i],\n",
    "                            predicted_prob[:,i])\n",
    "        ax[0].plot(fpr, tpr, lw=3,\n",
    "                label='{0} (area={1:0.2f})'.format(classes[i],\n",
    "                                metrics.auc(fpr, tpr))\n",
    "                )\n",
    "    ax[0].plot([0,1], [0,1], color='navy', lw=3, linestyle='--')\n",
    "    ax[0].set(xlim=[-0.05,1.0], ylim=[0.0,1.05],\n",
    "            xlabel='False Positive Rate',\n",
    "            ylabel=\"True Positive Rate (Recall)\",\n",
    "            title=\"Receiver operating characteristic\")\n",
    "    ax[0].legend(loc=\"lower right\")\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    return table_df, fpr, tpr, thresholds, auc, roc_curve, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b08c3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Recall Curve\n",
    "def get_pr_curve(X_test, y_test, recall, precision, auc, vectorizer_name, classifier_name, col):\n",
    "\n",
    "    no_skill = len(y_test[y_test == 1]) / len(y_test)\n",
    "    pr_curve = plt.figure(figsize=(4.0, 4.0))\n",
    "    plt.plot(\n",
    "        [0, 1], [no_skill, no_skill], linestyle='--', label='No Skill'\n",
    "    )\n",
    "    plt.plot(\n",
    "        recall, precision, marker='.', label=f'AUC = {auc}'\n",
    "    )\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.title(\n",
    "        f'Precision Recall Curve {str(col)} - {vectorizer_name} + {classifier_name}',\n",
    "        fontsize=12.0,\n",
    "    )\n",
    "    plt.ylabel('Precision', fontsize=12.0)\n",
    "    plt.xlabel('Recall', fontsize=12.0)\n",
    "    plt.show()\n",
    "    if save_enabled == True:\n",
    "        pr_curve.savefig(\n",
    "            plot_save_path\n",
    "            + f'Precision Recall Curve {str(col)} - {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
    "            format=image_save_format,\n",
    "            dpi=3000,\n",
    "        )\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n",
    "\n",
    "    classes = np.unique(y_test)\n",
    "    for i in range(len(classes)):\n",
    "        precision, recall, thresholds = metrics.precision_recall_curve(\n",
    "            y_test_array[:,i], predicted_prob[:,i])\n",
    "        ax[1].plot(recall, precision, lw=3,\n",
    "                label=f'{classes[i]} (area={metrics.auc(recall, precision):0.2f})')\n",
    "    ax[1].set(xlim=[0.0,1.05], ylim=[0.0,1.05], xlabel='Recall',\n",
    "            ylabel=\"Precision\", title=\"Precision-Recall curve\")\n",
    "    ax[1].legend(loc=\"best\")\n",
    "    ax[1].grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a59d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize Model\n",
    "def optimize_model(classifier, X_test, y_test, probability_of_1, vectorizer_name, classifier_name, table_df, scoring):\n",
    "    if hasattr(classifier, 'predict_log_proba'):\n",
    "\n",
    "        y_test_prob_log_pred = classifier.predict_log_proba(X_test)[:, 1]\n",
    "\n",
    "        # calculate pr-curve\n",
    "        (\n",
    "            precision_opt,\n",
    "            recall_opt,\n",
    "            thresholds_opt,\n",
    "        ) = metrics.precision_recall_curve(\n",
    "            y_test, probability_of_1\n",
    "        )\n",
    "        # convert to f score\n",
    "        fscore_opt = (2 * precision_opt * recall_opt) / (\n",
    "            precision_opt + recall_opt\n",
    "        )\n",
    "        # locate the index of the largest f score\n",
    "        ix_opt = argmax(fscore_opt)\n",
    "        best_thresh_opt = thresholds_opt[ix_opt]\n",
    "        print('=' * 20)\n",
    "        print(\n",
    "            f'Best Threshold: {best_thresh_opt}, F-Score={fscore_opt[ix_opt]}'\n",
    "        )\n",
    "        print(f'Optimal threshold: {np.exp(best_thresh_opt)}')\n",
    "        y_test_pred_new = np.where(\n",
    "            y_test_prob_log_pred[:, 1] > best_thresh_opt, 1, 0\n",
    "        )\n",
    "        print(f'New y_test_pred {str(col)} - {vectorizer_name} + {classifier_name}:\\n{y_test_pred_new}')\n",
    "\n",
    "        print(\n",
    "            f'SCORES FOR {str(col)} - {vectorizer_name} + {classifier_name} AFTER OPTIMIZATION:'\n",
    "        )\n",
    "        cm_opt, precision_opt, recall_opt, accuracy_opt, f1_opt, mcc_opt, best_threshold_opt, best_score_opt, report_opt = evaluation(\n",
    "            y_test, y_test_pred_new, scoring, print_enabled\n",
    "        )\n",
    "\n",
    "        table_df.loc[\n",
    "            (classifier_name), (col, vectorizer_name, 'Accuracy_opt')\n",
    "        ] = float(accuracy_opt)\n",
    "        table_df.loc[\n",
    "            (classifier_name), (col, vectorizer_name, 'Precision_opt')\n",
    "        ] = float(precision_opt)\n",
    "        table_df.loc[\n",
    "            (classifier_name), (col, vectorizer_name, 'Recall_opt')\n",
    "        ] = float(recall_opt)\n",
    "        table_df.loc[\n",
    "            (classifier_name), (col, vectorizer_name, 'F1-score_opt')\n",
    "        ] = float(f1_opt)\n",
    "        table_df.loc[\n",
    "            (classifier_name), (col, vectorizer_name, 'Matthews Correlation Coefficient_opt'),\n",
    "        ] = float(mcc_opt)\n",
    "        table_df.loc[\n",
    "            (classifier_name), (col, vectorizer_name, f'{scoring.title()} Best Threshold_opt'),\n",
    "        ] = float(best_threshold_opt)\n",
    "        table_df.loc[\n",
    "            (classifier_name), (col, vectorizer_name, f'{scoring.title()} Best Score_opt'),\n",
    "        ] = float(best_score_opt)\n",
    "        table_df.loc[\n",
    "            (classifier_name), (col, vectorizer_name, 'Classification Report_opt'),\n",
    "        ] = report_opt\n",
    "        table_df.loc[\n",
    "            (classifier_name), (col, vectorizer_name, 'Confusion Matrix_opt'),\n",
    "        ] = str(cm_opt)\n",
    "\n",
    "        print('=' * 20)\n",
    "\n",
    "    elif not hasattr(classifier, 'predict_log_proba'):\n",
    "        print('Classifier has no Attribute predict_log_proba.')\n",
    "\n",
    "    return classifier, table_df, y_test_prob_log_pred, y_test_pred_new, cm_opt, precision_opt, recall_opt, accuracy_opt, f1_opt, mcc_opt, report_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0b9401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "def saving_model_and_table(vectorizer, vectorizer_name, selector, selector_name, classifier, classifier_name, col, table_save_path, table_df, models_save_path, csv_file_name, pickle_file_name, excel_file_name, latex_file_name, markdown_file_name, save_enabled = True, task_enabled = False):\n",
    "    if save_enabled == True:\n",
    "        if task_enabled == False:\n",
    "            classifier_save_path = (\n",
    "                f'{models_save_path}Model {str(col)} - {vectorizer_name} + {classifier_name}.{file_save_format}'\n",
    "            )\n",
    "            vectorizer_save_path = (\n",
    "                f'{models_save_path}Vectorizer {str(col)} - {vectorizer_name} + {classifier_name}.{file_save_format}'\n",
    "            )\n",
    "            if select_best_enabled == True:\n",
    "                selector_save_path = (\n",
    "                    f'{models_save_path}Selector {str(col)} - {vectorizer_name} + {classifier_name}.{file_save_format}'\n",
    "                )\n",
    "\n",
    "        elif task_enabled == True:\n",
    "            classifier_save_path = (\n",
    "                f'{models_save_path}Model {str(col)} - {vectorizer_name} + {classifier_name}_WITH_TASK.{file_save_format}'\n",
    "            )\n",
    "            vectorizer_save_path = (\n",
    "                f'{models_save_path}Vectorizer {str(col)} - {vectorizer_name} + {classifier_name}_WITH_TASK.{file_save_format}'\n",
    "            )\n",
    "            if select_best_enabled == True:\n",
    "                selector_save_path = (\n",
    "                    f'{models_save_path}Selector {str(col)} - {vectorizer_name} + {classifier_name}_WITH_TASK.{file_save_format}'\n",
    "                )\n",
    "\n",
    "        # Save classifier\n",
    "        print(f'Saving Model and Table for {vectorizer_name} + {classifier_name}.')\n",
    "        table_df.to_csv(table_save_path + csv_file_name)\n",
    "        table_df.to_pickle(table_save_path + pickle_file_name)\n",
    "        table_df.to_excel(table_save_path + excel_file_name)\n",
    "        table_df.to_latex(table_save_path + latex_file_name)\n",
    "        table_df.to_markdown(table_save_path + markdown_file_name)\n",
    "\n",
    "        with open(classifier_save_path, 'wb') as f:\n",
    "            joblib.dump(classifier, f)\n",
    "        with open(vectorizer_save_path, 'wb') as f:\n",
    "            joblib.dump(vectorizer, f)\n",
    "        if select_best_enabled == True:\n",
    "            with open(selector_save_path, 'wb') as f:\n",
    "                joblib.dump(selector, f)\n",
    "\n",
    "    elif save_enabled == False:\n",
    "        print('Saving Model and Table is disabled.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3936a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_evaluate(train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, classifier, classifier_name, vectorizer, vectorizer_name, boe_pred, boe_validate_pred, table_df, col, text_col, scoring):\n",
    "\n",
    "    if classifier_name == 'DummyClassifier' and use_dict_for_classifiers_vectorizers == False:\n",
    "        classifier_name += f' - {str(classifier.strategy).title()}'\n",
    "    classifier, X_test, y_test, y_test_prob_pred, best_threshold, best_score = classify(train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, classifier, classifier_name, vectorizer, vectorizer_name, boe_pred, boe_validate_pred)\n",
    "    classifier, table_df = evaluate_model(X_train, y_train, X_test, y_test, table_df, classifier, classifier_name, vectorizer, vectorizer_name, col, text_col, scoring)\n",
    "\n",
    "    return classifier, table_df, X_test, y_test, y_test_prob_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b13febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_pipe(df_jobs_labeled, vectorizers, selector, classifiers, col, text_col, scoring, table_df, table_save_path, models_save_path, csv_file_name, pickle_file_name, excel_file_name, latex_file_name, markdown_file_name):\n",
    "\n",
    "    print('Not using Search')\n",
    "\n",
    "    if use_dict_for_classifiers_vectorizers == True:\n",
    "        print('Using dict for classifiers and vectorizers.')\n",
    "        for vectorizer_name, vectorizer_and_params in vectorizers.items():\n",
    "            vectorizer = vectorizer_and_params[0]\n",
    "            vectorizer_params = vectorizer_and_params[1]\n",
    "            vectorizer.set_params(**vectorizer_params)\n",
    "            df_jobs_labeled, vectorizer, selector, train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, feature_names, unique_features, vocabulary_map, best_threshold_boe, best_score_boe, boe_pred, boe_validate_pred = vectorize(vectorizer, vectorizer_name, selector, df_jobs_labeled, col, text_col)\n",
    "\n",
    "            for classifier_name, classifier_and_params in classifiers.items():\n",
    "                classifier = classifier_and_params[0]\n",
    "                classifier_params = classifier_and_params[1]\n",
    "                classifier.set_params(**classifier_params)\n",
    "                classifier, table_df, X_test, y_test, y_test_prob_pred = classify_and_evaluate(train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, classifier, classifier_name, vectorizer, vectorizer_name, boe_pred, boe_validate_pred, table_df, col, text_col, scoring)\n",
    "\n",
    "                # Save Vectorizer, Selector, and Classifier\n",
    "                if save_enabled == True:\n",
    "                    saving_model_and_table(vectorizer, vectorizer_name, selector, selector_name, classifier, classifier_name, col, table_save_path, table_df, models_save_path, csv_file_name, pickle_file_name, excel_file_name, latex_file_name, markdown_file_name)\n",
    "\n",
    "    elif use_dict_for_classifiers_vectorizers == False:\n",
    "        print('Using list for classifiers and vectorizers.')\n",
    "        for vectorizer in vectorizers_lst:\n",
    "            vectorizer_name = vectorizer.__class__.__name__\n",
    "            df_jobs_labeled, vectorizer, selector, train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, feature_names, unique_features, vocabulary_map, best_threshold_boe, best_score_boe, boe_pred, boe_validate_pred = vectorize(vectorizer, vectorizer_name, selector, df_jobs_labeled, col, text_col)\n",
    "\n",
    "            for classifier in classifiers_lst:\n",
    "                classifier_name = classifier.__class__.__name__\n",
    "                classifier, table_df, X_test, y_test, y_test_prob_pred = classify_and_evaluate(train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, classifier, classifier_name, vectorizer, vectorizer_name, boe_pred, boe_validate_pred, table_df, col, text_col, scoring)\n",
    "\n",
    "                # Save Vectorizer, Selector, and Classifier\n",
    "                if save_enabled == True:\n",
    "                    saving_model_and_table(vectorizer, vectorizer_name, selector, selector_name, classifier, classifier_name, col, table_save_path, table_df, models_save_path, csv_file_name, pickle_file_name, excel_file_name, latex_file_name, markdown_file_name)\n",
    "\n",
    "    return df_jobs_labeled, classifier, vectorizers, selector, table_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cf4591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe(df_jobs_labeled, vectorizers_pipe, selectors_pipe, classifiers_pipe, col, text_col, scoring, table_df, table_save_path, models_save_path, csv_file_name, pickle_file_name, excel_file_name, latex_file_name, markdown_file_name):\n",
    "\n",
    "    print('Using Search')\n",
    "\n",
    "    print('Using dict for classifiers and vectorizers.')\n",
    "\n",
    "    # Vectorization\n",
    "    for vectorizer_name, vectorizer_and_params in vectorizers_pipe.items():\n",
    "        vectorizer = vectorizer_and_params[0]\n",
    "        vectorizer_params = vectorizer_and_params[1]\n",
    "\n",
    "        # Selection\n",
    "        for selector_name, selector_and_params in selectors_pipe.items():\n",
    "            selector = selector_and_params[0]\n",
    "            selector_params = selector_and_params[1]\n",
    "\n",
    "            # Classification\n",
    "            for classifier_name, classifier_and_params in classifiers_pipe.items():\n",
    "                classifier = classifier_and_params[0]\n",
    "                classifier_params = classifier_and_params[1]\n",
    "\n",
    "                # Pipeline\n",
    "                if select_best_enabled == True:\n",
    "                    ## Steps\n",
    "                    steps = [\n",
    "                        (vectorizer_name, vectorizer),\n",
    "                        (selector_name, selector),\n",
    "                        (classifier_name, classifier)\n",
    "                    ]\n",
    "                    ## Params\n",
    "                    param_grid = {\n",
    "                        **vectorizer_params,\n",
    "                        **selector_params,\n",
    "                        **classifier_params,\n",
    "                    }\n",
    "                    ## Pipeline\n",
    "                    pipe = Pipeline(steps=steps)\n",
    "\n",
    "                    ## Vectorizers, selectors, classifiers\n",
    "                    vectorizer = pipe[:-2]\n",
    "                    selector = pipe[:-1]\n",
    "                    classifier = pipe[:]\n",
    "\n",
    "                elif select_best_enabled == False:\n",
    "                    ## Steps\n",
    "                    steps = [\n",
    "                        (vectorizer_name, vectorizer),\n",
    "                        (classifier_name, classifier)\n",
    "                    ]\n",
    "                    ## Params\n",
    "                    param_grid = {\n",
    "                        **vectorizer_params,\n",
    "                        **classifier_params,\n",
    "                    }\n",
    "                    ## Pipeline\n",
    "                    pipe = Pipeline(steps=steps)\n",
    "\n",
    "                    ## Vectorizers, selectors, classifiers\n",
    "                    vectorizer = pipe[:-1]\n",
    "                    classifier = pipe[:]\n",
    "\n",
    "                # Search\n",
    "                search = RandomizedSearchCV(\n",
    "                    estimator=pipe,\n",
    "                    param_distributions=param_grid,\n",
    "                    n_jobs=-1,\n",
    "                    scoring=scores,\n",
    "                    cv=cv,\n",
    "                    refit=scores[0],\n",
    "                    return_train_score=True,\n",
    "                    verbose=3,\n",
    "                )\n",
    "\n",
    "                # Fit SearchCV\n",
    "                searchcv = search.fit(X_train, y_train)\n",
    "\n",
    "                # Best Parameters\n",
    "                best_index = searchcv.best_index_\n",
    "                cv_results = sorted(searchcv.cv_results_)\n",
    "                best_params = searchcv.best_params_\n",
    "                classifier = searchcv.best_estimator_\n",
    "                y_train_pred = classifier.predict(X_train)\n",
    "                best_score = searchcv.best_score_\n",
    "                n_splits = searchcv.n_splits_\n",
    "\n",
    "                print('=' * 20)\n",
    "                print(f'Best index for {scores[0]}: {best_index}')\n",
    "                print(f'Best classifier for {scores[0]}: {classifier}')\n",
    "                print(f'Best y_train_pred for {scores[0]}: {y_train_pred}')\n",
    "                print(f'Best score for {scores[0]}: {best_score}')\n",
    "                print(f'Number of splits for {scores[0]}: {n_splits}')\n",
    "\n",
    "                print('-' * 20)\n",
    "                report = classification_report(y_train, y_train_pred)\n",
    "                print(f'Classification Report:\\n{report}')\n",
    "                ConfusionMatrixDisplay.from_estimator(\n",
    "                    searchcv, X_test, y_test, xticks_rotation=\"vertical\"\n",
    "                )\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                print('=' * 20)\n",
    "\n",
    "                # Make the predictions\n",
    "                score = searchcv.score(X_test, y_test)\n",
    "                y_test_pred = searchcv.predict(X_test)\n",
    "                if hasattr(searchcv, 'predict_proba'):\n",
    "                    y_test_prob_pred = searchcv.predict_proba(X_test)[:, 1]\n",
    "                    y_validate_prob_pred = searchcv.predict_proba(X_validate)[:, 1]\n",
    "                elif hasattr(searchcv, '_predict_proba_lr'):\n",
    "                    y_test_prob_pred = searchcv._predict_proba_lr(X_test)[:, 1]\n",
    "                    y_validate_prob_pred = searchcv._predict_proba_lr(X_validate)[:, 1]\n",
    "\n",
    "                # Fit Best Model\n",
    "                print(f'Fitting {classifier}.')\n",
    "                classifier.set_params(**classifier.get_params())\n",
    "                classifier = classifier.fit(X_train, y_train)\n",
    "\n",
    "                # Evaluate Model\n",
    "                classifier, table_df = evaluate_model(X_train, y_train, X_test, y_test, table_df, classifier, classifier_name, vectorizer, vectorizer_name, col, text_col, scoring)\n",
    "\n",
    "                # Save Vectorizer, Selector, and Classifier\n",
    "                if save_enabled == True:\n",
    "                    saving_model_and_table(vectorizer, vectorizer_name, selector, selector_name, classifier, classifier_name, col, table_save_path, table_df, models_save_path, csv_file_name, pickle_file_name, excel_file_name, latex_file_name, markdown_file_name)\n",
    "\n",
    "    return df_jobs_labeled, searchcv, classifier, vectorizers, selector, table_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2f86d",
   "metadata": {},
   "source": [
    "# Training Supervised Model: Warmth and Competence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16d94250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "\n",
      "\n",
      "============================ STARTING PROCESSING WARMTH ============================\n",
      "\n",
      "\n",
      "--------------------\n",
      "Not using Search\n",
      "Using dict for classifiers and vectorizers.\n",
      "============================ Warmth: CountVectorizer passed ============================\n",
      "Splitting data into training and test sets.\n",
      "Resampling Warmth to fix imbalance.\n",
      "====================\n",
      "--------------------\n",
      "Original dataset shape (4579,)\n",
      "Original dataset, counts of label \"1\": 1180\n",
      "Original dataset, counts of label \"0\": 3399\n",
      "Resampled dataset shape (4579,)\n",
      "Resampled dataset, counts of label \"1\": 1180\n",
      "Resampled dataset, counts of label \"0\": 3399\n",
      "--------------------\n",
      "Fitting and transforming data.\n",
      "Train words shape: torch.Size([55350])\n",
      "Train offsets shape: torch.Size([6783])\n",
      "Created words and offsets for train data\n",
      "Test words shape: torch.Size([5115])\n",
      "Test offsets shape: torch.Size([611])\n",
      "Created words and offsets for test data\n",
      "Validate words shape: torch.Size([7784])\n",
      "Validate offsets shape: torch.Size([916])\n",
      "Created words and offsets for validate data\n",
      "Embedding Model: BagOfEmbeddings(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (embedding): EmbeddingBag(10000, 300, mode=mean)\n",
      "  (final_layer): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=300, out_features=75, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Linear(in_features=75, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Training samples: 6783\n",
      "Starting epoch 1\n",
      "Training avg emb_model complete!\n",
      "Evaluating test set\n",
      "Test samples:  611\n",
      "Starting testing\n",
      "outputs.shape torch.Size([611, 1])\n",
      "Recall at best threshold 0.01: 1.0\n",
      "boe_pred:\n",
      " [0.97810125]\n",
      "Evaluating validate outputs\n",
      "Test samples:  916\n",
      "Starting testing\n",
      "boe_validate_pred:\n",
      " [0.9333397]\n",
      "Validate outputs done\n",
      "\n",
      "\n",
      "============================ Warmth: CountVectorizer + DummyClassifier_MostFrequent passed ============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:58<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating Equity/Study 1/Study1_Code/Analysis/1. train_and_evaluate_estimators.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000018?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000018?line=7'>8</a>\u001b[0m     \u001b[39mlen\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000018?line=8'>9</a>\u001b[0m         df_jobs_labeled[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000018?line=14'>15</a>\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000018?line=15'>16</a>\u001b[0m ):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000018?line=17'>18</a>\u001b[0m     \u001b[39mif\u001b[39;00m search_enabled \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000018?line=18'>19</a>\u001b[0m         df_jobs_labeled, classifier, vectorizers, selector, table_df \u001b[39m=\u001b[39m no_pipe(df_jobs_labeled, vectorizers, selector, classifiers, col, text_col, scoring, table_df, table_save_path, models_save_path, csv_file_name, excel_file_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000018?line=20'>21</a>\u001b[0m     \u001b[39melif\u001b[39;00m search_enabled \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000018?line=21'>22</a>\u001b[0m         df_jobs_labeled, searchcv, classifier, vectorizers, selector, table_df \u001b[39m=\u001b[39m pipe(df_jobs_labeled, vectorizers_pipe, selectors_pipe, classifiers_pipe, col, text_col, scoring, table_df, table_save_path, models_save_path, csv_file_name, excel_file_name)\n",
      "\u001b[1;32m/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating Equity/Study 1/Study1_Code/Analysis/1. train_and_evaluate_estimators.ipynb Cell 16'\u001b[0m in \u001b[0;36mno_pipe\u001b[0;34m(df_jobs_labeled, vectorizers, selector, classifiers, col, text_col, scoring, table_df, table_save_path, models_save_path, csv_file_name, excel_file_name)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000015?line=14'>15</a>\u001b[0m classifier_params \u001b[39m=\u001b[39m classifier_and_params[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000015?line=15'>16</a>\u001b[0m classifier\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mclassifier_params)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000015?line=16'>17</a>\u001b[0m classifier, table_df, X_test, y_test, y_test_prob_pred \u001b[39m=\u001b[39m classify_and_evaluate(train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, classifier, classifier_name, vectorizer, vectorizer_name, boe_pred, boe_validate_pred, table_df, col, text_col, scoring)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000015?line=18'>19</a>\u001b[0m \u001b[39m# Save Vectorizer, Selector, and Classifier\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000015?line=19'>20</a>\u001b[0m \u001b[39mif\u001b[39;00m save_enabled \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[1;32m/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating Equity/Study 1/Study1_Code/Analysis/1. train_and_evaluate_estimators.ipynb Cell 15'\u001b[0m in \u001b[0;36mclassify_and_evaluate\u001b[0;34m(train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, classifier, classifier_name, vectorizer, vectorizer_name, boe_pred, boe_validate_pred, table_df, col, text_col, scoring)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000014?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m classifier_name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDummyClassifier\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m use_dict_for_classifiers_vectorizers \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000014?line=3'>4</a>\u001b[0m     classifier_name \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m - \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(classifier\u001b[39m.\u001b[39mstrategy)\u001b[39m.\u001b[39mtitle()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000014?line=4'>5</a>\u001b[0m classifier, X_test, y_test, y_test_prob_pred, best_threshold, best_score \u001b[39m=\u001b[39m classify(train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, classifier, classifier_name, vectorizer, vectorizer_name, boe_pred, boe_validate_pred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000014?line=5'>6</a>\u001b[0m classifier, table_df \u001b[39m=\u001b[39m evaluate_model(X_train, y_train, X_test, y_test, table_df, classifier, classifier_name, vectorizer, vectorizer_name, col, text_col, scoring)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000014?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m classifier, table_df, X_test, y_test, y_test_prob_pred\n",
      "\u001b[1;32m/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating Equity/Study 1/Study1_Code/Analysis/1. train_and_evaluate_estimators.ipynb Cell 9'\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, classifier, classifier_name, vectorizer, vectorizer_name, boe_pred, boe_validate_pred)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000008?line=28'>29</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000008?line=29'>30</a>\u001b[0m     \u001b[39mraise\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mclassifier_name\u001b[39m}\u001b[39;00m\u001b[39m has neither predict_proba nor _predict_proba_lr attributes.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000008?line=31'>32</a>\u001b[0m final_classifier, X_test, y_test, y_test_prob_pred, best_threshold, best_score, df_preds \u001b[39m=\u001b[39m augment(classifier, classifier_name, vectorizer, vectorizer_name, final_classifier, test, y_test, y_test_prob_pred, validate, y_validate, y_validate_prob_pred, boe_pred, boe_validate_pred, scoring, print_enabled)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000008?line=33'>34</a>\u001b[0m \u001b[39mreturn\u001b[39;00m final_classifier, X_test, y_test, y_test_prob_pred, best_threshold, best_score\n",
      "\u001b[1;32m/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating Equity/Study 1/Study1_Code/Analysis/1. train_and_evaluate_estimators.ipynb Cell 8'\u001b[0m in \u001b[0;36maugment\u001b[0;34m(classifier, classifier_name, vectorizer, vectorizer_name, final_classifier, test, y_test, y_test_prob_pred, validate, y_validate, y_validate_prob_pred, boe_pred, boe_validate_pred, scoring, print_enabled)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maugment\u001b[39m(classifier, classifier_name, vectorizer, vectorizer_name, final_classifier, test, y_test, y_test_prob_pred, validate, y_validate, y_validate_prob_pred, boe_pred, boe_validate_pred, scoring, print_enabled):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000007?line=2'>3</a>\u001b[0m     num \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(test) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000007?line=4'>5</a>\u001b[0m     best_threshold, best_score \u001b[39m=\u001b[39m calculate_best_threshold(y_test[:num], y_test_prob_pred[:num], scoring, print_enabled)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000007?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m (boe_pred \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (boe_validate_pred \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000007?line=7'>8</a>\u001b[0m         num \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(boe_pred) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UvA/Automating Equity/Study 1/Study1_Code/setup_module/classification.py:898\u001b[0m, in \u001b[0;36mcalculate_best_threshold\u001b[0;34m(y_test, y_test_pred, scoring, print_enabled)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/setup_module/classification.py?line=894'>895</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/setup_module/classification.py?line=895'>896</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mscoring\u001b[39m.\u001b[39mtitle()\u001b[39m}\u001b[39;00m\u001b[39m is not a valid score\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='file:///Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/setup_module/classification.py?line=897'>898</a>\u001b[0m emb_model_score \u001b[39m=\u001b[39m scorer(y_true\u001b[39m=\u001b[39;49my_test, y_pred\u001b[39m=\u001b[39;49m(y_test_pred \u001b[39m>\u001b[39;49m threshold)\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m))\n\u001b[1;32m    <a href='file:///Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/setup_module/classification.py?line=898'>899</a>\u001b[0m \u001b[39mif\u001b[39;00m emb_model_score \u001b[39m>\u001b[39m best_score:\n\u001b[1;32m    <a href='file:///Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/setup_module/classification.py?line=899'>900</a>\u001b[0m     best_score \u001b[39m=\u001b[39m emb_model_score\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1901\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1769'>1770</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecall_score\u001b[39m(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1770'>1771</a>\u001b[0m     y_true,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1771'>1772</a>\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1777'>1778</a>\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1778'>1779</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1779'>1780</a>\u001b[0m     \u001b[39m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1780'>1781</a>\u001b[0m \n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1781'>1782</a>\u001b[0m \u001b[39m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1898'>1899</a>\u001b[0m \u001b[39m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1899'>1900</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1900'>1901</a>\u001b[0m     _, r, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1901'>1902</a>\u001b[0m         y_true,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1902'>1903</a>\u001b[0m         y_pred,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1903'>1904</a>\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1904'>1905</a>\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1905'>1906</a>\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1906'>1907</a>\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1907'>1908</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1908'>1909</a>\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1909'>1910</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1910'>1911</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1541'>1542</a>\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1542'>1543</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1543'>1544</a>\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1545'>1546</a>\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1546'>1547</a>\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1348\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1344'>1345</a>\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1345'>1346</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1347'>1348</a>\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1348'>1349</a>\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1349'>1350</a>\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1350'>1351</a>\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=89'>90</a>\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=91'>92</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=92'>93</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=93'>94</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=94'>95</a>\u001b[0m             type_true, type_pred\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=95'>96</a>\u001b[0m         )\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=96'>97</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=98'>99</a>\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=99'>100</a>\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "for col in tqdm.tqdm(analysis_columns):\n",
    "    print('-' * 20)\n",
    "    print('\\n')\n",
    "    print(f'============================ STARTING PROCESSING {col.upper()} ============================')\n",
    "    print('\\n')\n",
    "    print('-' * 20)\n",
    "    if (\n",
    "        len(\n",
    "            df_jobs_labeled[\n",
    "                df_jobs_labeled[str(col)].map(\n",
    "                    df_jobs_labeled[str(col)].value_counts() > 50\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        != 0\n",
    "    ):\n",
    "\n",
    "        # BOW Split\n",
    "        train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, prepared_text = split_data(df_jobs_labeled, vectorizer, col, text_col)\n",
    "\n",
    "        if search_enabled == False:\n",
    "            df_jobs_labeled, classifier, vectorizers, selector, table_df = no_pipe(df_jobs_labeled, vectorizers, selector, classifiers, col, text_col, scoring, table_df, table_save_path, models_save_path, csv_file_name, pickle_file_name, excel_file_name, latex_file_name, markdown_file_name)\n",
    "\n",
    "        elif search_enabled == True:\n",
    "            df_jobs_labeled, searchcv, classifier, vectorizers, selector, table_df = pipe(df_jobs_labeled, vectorizers_pipe, selectors_pipe, classifiers_pipe, col, text_col, scoring, table_df, table_save_path, models_save_path, csv_file_name, pickle_file_name, excel_file_name, latex_file_name, markdown_file_name)\n",
    "\n",
    "    print('-' * 20)\n",
    "    print('\\n')\n",
    "    print(f'============================ FINISHED PROCESSING {col.upper()} ============================')\n",
    "    print('\\n')\n",
    "    print('-' * 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6b4e024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Search\n",
      "Using dict for classifiers and vectorizers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(lowercase='True', max_features=10000, ngram_range=(1, 3),\n",
       "                stop_words='english')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ Warmth: CountVectorizer passed ============================\n",
      "Splitting data into training and test sets.\n",
      "Resampling Warmth to fix imbalance.\n",
      "====================\n",
      "--------------------\n",
      "Original dataset shape (4579,)\n",
      "Original dataset, counts of label \"1\": 1180\n",
      "Original dataset, counts of label \"0\": 3399\n",
      "Resampled dataset shape (4579,)\n",
      "Resampled dataset, counts of label \"1\": 1180\n",
      "Resampled dataset, counts of label \"0\": 3399\n",
      "--------------------\n",
      "Fitting and transforming data.\n",
      "Train words shape: torch.Size([54776])\n",
      "Train offsets shape: torch.Size([6777])\n",
      "Created words and offsets for train data\n",
      "Test words shape: torch.Size([5115])\n",
      "Test offsets shape: torch.Size([611])\n",
      "Created words and offsets for test data\n",
      "Validate words shape: torch.Size([7784])\n",
      "Validate offsets shape: torch.Size([916])\n",
      "Created words and offsets for validate data\n",
      "Embedding Model: BagOfEmbeddings(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (embedding): EmbeddingBag(10000, 300, mode=mean)\n",
      "  (final_layer): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=300, out_features=75, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Linear(in_features=75, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Training samples: 6777\n",
      "Starting epoch 1\n",
      "Training avg emb_model complete!\n",
      "Evaluating test set\n",
      "Test samples:  611\n",
      "Starting testing\n",
      "outputs.shape torch.Size([611, 1])\n",
      "Recall at best threshold 0.01: 1.0\n",
      "boe_pred:\n",
      " [0.95269847]\n",
      "Evaluating validate outputs\n",
      "Test samples:  916\n",
      "Starting testing\n",
      "boe_validate_pred:\n",
      " [0.8560855]\n",
      "Validate outputs done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=42, strategy='most_frequent')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=42, strategy='stratified')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=42, strategy='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=1, n_neighbors=3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', multi_class='ovr', n_jobs=1,\n",
       "                   random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(class_weight='balanced', n_jobs=1, random_state=42,\n",
       "                            tol=0.0001)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(class_weight='balanced', loss='hinge', random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_features=None,\n",
       "                       n_estimators=10, n_jobs=1, random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=0.7,\n",
       "              enable_categorical=False, eval_metric='auc', gamma=None,\n",
       "              gpu_id=None, importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.05, max_delta_step=None, max_depth=6,\n",
       "              min_child_weight=11, missing=-999, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, nthread=4, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, sample_type='weighted', scale_pos_weight=None,\n",
       "              seed=1337, silent=1, subsample=0.8, ...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Multinomial Naive Bayes', MultinomialNB()),\n",
       "                             ('Logistic Regression',\n",
       "                              LogisticRegression(class_weight='balanced',\n",
       "                                                 random_state=42))],\n",
       "                 n_jobs=1, voting='soft')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
       "                   estimators=[('Multinomial Naive Bayes', MultinomialNB()),\n",
       "                               ('Logistic Regression',\n",
       "                                LogisticRegression(class_weight='balanced',\n",
       "                                                   random_state=42))],\n",
       "                   final_estimator=RandomForestClassifier(class_weight={0: 1,\n",
       "                                                                        1: 2},\n",
       "                                                          random_state=42),\n",
       "                   n_jobs=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(lowercase='True', max_features=10000, ngram_range=(1, 3),\n",
       "                stop_words='english', use_idf='True')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ Warmth: TfidfVectorizer passed ============================\n",
      "Splitting data into training and test sets.\n",
      "Resampling Warmth to fix imbalance.\n",
      "====================\n",
      "--------------------\n",
      "Original dataset shape (4579,)\n",
      "Original dataset, counts of label \"1\": 1180\n",
      "Original dataset, counts of label \"0\": 3399\n",
      "Resampled dataset shape (4579,)\n",
      "Resampled dataset, counts of label \"1\": 1180\n",
      "Resampled dataset, counts of label \"0\": 3399\n",
      "--------------------\n",
      "Fitting and transforming data.\n",
      "Train words shape: torch.Size([102664])\n",
      "Train offsets shape: torch.Size([6790])\n",
      "Created words and offsets for train data\n",
      "Test words shape: torch.Size([5115])\n",
      "Test offsets shape: torch.Size([611])\n",
      "Created words and offsets for test data\n",
      "Validate words shape: torch.Size([7784])\n",
      "Validate offsets shape: torch.Size([916])\n",
      "Created words and offsets for validate data\n",
      "Embedding Model: BagOfEmbeddings(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (embedding): EmbeddingBag(10000, 300, mode=mean)\n",
      "  (final_layer): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=300, out_features=75, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Linear(in_features=75, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Training samples: 6790\n",
      "Starting epoch 1\n",
      "Training avg emb_model complete!\n",
      "Evaluating test set\n",
      "Test samples:  611\n",
      "Starting testing\n",
      "outputs.shape torch.Size([611, 1])\n",
      "Recall at best threshold 0.01: 1.0\n",
      "boe_pred:\n",
      " [0.80718166]\n",
      "Evaluating validate outputs\n",
      "Test samples:  916\n",
      "Starting testing\n",
      "boe_validate_pred:\n",
      " [0.72098076]\n",
      "Validate outputs done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=42, strategy='most_frequent')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=42, strategy='stratified')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=42, strategy='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=1, n_neighbors=3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', multi_class='ovr', n_jobs=1,\n",
       "                   random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(class_weight='balanced', n_jobs=1, random_state=42,\n",
       "                            tol=0.0001)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(class_weight='balanced', loss='hinge', random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_features=None,\n",
       "                       n_estimators=10, n_jobs=1, random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=0.7,\n",
       "              enable_categorical=False, eval_metric='auc', gamma=None,\n",
       "              gpu_id=None, importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.05, max_delta_step=None, max_depth=6,\n",
       "              min_child_weight=11, missing=-999, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, nthread=4, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, sample_type='weighted', scale_pos_weight=None,\n",
       "              seed=1337, silent=1, subsample=0.8, ...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Multinomial Naive Bayes', MultinomialNB()),\n",
       "                             ('Logistic Regression',\n",
       "                              LogisticRegression(class_weight='balanced',\n",
       "                                                 random_state=42))],\n",
       "                 n_jobs=1, voting='soft')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
       "                   estimators=[('Multinomial Naive Bayes', MultinomialNB()),\n",
       "                               ('Logistic Regression',\n",
       "                                LogisticRegression(class_weight='balanced',\n",
       "                                                   random_state=42))],\n",
       "                   final_estimator=RandomForestClassifier(class_weight={0: 1,\n",
       "                                                                        1: 2},\n",
       "                                                          random_state=42),\n",
       "                   n_jobs=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "FeatureUnion(transformer_list=[('CountVectorizer',\n",
       "                                CountVectorizer(lowercase='True',\n",
       "                                                max_features=10000,\n",
       "                                                ngram_range=(1, 3),\n",
       "                                                stop_words='english')),\n",
       "                               ('TfidfVectorizer',\n",
       "                                TfidfVectorizer(lowercase='True',\n",
       "                                                max_features=10000,\n",
       "                                                ngram_range=(1, 3),\n",
       "                                                stop_words='english',\n",
       "                                                use_idf='True'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ Warmth: UnionBOW passed ============================\n",
      "Splitting data into training and test sets.\n",
      "Resampling Warmth to fix imbalance.\n",
      "====================\n",
      "--------------------\n",
      "Original dataset shape (4579,)\n",
      "Original dataset, counts of label \"1\": 1180\n",
      "Original dataset, counts of label \"0\": 3399\n",
      "Resampled dataset shape (4579,)\n",
      "Resampled dataset, counts of label \"1\": 1180\n",
      "Resampled dataset, counts of label \"0\": 3399\n",
      "--------------------\n",
      "Fitting and transforming data.\n",
      "Train words shape: torch.Size([174048])\n",
      "Train offsets shape: torch.Size([6789])\n",
      "Created words and offsets for train data\n",
      "Test words shape: torch.Size([10230])\n",
      "Test offsets shape: torch.Size([611])\n",
      "Created words and offsets for test data\n",
      "Validate words shape: torch.Size([15568])\n",
      "Validate offsets shape: torch.Size([916])\n",
      "Created words and offsets for validate data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=42, strategy='most_frequent')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=42, strategy='stratified')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=42, strategy='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=1, n_neighbors=3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', multi_class='ovr', n_jobs=1,\n",
       "                   random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(class_weight='balanced', n_jobs=1, random_state=42,\n",
       "                            tol=0.0001)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(class_weight='balanced', loss='hinge', random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_features=None,\n",
       "                       n_estimators=10, n_jobs=1, random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=0.7,\n",
       "              enable_categorical=False, eval_metric='auc', gamma=None,\n",
       "              gpu_id=None, importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.05, max_delta_step=None, max_depth=6,\n",
       "              min_child_weight=11, missing=-999, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, nthread=4, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, sample_type='weighted', scale_pos_weight=None,\n",
       "              seed=1337, silent=1, subsample=0.8, ...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Multinomial Naive Bayes', MultinomialNB()),\n",
       "                             ('Logistic Regression',\n",
       "                              LogisticRegression(class_weight='balanced',\n",
       "                                                 random_state=42))],\n",
       "                 n_jobs=1, voting='soft')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=KFold(n_splits=2, random_state=None, shuffle=False),\n",
       "                   estimators=[('Multinomial Naive Bayes', MultinomialNB()),\n",
       "                               ('Logistic Regression',\n",
       "                                LogisticRegression(class_weight='balanced',\n",
       "                                                   random_state=42))],\n",
       "                   final_estimator=RandomForestClassifier(class_weight={0: 1,\n",
       "                                                                        1: 2},\n",
       "                                                          random_state=42),\n",
       "                   n_jobs=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Not using Search')\n",
    "\n",
    "if use_dict_for_classifiers_vectorizers == True:\n",
    "    print('Using dict for classifiers and vectorizers.')\n",
    "    for vectorizer_name, vectorizer_and_params in vectorizers.items():\n",
    "        vectorizer = vectorizer_and_params[0]\n",
    "        vectorizer_params = vectorizer_and_params[1]\n",
    "        vectorizer.set_params(**vectorizer_params)\n",
    "        df_jobs_labeled, vectorizer, selector, train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, feature_names, unique_features, vocabulary_map, best_threshold_boe, best_score_boe, boe_pred, boe_validate_pred = vectorize(vectorizer, vectorizer_name, selector, df_jobs_labeled, col, text_col)\n",
    "\n",
    "        for classifier_name, classifier_and_params in classifiers.items():\n",
    "            classifier = classifier_and_params[0]\n",
    "            classifier_params = classifier_and_params[1]\n",
    "            classifier.set_params(**classifier_params)\n",
    "            # classifier, table_df, X_test, y_test, y_test_prob_pred = classify_and_evaluate(train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, classifier, classifier_name, vectorizer, vectorizer_name, boe_pred, boe_validate_pred, table_df, col, text_col, scoring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e94000ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if classifier_name == 'DummyClassifier' and use_dict_for_classifiers_vectorizers == False:\n",
    "    classifier_name += f' - {str(classifier.strategy).title()}'\n",
    "# classifier, X_test, y_test, y_test_prob_pred, best_threshold, best_score = classify(train, X_train, y_train, test, X_test, y_test, validate, X_validate, y_validate, classifier, classifier_name, vectorizer, vectorizer_name, boe_pred, boe_validate_pred)\n",
    "# classifier, table_df = evaluate_model(X_train, y_train, X_test, y_test, table_df, classifier, classifier_name, vectorizer, vectorizer_name, col, text_col, scoring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "825727f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================ Warmth: UnionBOW + StackingClassifier passed ============================\n"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print(\n",
    "    f'============================ {str(col)}: {vectorizer_name} + {classifier_name} passed ============================'\n",
    ")\n",
    "num = len(test) // 2\n",
    "\n",
    "# BOW model\n",
    "if classifier_name == 'GaussianNB':\n",
    "    X_train = X_train.todense()\n",
    "    X_test = X_test.todense()\n",
    "    X_validate = X_validate.todense()\n",
    "\n",
    "if classifier_name == 'Sequential':\n",
    "    classifier.compile(loss='categorical_crossentropy')\n",
    "if hasattr(classifier, 'decision_function') and not hasattr(classifier, 'predict_proba'):\n",
    "    classifier = CalibratedClassifierCV(classifier, cv = cv, method = 'sigmoid')\n",
    "\n",
    "final_classifier = classifier\n",
    "classifier = classifier.fit(X_train, y_train)\n",
    "\n",
    "if hasattr(classifier, 'predict_proba'):\n",
    "    y_test_prob_pred = classifier.predict_proba(X_test)\n",
    "    y_validate_prob_pred = classifier.predict_proba(X_validate)\n",
    "elif hasattr(classifier, '_predict_proba_lr'):\n",
    "    y_test_prob_pred = classifier._predict_proba_lr(X_test)\n",
    "    y_validate_prob_pred = classifier._predict_proba_lr(X_validate)\n",
    "else:\n",
    "    raise(f'{classifier_name} has neither predict_proba nor _predict_proba_lr attributes.')\n",
    "\n",
    "# final_classifier, X_test, y_test, y_test_prob_pred, best_threshold, best_score, df_preds = augment(classifier, classifier_name, vectorizer, vectorizer_name, final_classifier, test, y_test, y_test_prob_pred, validate, y_validate, y_validate_prob_pred, boe_pred, boe_validate_pred, scoring, print_enabled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9b8173c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating Equity/Study 1/Study1_Code/Analysis/1. train_and_evaluate_estimators.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000022?line=0'>1</a>\u001b[0m num \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(test) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000022?line=2'>3</a>\u001b[0m best_threshold, best_score \u001b[39m=\u001b[39m calculate_best_threshold(y_test[:num], y_test_prob_pred[:num], scoring, print_enabled)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000022?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m (boe_pred \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (boe_validate_pred \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000022?line=5'>6</a>\u001b[0m     num \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(boe_pred) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-UvA/Automating Equity/Study 1/Study1_Code/setup_module/classification.py:898\u001b[0m, in \u001b[0;36mcalculate_best_threshold\u001b[0;34m(y_test, y_test_pred, scoring, print_enabled)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/setup_module/classification.py?line=894'>895</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/setup_module/classification.py?line=895'>896</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mscoring\u001b[39m.\u001b[39mtitle()\u001b[39m}\u001b[39;00m\u001b[39m is not a valid score\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='file:///Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/setup_module/classification.py?line=897'>898</a>\u001b[0m emb_model_score \u001b[39m=\u001b[39m scorer(y_true\u001b[39m=\u001b[39;49my_test, y_pred\u001b[39m=\u001b[39;49m(y_test_pred \u001b[39m>\u001b[39;49m threshold)\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m))\n\u001b[1;32m    <a href='file:///Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/setup_module/classification.py?line=898'>899</a>\u001b[0m \u001b[39mif\u001b[39;00m emb_model_score \u001b[39m>\u001b[39m best_score:\n\u001b[1;32m    <a href='file:///Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/setup_module/classification.py?line=899'>900</a>\u001b[0m     best_score \u001b[39m=\u001b[39m emb_model_score\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1901\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1769'>1770</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecall_score\u001b[39m(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1770'>1771</a>\u001b[0m     y_true,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1771'>1772</a>\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1777'>1778</a>\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1778'>1779</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1779'>1780</a>\u001b[0m     \u001b[39m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1780'>1781</a>\u001b[0m \n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1781'>1782</a>\u001b[0m \u001b[39m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1898'>1899</a>\u001b[0m \u001b[39m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1899'>1900</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1900'>1901</a>\u001b[0m     _, r, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1901'>1902</a>\u001b[0m         y_true,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1902'>1903</a>\u001b[0m         y_pred,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1903'>1904</a>\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1904'>1905</a>\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1905'>1906</a>\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1906'>1907</a>\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1907'>1908</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1908'>1909</a>\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1909'>1910</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1910'>1911</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1541'>1542</a>\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1542'>1543</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1543'>1544</a>\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1545'>1546</a>\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1546'>1547</a>\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1348\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1344'>1345</a>\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1345'>1346</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1347'>1348</a>\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1348'>1349</a>\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1349'>1350</a>\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1350'>1351</a>\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=89'>90</a>\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=91'>92</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=92'>93</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=93'>94</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=94'>95</a>\u001b[0m             type_true, type_pred\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=95'>96</a>\u001b[0m         )\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=96'>97</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=98'>99</a>\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=99'>100</a>\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "num = len(test) // 2\n",
    "\n",
    "best_threshold, best_score = calculate_best_threshold(y_test[:num], y_test_prob_pred[:num], scoring, print_enabled)\n",
    "\n",
    "if (boe_pred is not None) and (boe_validate_pred is not None):\n",
    "    num = len(boe_pred) // 2\n",
    "\n",
    "    X_final_augmented_train = pd.DataFrame({\n",
    "        \"y_test_prob_pred\": y_test_prob_pred[:num],\n",
    "        \"boe_pred\": boe_pred[:num].squeeze(),\n",
    "        \"num_words\": test[\"num_words\"].values[:num],\n",
    "        \"num_chars\": test[\"num_chars\"].values[:num]})\n",
    "    y_final_augmented_train = y_test[:num]\n",
    "\n",
    "    X_final_augmented_test = pd.DataFrame({\n",
    "        \"y_test_prob_pred\": y_test_prob_pred[num:],\n",
    "        \"boe_pred\": boe_pred[num:].squeeze(),\n",
    "        \"num_words\": test[\"num_words\"].values[num:],\n",
    "        \"num_chars\": test[\"num_chars\"].values[num:]})\n",
    "    y_final_augmented_test = y_test[num:]\n",
    "\n",
    "    final_classifier = final_classifier.fit(X_final_augmented_train, y_final_augmented_train)\n",
    "\n",
    "    if hasattr(final_classifier, 'predict_proba'):\n",
    "        y_final_test_prob_pred = final_classifier.predict_proba(X_final_augmented_test)[:, 1]\n",
    "    elif hasattr(final_classifier, '_predict_proba_lr'):\n",
    "        y_final_test_prob_pred = final_classifier._predict_proba_lr(X_final_augmented_test)[:, 1]\n",
    "\n",
    "    best_threshold_final, best_score_final = calculate_best_threshold(y_final_augmented_test, y_final_test_prob_pred, scoring, print_enabled)\n",
    "\n",
    "    X_final_augmented_validate = pd.DataFrame({\n",
    "        \"y_validate_prob_pred\": y_validate_prob_pred,\n",
    "        \"boe_validate_pred\": boe_validate_pred.squeeze(),\n",
    "        \"num_words\": validate[\"num_words\"].values,\n",
    "        \"num_chars\": validate[\"num_chars\"].values})\n",
    "    y_final_augmented_validate = y_validate\n",
    "\n",
    "    y_final_validate_prob_pred = final_classifier.predict_proba(X_final_augmented_validate)[:,1]\n",
    "\n",
    "    df_preds = get_df_preds(best_threshold_final, y_final_validate_prob_pred, validate, col, vectorizer_name, classifier_name)\n",
    "\n",
    "elif (boe_pred is None) and (boe_validate_pred is None):\n",
    "    final_classifier = classifier\n",
    "    X_final_augmented_validate = X_test\n",
    "    y_final_augmented_validate = y_test\n",
    "    y_final_validate_prob_pred = y_test_prob_pred\n",
    "    df_preds = get_df_preds(best_threshold, y_final_validate_prob_pred, test, col, vectorizer_name, classifier_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b03f35a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([305])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:num].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "977ffb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test[:num]\n",
    "y_test_pred = y_test_prob_pred[:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb27a586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics._classification.recall_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bdb7034",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating Equity/Study 1/Study1_Code/Analysis/1. train_and_evaluate_estimators.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000024?line=10'>11</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000024?line=11'>12</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mscoring\u001b[39m.\u001b[39mtitle()\u001b[39m}\u001b[39;00m\u001b[39m is not a valid score\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000024?line=13'>14</a>\u001b[0m emb_model_score \u001b[39m=\u001b[39m scorer(y_true\u001b[39m=\u001b[39;49my_test, y_pred\u001b[39m=\u001b[39;49m(y_test_pred \u001b[39m>\u001b[39;49m threshold)\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000024?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m emb_model_score \u001b[39m>\u001b[39m best_score:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nyxinsane/Library/CloudStorage/OneDrive-UvA/Automating%20Equity/Study%201/Study1_Code/Analysis/1.%20train_and_evaluate_estimators.ipynb#ch0000024?line=15'>16</a>\u001b[0m     best_score \u001b[39m=\u001b[39m emb_model_score\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1901\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1769'>1770</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecall_score\u001b[39m(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1770'>1771</a>\u001b[0m     y_true,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1771'>1772</a>\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1777'>1778</a>\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1778'>1779</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1779'>1780</a>\u001b[0m     \u001b[39m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1780'>1781</a>\u001b[0m \n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1781'>1782</a>\u001b[0m \u001b[39m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1898'>1899</a>\u001b[0m \u001b[39m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1899'>1900</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1900'>1901</a>\u001b[0m     _, r, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1901'>1902</a>\u001b[0m         y_true,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1902'>1903</a>\u001b[0m         y_pred,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1903'>1904</a>\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1904'>1905</a>\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1905'>1906</a>\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1906'>1907</a>\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1907'>1908</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1908'>1909</a>\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1909'>1910</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1910'>1911</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1541'>1542</a>\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1542'>1543</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1543'>1544</a>\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1545'>1546</a>\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1546'>1547</a>\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1348\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1344'>1345</a>\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1345'>1346</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1347'>1348</a>\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1348'>1349</a>\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1349'>1350</a>\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=1350'>1351</a>\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=89'>90</a>\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=91'>92</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=92'>93</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=93'>94</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=94'>95</a>\u001b[0m             type_true, type_pred\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=95'>96</a>\u001b[0m         )\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=96'>97</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=98'>99</a>\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniforge/base/envs/study1_venv_python3_9/lib/python3.9/site-packages/sklearn/metrics/_classification.py?line=99'>100</a>\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "best_threshold = -1\n",
    "best_score = -1\n",
    "for threshold in np.arange(0.01, 0.801, 0.01):\n",
    "    threshold = np.round(threshold, 2)\n",
    "\n",
    "    # globals()[f'metrics.{scoring.lower()}_score']\n",
    "    if scoring.lower() == 'recall':\n",
    "        scorer = metrics.recall_score\n",
    "    elif scoring.lower() == 'f1 score':\n",
    "        scorer = metrics.f1_score\n",
    "    else:\n",
    "        raise ValueError(f'{scoring.title()} is not a valid score')\n",
    "\n",
    "    emb_model_score = scorer(y_true=y_test, y_pred=(y_test_pred > threshold).astype(int))\n",
    "    if emb_model_score > best_score:\n",
    "        best_score = emb_model_score\n",
    "        best_threshold = threshold\n",
    "    if print_enabled:\n",
    "        print(f'{scoring.title()} at threshold {threshold}: {emb_model_score}')\n",
    "print(f'{scoring.title()} at best threshold {best_threshold}: {best_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd65a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent"
   }
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('study1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5b0d7544f82776c2b902af54887e7cde1aa7d2da4fd982551ffc3948bf7522f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
