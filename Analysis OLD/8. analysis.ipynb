{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26fa756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T22:26:27.736063Z",
     "start_time": "2022-07-30T22:22:47.925978Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 00:23:29.278085: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-07-31 00:23:29.278979: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: widget. Using notebook instead.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# %%\n",
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %% [markdown]\n",
    "# ### Install packages and import\n",
    "# %%\n",
    "# #################################### PLEASE INSTALL LATEST CHROME WEBDRIVER #####################################\n",
    "# Uncomment to run as required\n",
    "# #     --install-option=\"--chromedriver-version= *.**\" \\\n",
    "#   --install-option=\"--chromedriver-checksums=4fecc99b066cb1a346035bf022607104,058cd8b7b4b9688507701b5e648fd821\"\n",
    "# %%\n",
    "# ##### COPY THE LINES IN THIS COMMENT TO THE TOP OF NEW SCRIPTS #####\n",
    "# # Function to import this package to other files\n",
    "# import os\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# code_dir = None\n",
    "# code_dir_name = 'Code'\n",
    "# unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "# for _ in range(5):\n",
    "\n",
    "#     parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "#     if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "#         code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "#         if code_dir is not None:\n",
    "#             break\n",
    "\n",
    "# main_dir = str(Path(code_dir).parents[0])\n",
    "# scraped_data = f'{code_dir}/scraped_data'\n",
    "# sys.path.append(code_dir)\n",
    "\n",
    "# from setup_module.imports import *\n",
    "# from setup_module.params import *\n",
    "# from setup_module.scraping import *\n",
    "# from setup_module.classification import *\n",
    "# from setup_module.vectorizers_classifiers import *\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#
    "#
    "\n",
    "# %%\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "main_dir = str(Path(code_dir).parents[0])\n",
    "scraped_data = f'{code_dir}/scraped_data'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "from setup_module.imports import *\n",
    "from setup_module.params import *\n",
    "from setup_module.scraping import *\n",
    "from setup_module.classification import *\n",
    "from setup_module.vectorizers_classifiers import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "
    "
    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f63047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T17:49:19.116254Z",
     "start_time": "2022-07-30T17:49:19.116237Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get dict for normal and mean dfs + visualize\n",
    "dataframes  =  get_and_viz_df_dict(dataframes, df_loc)\n",
    "print('='*80)\n",
    "print(f'DATAFRAME KEYS:\\n{dataframes.keys()}')\n",
    "print('='*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a255035c",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b33e2",
   "metadata": {},
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99db52",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-13T12:30:07.869Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for df_name, df_df in dataframes.items():\n",
    "\n",
    "    print('+'*120)\n",
    "    print(f'====== RESULTS FOR {df_name} ======')\n",
    "\n",
    "    for iv in ivs:\n",
    "        print(f'IV: {iv}')\n",
    "        for dv_name, dv in dvs.items():\n",
    "            print(f'DV: {dv_name}')\n",
    "\n",
    "            # FREQUENCIES\n",
    "            print('\\n')\n",
    "            print('-' * 20)\n",
    "            print('FREQUENCIES')\n",
    "            print(f'IVs: {iv}')\n",
    "            freq_iv=rp.summary_cat(df_df[[iv]]).round(3)\n",
    "            print(freq_iv)\n",
    "            freq_iv.to_csv(f'{table_save_path}frequencies {df_name} - {iv}.{file_save_format_backup}')\n",
    "            print('-' * 20)\n",
    "            print('\\n')\n",
    "            print('-' * 20)\n",
    "            print(f'DVs: {dv_name}')\n",
    "            freq_dv=rp.summary_cont(df_df[[dv]]).round(3)\n",
    "            print(freq_dv)\n",
    "            freq_dv.to_csv(f'{table_save_path}frequencies {df_name} - {dv}.{file_save_format_backup}')\n",
    "            qq_plot = pg.qqplot(df_df[dv], dist='norm')\n",
    "            plt.ion()\n",
    "            plt.show()\n",
    "            print('-' * 20)\n",
    "            print('\\n')\n",
    "\n",
    "            # Test of Normality\n",
    "            norm = scipy.stats.normaltest(df_df[dv])\n",
    "\n",
    "            print('='*80)\n",
    "            print(f'{dv} Test of Normality:')\n",
    "            print('-'*80)\n",
    "            for key, val in dict(zip(normality_tests_labels, norm)).items():\n",
    "                print(key,': ', val) # Significant\n",
    "            print('\\n')\n",
    "\n",
    "            # Skewness-Kurtosis Test of Normality\n",
    "            norm_sk = scipy.stats.kurtosistest(df_df[dv])\n",
    "\n",
    "            print('='*80)\n",
    "            print(f'{dv} Skewness-Kurtosis Test of Normality:')\n",
    "            print('-'*80)\n",
    "            for key, val in dict(zip(normality_tests_labels, norm_sk)).items():\n",
    "                print(key,': ', val) # Significant\n",
    "            print('\\n')\n",
    "\n",
    "            # Shapir-Wilk Test of Normality\n",
    "            norm_res = scipy.stats.shapiro(df_df[dv])\n",
    "\n",
    "            print('='*80)\n",
    "            print(f'{dv} Shapir-Wilk Test of Normality:')\n",
    "            print('-'*80)\n",
    "            for key, val in dict(zip(normality_tests_labels, norm_res)).items():\n",
    "                print(key,': ', val) # Significant\n",
    "            print('\\n')\n",
    "\n",
    "            # Anderson-Darling Test of Normality\n",
    "            norm_and = scipy.stats.anderson(df_df[dv])\n",
    "\n",
    "            print('='*80)\n",
    "            print(f'{dv} Anderson-Darling Test of Normality:')\n",
    "            print('-'*80)\n",
    "            for key, val in dict(zip(normality_tests_labels, norm_and)).items():\n",
    "                print(key,': ', val) # Significant\n",
    "            print('\\n')\n",
    "\n",
    "            # NORMALITY TESTS\n",
    "            print('NORMALITY TEST')\n",
    "            print('\\n')\n",
    "            print('-' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            norm = pg.normality(data=df_df, dv=dv, group=iv).round(3)\n",
    "            normal = bool(norm['normal'].to_string(index=False))\n",
    "            print(f\"{iv} x {dv} Normality test:\\n{norm}\")\n",
    "            norm.to_csv(f\"{table_save_path}normality {df_name} - {iv} x {dv}.{file_save_format_backup}\")\n",
    "            print('-' * 20)\n",
    "            print('\\n')\n",
    "\n",
    "            # ANOVA SPHERICITY TEST\n",
    "            print('SPHERICITY TEST')\n",
    "            print('\\n')\n",
    "            print('-' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            spher_all = pg.sphericity(data=df_df, dv=dv, within=iv, method='mauchly')\n",
    "            spher, test_stat, chisq, dof, pval = spher_all\n",
    "            print('-' * 20)\n",
    "            print(f\"{iv} x {dv} Sphericity test:\\n{spher} at p-value: {round(pval, 3)}, chi-square: {round(chisq, 3)}, degrees of freedom: {round(dof)}, Test statistic: {round(test_stat)}\") # if p-value < 0.05, then the data are not spherically distributed = Multivariate analysis\n",
    "            # spher.to_csv(f\"{table_save_path}sphericity {df_name} - {iv} x {dv}.{file_save_format_backup}\")\n",
    "            print('-' * 20)\n",
    "            print('\\n')\n",
    "\n",
    "            # LEVENE'S TESTS\n",
    "            print(\"LEVENE'S TEST\")\n",
    "            print('\\n')\n",
    "            print('-' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            levene = pg.homoscedasticity(data=df_df, dv=dv, group=iv, method='levene').round(3) #dvs[f'{dv_name}']\n",
    "            equal_var_levene = bool(levene['equal_var'].to_string(index=False))\n",
    "            print(f\"{iv} x {dv} Levene's test:\\n{levene}\")\n",
    "            levene.to_csv(f\"{table_save_path}levene's {df_name} - {iv} x {dv}.{file_save_format_backup}\")\n",
    "            print('-' * 20)\n",
    "            print('\\n')\n",
    "\n",
    "            # BARTLETTS TESTS\n",
    "            print(\"BARTLETT'S TEST\")\n",
    "            print('\\n')\n",
    "            print('-' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            bartlett = pg.homoscedasticity(data=df_df, dv=dv, group=iv, method='bartlett').round(3) #dvs[f'{dv_name}']\n",
    "            equal_var_bartlett = bool(bartlett['equal_var'].to_string(index=False))\n",
    "            print(f\"{iv} x {dv} Bartlett's test:\\n{bartlett}\")\n",
    "            bartlett.to_csv(f\"{table_save_path}bartlett's {df_name} - {iv} x {dv}.{file_save_format_backup}\")\n",
    "            print('-' * 20)\n",
    "            print('\\n')\n",
    "\n",
    "            # SCIPY ANOVAS\n",
    "            print('ANOVA SIGNIFICANCE')\n",
    "            print('\\n')\n",
    "            print('-' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            f_statistic, p_value = stats.f_oneway(\n",
    "                df_df[dv][df_df[iv] == ivs_dict[iv][0]],\n",
    "                df_df[dv][df_df[iv] == ivs_dict[iv][1]],\n",
    "                df_df[dv][df_df[iv] == ivs_dict[iv][2]]\n",
    "            )\n",
    "            reject_H0 = p_value < alpha\n",
    "            print('-' * 20)\n",
    "            print(f'One-way ANOVA p-value: {p_value}. Rejected: {reject_H0}')\n",
    "            print('-' * 20)\n",
    "\n",
    "            # SUMMARY ANOVAS\n",
    "            print('SUMMARY ANOVA')\n",
    "            print('\\n')\n",
    "            print('-' * 20)\n",
    "            print(f'{iv} x {dv}')\n",
    "            summary_aova = rp.summary_cont(df_df[dv].groupby(df_df[iv]), conf=0.95, decimals=3)\n",
    "            print(summary_aova)\n",
    "            summary_aova.to_csv(f'{table_save_path}summary anova {df_name} - {iv} x {dv}.{file_save_format_backup}')\n",
    "            print('-' * 20)\n",
    "            print('\\n')\n",
    "\n",
    "            # INTERACTION MODEL\n",
    "            print(f'INTEACTION ANOVA {dv}')\n",
    "            print('\\n')\n",
    "            print('-' * 20)\n",
    "            formula = f'{dv} ~ C({ivs[0]}, Treatment(\"{ivs_dict[ivs[0]][0]}\")) + C({ivs[1]}, Treatment(\"{ivs_dict[ivs[1]][0]}\")) + C({ivs[0]}, Treatment(\"{ivs_dict[ivs[0]][0]}\")):C({ivs[1]}, Treatment(\"{ivs_dict[ivs[1]][0]}\"))'\n",
    "            model = ols(data = df_df, formula = formula).fit()\n",
    "            anova_interaction_model = sm.stats.anova_lm(model, typ=2).round(3)\n",
    "            print(model.summary())\n",
    "            print(f\"{iv} x {dv} ANOVA interaction model:\\n{anova_interaction_model}\")\n",
    "            print('-' * 20)\n",
    "            print('\\n')\n",
    "\n",
    "            if equal_var_levene is False:\n",
    "                # ONE-WAY ANOVA\n",
    "                print('ONE-WAY ANOVA')\n",
    "                print('\\n')\n",
    "                print('-' * 20)\n",
    "                print(f'{iv} x {dv}')\n",
    "                anova = pg.anova(data=df_df, dv=dv, between=iv, detailed=True).round(3)\n",
    "                pg.print_table(anova)\n",
    "                anova.to_csv(f'{table_save_path}one-way anova {df_name} - {iv} x {dv}.{file_save_format_backup}')\n",
    "                print('-' * 20)\n",
    "                print('\\n')\n",
    "\n",
    "                # TWO-WAY ANOVA\n",
    "                print('ONE-WAY ANOVA')\n",
    "                print('\\n')\n",
    "                print('-' * 20)\n",
    "                print(f'{iv} x {dv}')\n",
    "                anova = pg.anova(data=df_df, dv=dv, between=ivs, detailed=True).round(3)\n",
    "                pg.print_table(anova)\n",
    "                anova.to_csv(f'{table_save_path}two-way anova {df_name} - {ivs[0]} and {ivs[1]} x {dv}.{file_save_format_backup}')\n",
    "                print('-' * 20)\n",
    "                print('\\n')\n",
    "\n",
    "                # INTERACTION ANOVA\n",
    "                print('INTERACTION ONE-WAY ANOVA')\n",
    "                print('\\n')\n",
    "                print('-' * 20)\n",
    "                print(f'Interaction: {ivs[0]} and {ivs[1]} x {dv}')\n",
    "                anova_interaction = pg.anova(data=df_df, dv=dv, between=ivs, detailed=True).round(3)\n",
    "                pg.print_table(anova_interaction)\n",
    "                anova_interaction.to_csv(f'{table_save_path}interaction one-way anova {df_name} - {ivs} x {dv}.{file_save_format_backup}')\n",
    "                print('-' * 20)\n",
    "                print('\\n')\n",
    "\n",
    "                # TUKEY POST HOC\n",
    "                print('POST HOC GAMES HOWELL ANOVA')\n",
    "                print('\\n')\n",
    "                print('-' * 20)\n",
    "                print(f'{iv} x {dv}')\n",
    "                anova_pairwise_tukey = pg.pairwise_tukey(\n",
    "                    data=df_df, dv=dv, between=iv, effsize='eta-square'\n",
    "                ).round(3)\n",
    "                pg.print_table(anova_pairwise_tukey)\n",
    "                anova_pairwise_tukey.to_csv(f'{table_save_path}post hoc tukey {df_name} - {iv} x {dv}.{file_save_format_backup}')\n",
    "                print('-' * 20)\n",
    "                print('\\n')\n",
    "\n",
    "            if equal_var_levene is True:\n",
    "                # WELCH ANOVA\n",
    "                print('WELCH ANOVA')\n",
    "                print('\\n')\n",
    "                print('-' * 20)\n",
    "                print(f'{iv} x {dv}')\n",
    "                anova_welch = pg.welch_anova(data=df_df, dv=dv, between=iv).round(3)\n",
    "                pg.print_table(anova_welch)\n",
    "                anova_welch.to_csv(f'{table_save_path}welch anova {df_name} - {iv} x {dv}.{file_save_format_backup}')\n",
    "                print('-' * 20)\n",
    "                print('\\n')\n",
    "\n",
    "                # KRUSKAL-WALLIS ANOVA\n",
    "                print('KRUSKAL-WALLIS ANOVA')\n",
    "                print('\\n')\n",
    "                print('-' * 20)\n",
    "                print(f'{iv} x {dv}')\n",
    "                anova_kruskal = pg.kruskal(data=df_df, dv=dvs[f'{dv_name}'], between=iv).round(3)\n",
    "                pg.print_table(anova_kruskal)\n",
    "                anova_kruskal.to_csv(f'{table_save_path}kruskal-wallis anova {df_name} - {iv} x {dv}.{file_save_format_backup}')\n",
    "                print('-' * 20)\n",
    "                print('\\n')\n",
    "\n",
    "                # INTERACTION ANOVA\n",
    "                print('INTERACTION ONE-WAY ANOVA')\n",
    "                print('\\n')\n",
    "                print('-' * 20)\n",
    "                print(f'{ivs[0]} and {ivs[1]} x {dv}')\n",
    "                anova_interaction = pg.anova(data=df_df, dv=dv, between=ivs, detailed=True).round(3)\n",
    "                pg.print_table(anova_interaction)\n",
    "                anova_interaction.to_csv(f'{table_save_path}interaction one-way anova {df_name} - {ivs} x {dv}.{file_save_format_backup}')\n",
    "                print('-' * 20)\n",
    "                print('\\n')\n",
    "\n",
    "                # GAMES HOWELL POST HOC\n",
    "                print('POST HOC GAMES HOWELL ANOVA')\n",
    "                print('\\n')\n",
    "                print('-' * 20)\n",
    "                print(f'{iv} x {dv}')\n",
    "                anova_games_posthoc = pg.pairwise_gameshowell(\n",
    "                    data=df_df, dv=dv, between=iv, effsize='eta-square'\n",
    "                ).round(3)\n",
    "                pg.print_table(anova_games_posthoc)\n",
    "                anova_games_posthoc.to_csv(f'{table_save_path}post hoc gameshowell {df_name} - {iv} x {dv}.{file_save_format_backup}')\n",
    "                print('-' * 20)\n",
    "                print('\\n')\n",
    "                print('+'*120)\n",
    "                print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a5a36",
   "metadata": {},
   "source": [
    "# Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c7fe0",
   "metadata": {},
   "source": [
    "## OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77461a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df_df in dataframes.items():\n",
    "    for dv_name, dv in dvs.items():\n",
    "        if '_Probability' in dv_name:\n",
    "            print(f'DV {dv_name}:')\n",
    "\n",
    "            x = sm.add_constant(df[ivs_all_dummy])\n",
    "            model = sm.OLS(df[dv], x)\n",
    "            results = model.fit()\n",
    "\n",
    "            # display results\n",
    "            print(results.summary())\n",
    "            print(f'y = {results.params.const:.2f} + {results.params.x:.2f} * x')\n",
    "            print(f'AIC: {results.aic:.2f}'.format(results.aic))\n",
    "            print(f'Coehn\\'s F2: {results.rsquared_adj:.3f}')\n",
    "            table = sm.stats.anova_lm(results, typ=2)\n",
    "            print(table)\n",
    "\n",
    "            # Boxplot\n",
    "            boxplot = df.boxplot([dv], by = [ivs[0], ivs[1]],\n",
    "                                figsize = (16, 9),\n",
    "                                showmeans = True,\n",
    "                                notch = True)\n",
    "\n",
    "            boxplot.set_xlabel('Categories')\n",
    "            boxplot.set_ylabel(dv)\n",
    "            # Creating a path to save the plot.\n",
    "            plt.ion()\n",
    "            plt.show()\n",
    "            plt.pause(.001)\n",
    "            boxplot.figure.savefig(\n",
    "                f'{plot_save_path}Probability Boxplot - {ivs[0]} x {ivs[1]} x {dv}.{image_save_format}',\n",
    "                format=image_save_format,\n",
    "                dpi=3000,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76dfa8",
   "metadata": {},
   "source": [
    "## Multi-level Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56359b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df_df in dataframes.items():\n",
    "    df_df['Intercept'] = 1\n",
    "\n",
    "    print('+'*120)\n",
    "    print(f'====== RESULTS FOR {df_name} ======')\n",
    "\n",
    "    for dv_name, dv in dvs.items():\n",
    "        save_name = f'Multilevel model {df_name} - {list(iter(ivs_dict))[0]} + {list(iter(ivs_dict))[1]} x {dv}'\n",
    "        endog = df_df[dv]\n",
    "        exog0 = df_df[['Intercept', f'{list(iter(ivs_dict))[0]}']]\n",
    "        exog1 = df_df[['Intercept', f'{list(iter(ivs_dict))[1]}']]\n",
    "\n",
    "        print('='*80)\n",
    "        print(f'DV: {dv_name}:')\n",
    "        print('='*80)\n",
    "        # formula = f'dv ~ C(iv, Treatment(\"Reference_Category\") + C(iv, Treatment(\"Reference_Category\")'\n",
    "\n",
    "        model = smf.mixedlm(\n",
    "            formula=\n",
    "            f'''{dv} ~ C({list(iter(ivs_dict))[0]}, Treatment(\"{ivs_dict[f'{list(iter(ivs_dict))[0]}'][0]}\")) +\n",
    "            C({list(iter(ivs_dict))[1]}, Treatment(\"{ivs_dict[f'{list(iter(ivs_dict))[1]}'][0]}\"))''',\n",
    "            data=df_df, groups=df_df['Job ID'].astype(str)).fit()\n",
    "        print(model.summary())\n",
    "        df_model = pd.DataFrame(index=['Descriptives', 'Results'], columns=[f'{save_name}'])\n",
    "        df_model[f'{save_name}']['Descriptives'] = model.summary().tables[0]\n",
    "        df_model[f'{save_name}']['Results'] = model.summary().tables[1]\n",
    "\n",
    "        df_model.to_csv(f'{table_save_path}{save_name.split(\" model\")[0].lower() + \" model\" + save_name.split(\" model\")[1]}.{file_save_format_backup}', header=True, index=True, index_label=['Index col: Descriptives and Results'])\n",
    "\n",
    "        # Normality Tests (https://www.pythonfordatascience.org/mixed-effects-regression-python/)\n",
    "        ## Residual and Kernal Density Estimate (KDE) Plot for Homoskedasticity\n",
    "        fig = plt.figure(figsize = (16, 9))\n",
    "\n",
    "        ax = sns.distplot(model.resid, hist = True, kde_kws = {\"shade\" : True, \"lw\": 1}, fit = scipy.stats.norm, kde=True, color='blue')\n",
    "\n",
    "        ax.set_title(f\"Kernal Density Estimate (KDE) Plot of Model Residuals (Blue) and Normal Distribution (Black)\\n{save_name}\")\n",
    "        ax.set_xlabel(\"Residuals\")\n",
    "        plt.ion()\n",
    "        fig.show('notebook')\n",
    "        plt.pause(.001)\n",
    "\n",
    "        # Q-Q Plot\n",
    "        fig = plt.figure(figsize = (16, 9))\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        qq = sm.qqplot(model.resid, dist = scipy.stats.norm, line = 's', ax = ax, color='blue', markerfacecolor='blue')\n",
    "        ax.set_title(f\"Q-Q Plot\\n{save_name}\",fontsize=15)\n",
    "        ax.xaxis.get_label().set_fontsize(12)\n",
    "        ax.yaxis.get_label().set_fontsize(12)\n",
    "        ax.get_lines()[0].set_color('black')\n",
    "        ax.get_lines()[0].set_linewidth('2')\n",
    "        ax.get_lines()[1].set_color('black')\n",
    "        ax.get_lines()[1].set_linewidth('2')\n",
    "        plt.ion()\n",
    "        fig.show('notebook')\n",
    "        plt.pause(.001)\n",
    "\n",
    "        # Test of Normality\n",
    "        norm = scipy.stats.normaltest(model.resid)\n",
    "\n",
    "        print('='*80)\n",
    "        print(f'{dv} Test of Normality:')\n",
    "        print('-'*80)\n",
    "        for key, val in dict(zip(normality_tests_labels, norm)).items():\n",
    "            print(key,': ', val) # Significant\n",
    "        print('\\n')\n",
    "\n",
    "        # Skewness-Kurtosis Test of Normality\n",
    "        norm_sk = scipy.stats.kurtosistest(model.resid)\n",
    "\n",
    "        print('='*80)\n",
    "        print(f'{dv} Skewness-Kurtosis Test of Normality:')\n",
    "        print('-'*80)\n",
    "        for key, val in dict(zip(normality_tests_labels, norm_sk)).items():\n",
    "            print(key,': ', val) # Significant\n",
    "        print('\\n')\n",
    "\n",
    "        # Shapir-Wilk Test of Normality\n",
    "        norm_res = scipy.stats.shapiro(model.resid)\n",
    "\n",
    "        print('='*80)\n",
    "        print(f'{dv} Shapir-Wilk Test of Normality:')\n",
    "        print('-'*80)\n",
    "        for key, val in dict(zip(normality_tests_labels, norm_res)).items():\n",
    "            print(key,': ', val) # Significant\n",
    "        print('\\n')\n",
    "\n",
    "        # Anderson-Darling Test of Normality\n",
    "        norm_and = scipy.stats.anderson(model.resid)\n",
    "\n",
    "        print('='*80)\n",
    "        print(f'{dv} Anderson-Darling Test of Normality:')\n",
    "        print('-'*80)\n",
    "        for key, val in dict(zip(normality_tests_labels, norm_and)).items():\n",
    "            print(key,': ', val) # Significant\n",
    "        print('\\n')\n",
    "\n",
    "        # Residuals versus Fitted values (RVF) Plot for Homoskedasticity\n",
    "        fig = plt.figure(figsize = (16, 9))\n",
    "\n",
    "        ax = sns.scatterplot(y = model.resid, x = model.fittedvalues, color='blue')\n",
    "\n",
    "        ax.set_title(f\"Residuals versus Fitted values (RVF) Plot\\n{save_name}\")\n",
    "        ax.set_xlabel(\"Fitted Values\")\n",
    "        ax.set_ylabel(\"Residuals\")\n",
    "        plt.ion()\n",
    "        fig.show('notebook')\n",
    "        plt.pause(.001)\n",
    "\n",
    "        # White’s Lagrange Multiplier Test for Heteroscedasticity\n",
    "        het_white_res = het_white(model.resid, model.model.exog)\n",
    "\n",
    "        het_white_labels = [\"LM Statistic\", \"LM-Test p-value\", \"F-Statistic\", \"F-Test p-value\"]\n",
    "\n",
    "        print('='*80)\n",
    "        print('White’s Lagrange Multiplier Test for Heteroscedasticity')\n",
    "        print('-'*80)\n",
    "        for key, val in dict(zip(het_white_labels, het_white_res)).items():\n",
    "            print(key, val)\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('+'*120)\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fa314f",
   "metadata": {},
   "source": [
    "# Specification Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851d617",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-13T12:30:09.886Z"
    }
   },
   "outputs": [],
   "source": [
    "# for df_name, df_df in dataframes.items():\n",
    "\n",
    "#     df_df.columns\n",
    "\n",
    "#     print(f'====== RESULTS FOR {df_name} ======')\n",
    "\n",
    "#     x_1 = 'Gender'\n",
    "#     x_2 = 'Age'\n",
    "#     y_1 = 'Warmth_Outliers_Removed_Zscore0'\n",
    "#     y_2 = 'Warmth_Outliers_Removed_Zscore1.96'\n",
    "#     y_3 = 'Warmth_Outliers_Removed_Zscore2.58'\n",
    "#     y_4 = 'Warmth_Outliers_Removed_Zscore3.29'\n",
    "#     x_exog = list(ivs)\n",
    "#     y_endog = list(dvs_probas.values())\n",
    "#     controls = ['English Requirement', 'Dutch Requirement']\n",
    "#     sc = specy.SpecificationCurve(df_df, y_1, y_2, y_3, y_4)\n",
    "#     # sc = specy.SpecificationCurve(df_df, y_endog, x_exog, controls)\n",
    "#     # sc = specy.SpecificationCurve(df_df, y_endog, x_exog, controls)\n",
    "#     # sc = specy.SpecificationCurve(df_df, y_1, y_2, y_3, y_4, x_1, x_2)\n",
    "#     sc.fit()\n",
    "#     sc.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a29944e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "study1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \n[Clang 13.0.1 ]"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5b0d7544f82776c2b902af54887e7cde1aa7d2da4fd982551ffc3948bf7522f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
