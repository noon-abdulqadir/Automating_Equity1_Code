{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8527268bd5428c8d63c203a9a46f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 13:07:37.303401: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-12 13:07:37.303881: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: widget. Using notebook instead.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# %%\n",
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %% [markdown]\n",
    "# ### Install packages and import\n",
    "# %%\n",
    "# #################################### PLEASE INSTALL LATEST CHROME WEBDRIVER #####################################\n",
    "# Uncomment to run as required\n",
    "# #     --install-option=\"--chromedriver-version= *.**\" \\\n",
    "#   --install-option=\"--chromedriver-checksums=4fecc99b066cb1a346035bf022607104,058cd8b7b4b9688507701b5e648fd821\"\n",
    "# %%\n",
    "# ##### COPY THE LINES IN THIS COMMENT TO THE TOP OF NEW SCRIPTS #####\n",
    "# # Function to import this package to other files\n",
    "# import os\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# code_dir = None\n",
    "# code_dir_name = 'Code'\n",
    "# unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "# for _ in range(5):\n",
    "\n",
    "#     parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "#     if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "#         code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "#         if code_dir is not None:\n",
    "#             break\n",
    "\n",
    "# main_dir = str(Path(code_dir).parents[0])\n",
    "# scraped_data = f'{code_dir}/scraped_data'\n",
    "# sys.path.append(code_dir)\n",
    "\n",
    "# from setup_module.imports import *\n",
    "# from setup_module.params import *\n",
    "# from setup_module.scraping import *\n",
    "# from setup_module.classification import *\n",
    "# from setup_module.vectorizers_classifiers import *\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#
    "#
    "\n",
    "# %%\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "main_dir = str(Path(code_dir).parents[0])\n",
    "scraped_data = f'{code_dir}/scraped_data'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "from setup_module.imports import *\n",
    "from setup_module.scraping import *\n",
    "from setup_module.post_collection_processing import *\n",
    "from setup_module.params import *\n",
    "from setup_module.classification import *\n",
    "# from setup_module.vectorizers_classifiers import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "
    "
    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "# columns\n",
    "cols=['Sector', \n",
    "      'Sector Code', \n",
    "      'Gender', \n",
    "      'Age', \n",
    "      'Language', \n",
    "      'Dutch Requirement', \n",
    "      'English Requirement', \n",
    "      'Gender_Female', \n",
    "      'Gender_Mixed', \n",
    "      'Gender_Male', \n",
    "      'Age_Older', \n",
    "      'Age_Mixed', \n",
    "      'Age_Younger', \n",
    "      'Gender_Num', \n",
    "      'Age_Num', \n",
    "      '% Female', \n",
    "      '% Male', \n",
    "      '% Older', \n",
    "      '% Younger']\n",
    "\n",
    "int_variable: str = 'Job ID'\n",
    "str_variable: str = 'Job Description'\n",
    "gender: str = 'Gender'\n",
    "age: str = 'Age'\n",
    "language: str = 'en'\n",
    "languages = [\"en\", \"['nl', 'en']\", ['en', 'nl']]\n",
    "str_cols = ['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name', 'Location', 'Job Description', 'Company URL', 'Job URL', 'Tracking ID']\n",
    "nan_list = [None, 'None', '', ' ', [], -1, '-1', 0, '0', 'nan', np.nan, 'Nan']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_word2vec(\n",
    "    df, ngram_number, embedding_library, size = 300,\n",
    "    words = ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer'],\n",
    "    t = time.time(), cores = multiprocessing.cpu_count(),\n",
    "):\n",
    "    sentences = df[f'Job Description {embedding_library}_{ngram_number}grams_original_list'].values\n",
    "\n",
    "    w2v_model = Word2Vec(\n",
    "        sentences=sentences,\n",
    "        vector_size=size,\n",
    "        min_count=0,\n",
    "        window=2,\n",
    "        sample=6e-5,\n",
    "        alpha=0.03,\n",
    "        min_alpha=0.0007,\n",
    "        negative=20,\n",
    "        workers=cores - 1,\n",
    "        sg = 1,\n",
    "    )\n",
    "\n",
    "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "    print(f'Time to train the model for {size}: {round((time.time() - t) / 60, 2)} mins')\n",
    "\n",
    "    w2v_model.train(\n",
    "        sentences,\n",
    "        total_examples=w2v_model.corpus_count,\n",
    "        epochs=30,\n",
    "        report_delay=1,\n",
    "    )\n",
    "\n",
    "    print(f'Time to build w2v_vocab for {size}: {round((time.time() - t) / 60, 2)} mins')\n",
    "    w2v_vocab = list(w2v_model.wv.index_to_key)\n",
    "\n",
    "    print(f'Checking words form list of length {len(words)}')\n",
    "    print(f'WORDS LIST: {words}')\n",
    "\n",
    "    for word in words:\n",
    "        print(f'Checking word:\\n{word.upper()}:')\n",
    "        try:\n",
    "            # print(f'{sector} 300: {w2v_model_300.wv[word]}')\n",
    "            # print(f'{sector} 100: {w2v_model_100.wv[word]}')\n",
    "            print(f'Length of {size} model vobal: {len(w2v_vocab)}')\n",
    "            print(f'{size} - Positive most similar to {word}: {w2v_model.wv.most_similar(positive=word, topn=5)}')\n",
    "            print(f'{size} - Negative most similar to {word}: {w2v_model.wv.most_similar(negative=word, topn=5)}')\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "\n",
    "    return w2v_vocab, w2v_model\n",
    "\n",
    "def word2vec_embeddings(sentences, w2v_vocab, w2v_model, size=300):\n",
    "\n",
    "    sentences = [word for word in sentences if word in w2v_vocab]\n",
    "\n",
    "    return np.mean(w2v_model.wv[sentences], axis=0) if len(sentences) >= 1 else np.zeros(size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_fasttext(\n",
    "    df, ngram_number, embedding_library, size = 300,\n",
    "    words = ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer'],\n",
    "    t = time.time(), cores = multiprocessing.cpu_count(),\n",
    "):\n",
    "    sentences = df[f'Job Description {embedding_library}_{ngram_number}grams_original_list'].values\n",
    "\n",
    "    ft_model = FastText(\n",
    "        sentences=sentences,\n",
    "        vector_size=size,\n",
    "        min_count=0,\n",
    "        window=2,\n",
    "        sample=6e-5,\n",
    "        alpha=0.03,\n",
    "        min_alpha=0.0007,\n",
    "        negative=20,\n",
    "        workers=cores - 1,\n",
    "        sg = 1,\n",
    "    )\n",
    "\n",
    "    ft_model.build_vocab(sentences, progress_per=10000)\n",
    "    print(f'Time to train the model for {size}: {round((time.time() - t) / 60, 2)} mins')\n",
    "\n",
    "    ft_model.train(\n",
    "        sentences,\n",
    "        total_examples=ft_model.corpus_count,\n",
    "        epochs=30,\n",
    "        report_delay=1,\n",
    "    )\n",
    "\n",
    "    print(f'Time to build vocab for {size}: {round((time.time() - t) / 60, 2)} mins')\n",
    "    ft_vocab = list(ft_model.wv.index_to_key)\n",
    "\n",
    "    print(f'Checking words form list of length {len(words)}')\n",
    "    print(f'WORDS LIST: {words}')\n",
    "\n",
    "    for word in words:\n",
    "        print(f'Checking word:\\n{word.upper()}:')\n",
    "        try:\n",
    "            # print(f'{sector} 300: {ft_model_300.wv[word]}')\n",
    "            # print(f'{sector} 100: {ft_model_100.wv[word]}')\n",
    "            print(f'Length of {size} model vobal: {len(ft_vocab)}')\n",
    "            print(f'{size} - Positive most similar to {word}: {ft_model.wv.most_similar(positive=word, topn=5)}')\n",
    "            print(f'{size} - Negative most similar to {word}: {ft_model.wv.most_similar(negative=word, topn=5)}')\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "\n",
    "    return ft_vocab, ft_model\n",
    "\n",
    "def fasttext_embeddings(sentences, ft_vocab, ft_model, size=300):\n",
    "\n",
    "    sentences = [word for word in sentences if word in ft_vocab]\n",
    "\n",
    "    return np.mean(ft_model.wv[sentences], axis=0) if len(sentences) >= 1 else np.zeros(size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove(glove_file = f'{llm_path}/gensim/glove/glove.840B.300d.txt'):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file, 'r', encoding='utf8') as glove:\n",
    "\n",
    "        for line in glove:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "\n",
    "            try:\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_index[word] = coefs\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    print(f'Found {len(embeddings_index)} word vectors.')\n",
    "\n",
    "    return embeddings_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing DF.\n",
      "\"['Task_Mentioned', 'Task_Warmth', 'Task_Competence'] not found in axis\"\n",
      "DF Processed:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5687 entries, 0 to 5686\n",
      "Columns: 219 entries, % Sector per Workforce to Job Description gensim_123grams_sent2vec_embeddings\n",
      "dtypes: float64(35), int64(4), object(180)\n",
      "memory usage: 9.5+ MB\n",
      "\n",
      "DF INFO:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5687 entries, 0 to 5686\n",
      "Columns: 219 entries, % Sector per Workforce to Job Description gensim_123grams_sent2vec_embeddings\n",
      "dtypes: float64(35), int64(4), object(180)\n",
      "memory usage: 9.5+ MB\n",
      "====================\n",
      "Gender:\n",
      "--------------------\n",
      "Gender Counts:\n",
      "Mixed Gender    4590\n",
      "Male             634\n",
      "Female           463\n",
      "Name: Gender, dtype: int64\n",
      "--------------------\n",
      "Gender Percentages:\n",
      "Mixed Gender   80.700\n",
      "Male           11.100\n",
      "Female          8.100\n",
      "Name: Gender, dtype: float64\n",
      "--------------------\n",
      "====================\n",
      "Gender_Num:\n",
      "--------------------\n",
      "Gender_Num Counts:\n",
      "2.000    4590\n",
      "3.000     634\n",
      "1.000     463\n",
      "Name: Gender_Num, dtype: int64\n",
      "--------------------\n",
      "Gender_Num Percentages:\n",
      "2.000   80.700\n",
      "3.000   11.100\n",
      "1.000    8.100\n",
      "Name: Gender_Num, dtype: float64\n",
      "--------------------\n",
      "Gender_Num Mean: 2.03\n",
      "--------------------\n",
      "Gender_Num Standard Deviation: 0.44\n",
      "====================\n",
      "Gender_Female:\n",
      "--------------------\n",
      "Gender_Female Counts:\n",
      "0.000    5224\n",
      "1.000     463\n",
      "Name: Gender_Female, dtype: int64\n",
      "--------------------\n",
      "Gender_Female Percentages:\n",
      "0.000   91.900\n",
      "1.000    8.100\n",
      "Name: Gender_Female, dtype: float64\n",
      "--------------------\n",
      "Gender_Female Mean: 0.08\n",
      "--------------------\n",
      "Gender_Female Standard Deviation: 0.27\n",
      "====================\n",
      "Gender_Mixed:\n",
      "--------------------\n",
      "Gender_Mixed Counts:\n",
      "1.000    4590\n",
      "0.000    1097\n",
      "Name: Gender_Mixed, dtype: int64\n",
      "--------------------\n",
      "Gender_Mixed Percentages:\n",
      "1.000   80.700\n",
      "0.000   19.300\n",
      "Name: Gender_Mixed, dtype: float64\n",
      "--------------------\n",
      "Gender_Mixed Mean: 0.81\n",
      "--------------------\n",
      "Gender_Mixed Standard Deviation: 0.39\n",
      "====================\n",
      "Gender_Male:\n",
      "--------------------\n",
      "Gender_Male Counts:\n",
      "0.000    5053\n",
      "1.000     634\n",
      "Name: Gender_Male, dtype: int64\n",
      "--------------------\n",
      "Gender_Male Percentages:\n",
      "0.000   88.900\n",
      "1.000   11.100\n",
      "Name: Gender_Male, dtype: float64\n",
      "--------------------\n",
      "Gender_Male Mean: 0.11\n",
      "--------------------\n",
      "Gender_Male Standard Deviation: 0.31\n",
      "====================\n",
      "Age:\n",
      "--------------------\n",
      "Age Counts:\n",
      "Younger      3178\n",
      "Mixed Age    1827\n",
      "Older         682\n",
      "Name: Age, dtype: int64\n",
      "--------------------\n",
      "Age Percentages:\n",
      "Younger     55.900\n",
      "Mixed Age   32.100\n",
      "Older       12.000\n",
      "Name: Age, dtype: float64\n",
      "--------------------\n",
      "====================\n",
      "Age_Num:\n",
      "--------------------\n",
      "Age_Num Counts:\n",
      "3.000    3178\n",
      "2.000    1827\n",
      "1.000     682\n",
      "Name: Age_Num, dtype: int64\n",
      "--------------------\n",
      "Age_Num Percentages:\n",
      "3.000   55.900\n",
      "2.000   32.100\n",
      "1.000   12.000\n",
      "Name: Age_Num, dtype: float64\n",
      "--------------------\n",
      "Age_Num Mean: 2.44\n",
      "--------------------\n",
      "Age_Num Standard Deviation: 0.7\n",
      "====================\n",
      "Age_Older:\n",
      "--------------------\n",
      "Age_Older Counts:\n",
      "0.000    5005\n",
      "1.000     682\n",
      "Name: Age_Older, dtype: int64\n",
      "--------------------\n",
      "Age_Older Percentages:\n",
      "0.000   88.000\n",
      "1.000   12.000\n",
      "Name: Age_Older, dtype: float64\n",
      "--------------------\n",
      "Age_Older Mean: 0.12\n",
      "--------------------\n",
      "Age_Older Standard Deviation: 0.32\n",
      "====================\n",
      "Age_Mixed:\n",
      "--------------------\n",
      "Age_Mixed Counts:\n",
      "0.000    3860\n",
      "1.000    1827\n",
      "Name: Age_Mixed, dtype: int64\n",
      "--------------------\n",
      "Age_Mixed Percentages:\n",
      "0.000   67.900\n",
      "1.000   32.100\n",
      "Name: Age_Mixed, dtype: float64\n",
      "--------------------\n",
      "Age_Mixed Mean: 0.32\n",
      "--------------------\n",
      "Age_Mixed Standard Deviation: 0.47\n",
      "====================\n",
      "Age_Younger:\n",
      "--------------------\n",
      "Age_Younger Counts:\n",
      "1.000    3178\n",
      "0.000    2509\n",
      "Name: Age_Younger, dtype: int64\n",
      "--------------------\n",
      "Age_Younger Percentages:\n",
      "1.000   55.900\n",
      "0.000   44.100\n",
      "Name: Age_Younger, dtype: float64\n",
      "--------------------\n",
      "Age_Younger Mean: 0.56\n",
      "--------------------\n",
      "Age_Younger Standard Deviation: 0.5\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No     5678\n",
       "Yes       9\n",
       "Name: English Requirement, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "No     5682\n",
       "Yes       5\n",
       "Name: Dutch Requirement, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessed unlabeled dataframe\n",
    "print('Analyzing DF.')\n",
    "df_all = pd.read_pickle(f'{data_dir}df_manual_for_trainning.pkl')\n",
    "# n job ads = 21204\n",
    "\n",
    "# df_name = 'df_manual_mean'\n",
    "# df_all = pd.read_pickle(f'{df_dir}{df_name}_outliers.{file_save_format}')\n",
    "\n",
    "try:\n",
    "    df_all.drop(\n",
    "        ['Task_Mentioned', 'Task_Warmth', 'Task_Competence'],\n",
    "        axis=1,\n",
    "        inplace=True,\n",
    "    )\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "\n",
    "# df_all.dropna(subset=dv_cols, inplace=True)\n",
    "print('DF Processed:')\n",
    "df_all.info()\n",
    "df_gender_age_info(df_all)\n",
    "df_all['English Requirement'].value_counts()\n",
    "df_all['Dutch Requirement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5687 entries, 0 to 5686\n",
      "Columns: 219 entries, % Sector per Workforce to Job Description gensim_123grams_sent2vec_embeddings\n",
      "dtypes: float64(35), int64(4), object(180)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word2Vec Model\n",
    "for embedding_library, ngram_number in itertools.product(embedding_libraries_list, ngrams_list):\n",
    "    for embed_model_name, embed_func_list in embedding_models_dict.items():\n",
    "        build_train_func, embed_func, model_loader = embed_func_list\n",
    "\n",
    "        model = model_loader.load(\n",
    "            validate_path(\n",
    "                f'{data_dir}embeddings models/{embedding_library}_{ngram_number}grams_{embed_model_name}_model.model'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        setattr(mod, f'model_{embed_model_name}_{ngram_number}grams', model)\n",
    "\n",
    "# ft_model_gensim = FastText.load(\n",
    "#     validate_path(\n",
    "#         f'{args[\"embeddings_save_path\"]}123grams_{embedding_library}_ft_model.model'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# word2vec_model300 = gensim_api.load('word2vec-google-news-300')\n",
    "# glove_model300 = gensim_api.load('glove-wiki-gigaword-300')\n",
    "# fasttext_model300 = gensim_api.load('fasttext-wiki-news-subwords-300')\n",
    "\n",
    "# word_embedding_models = {'Word2Vec': word2vec_model300, 'GLoVe': glove_model300, 'fastText': fasttext_model300}\n",
    "\n",
    "embedding_models_dict['w2v'].append(gensim_api.load('word2vec-google-news-300'))\n",
    "embedding_models_dict['glove'] = [gensim_api.load('glove-wiki-gigaword-300')]\n",
    "embedding_models_dict['ft'].append(gensim_api.load('fasttext-wiki-news-subwords-300'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['w2v', 'ft', 'glove'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_models_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DF INFO:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5687 entries, 0 to 5686\n",
      "Columns: 219 entries, % Sector per Workforce to Job Description gensim_123grams_sent2vec_embeddings\n",
      "dtypes: float64(35), int64(4), object(180)\n",
      "memory usage: 9.5+ MB\n",
      "====================\n",
      "Gender:\n",
      "--------------------\n",
      "Gender Counts:\n",
      "Mixed Gender    4590\n",
      "Male             634\n",
      "Female           463\n",
      "Name: Gender, dtype: int64\n",
      "--------------------\n",
      "Gender Percentages:\n",
      "Mixed Gender   80.700\n",
      "Male           11.100\n",
      "Female          8.100\n",
      "Name: Gender, dtype: float64\n",
      "--------------------\n",
      "====================\n",
      "Gender_Num:\n",
      "--------------------\n",
      "Gender_Num Counts:\n",
      "2.000    4590\n",
      "3.000     634\n",
      "1.000     463\n",
      "Name: Gender_Num, dtype: int64\n",
      "--------------------\n",
      "Gender_Num Percentages:\n",
      "2.000   80.700\n",
      "3.000   11.100\n",
      "1.000    8.100\n",
      "Name: Gender_Num, dtype: float64\n",
      "--------------------\n",
      "Gender_Num Mean: 2.03\n",
      "--------------------\n",
      "Gender_Num Standard Deviation: 0.44\n",
      "====================\n",
      "Gender_Female:\n",
      "--------------------\n",
      "Gender_Female Counts:\n",
      "0.000    5224\n",
      "1.000     463\n",
      "Name: Gender_Female, dtype: int64\n",
      "--------------------\n",
      "Gender_Female Percentages:\n",
      "0.000   91.900\n",
      "1.000    8.100\n",
      "Name: Gender_Female, dtype: float64\n",
      "--------------------\n",
      "Gender_Female Mean: 0.08\n",
      "--------------------\n",
      "Gender_Female Standard Deviation: 0.27\n",
      "====================\n",
      "Gender_Mixed:\n",
      "--------------------\n",
      "Gender_Mixed Counts:\n",
      "1.000    4590\n",
      "0.000    1097\n",
      "Name: Gender_Mixed, dtype: int64\n",
      "--------------------\n",
      "Gender_Mixed Percentages:\n",
      "1.000   80.700\n",
      "0.000   19.300\n",
      "Name: Gender_Mixed, dtype: float64\n",
      "--------------------\n",
      "Gender_Mixed Mean: 0.81\n",
      "--------------------\n",
      "Gender_Mixed Standard Deviation: 0.39\n",
      "====================\n",
      "Gender_Male:\n",
      "--------------------\n",
      "Gender_Male Counts:\n",
      "0.000    5053\n",
      "1.000     634\n",
      "Name: Gender_Male, dtype: int64\n",
      "--------------------\n",
      "Gender_Male Percentages:\n",
      "0.000   88.900\n",
      "1.000   11.100\n",
      "Name: Gender_Male, dtype: float64\n",
      "--------------------\n",
      "Gender_Male Mean: 0.11\n",
      "--------------------\n",
      "Gender_Male Standard Deviation: 0.31\n",
      "====================\n",
      "Age:\n",
      "--------------------\n",
      "Age Counts:\n",
      "Younger      3178\n",
      "Mixed Age    1827\n",
      "Older         682\n",
      "Name: Age, dtype: int64\n",
      "--------------------\n",
      "Age Percentages:\n",
      "Younger     55.900\n",
      "Mixed Age   32.100\n",
      "Older       12.000\n",
      "Name: Age, dtype: float64\n",
      "--------------------\n",
      "====================\n",
      "Age_Num:\n",
      "--------------------\n",
      "Age_Num Counts:\n",
      "3.000    3178\n",
      "2.000    1827\n",
      "1.000     682\n",
      "Name: Age_Num, dtype: int64\n",
      "--------------------\n",
      "Age_Num Percentages:\n",
      "3.000   55.900\n",
      "2.000   32.100\n",
      "1.000   12.000\n",
      "Name: Age_Num, dtype: float64\n",
      "--------------------\n",
      "Age_Num Mean: 2.44\n",
      "--------------------\n",
      "Age_Num Standard Deviation: 0.7\n",
      "====================\n",
      "Age_Older:\n",
      "--------------------\n",
      "Age_Older Counts:\n",
      "0.000    5005\n",
      "1.000     682\n",
      "Name: Age_Older, dtype: int64\n",
      "--------------------\n",
      "Age_Older Percentages:\n",
      "0.000   88.000\n",
      "1.000   12.000\n",
      "Name: Age_Older, dtype: float64\n",
      "--------------------\n",
      "Age_Older Mean: 0.12\n",
      "--------------------\n",
      "Age_Older Standard Deviation: 0.32\n",
      "====================\n",
      "Age_Mixed:\n",
      "--------------------\n",
      "Age_Mixed Counts:\n",
      "0.000    3860\n",
      "1.000    1827\n",
      "Name: Age_Mixed, dtype: int64\n",
      "--------------------\n",
      "Age_Mixed Percentages:\n",
      "0.000   67.900\n",
      "1.000   32.100\n",
      "Name: Age_Mixed, dtype: float64\n",
      "--------------------\n",
      "Age_Mixed Mean: 0.32\n",
      "--------------------\n",
      "Age_Mixed Standard Deviation: 0.47\n",
      "====================\n",
      "Age_Younger:\n",
      "--------------------\n",
      "Age_Younger Counts:\n",
      "1.000    3178\n",
      "0.000    2509\n",
      "Name: Age_Younger, dtype: int64\n",
      "--------------------\n",
      "Age_Younger Percentages:\n",
      "1.000   55.900\n",
      "0.000   44.100\n",
      "Name: Age_Younger, dtype: float64\n",
      "--------------------\n",
      "Age_Younger Mean: 0.56\n",
      "--------------------\n",
      "Age_Younger Standard Deviation: 0.5\n",
      "\n",
      "\n",
      "====================\n",
      "English Requirement:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No     5678\n",
       "Yes       9\n",
       "Name: English Requirement, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Dutch Requirement:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No     5682\n",
       "Yes       5\n",
       "Name: Dutch Requirement, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gender_age_info(df_all)\n",
    "print('='*20)\n",
    "print('English Requirement:')\n",
    "df_all['English Requirement'].value_counts()\n",
    "print('='*20)\n",
    "print('Dutch Requirement:')\n",
    "df_all['Dutch Requirement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample(df_all, n, sampling_enabled = True, random_state=random_state):\n",
    "    if sampling_enabled is True:\n",
    "        df_all_sample = df_all.sample(n=n, random_state=random_state).reset_index(drop=True)\n",
    "    elif sampling_enabled is False:\n",
    "        df_all_sample = df_all\n",
    "\n",
    "    print(f'Sample size: {len(df_all_sample)}')\n",
    "    # df_all_sample['Search Keyword'].isnull().values.any()\n",
    "#     df_all_sample.duplicated(subset=[\"Job ID\", 'Job Description_cleaned']).value_counts()\n",
    "\n",
    "    return df_all_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample_dfs(\n",
    "    df_all, model_sizes = model_sizes, n=300, sampling_enabled = True,\n",
    "    dfs_dict = {\n",
    "        # 'All Sample': {'categories': {'All Sample': defaultdict()}},\n",
    "        'Gender': {'categories': {'Female': defaultdict(), 'Mixed Gender': defaultdict(), 'Male': defaultdict(), }},\n",
    "        'Age': {'categories': {'Older': defaultdict(), 'Mixed Age': defaultdict(), 'Younger': defaultdict()}}\n",
    "    }\n",
    "):\n",
    "\n",
    "    df_all_sample = make_sample(df_all, n=n, sampling_enabled=sampling_enabled)\n",
    "\n",
    "    for gen in order_gender:\n",
    "        df_gen = df_all_sample.loc[df_all_sample['Gender'] == gen]\n",
    "        dfs_dict['Gender']['categories'][gen]['df'] = df_gen\n",
    "        print(f'Length of {gen}: {len(df_gen)}')\n",
    "\n",
    "    for age in order_age:\n",
    "        df_age = df_all_sample.loc[df_all_sample['Age'] == age]\n",
    "        dfs_dict['Age']['categories'][age]['df'] = df_age\n",
    "        print(f'Length of {age}: {len(df_age)}')\n",
    "\n",
    "    return dfs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 300\n",
      "Length of Female: 25\n",
      "Length of Mixed Gender: 242\n",
      "Length of Male: 33\n",
      "Length of Older: 33\n",
      "Length of Mixed Age: 94\n",
      "Length of Younger: 173\n"
     ]
    }
   ],
   "source": [
    "dfs_dict = make_sample_dfs(df_all, sampling_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEMALE:\n",
      "Female word frequency length: 197\n",
      "Female word frequency sorted: ['clinical', 'gsk', 'preferred', 'ahold', 'delhaize']\n",
      "--------------------\n",
      "Female nltk 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "          abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "clinical     7.000          0.288            1.373       \n",
      "gsk          4.000          0.184            0.656       \n",
      "within       3.000          0.169            0.811       \n",
      "ahold        3.000          0.560            1.226       \n",
      "delhaize     3.000          0.560            1.786       \n",
      "================================================================================\n",
      "FEMALE:\n",
      "Female word frequency length: 208\n",
      "Female word frequency sorted: ['ahold_delhaize', 'fees_arising', 'audiovisual_media', 'infectious_diseases', 'clinical_data']\n",
      "--------------------\n",
      "Female nltk 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "                     abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "ahold_delhaize          3.000          0.700            1.500       \n",
      "fees_arising            2.000          0.133            0.133       \n",
      "infectious_diseases     2.000          0.194            1.667       \n",
      "clinical_data           2.000          0.106            0.621       \n",
      "audiovisual_media       2.000          0.080            0.080       \n",
      "================================================================================\n",
      "FEMALE:\n",
      "Female word frequency length: 192\n",
      "Female word frequency sorted: ['experience_working_fast-growth', 'working_fast-growth_technology', 'fast-growth_technology_company', 'technology_company_strongly', 'company_strongly_preferred']\n",
      "--------------------\n",
      "Female nltk 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                                abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "experience_working_fast-growth     1.000          0.200            0.200       \n",
      "working_fast-growth_technology     1.000          0.200            0.400       \n",
      "strategy_drives_opportunity        1.000          0.091            0.636       \n",
      "drives_opportunity_protect         1.000          0.091            0.727       \n",
      "opportunity_protect_people         1.000          0.091            0.818       \n",
      "================================================================================\n",
      "FEMALE:\n",
      "Female word frequency length: 597\n",
      "Female word frequency sorted: ['clinical', 'gsk', 'preferred', 'ahold', 'delhaize']\n",
      "--------------------\n",
      "Female nltk 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "           abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "clinical      7.000          0.103            1.732       \n",
      "gsk           4.000          0.065            0.289       \n",
      "expertise     3.000          0.157            0.324       \n",
      "eu            3.000          0.040            0.040       \n",
      "within        3.000          0.063            1.026       \n",
      "================================================================================\n",
      "FEMALE:\n",
      "Female word frequency length: 173\n",
      "Female word frequency sorted: ['clinic', 'work', 'gsk', 'experi', 'prefer']\n",
      "--------------------\n",
      "Female gensim 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "          abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "clinic       7.000          0.293            1.378       \n",
      "work         4.000          0.658            2.017       \n",
      "gsk          4.000          0.186            0.622       \n",
      "experi       3.000          0.492            1.458       \n",
      "expertis     3.000          0.400            0.800       \n",
      "================================================================================\n",
      "FEMALE:\n",
      "Female word frequency length: 69\n",
      "Female word frequency sorted: ['ahold_delhaiz', 'fee_aris', 'audiovisu_media', 'infecti_diseas', 'clinic_data']\n",
      "--------------------\n",
      "Female gensim 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "                 abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "clinic_develop      2.000          0.143            0.143       \n",
      "infecti_diseas      2.000          0.833            1.500       \n",
      "fee_aris            2.000          0.333            0.333       \n",
      "ahold_delhaiz       2.000          1.000            1.000       \n",
      "audiovisu_media     2.000          0.286            0.286       \n",
      "================================================================================\n",
      "FEMALE:\n",
      "Female word frequency length: 18\n",
      "Female word frequency sorted: ['growth_technolog_compani', 'main_prioriti_continu_health', 'safeti_employe_custom', 'effici_decis_make_skill', 'respect_vacanc_post_site']\n",
      "--------------------\n",
      "Female gensim 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                                abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "growth_technolog_compani           1.000          1.000            1.000       \n",
      "main_prioriti_continu_health       1.000          0.500            0.500       \n",
      "prioriti_strategi_cours_action     1.000          0.333            0.667       \n",
      "capac_propos_debat_appropri        1.000          0.333            0.333       \n",
      "standard_oper_procedur_sop         1.000          0.250            1.000       \n",
      "================================================================================\n",
      "FEMALE:\n",
      "Female word frequency length: 260\n",
      "Female word frequency sorted: ['clinic', 'work', 'gsk', 'experi', 'prefer']\n",
      "--------------------\n",
      "Female gensim 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "          abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "clinic       7.000          0.228            1.124       \n",
      "work         4.000          0.475            1.442       \n",
      "gsk          4.000          0.139            0.564       \n",
      "expertis     3.000          0.243            0.493       \n",
      "manag        3.000          0.289            0.911       \n",
      "================================================================================\n",
      "MIXED GENDER:\n",
      "Mixed Gender word frequency length: 1097\n",
      "Mixed Gender word frequency sorted: ['team', 'experience', '’', 'skills', 'role']\n",
      "--------------------\n",
      "Mixed Gender nltk 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "            abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "team           21.000         2.305            15.724      \n",
      "experience     17.000         2.151            10.489      \n",
      "’              13.000         2.165             5.932      \n",
      "skills         12.000         2.386             8.069      \n",
      "role           11.000         0.917             1.870      \n",
      "================================================================================\n",
      "MIXED GENDER:\n",
      "Mixed Gender word frequency length: 1553\n",
      "Mixed Gender word frequency sorted: ['communication_skills', 'fluent_english', 'opportunity_develop', 'digital_marketing', 'years_experience']\n",
      "--------------------\n",
      "Mixed Gender nltk 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "                      abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "communication_skills     5.000          0.928            3.744       \n",
      "fluent_english           4.000          1.617            1.617       \n",
      "digital_marketing        3.000          0.674            1.701       \n",
      "years_experience         3.000          0.492            1.350       \n",
      "content_marketing        3.000          0.958            1.833       \n",
      "================================================================================\n",
      "MIXED GENDER:\n",
      "Mixed Gender word frequency length: 1363\n",
      "Mixed Gender word frequency sorted: ['verbal_written_communication', 'written_communication_skills', 'fluent_english_dutch', 'global_digital_marketing', 'content_marketing_intern']\n",
      "--------------------\n",
      "Mixed Gender nltk 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                                abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "verbal_written_communication       3.000          0.783            1.617       \n",
      "written_communication_skills       3.000          0.783            2.400       \n",
      "trainee_team_likeminded            2.000          0.286            1.714       \n",
      "international_trainee_team         2.000          0.286            1.429       \n",
      "meet-ups_international_trainee     2.000          0.286            1.143       \n",
      "================================================================================\n",
      "MIXED GENDER:\n",
      "Mixed Gender word frequency length: 4013\n",
      "Mixed Gender word frequency sorted: ['team', 'experience', '’', 'skills', 'role']\n",
      "--------------------\n",
      "Mixed Gender nltk 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "            abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "team           21.000         0.911            14.117      \n",
      "experience     17.000         0.836            10.435      \n",
      "’              13.000         1.023             6.028      \n",
      "skills         12.000         1.211             7.525      \n",
      "role           11.000         0.341             0.996      \n",
      "================================================================================\n",
      "MIXED GENDER:\n",
      "Mixed Gender word frequency length: 807\n",
      "Mixed Gender word frequency sorted: ['team', 'manag', 'experi', 'year', 'work']\n",
      "--------------------\n",
      "Mixed Gender gensim 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "        abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "team       26.000         2.801            16.114      \n",
      "experi     18.000         2.630            11.161      \n",
      "manag      18.000         2.917            10.134      \n",
      "year       16.000         2.423             7.164      \n",
      "work       15.000         2.010             8.039      \n",
      "================================================================================\n",
      "MIXED GENDER:\n",
      "Mixed Gender word frequency length: 407\n",
      "Mixed Gender word frequency sorted: ['fluent_english', 'sale_team', 'opportun_develop', 'year_experi', 'content_market']\n",
      "--------------------\n",
      "Mixed Gender gensim 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "                  abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "fluent_english       4.000          2.167            2.167       \n",
      "year_experi          3.000          2.500            2.500       \n",
      "sale_team            3.000          0.536            0.786       \n",
      "opportun_develop     3.000          1.833            1.833       \n",
      "content_market       3.000          2.500            3.000       \n",
      "================================================================================\n",
      "MIXED GENDER:\n",
      "Mixed Gender word frequency length: 110\n",
      "Mixed Gender word frequency sorted: ['content_market_intern', 'traine_year_fill_meet', 'up_intern_traine_team', 'attract_discount_insur_polici', 'dilig_reliabl_proactiv']\n",
      "--------------------\n",
      "Mixed Gender gensim 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                               abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "traine_year_fill_meet             2.000          1.000            1.000       \n",
      "up_intern_traine_team             2.000          1.000            2.000       \n",
      "content_market_intern             2.000          2.000            2.000       \n",
      "attract_discount_insur_polici     1.000          1.000            1.000       \n",
      "oper_interfac_adyen_merchant      1.000          1.000            1.000       \n",
      "================================================================================\n",
      "MIXED GENDER:\n",
      "Mixed Gender word frequency length: 1324\n",
      "Mixed Gender word frequency sorted: ['team', 'manag', 'experi', 'year', 'work']\n",
      "--------------------\n",
      "Mixed Gender gensim 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "        abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "team       26.000         2.108            12.511      \n",
      "manag      18.000         2.119             8.057      \n",
      "experi     18.000         2.019             9.430      \n",
      "year       16.000         1.854             6.459      \n",
      "work       15.000         1.435             6.816      \n",
      "================================================================================\n",
      "MALE:\n",
      "Male word frequency length: 201\n",
      "Male word frequency sorted: ['work', 'days', '’', 'energy', 'experience']\n",
      "--------------------\n",
      "Male nltk 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "            abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "work           3.000          0.800            1.100       \n",
      "sectors        3.000          0.318            1.118       \n",
      "energy         3.000          0.243            0.671       \n",
      "’              3.000          0.393            1.714       \n",
      "experience     3.000          0.412            0.808       \n",
      "================================================================================\n",
      "MALE:\n",
      "Male word frequency length: 188\n",
      "Male word frequency sorted: ['work_includes', 'co_develop', 'develop_design', 'design_validation', 'validation_plans']\n",
      "--------------------\n",
      "Male nltk 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "                     abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "work_includes           1.000          1.000            1.000       \n",
      "portfolio_solutions     1.000          0.062            1.000       \n",
      "sectors_engaging        1.000          0.062            0.438       \n",
      "engaging_full           1.000          0.062            0.500       \n",
      "full_value              1.000          0.062            0.562       \n",
      "================================================================================\n",
      "MALE:\n",
      "Male word frequency length: 159\n",
      "Male word frequency sorted: ['co_develop_design', 'develop_design_validation', 'design_validation_plans', 'validation_plans_npi', 'plans_npi_new']\n",
      "--------------------\n",
      "Male nltk 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                            abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "co_develop_design              1.000          0.125            0.125       \n",
      "scale_deployment_portfolio     1.000          0.067            0.933       \n",
      "sectors_engaging_full          1.000          0.067            0.467       \n",
      "engaging_full_value            1.000          0.067            0.533       \n",
      "full_value_chain               1.000          0.067            0.600       \n",
      "================================================================================\n",
      "MALE:\n",
      "Male word frequency length: 548\n",
      "Male word frequency sorted: ['work', 'days', '’', 'energy', 'experience']\n",
      "--------------------\n",
      "Male nltk 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "            abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "work           3.000          0.454            1.009       \n",
      "energy         3.000          0.091            0.924       \n",
      "sectors        3.000          0.125            0.458       \n",
      "’              3.000          0.156            1.684       \n",
      "experience     3.000          0.170            1.693       \n",
      "================================================================================\n",
      "MALE:\n",
      "Male word frequency length: 182\n",
      "Male word frequency sorted: ['work', 'energi', 'product', 'dai', 'market']\n",
      "--------------------\n",
      "Male gensim 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "         abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "work        4.000          0.950            0.950       \n",
      "energi      4.000          0.427            1.356       \n",
      "product     3.000          0.278            1.000       \n",
      "market      3.000          0.359            2.784       \n",
      "sector      3.000          0.278            1.111       \n",
      "================================================================================\n",
      "MALE:\n",
      "Male word frequency length: 41\n",
      "Male word frequency sorted: ['work_dai', 'develop_design', 'new_product', 'kei_messag', 'busi_unit']\n",
      "--------------------\n",
      "Male gensim 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "                abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "work_dai           2.000          1.000            1.000       \n",
      "develop_design     1.000          0.500            0.500       \n",
      "help_enabl         1.000          1.000            1.000       \n",
      "spoken_written     1.000          1.000            1.000       \n",
      "job_type           1.000          1.000            1.000       \n",
      "================================================================================\n",
      "MALE:\n",
      "Male word frequency length: 6\n",
      "Male word frequency sorted: ['new_product_introduct', 'transform_econom_system', 'jlt_pioneer_rug', 'spoken_written_english', 'job_type_time']\n",
      "--------------------\n",
      "Male gensim 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                         abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "new_product_introduct       1.000          1.000            1.000       \n",
      "transform_econom_system     1.000          1.000            1.000       \n",
      "jlt_pioneer_rug             1.000          1.000            1.000       \n",
      "spoken_written_english      1.000          1.000            1.000       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_type_time               1.000          1.000            1.000       \n",
      "================================================================================\n",
      "MALE:\n",
      "Male word frequency length: 229\n",
      "Male word frequency sorted: ['work', 'energi', 'product', 'dai', 'market']\n",
      "--------------------\n",
      "Male gensim 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "        abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "work       4.000          0.843            0.843       \n",
      "energi     4.000          0.341            1.103       \n",
      "sector     3.000          0.243            0.957       \n",
      "experi     3.000          0.412            0.737       \n",
      "dai        3.000          0.450            1.150       \n",
      "================================================================================\n",
      "OLDER:\n",
      "Older word frequency length: 213\n",
      "Older word frequency sorted: ['days', '’', 'year', 'experience', 'also']\n",
      "--------------------\n",
      "Older nltk 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "            abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "days           4.000          0.479            1.347       \n",
      "experience     3.000          0.412            0.808       \n",
      "’              3.000          0.393            1.714       \n",
      "year           3.000          0.229            0.376       \n",
      "role           2.000          0.154            0.154       \n",
      "================================================================================\n",
      "OLDER:\n",
      "Older word frequency length: 204\n",
      "Older word frequency sorted: ['co_develop', 'develop_design', 'design_validation', 'validation_plans', 'plans_npi']\n",
      "--------------------\n",
      "Older nltk 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "               abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "co_develop        1.000          0.111            0.111       \n",
      "attitude_grow     1.000          0.077            0.769       \n",
      "jou_bieden        1.000          0.333            1.000       \n",
      "looking_huge      1.000          0.077            0.077       \n",
      "huge_amount       1.000          0.077            0.154       \n",
      "================================================================================\n",
      "OLDER:\n",
      "Older word frequency length: 176\n",
      "Older word frequency sorted: ['co_develop_design', 'develop_design_validation', 'design_validation_plans', 'validation_plans_npi', 'plans_npi_new']\n",
      "--------------------\n",
      "Older nltk 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                           abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "co_develop_design             1.000          0.125            0.125       \n",
      "develop_design_validation     1.000          0.125            0.250       \n",
      "looking_huge_amount           1.000          0.083            0.083       \n",
      "huge_amount_experience        1.000          0.083            0.167       \n",
      "amount_experience_–           1.000          0.083            0.250       \n",
      "================================================================================\n",
      "OLDER:\n",
      "Older word frequency length: 593\n",
      "Older word frequency sorted: ['days', '’', 'year', 'experience', 'also']\n",
      "--------------------\n",
      "Older nltk 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "            abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "days           4.000          0.195            1.064       \n",
      "’              3.000          0.156            1.684       \n",
      "experience     3.000          0.170            1.693       \n",
      "year           3.000          0.084            0.609       \n",
      "salary         2.000          0.047            1.579       \n",
      "================================================================================\n",
      "OLDER:\n",
      "Older word frequency length: 186\n",
      "Older word frequency sorted: ['dai', 'work', 'role', 'high', 'end']\n",
      "--------------------\n",
      "Older gensim 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "      abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "dai      4.000          0.613            1.647       \n",
      "role     3.000          0.245            1.328       \n",
      "year     3.000          0.363            0.510       \n",
      "high     3.000          0.279            1.978       \n",
      "work     3.000          0.450            0.450       \n",
      "================================================================================\n",
      "OLDER:\n",
      "Older word frequency length: 56\n",
      "Older word frequency sorted: ['work_dai', 'develop_design', 'new_product', 'kei_messag', 'busi_unit']\n",
      "--------------------\n",
      "Older gensim 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "                 abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "work_dai            2.000          1.000            1.000       \n",
      "develop_design      1.000          0.500            0.500       \n",
      "belgium_citizen     1.000          0.059            0.294       \n",
      "proven_track        1.000          0.333            0.333       \n",
      "record_develop      1.000          0.333            0.667       \n",
      "================================================================================\n",
      "OLDER:\n",
      "Older word frequency length: 14\n",
      "Older word frequency sorted: ['new_product_introduct', 'role_come_high_end', 'stock_plan_bonu_scheme', 'gross_monthli_salari', 'spoken_written_english']\n",
      "--------------------\n",
      "Older gensim 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                        abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "new_product_introduct      1.000          1.000            1.000       \n",
      "role_come_high_end         1.000          0.500            0.500       \n",
      "stock_plan_bonu_scheme     1.000          0.500            1.000       \n",
      "gross_monthli_salari       1.000          1.000            1.000       \n",
      "spoken_written_english     1.000          1.000            1.000       \n",
      "================================================================================\n",
      "OLDER:\n",
      "Older word frequency length: 256\n",
      "Older word frequency sorted: ['dai', 'work', 'role', 'high', 'end']\n",
      "--------------------\n",
      "Older gensim 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "      abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "dai      4.000          0.467            2.029       \n",
      "high     3.000          0.172            1.369       \n",
      "year     3.000          0.267            1.147       \n",
      "role     3.000          0.180            1.256       \n",
      "work     3.000          0.343            0.343       \n",
      "================================================================================\n",
      "MIXED AGE:\n",
      "Mixed Age word frequency length: 532\n",
      "Mixed Age word frequency sorted: ['work', 'team', 'clinical', 'within', 'skills']\n",
      "--------------------\n",
      "Mixed Age nltk 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "          abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "work         8.000          1.348            4.192       \n",
      "clinical     7.000          0.288            1.373       \n",
      "team         7.000          1.024            6.300       \n",
      "within       6.000          0.427            2.796       \n",
      "skills       6.000          1.084            4.383       \n",
      "================================================================================\n",
      "MIXED AGE:\n",
      "Mixed Age word frequency length: 605\n",
      "Mixed Age word frequency sorted: ['ahold_delhaize', 'stakeholders_ensure', 'digital_marketing', 'marketing_internship', 'fees_arising']\n",
      "--------------------\n",
      "Mixed Age nltk 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "                      abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "ahold_delhaize           3.000          0.700            1.500       \n",
      "marketing_internship     2.000          1.500            2.000       \n",
      "fees_arising             2.000          0.133            0.133       \n",
      "clinical_data            2.000          0.106            0.621       \n",
      "audiovisual_media        2.000          0.080            0.080       \n",
      "================================================================================\n",
      "MIXED AGE:\n",
      "Mixed Age word frequency length: 530\n",
      "Mixed Age word frequency sorted: ['content_marketing_intern', 'experience_working_fast-growth', 'working_fast-growth_technology', 'fast-growth_technology_company', 'technology_company_strongly']\n",
      "--------------------\n",
      "Mixed Age nltk 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                                abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "content_marketing_intern           2.000          1.500            1.500       \n",
      "experience_working_fast-growth     1.000          0.200            0.200       \n",
      "drives_opportunity_protect         1.000          0.091            0.727       \n",
      "opportunity_accelerate_deliver     1.000          0.091            0.182       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate_deliver_clinical        1.000          0.091            0.273       \n",
      "================================================================================\n",
      "MIXED AGE:\n",
      "Mixed Age word frequency length: 1667\n",
      "Mixed Age word frequency sorted: ['work', 'team', 'clinical', 'within', 'skills']\n",
      "--------------------\n",
      "Mixed Age nltk 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "           abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "work          8.000          0.657            6.639       \n",
      "team          7.000          0.429            5.157       \n",
      "clinical      7.000          0.103            1.732       \n",
      "within        6.000          0.157            3.490       \n",
      "marketing     6.000          0.965            2.035       \n",
      "================================================================================\n",
      "MIXED AGE:\n",
      "Mixed Age word frequency length: 438\n",
      "Mixed Age word frequency sorted: ['work', 'team', 'manag', 'market', 'clinic']\n",
      "--------------------\n",
      "Mixed Age gensim 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "        abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "work       12.000         2.069            6.083       \n",
      "team       10.000         1.437            7.662       \n",
      "clinic      7.000         0.293            1.378       \n",
      "manag       7.000         0.927            4.959       \n",
      "market      7.000         1.960            4.000       \n",
      "================================================================================\n",
      "MIXED AGE:\n",
      "Mixed Age word frequency length: 174\n",
      "Mixed Age word frequency sorted: ['ahold_delhaiz', 'plan_execut', 'fee_aris', 'audiovisu_media', 'infecti_diseas']\n",
      "--------------------\n",
      "Mixed Age gensim 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "                abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "ahold_delhaiz      2.000          1.000            1.000       \n",
      "content_market     2.000          2.000            2.000       \n",
      "clinic_data        2.000          0.405            1.190       \n",
      "clinic_develop     2.000          0.143            0.143       \n",
      "fee_aris           2.000          0.333            0.333       \n",
      "================================================================================\n",
      "MIXED AGE:\n",
      "Mixed Age word frequency length: 39\n",
      "Mixed Age word frequency sorted: ['content_market_intern', 'growth_technolog_compani', 'main_prioriti_continu_health', 'safeti_employe_custom', 'effici_decis_make_skill']\n",
      "--------------------\n",
      "Mixed Age gensim 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                                abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "content_market_intern              2.000          2.000            2.000       \n",
      "inclus_cultur_encourag_support     1.000          0.500            0.500       \n",
      "jlt_pioneer_rug                    1.000          1.000            1.000       \n",
      "scale_work_colleagu_netherland     1.000          1.000            1.000       \n",
      "strong_written_verbal_commun       1.000          1.000            1.000       \n",
      "================================================================================\n",
      "MIXED AGE:\n",
      "Mixed Age word frequency length: 651\n",
      "Mixed Age word frequency sorted: ['work', 'team', 'manag', 'market', 'clinic']\n",
      "--------------------\n",
      "Mixed Age gensim 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "        abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "work       12.000         1.646            4.626       \n",
      "team       10.000         1.186            5.998       \n",
      "manag       7.000         0.667            3.096       \n",
      "market      7.000         1.350            3.367       \n",
      "clinic      7.000         0.228            1.124       \n",
      "================================================================================\n",
      "YOUNGER:\n",
      "Younger word frequency length: 864\n",
      "Younger word frequency sorted: ['team', 'experience', '’', 'business', 'skills']\n",
      "--------------------\n",
      "Younger nltk 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "            abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "experience     14.000         1.742            8.017       \n",
      "team           14.000         1.281            9.424       \n",
      "’              12.000         1.832            5.599       \n",
      "skills          8.000         1.886            5.686       \n",
      "business        8.000         0.961            5.086       \n",
      "================================================================================\n",
      "YOUNGER:\n",
      "Younger word frequency length: 1156\n",
      "Younger word frequency sorted: ['fluent_english', 'years_experience', 'communication_skills', 'palo_alto', 'loyalty_initiatives']\n",
      "--------------------\n",
      "Younger nltk 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "                        abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "years_experience           3.000          0.492            1.350       \n",
      "fluent_english             3.000          1.450            1.450       \n",
      "communication_skills       3.000          0.617            2.300       \n",
      "meet-ups_international     2.000          0.250            1.000       \n",
      "role_opportunity           2.000          0.171            0.343       \n",
      "================================================================================\n",
      "YOUNGER:\n",
      "Younger word frequency length: 1013\n",
      "Younger word frequency sorted: ['fluent_english_dutch', 'trainee_year_filled', 'year_filled_meet-ups', 'filled_meet-ups_international', 'meet-ups_international_trainee']\n",
      "--------------------\n",
      "Younger nltk 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                              abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "trainee_year_filled              2.000          0.286            0.286       \n",
      "international_trainee_team       2.000          0.286            1.429       \n",
      "written_communication_skills     2.000          0.533            1.400       \n",
      "verbal_written_communication     2.000          0.533            0.867       \n",
      "trainee_team_likeminded          2.000          0.286            1.714       \n",
      "================================================================================\n",
      "YOUNGER:\n",
      "Younger word frequency length: 3033\n",
      "Younger word frequency sorted: ['team', 'experience', '’', 'business', 'skills']\n",
      "--------------------\n",
      "Younger nltk 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "            abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "experience     14.000         0.677            8.406       \n",
      "team           14.000         0.481            8.960       \n",
      "’              12.000         0.856            5.861       \n",
      "business        8.000         0.413            4.811       \n",
      "skills          8.000         1.018            4.391       \n",
      "================================================================================\n",
      "YOUNGER:\n",
      "Younger word frequency length: 652\n",
      "Younger word frequency sorted: ['team', 'experi', 'manag', 'year', 'develop']\n",
      "--------------------\n",
      "Younger gensim 1grams abs_word_freq_df:\n",
      "--------------------\n",
      "         abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "team        17.000         1.465            9.452       \n",
      "experi      15.000         2.102            8.772       \n",
      "manag       14.000         2.447            7.409       \n",
      "employe     11.000         1.470            6.188       \n",
      "custom      11.000         1.058            4.883       \n",
      "================================================================================\n",
      "YOUNGER:\n",
      "Younger word frequency length: 302\n",
      "Younger word frequency sorted: ['sale_team', 'fluent_english', 'year_experi', 'palo_alto', 'revenu_target']\n",
      "--------------------\n",
      "Younger gensim 2grams abs_word_freq_df:\n",
      "--------------------\n",
      "                abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "fluent_english     3.000          1.833            1.833       \n",
      "sale_team          3.000          0.536            0.786       \n",
      "year_experi        3.000          2.500            2.500       \n",
      "fill_meet          2.000          0.400            0.800       \n",
      "we’r_look          2.000          2.000            2.000       \n",
      "================================================================================\n",
      "YOUNGER:\n",
      "Younger word frequency length: 81\n",
      "Younger word frequency sorted: ['traine_year_fill_meet', 'up_intern_traine_team', 'attract_discount_insur_polici', 'dilig_reliabl_proactiv', 'fluent_english_dutch_languag']\n",
      "--------------------\n",
      "Younger gensim 3grams abs_word_freq_df:\n",
      "--------------------\n",
      "                               abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "traine_year_fill_meet             2.000          1.000            1.000       \n",
      "up_intern_traine_team             2.000          1.000            2.000       \n",
      "attract_discount_insur_polici     1.000          1.000            1.000       \n",
      "oper_interfac_adyen_merchant      1.000          1.000            1.000       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ownership_place_low_possibl       1.000          0.500            0.500       \n",
      "================================================================================\n",
      "YOUNGER:\n",
      "Younger word frequency length: 1035\n",
      "Younger word frequency sorted: ['team', 'experi', 'manag', 'year', 'develop']\n",
      "--------------------\n",
      "Younger gensim 123grams abs_word_freq_df:\n",
      "--------------------\n",
      "         abs_word_freq  abs_word_perc  abs_word_perc_cum\n",
      "team        17.000         1.022            7.513       \n",
      "experi      15.000         1.662            7.858       \n",
      "manag       14.000         1.741            5.871       \n",
      "develop     11.000         1.201            4.172       \n",
      "employe     11.000         1.303            4.852       \n"
     ]
    }
   ],
   "source": [
    "for iv, iv_cats in dfs_dict.items():\n",
    "    for iv_cat, value in iv_cats['categories'].items():\n",
    "        for embedding_library, ngram_number in itertools.product(embedding_libraries_list, ngrams_list):\n",
    "            value['frequencies'] = defaultdict()\n",
    "            value['frequencies'][f'{embedding_library}_{ngram_number}grams_abs_word_freq'] = convert_frequency(\n",
    "                value,\n",
    "                f'Job Description {embedding_library}_{ngram_number}grams_abs_word_freq'\n",
    "            )\n",
    "            value['frequencies'][f'{embedding_library}_{ngram_number}grams_abs_word_perc'] = convert_frequency(\n",
    "                value,\n",
    "                f'Job Description {embedding_library}_{ngram_number}grams_abs_word_perc'\n",
    "            )\n",
    "            value['frequencies'][f'{embedding_library}_{ngram_number}grams_abs_word_perc_cum'] = convert_frequency(\n",
    "                value,\n",
    "                f'Job Description {embedding_library}_{ngram_number}grams_abs_word_perc_cum'\n",
    "            )\n",
    "            value['frequencies'][f'{embedding_library}_{ngram_number}grams_abs_word_freq_df'] = pd.DataFrame(\n",
    "                data=[\n",
    "                    value['frequencies'][f'{embedding_library}_{ngram_number}grams_abs_word_freq'],\n",
    "                    value['frequencies'][f'{embedding_library}_{ngram_number}grams_abs_word_perc'],\n",
    "                    value['frequencies'][f'{embedding_library}_{ngram_number}grams_abs_word_perc_cum']\n",
    "                ]).T.sort_values(0, ascending=False).rename(columns={0: 'abs_word_freq', 1: 'abs_word_perc', 2: 'abs_word_perc_cum'})\n",
    "\n",
    "            print('='*80)\n",
    "            print(f'{iv_cat.upper()}:')\n",
    "            print(f'{iv_cat} word frequency length: {len(value[\"frequencies\"][f\"{embedding_library}_{ngram_number}grams_abs_word_freq_df\"])}')\n",
    "            print(f'{iv_cat} word frequency sorted: {sorted(value[\"frequencies\"][f\"{embedding_library}_{ngram_number}grams_abs_word_freq\"], key=value[\"frequencies\"][f\"{embedding_library}_{ngram_number}grams_abs_word_freq\"].get, reverse=True)[:5]}')\n",
    "            print('-'*20)\n",
    "            print(f'{iv_cat} {embedding_library} {ngram_number}grams abs_word_freq_df:')\n",
    "            print('-'*20)\n",
    "            print(f'{value[\"frequencies\"][f\"{embedding_library}_{ngram_number}grams_abs_word_freq_df\"].head()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iv_cats['categories'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 123]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.62 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.62 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 197\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 197\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 197\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 197\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 197\n",
      "300 - Positive most similar to management: [('opportunity', 0.15808656811714172), ('humanitarian', 0.13282975554466248), ('best', 0.1311216950416565), ('process', 0.1282862275838852), ('3-5', 0.1140107661485672)]\n",
      "300 - Negative most similar to management: [('priority', 0.1571284830570221), ('expertise', 0.15222136676311493), ('impact', 0.13428689539432526), ('call', 0.12418463081121445), ('company', 0.12293136119842529)]\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 197\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 197\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 197\n",
      "300 - Positive most similar to customer: [('accelerate', 0.16805557906627655), ('call', 0.15683305263519287), ('work', 0.12965364754199982), ('chicago', 0.1277429312467575), ('protection', 0.1207423061132431)]\n",
      "300 - Negative most similar to customer: [('years', 0.1300928294658661), ('liable', 0.12120894342660904), ('contexts', 0.11754046380519867), ('improving', 0.11381962150335312), ('order', 0.11279641091823578)]\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 197\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 197\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 197\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 197\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.62 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.62 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 208\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.62 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.62 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 192\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.62 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.62 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 597\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 597\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 597\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 597\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 597\n",
      "300 - Positive most similar to management: [('infectious_diseases', 0.5976136326789856), ('process', 0.5770592093467712), ('tasks_deliver_deadlines', 0.561825156211853), ('gsk_vaccines', 0.5578914880752563), ('ability_prioritize', 0.5520333051681519)]\n",
      "300 - Negative most similar to management: [('platform_product_preferred', 0.062304187566041946), ('retailers', 0.014167792163789272), ('manager', 0.01283725444227457), ('high_performance_standards', 0.0013741211732849479), ('protect', -0.004218392539769411)]\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 597\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 597\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 597\n",
      "300 - Positive most similar to customer: [('infectious_diseases', 0.4241069257259369), (\"eu_'s\", 0.39079004526138306), ('management', 0.3886280953884125), ('rules_application', 0.38530489802360535), ('protect_people', 0.3826046884059906)]\n",
      "300 - Negative most similar to customer: [('expertise_areas_role', 0.0857551246881485), ('efficient', 0.038946013897657394), ('company_strongly_preferred', 0.027104048058390617), ('delhaize_aim_grow', 0.011236838065087795), ('deadlines_high_performance', 0.00562130194157362)]\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 597\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 597\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 597\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 597\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.63 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.63 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 173\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.63 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.63 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 69\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.63 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.63 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 18\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.63 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.63 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 260\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 100: 13.63 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 100: 13.63 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 100 model vobal: 197\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 100 model vobal: 197\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 100 model vobal: 197\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 100 model vobal: 197\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 100 model vobal: 197\n",
      "100 - Positive most similar to management: [('diseases', 0.2952723801136017), ('registration', 0.2302073985338211), ('sop', 0.21512392163276672), ('commitment', 0.21146243810653687), ('following', 0.18255770206451416)]\n",
      "100 - Negative most similar to management: [('data', 0.25240358710289), ('energized', 0.23921509087085724), ('media', 0.22973155975341797), ('scale', 0.21534164249897003), ('areas', 0.21436257660388947)]\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 100 model vobal: 197\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 100 model vobal: 197\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 100 model vobal: 197\n",
      "100 - Positive most similar to customer: [('propose', 0.31189703941345215), ('standard', 0.2617455720901489), ('media', 0.2483190894126892), ('site', 0.21161505579948425), ('pharma', 0.1964459866285324)]\n",
      "100 - Negative most similar to customer: [('people', 0.28631213307380676), ('commitment', 0.2326827198266983), ('standards', 0.20935508608818054), ('actions', 0.2057846337556839), ('culture', 0.18503129482269287)]\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 100 model vobal: 197\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 100 model vobal: 197\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 100 model vobal: 197\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 100 model vobal: 197\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 100: 13.63 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 100: 13.64 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 100 model vobal: 208\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 100: 13.64 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 100: 13.64 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 100 model vobal: 192\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 100: 13.64 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 100: 13.65 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 100 model vobal: 597\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 100 model vobal: 597\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 100 model vobal: 597\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 100 model vobal: 597\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 100 model vobal: 597\n",
      "100 - Positive most similar to management: [('site', 0.627310574054718), (\"eu_'s\", 0.5948191285133362), (\"eu_'s_audiovisual\", 0.589059591293335), ('group', 0.5763707160949707), ('within_program_group', 0.5633382797241211)]\n",
      "100 - Negative most similar to management: [('expertise_areas_role', 0.1403791308403015), ('manager', 0.08987310528755188), ('specializing', 0.08830534666776657), ('platform_product_preferred', 0.08299560099840164), ('specialist', 0.07262527197599411)]\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 100 model vobal: 597\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 100 model vobal: 597\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 100 model vobal: 597\n",
      "100 - Positive most similar to customer: [('posted_site', 0.5368291735649109), ('commitment', 0.488662451505661), ('sop', 0.48340630531311035), ('arising_referrals_employment', 0.48333778977394104), ('expertise_areas', 0.47750478982925415)]\n",
      "100 - Negative most similar to customer: [('manager', 0.1912163943052292), ('specializing', 0.17916488647460938), ('work_1,500_colleagues', 0.17082010209560394), ('programs_within_context', 0.12649062275886536), ('delhaize_work_one', 0.11307466775178909)]\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 100 model vobal: 597\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 100 model vobal: 597\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 100 model vobal: 597\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 100 model vobal: 597\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 100: 13.65 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 100: 13.65 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 100 model vobal: 173\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 100: 13.65 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 100: 13.65 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 100 model vobal: 69\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 100: 13.65 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 100: 13.65 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 100 model vobal: 18\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 100: 13.66 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 100: 13.66 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 100 model vobal: 260\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Mixed Gender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.66 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.66 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 1097\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 1097\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 1097\n",
      "300 - Positive most similar to support: [('team', 0.9907941222190857), ('business', 0.9907481074333191), ('within', 0.9900650382041931), ('new', 0.9900382161140442), ('year', 0.9893358945846558)]\n",
      "300 - Negative most similar to support: [('contract', 0.03886431083083153), ('requirement', 0.01717418059706688), ('supplement', 0.010266951285302639), ('shift', -0.002982174977660179), ('ql', -0.00624465849250555)]\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 1097\n",
      "300 - Positive most similar to leader: [('business', 0.9589440822601318), ('team', 0.9585341811180115), ('activities', 0.9585102796554565), ('within', 0.9579395651817322), ('leaders', 0.9573566913604736)]\n",
      "300 - Negative most similar to leader: [('contract', 0.0414595827460289), ('requirement', 0.015910672023892403), ('shift', 0.009169532917439938), ('qualification', 0.006701569072902203), ('supplement', -0.006703208666294813)]\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 1097\n",
      "300 - Positive most similar to management: [('work', 0.9702794551849365), ('team', 0.9696487188339233), ('within', 0.9690110087394714), ('business', 0.9686528444290161), ('year', 0.9680986404418945)]\n",
      "300 - Negative most similar to management: [('contract', 0.03384185954928398), ('requirement', 0.01942363567650318), ('ql', 0.01586860418319702), ('supplement', 0.014493667520582676), ('shift', 0.010689514689147472)]\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 1097\n",
      "300 - Positive most similar to team: [('business', 0.9915639758110046), ('within', 0.9913766384124756), ('new', 0.9908058047294617), ('support', 0.9907941222190857), ('work', 0.9902111291885376)]\n",
      "300 - Negative most similar to team: [('contract', 0.038841988891363144), ('requirement', 0.015773560851812363), ('supplement', 0.007228096015751362), ('shift', -0.005373114254325628), ('qualification', -0.00552132073789835)]\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 1097\n",
      "300 - Positive most similar to business: [('team', 0.9915639162063599), ('within', 0.991237461566925), ('year', 0.9910564422607422), ('support', 0.9907481074333191), ('applicable', 0.9907267689704895)]\n",
      "300 - Negative most similar to business: [('contract', 0.03600422292947769), ('supplement', 0.01191712822765112), ('requirement', 0.010475043207406998), ('shift', 0.0017010689480230212), ('ql', -0.013487575575709343)]\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 1097\n",
      "300 - Positive most similar to customer: [('support', 0.9839182496070862), ('new', 0.9838759899139404), ('team', 0.9836087822914124), ('within', 0.9833361506462097), ('applicable', 0.9831610918045044)]\n",
      "300 - Negative most similar to customer: [('contract', 0.05313435569405556), ('supplement', 0.020559420809149742), ('shift', 0.0157563928514719), ('requirement', 0.007950958795845509), ('qualification', -0.008395536802709103)]\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 1097\n",
      "300 - Positive most similar to risk: [('within', 0.9660745859146118), ('business', 0.9641702771186829), ('team', 0.9634939432144165), ('hr', 0.962692379951477), ('new', 0.9626535773277283)]\n",
      "300 - Negative most similar to risk: [('contract', 0.04744500666856766), ('supplement', 0.020267250016331673), ('requirement', 0.012034788727760315), ('qualification', 0.005412839353084564), ('ql', -0.001763285486958921)]\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 1097\n",
      "300 - Positive most similar to build: [('within', 0.9849033355712891), ('work', 0.9839462041854858), ('team', 0.9835556149482727), ('new', 0.9832484126091003), ('business', 0.9832127094268799)]\n",
      "300 - Negative most similar to build: [('contract', 0.04831602796912193), ('requirement', 0.03062022663652897), ('supplement', 0.012103654444217682), ('ql', 0.0018354625208303332), ('qualification', -0.0074619450606405735)]\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 1097\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 1097\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Mixed Gender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.67 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.67 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 1553\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Mixed Gender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.67 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.67 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'support' not present in vocabulary\"\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'leader' not present in vocabulary\"\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'team' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'customer' not present in vocabulary\"\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'risk' not present in vocabulary\"\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'build' not present in vocabulary\"\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 1363\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Mixed Gender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.68 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.71 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 4013\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 4013\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 4013\n",
      "300 - Positive most similar to support: [('successful_role_opportunity', 0.9996843338012695), ('best', 0.9996820688247681), ('digital_kpi', 0.9996811151504517), ('business', 0.9996782541275024), ('paid_search', 0.9996756315231323)]\n",
      "300 - Negative most similar to support: [('mac', -0.0030713756568729877), ('ql', -0.017145255580544472), ('contract', -0.023472309112548828), ('qualification', -0.05719062685966492), ('requirement', -0.09559708088636398)]\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 4013\n",
      "300 - Positive most similar to leader: [('enhancement_employee', 0.9996404051780701), ('sustainable_way', 0.9996395707130432), ('training_curriculum', 0.9996309876441956), ('work_environment_please', 0.9996303915977478), ('brings_personal', 0.9996283054351807)]\n",
      "300 - Negative most similar to leader: [('mac', -0.0014902252005413175), ('ql', -0.017365973442792892), ('contract', -0.024975640699267387), ('qualification', -0.058108579367399216), ('requirement', -0.09492109715938568)]\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 4013\n",
      "300 - Positive most similar to management: [('business', 0.999726414680481), ('many_varied_technical', 0.9996922016143799), ('help', 0.9996905326843262), ('msf', 0.9996902942657471), ('levels', 0.9996867775917053)]\n",
      "300 - Negative most similar to management: [('mac', -0.003893651533871889), ('ql', -0.018168089911341667), ('contract', -0.02297174371778965), ('qualification', -0.05751165375113487), ('requirement', -0.09428384900093079)]\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 4013\n",
      "300 - Positive most similar to team: [('msf', 0.9997162222862244), ('days', 0.9997114539146423), ('within', 0.9997074604034424), ('consensus', 0.999698281288147), ('calls', 0.9996970295906067)]\n",
      "300 - Negative most similar to team: [('mac', -0.002853400306776166), ('ql', -0.017605863511562347), ('contract', -0.02401699684560299), ('qualification', -0.054828155785799026), ('requirement', -0.09327688068151474)]\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 4013\n",
      "300 - Positive most similar to business: [('management', 0.9997263550758362), ('lead', 0.9997245073318481), ('grow_career', 0.9997243881225586), ('role_opportunity', 0.9997223019599915), ('within_organization', 0.9997187852859497)]\n",
      "300 - Negative most similar to business: [('mac', -0.004348785150796175), ('ql', -0.01801205612719059), ('contract', -0.023872941732406616), ('qualification', -0.05870568007230759), ('requirement', -0.09543486684560776)]\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 4013\n",
      "300 - Positive most similar to customer: [('business_continued_expansion', 0.9996943473815918), ('needed', 0.9996903538703918), ('navigate', 0.9996901750564575), ('critical_partner_construction', 0.9996901154518127), ('successful_role_opportunity', 0.9996888637542725)]\n",
      "300 - Negative most similar to customer: [('mac', -0.002518501365557313), ('ql', -0.018110308796167374), ('contract', -0.022617138922214508), ('qualification', -0.05653543770313263), ('requirement', -0.09418856352567673)]\n",
      "Checking word:\n",
      "RISK:\n",
      "Length of 300 model vobal: 4013\n",
      "300 - Positive most similar to risk: [('written_verbal_communication', 0.9996400475502014), ('students_fully', 0.9996393918991089), ('respected', 0.9996367692947388), ('candidates', 0.9996351003646851), ('business', 0.9996317028999329)]\n",
      "300 - Negative most similar to risk: [('mac', -0.0021451085340231657), ('ql', -0.015621167607605457), ('contract', -0.024546004831790924), ('qualification', -0.05523614585399628), ('requirement', -0.09651710838079453)]\n",
      "Checking word:\n",
      "BUILD:\n",
      "Length of 300 model vobal: 4013\n",
      "300 - Positive most similar to build: [('forms_identity', 0.9996655583381653), ('example_ockto', 0.9996500611305237), ('variables_relationships_important', 0.9996494054794312), ('working_atmosphere', 0.9996471405029297), ('calls', 0.9996464848518372)]\n",
      "300 - Negative most similar to build: [('mac', -0.003286655992269516), ('ql', -0.016273580491542816), ('contract', -0.023632032796740532), ('qualification', -0.05547318235039711), ('requirement', -0.09425046294927597)]\n",
      "Checking word:\n",
      "COMPUTER:\n",
      "Length of 300 model vobal: 4013\n",
      "\"Key 'computer' not present in vocabulary\"\n",
      "Checking word:\n",
      "PROGRAMMER:\n",
      "Length of 300 model vobal: 4013\n",
      "\"Key 'programmer' not present in vocabulary\"\n",
      "Mixed Gender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model for 300: 13.71 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build w2v_vocab for 300: 13.71 mins\n",
      "Checking words form list of length 12\n",
      "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
      "Checking word:\n",
      "SHE:\n",
      "Length of 300 model vobal: 807\n",
      "\"Key 'she' not present in vocabulary\"\n",
      "Checking word:\n",
      "HE:\n",
      "Length of 300 model vobal: 807\n",
      "\"Key 'he' not present in vocabulary\"\n",
      "Checking word:\n",
      "SUPPORT:\n",
      "Length of 300 model vobal: 807\n",
      "300 - Positive most similar to support: [('team', 0.9816700220108032), ('custom', 0.9810563325881958), ('set', 0.9802677631378174), ('new', 0.9800705909729004), ('partner', 0.979957103729248)]\n",
      "300 - Negative most similar to support: [('contract', 0.03378346189856529), ('gmp', -0.016563590615987778), ('mac', -0.0266855638474226), ('touch', -0.03582179918885231), ('sight', -0.049798641353845596)]\n",
      "Checking word:\n",
      "LEADER:\n",
      "Length of 300 model vobal: 807\n",
      "300 - Positive most similar to leader: [('strong', 0.9557567238807678), ('custom', 0.9548636674880981), ('client', 0.9548543691635132), ('set', 0.9542556405067444), ('new', 0.9542292356491089)]\n",
      "300 - Negative most similar to leader: [('contract', 0.03524753078818321), ('gmp', -0.007825896143913269), ('touch', -0.02527865394949913), ('supplement', -0.03321506083011627), ('sight', -0.04718206450343132)]\n",
      "Checking word:\n",
      "MANAGEMENT:\n",
      "Length of 300 model vobal: 807\n",
      "\"Key 'management' not present in vocabulary\"\n",
      "Checking word:\n",
      "TEAM:\n",
      "Length of 300 model vobal: 807\n",
      "300 - Positive most similar to team: [('custom', 0.9901898503303528), ('new', 0.9887864589691162), ('set', 0.9882695078849792), ('partner', 0.9874029755592346), ('engag', 0.9871124029159546)]\n",
      "300 - Negative most similar to team: [('contract', 0.03121127001941204), ('gmp', -0.015087169595062733), ('sight', -0.020724261179566383), ('mac', -0.04852915555238724), ('join', -0.0491824746131897)]\n",
      "Checking word:\n",
      "BUSINESS:\n",
      "Length of 300 model vobal: 807\n",
      "\"Key 'business' not present in vocabulary\"\n",
      "Checking word:\n",
      "CUSTOMER:\n",
      "Length of 300 model vobal: 807\n"
     ]
    }
   ],
   "source": [
    "for iv, iv_cats in dfs_dict.items():\n",
    "    for (iv_cat, value), model_size in itertools.product(iv_cats['categories'].items(), model_sizes):\n",
    "        for embedding_library, ngram_number in itertools.product(embedding_libraries_list, ngrams_list):\n",
    "            print(iv_cat.upper())\n",
    "            print('+'*30)\n",
    "            value[f'w2v_model_size_{model_size}'] = defaultdict()\n",
    "            value[f'w2v_model_size_{model_size}']['w2v_vocab'], value[f'w2v_model_size_{model_size}']['w2v_model'] = build_train_word2vec(\n",
    "                value['df'], size=model_size, ngram_number=ngram_number, embedding_library=embedding_library\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iv, iv_cats in dfs_dict.items():\n",
    "    for (iv_cat, value), model_size in itertools.product(iv_cats['categories'].items(), model_sizes):\n",
    "        for embedding_library, ngram_number in itertools.product(embedding_libraries_list, ngrams_list):\n",
    "            print(iv_cat.upper())\n",
    "            print('+'*30)\n",
    "            value[f'ft_model_size_{model_size}'] = defaultdict()\n",
    "            value[f'ft_model_size_{model_size}']['ft_vocab'], value[f'ft_model_size_{model_size}']['ft_model'] = build_train_fasttext(\n",
    "                value['df'], size=model_size, ngram_number=ngram_number, embedding_library=embedding_library\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dict.keys() #iv\n",
    "dfs_dict['Gender'].keys() #iv_cat\n",
    "dfs_dict['Gender']['categories'].keys()\n",
    "dfs_dict['Gender']['categories']['Female'].keys() #iv_cat\n",
    "dfs_dict['Gender']['categories']['Female']['df'].keys() #df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iv, iv_cats in dfs_dict.items():\n",
    "    sentences_list = []\n",
    "    for iv_cat, value in iv_cats['categories'].items():\n",
    "        lst = value['df'][f'{n_gram}'].to_list()\n",
    "        sentences_list.append(' '.join([sentence for sentences in value['df'][f'{n_gram}'].to_list() for sentence in sentences if sentence]))\n",
    "        # print(value['df'][f'{n_gram}'].to_list())\n",
    "        # for df_name, df in value['df'].items():\n",
    "len(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iv, iv_cats in dfs_dict.items():\n",
    "\n",
    "    print(f'Soft Cosine Similarity for {iv}:')\n",
    "\n",
    "    dfs_dict[f'{iv}']['word_embeddings'] = defaultdict()\n",
    "\n",
    "    sentence_list = []\n",
    "\n",
    "    for iv_cat, value in iv_cats['categories'].items():\n",
    "        sentences_list.append(' '.join([sentence for sentences in value['df'][f'{n_gram}'].to_list() for sentence in sentences if sentence]))\n",
    "\n",
    "    dictionary = corpora.Dictionary([sentences for sentences in sentences_list if sentences])\n",
    "    dfs_dict[f'{iv}']['word_embeddings']['dictionary'] = dictionary\n",
    "    print(f'{iv} Dictionary:\\n{dictionary}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iv, iv_cats in dfs_dict.items():\n",
    "    sentences_list = []\n",
    "    for iv_cat, value in iv_cats['categories'].items():\n",
    "        lst = value['df'][f'{n_gram}'].to_list()\n",
    "        sentences_list.append(' '.join([sentence for sentences in value['df'][f'{n_gram}'].to_list() for sentence in sentences if sentence]))\n",
    "        # print(value['df'][f'{n_gram}'].to_list())\n",
    "        # for df_name, df in value['df'].items():\n",
    "len(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iv, iv_cats in dfs_dict.items():\n",
    "\n",
    "    print(f'Soft Cosine Similarity for {iv}:')\n",
    "\n",
    "    dfs_dict[f'{iv}']['word_embeddings'] = defaultdict()\n",
    "\n",
    "    sentence_list = []\n",
    "\n",
    "    for iv_cat, value in iv_cats['categories'].items():\n",
    "        sentences_list.append(' '.join([sentence for sentences in value['df'][f'{n_gram}'].to_list() for sentence in sentences if sentence]))\n",
    "\n",
    "    dictionary = corpora.Dictionary([sent for sentences in sentences_list for sent in sentences if len(sent) > 0])\n",
    "    dfs_dict[f'{iv}']['word_embeddings']['dictionary'] = dictionary\n",
    "    print(f'{iv} Dictionary:\\n{dictionary}')\n",
    "\n",
    "    bow_vectors = [\n",
    "    dictionary.doc2bow(sent) for sentences in sentences_list for sent in sentences\n",
    "    ]\n",
    "    dfs_dict[f'{iv}']['word_embeddings']['bow_vectors'] = bow_vectors\n",
    "    print(f'{iv} TOP 5 BOW:\\n{bow_vectors[0][:5]}')\n",
    "\n",
    "    tfidf_vectors = TfidfModel(corpus=bow_vectors, dictionary=dictionary)\n",
    "    dfs_dict[f'{iv}']['word_embeddings']['tfidf_vectors'] = tfidf_vectors\n",
    "\n",
    "    # Soft Cosine Similarities\n",
    "    for embed_model_name, embed_func_list in embedding_models_dict.items():\n",
    "        build_train_func, embed_func, model_loader, model = embed_func_list\n",
    "\n",
    "        similarity_matrix = SparseTermSimilarityMatrix(WordEmbeddingSimilarityIndex(model), dictionary)\n",
    "        dfs_dict[f'{iv}']['word_embeddings'][f'{embed_model_name}_similarity_matrix'] = similarity_matrix\n",
    "\n",
    "        softcos_index = SoftCosineSimilarity(bow_vectors, similarity_matrix, num_best=10)\n",
    "        dfs_dict[f'{iv}']['word_embeddings'][f'{embed_model_name}_docsim_index'] = softcos_index\n",
    "\n",
    "        scm1 = similarity_matrix.inner_product(\n",
    "            bow_vectors[0],\n",
    "            bow_vectors[1],\n",
    "            normalized=(True, True)\n",
    "        )\n",
    "        scm2 = similarity_matrix.inner_product(\n",
    "            bow_vectors[0],\n",
    "            bow_vectors[2],\n",
    "            normalized=(True, True)\n",
    "        )\n",
    "        scm3 = similarity_matrix.inner_product(\n",
    "            bow_vectors[1],\n",
    "            bow_vectors[2],\n",
    "            normalized=(True, True)\n",
    "        )\n",
    "        print(f'{model_name} Soft Cosine Similarity between:\\n{list(iv_cats[\"categories\"].keys())[0]} Dominated Sectors <-> {list(iv_cats[\"categories\"].keys())[1]} Dominated Sectors: {scm1:.2f}\\n{list(iv_cats[\"categories\"].keys())[0]} Dominated Sectors <-> {list(iv_cats[\"categories\"].keys())[2]} Dominated Sectors: {scm2:.2f}\\n{list(iv_cats[\"categories\"].keys())[1]} Dominated Sectors <-> {list(iv_cats[\"categories\"].keys())[2]} Dominated Sectors: {scm3:.2f}')\n",
    "\n",
    "        df_sims = create_soft_cossim_matrix(bow_vectors, list(iv_cats[\"categories\"].keys()), similarity_matrix)\n",
    "        dfs_dict[f'{iv}']['word_embeddings'][f'{model_name}_df_sims'] = df_sims\n",
    "        print(f'DF of cosine similarities:\\n{df_sims.head()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary([sent for sentences in sentences_list for sent in sentences if len(sent) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectors = [\n",
    "    dictionary.doc2bow(sent) for sentences in sentences_list for sent in sentences\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bow_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dfs_dict[f'{iv}']['categories'][f'{list(iv_cats[\"categories\"].keys())[0]}']['df'][f'{n_gram}'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ''\n",
    "for token_list in x:\n",
    "    if token_list:\n",
    "        for token in token_list:\n",
    "            sent += ' ' + token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sent[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_all_sentences = [\n",
    "    f' {token}' for token in token_list for token_list in dfs_dict[f'{iv}']['categories'][f'{list(iv_cats[\"categories\"].keys())[0]}']['df'][f'{n_gram}'].to_list()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_list = [\n",
    "        dfs_dict[f'{iv}']['categories'][f'{list(iv_cats[\"categories\"].keys())[0]}']['df'][f'{n_gram}'].to_list(),\n",
    "        dfs_dict[f'{iv}']['categories'][f'{list(iv_cats[\"categories\"].keys())[1]}']['df'][f'{n_gram}'].to_list(),\n",
    "        dfs_dict[f'{iv}']['categories'][f'{list(iv_cats[\"categories\"].keys())[2]}']['df'][f'{n_gram}'].to_list(),\n",
    "        ]\n",
    "\n",
    "dictionary = corpora.Dictionary([sent for sentences in sentences_list for sent in sentences if len(sent) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_sample(sector, size, model, vocab):\n",
    "\n",
    "    print('\\n')\n",
    "    print(f'PCA for {sector} model {size}')\n",
    "    pca = PCA(n_components=3, random_state=random_state)\n",
    "    X = model.wv[vocab]\n",
    "    pca_clf = pca.fit_transform(X)\n",
    "    pca_components = pca.components_\n",
    "    pca_eigenvalues = pca.explained_variance_ratio_\n",
    "    pca_perc_explained_variance=np.cumsum(np.round(pca_eigenvalues, decimals=3)*100)\n",
    "    pca_tmp = pd.DataFrame(pca_clf, index=vocab, columns=['x', 'y', 'z'])\n",
    "    print(pca_tmp.head(3))\n",
    "    try:\n",
    "        pca_tmp = pca_tmp.sample(150)\n",
    "    except ValueError as e:\n",
    "        print(f'For {sector} model {size}, error: {e}')\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.scatter(pca_tmp['x'], pca_tmp['y'], pca_tmp['z'], alpha = 0.5)\n",
    "\n",
    "    for word, row in pca_tmp.iterrows():\n",
    "        x, y, z = row\n",
    "        pos = (x, y, z)\n",
    "        ax.text(x, y, z, s=word, size=8, zorder=1, color='k')\n",
    "\n",
    "    plt.title('Word2Vec map - PCA')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.figure.savefig(f'{plot_save_path}w2v_{sector}_{size}_map_PCA.{str(image_save_format)}', format=image_save_format, dpi=3000, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    return pca_clf, pca_tmp, pca_components, pca_eigenvalues, pca_perc_explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iv, iv_cats in dfs_dict.items():\n",
    "    for (iv_cat, value), model_size in itertools.product(iv_cats['categories'].items(), model_sizes):\n",
    "        # Word2Vec\n",
    "        value[f'w2v_model_size_{model_size}']['w2v_pca_clf'], value[f'w2v_model_size_{model_size}']['w2v_pca_tmp'], value[f'w2v_model_size_{model_size}']['w2v_pca_components'], value[f'w2v_model_size_{model_size}']['w2v_pca_eigenvalues'], value[f'w2v_model_size_{model_size}']['w2v_pca_perc_explained_variance'] = pca_sample(iv_cat, model_size, value[f'w2v_model_size_{model_size}']['w2v_model'], value[f'w2v_model_size_{model_size}']['w2v_vocab'])\n",
    "        # FastText\n",
    "        value[f'ft_model_size_{model_size}']['ft_pca_clf'], value[f'ft_model_size_{model_size}']['ft_pca_tmp'], value[f'ft_model_size_{model_size}']['ft_pca_components'], value[f'ft_model_size_{model_size}']['ft_pca_eigenvalues'], value[f'ft_model_size_{model_size}']['ft_pca_perc_explained_variance'] = pca_sample(iv_cat, model_size, value[f'ft_model_size_{model_size}']['ft_model'], value[f'ft_model_size_{model_size}']['ft_vocab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_sample(sector, size, model, vocab):\n",
    "\n",
    "    print(f'TSNE for {sector} model {size}')\n",
    "    tsne = TSNE(perplexity=40, n_components=3, random_state=random_state, init='pca')\n",
    "    X = model.wv[vocab]\n",
    "    tsne_clf = tsne.fit_transform(X)\n",
    "    tsne_tmp = pd.DataFrame(tsne_clf, index=vocab, columns=['x', 'y', 'z'])\n",
    "    tsne_tmp['input'] = 0\n",
    "    tsne_tmp['input'].iloc[0:1] = 1\n",
    "    print(tsne_tmp.head(3))\n",
    "    try:\n",
    "        tsne_tmp = tsne_tmp.sample(150)\n",
    "    except ValueError as e:\n",
    "        print(f'For {sector} model {size}, error: {e}')\n",
    "\n",
    "    # Plotting TSNE\n",
    "    # 3D Plot\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(tsne_tmp[tsne_tmp[\"input\"]==0]['x'],\n",
    "            tsne_tmp[tsne_tmp[\"input\"]==0]['y'],\n",
    "            tsne_tmp[tsne_tmp[\"input\"]==0]['z'],\n",
    "            c='black', alpha = 0.5)\n",
    "    ax.scatter(tsne_tmp[tsne_tmp[\"input\"]==1]['x'],\n",
    "            tsne_tmp[tsne_tmp[\"input\"]==1]['y'],\n",
    "            tsne_tmp[tsne_tmp[\"input\"]==1]['z'],\n",
    "            c='red', alpha = 0.5)\n",
    "    ax.set(xlabel=None, ylabel=None, zlabel=None, xticklabels=[],\n",
    "        yticklabels=[], zticklabels=[])\n",
    "\n",
    "    for word, row in tsne_tmp[[\"x\",\"y\",\"z\"]].iterrows():\n",
    "        x, y, z = row\n",
    "        pos = (x, y, z)\n",
    "        ax.text(x, y, z, s=word, size=8, zorder=1, color='k')\n",
    "\n",
    "    plt.title('Word2Vec map - TSNE')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.figure.savefig(\n",
    "        f'{plot_save_path}w2v_{sector}_{size}_map_TSNE.{image_save_format}', format=image_save_format, dpi=3000, bbox_inches='tight'\n",
    "    )\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in tsne_clf:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i])\n",
    "        plt.annotate(\n",
    "            labels[i],\n",
    "            xy=(x[i], y[i]),\n",
    "            xytext=(5, 2),\n",
    "            textcoords=\"offset points\",\n",
    "            ha=\"right\",\n",
    "            va=\"bottom\",\n",
    "        )\n",
    "    plt.title('Word2Vec plot - TSNE')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(\n",
    "        f'{plot_save_path}w2v_{sector}_{size}_plot_TSNE.{image_save_format}', format=image_save_format, dpi=3000, bbox_inches='tight'\n",
    "    )\n",
    "\n",
    "    return tsne_clf, tsne_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iv, iv_cats in dfs_dict.items():\n",
    "    for (iv_cat, value), model_size in itertools.product(iv_cats['categories'].items(), model_sizes):\n",
    "        value[f'w2v_model_size_{model_size}']['tsne_clf'], value[f'w2v_model_size_{model_size}']['tsne_tmp'] = tsne_sample(iv_cat, model_size, value[f'w2v_model_size_{model_size}']['w2v_model'], value[f'w2v_model_size_{model_size}']['w2v_vocab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(sector, size, model, words):\n",
    "    # trained word2vec model dimention\n",
    "    dim_size = model.wv.vectors.shape[1]\n",
    "\n",
    "    arrays = np.empty((0, dim_size), dtype='f')\n",
    "    for word in words:\n",
    "        try:\n",
    "            print(f'For {sector} model {size}, analyzing word: {word.title()}')\n",
    "            word_labels = [word]\n",
    "            color_list  = ['red']\n",
    "\n",
    "            # adds the vector of the query word\n",
    "            arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n",
    "\n",
    "            # gets list of most similar words\n",
    "            sim_words = model.wv.most_similar(word, topn=10)\n",
    "\n",
    "            # adds the vector for each of the closest words to the array\n",
    "            for wrd_score in sim_words:\n",
    "                wrd_vector = model.wv.__getitem__([wrd_score[0]])\n",
    "                word_labels.append(wrd_score[0])\n",
    "                color_list.append('green')\n",
    "                arrays = np.append(arrays, wrd_vector, axis=0)\n",
    "\n",
    "            #---------------------- Apply PCA and tsne to reduce dimention --------------\n",
    "\n",
    "            # fit 2d PCA model to the similar word vectors\n",
    "            model_pca = PCA(n_components = 10).fit_transform(arrays)\n",
    "\n",
    "            # Finds 2d coordinates t-SNE\n",
    "            np.set_printoptions(suppress=True)\n",
    "            Y = TSNE(n_components=2, random_state=random_state, perplexity=15).fit_transform(model_pca)\n",
    "\n",
    "            try:\n",
    "                # Sets everything up to plot\n",
    "                df_plot = pd.DataFrame({'x': list(Y[:, 0]), 'y': list(Y[:, 1]), 'words_name': word_labels, 'words_color': color_list})\n",
    "\n",
    "\n",
    "                #------------------------- tsne plot Python -----------------------------------\n",
    "\n",
    "                # plot dots with color and position\n",
    "                plot_dot = sns.regplot(data=df_plot,\n",
    "                                x=\"x\",\n",
    "                                y=\"y\",\n",
    "                                fit_reg=False,\n",
    "                                marker=\"o\",\n",
    "                                scatter_kws={'s': 40,\n",
    "                                            'facecolors': df_plot['words_color']\n",
    "                                            }\n",
    "                                )\n",
    "\n",
    "                # Adds annotations with color one by one with a loop\n",
    "                for line in range(df_plot.shape[0]):\n",
    "                    plot_dot.text(df_plot[\"x\"][line],\n",
    "                            df_plot['y'][line],\n",
    "                            '  ' + df_plot[\"words_name\"][line].title(),\n",
    "                            horizontalalignment='left',\n",
    "                            verticalalignment='bottom', size='medium',\n",
    "                            color=df_plot['words_color'][line],\n",
    "                            weight='normal'\n",
    "                            ).set_size(15)\n",
    "\n",
    "\n",
    "                plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
    "                plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
    "\n",
    "                plt.title(f'{sector} model {size} t-SNE visualization for word {word.title()}')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            except ValueError as e:\n",
    "                print(f'{sector} model {size} error for {word}: {e}')\n",
    "        except KeyError as e:\n",
    "            print(f'{sector} model {size} error for {word}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iv, iv_cats in dfs_dict.items():\n",
    "    for (iv_cat, value), model_size in itertools.product(iv_cats['categories'].items(), model_sizes):\n",
    "        tsne_plot(iv_cat, model_size, value[f'w2v_model_size_{model_size}']['w2v_model'], value['frequencies']['abs_word_freq_df'].index.values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "for iv, iv_cats in dfs_dict.items():\n",
    "    for iv_cat, value in iv_cats['categories'].items():\n",
    "        print(f'{iv_cat} model wordcloud:')\n",
    "        Cloud = WordCloud(colormap='viridis', background_color=\"white\", max_words=50, random_state=random_state).generate_from_frequencies(value['frequencies']['abs_word_freq'])\n",
    "\n",
    "        plt.imshow(Cloud)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        plt.savefig(f'{plot_save_path}w2v_{iv_cat}_wordcloud.{image_save_format}', format=image_save_format, dpi=3000, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['save_enabled'] is True:\n",
    "    with open(validate_path(f'{args[\"embeddings_save_path\"]}dfs_dict.json'), 'w') as f:\n",
    "        for key in dfs_dict.keys():\n",
    "            f.write(f\"{key}, {dfs_dict[key]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize document using TF-IDF\n",
    "tfidf = TfidfVectorizer(lowercase=True,\n",
    "                        stop_words='english',\n",
    "                        ngram_range = (1,1),\n",
    "                        tokenizer = tokenizer.tokenize)\n",
    "\n",
    "# Fit and Transform the documents\n",
    "train_data = tfidf.fit_transform(documents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of topics or components\n",
    "num_components=10\n",
    "\n",
    "# Create SVD object\n",
    "lsa = TruncatedSVD(n_components=num_components, n_iter=100, random_state=42)\n",
    "\n",
    "# Fit SVD model on data\n",
    "lsa.fit_transform(train_data)\n",
    "\n",
    "# Get Singular values and Components \n",
    "Sigma = lsa.singular_values_ \n",
    "V_transpose = lsa.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topics with their terms\n",
    "terms = tfidf.get_feature_names()\n",
    "\n",
    "for index, component in enumerate(lsa.components_):\n",
    "    zipped = zip(terms, component)\n",
    "    top_terms_key=sorted(zipped, key = lambda t: t[1], reverse=True)[:5]\n",
    "    top_terms_list=list(dict(top_terms_key).keys())\n",
    "    print(\"Topic \"+str(index)+\": \",top_terms_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e64b55c31e662d3b8ca165241f15a246a93354fe580fc7a1249b2f351dbc5a06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
