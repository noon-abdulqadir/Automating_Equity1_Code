Using MPS
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using MPS
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using MPS
0it [00:00, ?it/s]0it [00:00, ?it/s]
Dataframe loaded with shape: (5978, 58)
########################################
Starting!
########################################
Searching for existing estimators in directory:
/Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Supervised Results/
  0%|          | 0/49 [00:00<?, ?it/s]100%|██████████| 49/49 [00:00<00:00, 429062.41it/s]
  0%|          | 0/2 [00:00<?, ?it/s]--------------------
============================== TRAINING DATASET OF LENGTH 5978 ON WARMTH ==============================
--------------------
Vectorizers to be used (3):
['CountVectorizer', 'TfidfVectorizer', 'FeatureUnion']
Total number of vectorizer parameters = 6
Selectors to be used (1):
['SelectKBest']
Total number of selector parameters = 2
Resamplers to be used (1):
['SMOTETomek']
Total number of resamplers parameters = 2
classifiers to be used (5):
['DummyClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'XGBClassifier']
Total number of classifiers parameters = 18
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_train_data from /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_train_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_val_data from /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_val_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4023,)
----------
Training set example:
Analysis (technical, quantitative and qualitative) of multiple sources of information (commercial Intelligence, OSINT, community, **ISACs sharing) to provide timely, actionable intelligence and reporting.
~~~~~~~~~~
Testing set shape: (537,)
----------
Testing set example:
Experience with agile development practices, particularly owning and running specific agile events such as backlog refinement and sprint reviews Knowledge of multi channel supply chain processes, preferable in a retail context.
~~~~~~~~~~
Validation set shape: (805,)
----------
Validation set example:
Duties and responsibilities: Handling incoming phone calls and emails from the website users;Acting as an intermediary between the customers and accommodations;Managing reservations, special requests, and complaints and finding solutions to website users inquiries.
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.40 (0 = 0.70, 1 = 1.74)
----------
Validation data class weights:
Ratio = 0.30 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!

  0%|          | 0/15 [00:00<?, ?it/s][A--------------------
Already trained Warmth - CountVectorizer + DummyClassifier
--------------------
--------------------
Already trained Warmth - CountVectorizer + KNeighborsClassifier
--------------------
--------------------
Already trained Warmth - CountVectorizer + DecisionTreeClassifier
--------------------
--------------------
Already trained Warmth - CountVectorizer + RandomForestClassifier
--------------------
--------------------
Already trained Warmth - CountVectorizer + XGBClassifier
--------------------
--------------------
Already trained Warmth - TfidfVectorizer + DummyClassifier
--------------------
--------------------
Already trained Warmth - TfidfVectorizer + KNeighborsClassifier
--------------------
--------------------
Already trained Warmth - TfidfVectorizer + DecisionTreeClassifier
--------------------
--------------------
Already trained Warmth - TfidfVectorizer + RandomForestClassifier
--------------------
--------------------
Already trained Warmth - TfidfVectorizer + XGBClassifier
--------------------
--------------------
Already trained Warmth - FeatureUnion + DummyClassifier
--------------------
--------------------
Already trained Warmth - FeatureUnion + KNeighborsClassifier
--------------------
--------------------
Already trained Warmth - FeatureUnion + DecisionTreeClassifier
--------------------
--------------------
Already trained Warmth - FeatureUnion + RandomForestClassifier
--------------------
--------------------
Already trained Warmth - FeatureUnion + XGBClassifier
--------------------
100%|██████████| 15/15 [00:00<00:00, 67650.06it/s]
--------------------
============================== TRAINING DATASET OF LENGTH 5978 ON COMPETENCE ==============================
--------------------
Vectorizers to be used (3):
['CountVectorizer', 'TfidfVectorizer', 'FeatureUnion']
Total number of vectorizer parameters = 6
Selectors to be used (1):
['SelectKBest']
Total number of selector parameters = 2
Resamplers to be used (1):
['SMOTETomek']
Total number of resamplers parameters = 2
classifiers to be used (5):
['DummyClassifier', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier', 'XGBClassifier']
Total number of classifiers parameters = 18
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Competence ==========
++++++++++++++++++++++++++++++
Loading df_test_data from /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_test_data - Competence - (Save_protocol=5).pkl
Loading df_train_data from /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_train_data - Competence - (Save_protocol=5).pkl
Loading df_val_data from /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_val_data - Competence - (Save_protocol=5).pkl
Done loading Xy from previous for Competence!
Done splitting data into training and testing sets.
====================
Training set shape: (3997,)
----------
Training set example:
The job includes statistical programming and handling/processing of big data sets, for which you will need to have extensive experience in coding.
~~~~~~~~~~
Testing set shape: (534,)
----------
Testing set example:
1-3 or more years advisory/consulting/industry project experience in a high calibre and international environment, ideally working with industry, energy, manufacturing, or agricultural clients
~~~~~~~~~~
Validation set shape: (799,)
----------
Validation set example:
Developing your team and motivating them to achieve their goals.
~~~~~~~~~~
Training data class weights:
Ratio = 0.83 (0 = 0.92, 1 = 1.10)
----------
Testing data class weights:
Ratio = 0.83 (0 = 0.91, 1 = 1.10)
----------
Validation data class weights:
Ratio = 0.91 (0 = 0.95, 1 = 1.05)
====================
Done loading Xy from previous for Competence!

  0%|          | 0/15 [00:00<?, ?it/s][A--------------------
Already trained Competence - CountVectorizer + DummyClassifier
--------------------
--------------------
Already trained Competence - CountVectorizer + KNeighborsClassifier
--------------------
--------------------
Already trained Competence - CountVectorizer + DecisionTreeClassifier
--------------------
--------------------
Already trained Competence - CountVectorizer + RandomForestClassifier
--------------------
--------------------
Already trained Competence - CountVectorizer + XGBClassifier
--------------------
--------------------
Already trained Competence - TfidfVectorizer + DummyClassifier
--------------------
--------------------
Already trained Competence - TfidfVectorizer + KNeighborsClassifier
--------------------
--------------------
Already trained Competence - TfidfVectorizer + DecisionTreeClassifier
--------------------
--------------------
Already trained Competence - TfidfVectorizer + RandomForestClassifier
--------------------
--------------------
Already trained Competence - TfidfVectorizer + XGBClassifier
--------------------
--------------------
Already trained Competence - FeatureUnion + DummyClassifier
--------------------
--------------------
Already trained Competence - FeatureUnion + KNeighborsClassifier
--------------------
--------------------
Already trained Competence - FeatureUnion + DecisionTreeClassifier
--------------------
--------------------
Already trained Competence - FeatureUnion + RandomForestClassifier
--------------------
--------------------
Already trained Competence - FeatureUnion + XGBClassifier
--------------------
100%|██████████| 15/15 [00:00<00:00, 68534.38it/s]
100%|██████████| 2/2 [00:00<00:00, 92.19it/s]
╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/2. Trainning and     │
│ Classification/1. supervised_estimators_train_nonlinear.py:820 in <module>                       │
│                                                                                                  │
│   817 │   │   )                                                                                  │
│   818                                                                                            │
│   819 # Assert that all classifiers were used                                                    │
│ ❱ 820 assert_all_classifiers_used(classifiers_pipe=classifiers_pipe)                             │
│   821 print('#'*40)                                                                              │
│   822 print('DONE!')                                                                             │
│   823 print('#'*40)                                                                              │
│                                                                                                  │
│ /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/2. Trainning and     │
│ Classification/1. supervised_estimators_train_nonlinear.py:580 in assert_all_classifiers_used    │
│                                                                                                  │
│   577 │   │   classifier_name = estimator_path.split(f'{results_save_path}{method} ')[1].split   │
│   578 │   │   used_classifiers.append(classifier_name)                                           │
│   579 │                                                                                          │
│ ❱ 580 │   assert set(list(classifiers_pipe.keys())) == set(used_classifiers), f'Not all classi   │
│   581 │   print('All classifiers were used!')                                                    │
│   582                                                                                            │
│   583                                                                                            │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
AssertionError: Not all classifiers were used!
Avaliable Classifiers:
{'DecisionTreeClassifier', 'KNeighborsClassifier', 'XGBClassifier', 'DummyClassifier', 'RandomForestClassifier'}
Used Classifiers:
{'DecisionTreeClassifier', 'GradientBoostingClassifier', 'KNeighborsClassifier', 'AdaBoostClassifier', 'PassiveAggressiveClassifier', 'StackingClassifier', 'XGBClassifier', 'DummyClassifier', 'LinearSVC',
'LogisticRegression', 'Perceptron', 'RandomForestClassifier', 'BaggingClassifier', 'MLPClassifier', 'SGDClassifier', 'VotingClassifier'}
Leftout Classifiers:
{'PassiveAggressiveClassifier', 'Perceptron', 'SGDClassifier', 'VotingClassifier', 'GradientBoostingClassifier', 'AdaBoostClassifier', 'StackingClassifier', 'LinearSVC', 'LogisticRegression', 
'BaggingClassifier', 'MLPClassifier'}
