Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
########################################
Starting!
########################################
Searching for existing estimators in directory:
/home/nfatahelra/Study1_Code/data/classification models/Supervised Results/
0it [00:00, ?it/s]0it [00:00, ?it/s]
  0%|          | 0/2 [00:00<?, ?it/s]--------------------
============================== TRAINING DATASET OF LENGTH 5978 ON WARMTH ==============================
--------------------
Vectorizers to be used (3):
['CountVectorizer', 'TfidfVectorizer', 'FeatureUnion']
Total number of vectorizer parameters = 22
Selectors to be used (1):
['SelectKBest']
Total number of selector parameters = 2
Resamplers to be used (1):
['SMOTETomek']
Total number of resamplers parameters = 2
Classifers to be used (20):
['DummyClassifier', 'MultinomialNB', 'KNeighborsClassifier', 'LogisticRegression', 'LinearSVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'AdaBoostClassifier', 'XGBClassifier', 'MLPClassifier', 'MLPRegressor', 'PassiveAggressiveClassifier', 'Perceptron', 'BernoulliNB', 'GaussianNB', 'SGDClassifier', 'GradientBoostingClassifier', 'VotingClassifier', 'StackingClassifier']
Total number of classifers parameters = 83
====================
Splitting data into training and testing:
Ratios: train_size = 0.75, test size = 0.1
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================

  0%|          | 0/60 [00:00<?, ?it/s][A====================
Saving Xy df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Done saving Xy!
['df_train_data', 'df_test_data', 'df_val_data']
====================
--------------------
============================== Using GridSearchCV ==============================
--------------------
GridSearchCV with:
Pipe:
Pipeline(steps=[('CountVectorizer', CountVectorizer()),
                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),
                ('DummyClassifier', DummyClassifier())])
Params:
{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x7f622389d240>, <function chi2 at 0x7f622389d360>, <function mutual_info_classif at 0x7f622389fb50>, <function f_regression at 0x7f622389d480>, <function mutual_info_regression at 0x7f622389fac0>], 'SelectKBest__k': ['all'], 'DummyClassifier__strategy': ['stratified', 'most_frequent', 'prior', 'uniform'], 'DummyClassifier__random_state': [42]}
++++++++++++++++++++++++++++++
Fitting GridSearchCV
n_iterations: 4
n_required_iterations: 7
n_possible_iterations: 4
min_resources_: 120
max_resources_: 5380
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 1000
n_resources: 120
Fitting 30 folds for each of 1000 candidates, totalling 30000 fits

  2%|‚ñè         | 1/60 [01:02<1:01:31, 62.57s/it][A
  3%|‚ñé         | 2/60 [02:30<1:14:57, 77.55s/it][A
  5%|‚ñå         | 3/60 [04:30<1:32:03, 96.91s/it][A----------
iter: 1
n_candidates: 334
n_resources: 360
Fitting 30 folds for each of 334 candidates, totalling 10020 fits
----------
iter: 2
n_candidates: 112
n_resources: 1080
Fitting 30 folds for each of 112 candidates, totalling 3360 fits
----------
iter: 3
n_candidates: 38
n_resources: 3240
Fitting 30 folds for each of 38 candidates, totalling 1140 fits
====================
Saving Grid Search at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving SearchCV at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_cv_results at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving Estimator at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/
Done saving Xy, CV data, and estimator!
['Grid Search', 'SearchCV', 'df_cv_results', 'df_train_data', 'df_test_data', 'df_val_data', 'Estimator']
====================
====================
Saving Xy df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Done saving Xy!
['df_train_data', 'df_test_data', 'df_val_data']
====================
--------------------
============================== Using GridSearchCV ==============================
--------------------
GridSearchCV with:
Pipe:
Pipeline(steps=[('CountVectorizer', CountVectorizer()),
                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),
                ('MultinomialNB', MultinomialNB())])
Params:
{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x7f622389d240>, <function chi2 at 0x7f622389d360>, <function mutual_info_classif at 0x7f622389fb50>, <function f_regression at 0x7f622389d480>, <function mutual_info_regression at 0x7f622389fac0>], 'SelectKBest__k': ['all'], 'MultinomialNB__fit_prior': [True, False], 'MultinomialNB__alpha': [0.1, 0.2, 0.3]}
++++++++++++++++++++++++++++++
Fitting GridSearchCV
n_iterations: 4
n_required_iterations: 7
n_possible_iterations: 4
min_resources_: 120
max_resources_: 5380
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 1500
n_resources: 120
Fitting 30 folds for each of 1500 candidates, totalling 45000 fits
----------
iter: 1
n_candidates: 500
n_resources: 360
Fitting 30 folds for each of 500 candidates, totalling 15000 fits
----------
iter: 2
n_candidates: 167
n_resources: 1080
Fitting 30 folds for each of 167 candidates, totalling 5010 fits
----------
iter: 3
n_candidates: 56
n_resources: 3240
Fitting 30 folds for each of 56 candidates, totalling 1680 fits
====================
Saving Grid Search at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving SearchCV at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_cv_results at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving Estimator at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/
Done saving Xy, CV data, and estimator!
['Grid Search', 'SearchCV', 'df_cv_results', 'df_train_data', 'df_test_data', 'df_val_data', 'Estimator']
====================
====================
Saving Xy df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Done saving Xy!
['df_train_data', 'df_test_data', 'df_val_data']
====================
--------------------
============================== Using GridSearchCV ==============================
--------------------
GridSearchCV with:
Pipe:
Pipeline(steps=[('CountVectorizer', CountVectorizer()),
                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),
                ('KNeighborsClassifier', KNeighborsClassifier())])
Params:
{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x7f622389d240>, <function chi2 at 0x7f622389d360>, <function mutual_info_classif at 0x7f622389fb50>, <function f_regression at 0x7f622389d480>, <function mutual_info_regression at 0x7f622389fac0>], 'SelectKBest__k': ['all'], 'KNeighborsClassifier__weights': ['uniform', 'distance'], 'KNeighborsClassifier__n_neighbors': [2, 5, 15], 'KNeighborsClassifier__algorithm': ['auto']}
++++++++++++++++++++++++++++++
Fitting GridSearchCV
n_iterations: 4
n_required_iterations: 7
n_possible_iterations: 4
min_resources_: 120
max_resources_: 5380
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 1500
n_resources: 120
Fitting 30 folds for each of 1500 candidates, totalling 45000 fits
----------
iter: 1
n_candidates: 500
n_resources: 360
Fitting 30 folds for each of 500 candidates, totalling 15000 fits
----------
iter: 2
n_candidates: 167
n_resources: 1080
Fitting 30 folds for each of 167 candidates, totalling 5010 fits
----------
iter: 3
n_candidates: 56
n_resources: 3240
Fitting 30 folds for each of 56 candidates, totalling 1680 fits
====================
Saving Grid Search at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving SearchCV at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_cv_results at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Search+Xy/
Saving Estimator at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/
Done saving Xy, CV data, and estimator!
['Grid Search', 'SearchCV', 'df_cv_results', 'df_train_data', 'df_test_data', 'df_val_data', 'Estimator']
====================
====================
Saving Xy df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 44.
  warnings.warn(

  7%|‚ñã         | 4/60 [09:24<2:43:12, 174.86s/it][A/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
########################################
Starting!
########################################
Searching for existing estimators in directory:
/home/nfatahelra/Study1_Code/data/classification models/Supervised Results/
  0%|          | 0/56 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:00<00:00, 228039.83it/s]
  0%|          | 0/2 [00:00<?, ?it/s]--------------------
============================== TRAINING DATASET OF LENGTH 5978 ON WARMTH ==============================
--------------------
Vectorizers to be used (3):
['CountVectorizer', 'TfidfVectorizer', 'FeatureUnion']
Total number of vectorizer parameters = 22
Selectors to be used (1):
['SelectKBest']
Total number of selector parameters = 2
Resamplers to be used (1):
['SMOTETomek']
Total number of resamplers parameters = 2
Classifers to be used (20):
['DummyClassifier', 'MultinomialNB', 'KNeighborsClassifier', 'LogisticRegression', 'LinearSVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'AdaBoostClassifier', 'XGBClassifier', 'MLPClassifier', 'MLPRegressor', 'PassiveAggressiveClassifier', 'Perceptron', 'BernoulliNB', 'GaussianNB', 'SGDClassifier', 'GradientBoostingClassifier', 'VotingClassifier', 'StackingClassifier']
Total number of classifers parameters = 84
====================
Splitting data into training and testing:
Ratios: train_size = 0.75, test size = 0.1
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================

  0%|          | 0/60 [00:00<?, ?it/s][A--------------------
Already trained Warmth - CountVectorizer + DummyClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + MultinomialNB
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + KNeighborsClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + LogisticRegression
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
====================
Saving Xy df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Done saving Xy!
['df_train_data', 'df_test_data', 'df_val_data']
====================
--------------------
============================== Using GridSearchCV ==============================
--------------------
GridSearchCV with:
Pipe:
Pipeline(steps=[('CountVectorizer', CountVectorizer()),
                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),
                ('LinearSVC', LinearSVC())])
Params:
{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x7fbd961ed240>, <function chi2 at 0x7fbd961ed360>, <function mutual_info_classif at 0x7fbd961efb50>, <function f_regression at 0x7fbd961ed480>, <function mutual_info_regression at 0x7fbd961efac0>], 'SelectKBest__k': ['all'], 'LinearSVC__loss': ['hinge', 'squared_hinge'], 'LinearSVC__random_state': [42], 'LinearSVC__fit_intercept': [True, False], 'LinearSVC__class_weight': ['balanced'], 'LinearSVC__C': [0.01, 0.5, 1, 5, 10, 15, 20, 30, 50, 100], 'LinearSVC__max_iter': [200000, 400000, 500000, 600000, 700000, 800000, 900000, 1000000]}
++++++++++++++++++++++++++++++
Fitting GridSearchCV
n_iterations: 4
n_required_iterations: 11
n_possible_iterations: 4
min_resources_: 120
max_resources_: 5380
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 80000
n_resources: 120
Fitting 30 folds for each of 80000 candidates, totalling 2400000 fits
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
########################################
Starting!
########################################
Searching for existing estimators in directory:
/home/nfatahelra/Study1_Code/data/classification models/Supervised Results/
  0%|          | 0/56 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:00<00:00, 220752.84it/s]
  0%|          | 0/2 [00:00<?, ?it/s]--------------------
============================== TRAINING DATASET OF LENGTH 5978 ON WARMTH ==============================
--------------------
Vectorizers to be used (3):
['CountVectorizer', 'TfidfVectorizer', 'FeatureUnion']
Total number of vectorizer parameters = 22
Selectors to be used (1):
['SelectKBest']
Total number of selector parameters = 2
Resamplers to be used (1):
['SMOTETomek']
Total number of resamplers parameters = 2
Classifers to be used (20):
['DummyClassifier', 'MultinomialNB', 'KNeighborsClassifier', 'LogisticRegression', 'LinearSVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'AdaBoostClassifier', 'XGBClassifier', 'MLPClassifier', 'MLPRegressor', 'PassiveAggressiveClassifier', 'Perceptron', 'BernoulliNB', 'GaussianNB', 'SGDClassifier', 'GradientBoostingClassifier', 'VotingClassifier', 'StackingClassifier']
Total number of classifers parameters = 85
====================
Splitting data into training and testing:
Ratios: train_size = 0.75, test size = 0.1
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================

  0%|          | 0/60 [00:00<?, ?it/s][A--------------------
Already trained Warmth - CountVectorizer + DummyClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + MultinomialNB
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + KNeighborsClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + LogisticRegression
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
====================
Saving Xy df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Done saving Xy!
['df_train_data', 'df_test_data', 'df_val_data']
====================
--------------------
============================== Using GridSearchCV ==============================
--------------------
GridSearchCV with:
Pipe:
Pipeline(steps=[('CountVectorizer', CountVectorizer()),
                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),
                ('LinearSVC', LinearSVC())])
Params:
{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x7fe0c02f1240>, <function chi2 at 0x7fe0c02f1360>, <function mutual_info_classif at 0x7fe0c02f3b50>, <function f_regression at 0x7fe0c02f1480>, <function mutual_info_regression at 0x7fe0c02f3ac0>], 'SelectKBest__k': ['all'], 'LinearSVC__loss': ['hinge', 'squared_hinge'], 'LinearSVC__random_state': [42], 'LinearSVC__fit_intercept': [True, False], 'LinearSVC__class_weight': ['balanced'], 'LinearSVC__C': [0.01, 0.5, 1, 5, 10, 15, 20, 30, 50, 100], 'LinearSVC__max_iter': [400000, 500000, 600000, 700000, 800000, 900000, 1000000], 'LinearSVC__dual': [False]}
++++++++++++++++++++++++++++++
Fitting GridSearchCV
n_iterations: 4
n_required_iterations: 11
n_possible_iterations: 4
min_resources_: 120
max_resources_: 5380
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 70000
n_resources: 120
Fitting 30 folds for each of 70000 candidates, totalling 2100000 fits
  7%|‚ñã         | 4/60 [00:02<00:30,  1.84it/s]
  0%|          | 0/2 [00:02<?, ?it/s]
joblib.externals.loky.process_executor._RemoteTraceback:
"""
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 123, in __call__
    return self.function(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 297, in fit
    self._final_estimator.fit(Xt, yt, **fit_params_last_step)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_classes.py", line 274, in fit
    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py", line 1223, in _fit_liblinear
    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/svm/_base.py", line 1062, in _get_liblinear_solver_type
    raise ValueError(
ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nfatahelra/Study1_Code/2. Trainning and Classification/1. supervised_estimators_train.py", line 759, in <module>
    searchcv = grid_search.fit(np.concatenate((X_train, X_val), axis=0), np.concatenate((y_train, y_val), axis=0))
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py", line 273, in fit
    super().fit(X, y=y, groups=groups, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 874, in fit
    self._run_search(evaluate_candidates)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py", line 378, in _run_search
    results = evaluate_candidates(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 821, in evaluate_candidates
    out = parallel(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 63, in __call__
    return super().__call__(iterable_with_config)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 1098, in __call__
    self.retrieve()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/concurrent/futures/_base.py", line 458, in result
    return self.__get_result()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False
The library  'pingouin' is not installed. Installing now.
Traceback (most recent call last):
  File "/home/nfatahelra/Study1_Code/2. Trainning and Classification/1. supervised_estimators_train.py", line 29, in <module>
    from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8
  File "/home/nfatahelra/Study1_Code/setup_module/imports.py", line 503, in <module>
    stop_words = set(stopwords.words('english'))
NameError: name 'stopwords' is not defined
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
########################################
Starting!
########################################
Searching for existing estimators in directory:
/home/nfatahelra/Study1_Code/data/classification models/Supervised Results/
  0%|                                                                                                           | 0/56 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:00<00:00, 174502.99it/s]
  0%|                                                                                                            | 0/2 [00:00<?, ?it/s]--------------------
============================== TRAINING DATASET OF LENGTH 5978 ON WARMTH ==============================
--------------------
Vectorizers to be used (3):
['CountVectorizer', 'TfidfVectorizer', 'FeatureUnion']
Total number of vectorizer parameters = 22
Selectors to be used (1):
['SelectKBest']
Total number of selector parameters = 2
Resamplers to be used (1):
['SMOTETomek']
Total number of resamplers parameters = 2
Classifers to be used (20):
['DummyClassifier', 'MultinomialNB', 'KNeighborsClassifier', 'LogisticRegression', 'LinearSVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'AdaBoostClassifier', 'XGBClassifier', 'MLPClassifier', 'MLPRegressor', 'PassiveAggressiveClassifier', 'Perceptron', 'BernoulliNB', 'GaussianNB', 'SGDClassifier', 'GradientBoostingClassifier', 'VotingClassifier', 'StackingClassifier']
Total number of classifers parameters = 85
====================
Splitting data into training and testing:
Ratios: train_size = 0.75, test size = 0.1
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================

  0%|                                                                                                           | 0/60 [00:00<?, ?it/s][A--------------------
Already trained Warmth - CountVectorizer + DummyClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + MultinomialNB
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + KNeighborsClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + LogisticRegression
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
====================
Saving Xy df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Done saving Xy!
['df_train_data', 'df_test_data', 'df_val_data']
====================
--------------------
============================== Using GridSearchCV ==============================
--------------------
GridSearchCV with:
Pipe:
Pipeline(steps=[('CountVectorizer', CountVectorizer()),
                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),
                ('LinearSVC', LinearSVC())])
Params:
{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x7ff39d49f880>, <function chi2 at 0x7ff39d49f9a0>, <function mutual_info_classif at 0x7ff39d4c6200>, <function f_regression at 0x7ff39d49fac0>, <function mutual_info_regression at 0x7ff39d4c6170>], 'SelectKBest__k': ['all'], 'LinearSVC__loss': ['squared_hinge'], 'LinearSVC__random_state': [42], 'LinearSVC__fit_intercept': [True, False], 'LinearSVC__class_weight': ['balanced'], 'LinearSVC__C': [0.01, 0.5, 1, 5, 10, 15, 20, 30, 50, 100], 'LinearSVC__max_iter': [400000, 500000, 600000, 700000, 800000, 900000, 1000000], 'LinearSVC__dual': [False]}
++++++++++++++++++++++++++++++
Fitting GridSearchCV
n_iterations: 4
n_required_iterations: 10
n_possible_iterations: 4
min_resources_: 120
max_resources_: 5380
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 35000
n_resources: 120
Fitting 30 folds for each of 35000 candidates, totalling 1050000 fits
----------
iter: 1
n_candidates: 11667
n_resources: 360
Fitting 30 folds for each of 11667 candidates, totalling 350010 fits
----------
iter: 2
n_candidates: 3889
n_resources: 1080
Fitting 30 folds for each of 3889 candidates, totalling 116670 fits
----------
iter: 3
n_candidates: 1297
n_resources: 3240
Fitting 30 folds for each of 1297 candidates, totalling 38910 fits
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
########################################
Starting!
########################################
Searching for existing estimators in directory:
/home/nfatahelra/Study1_Code/data/classification models/Supervised Results/
  0%|                                                                                                                  | 0/56 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:00<00:00, 192367.75it/s]
  0%|                                                                                                                   | 0/2 [00:00<?, ?it/s]--------------------
============================== TRAINING DATASET OF LENGTH 5978 ON WARMTH ==============================
--------------------
Vectorizers to be used (3):
['CountVectorizer', 'TfidfVectorizer', 'FeatureUnion']
Total number of vectorizer parameters = 22
Selectors to be used (1):
['SelectKBest']
Total number of selector parameters = 2
Resamplers to be used (1):
['SMOTETomek']
Total number of resamplers parameters = 2
Classifers to be used (20):
['DummyClassifier', 'MultinomialNB', 'KNeighborsClassifier', 'LogisticRegression', 'LinearSVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'AdaBoostClassifier', 'XGBClassifier', 'MLPClassifier', 'MLPRegressor', 'PassiveAggressiveClassifier', 'Perceptron', 'BernoulliNB', 'GaussianNB', 'SGDClassifier', 'GradientBoostingClassifier', 'VotingClassifier', 'StackingClassifier']
Total number of classifers parameters = 85
====================
Splitting data into training and testing:
Ratios: train_size = 0.75, test size = 0.1
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================

  0%|                                                                                                                  | 0/60 [00:00<?, ?it/s][A--------------------
Already trained Warmth - CountVectorizer + DummyClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + MultinomialNB
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + KNeighborsClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + LogisticRegression
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
====================
Saving Xy df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Done saving Xy!
['df_train_data', 'df_test_data', 'df_val_data']
====================
--------------------
============================== Using GridSearchCV ==============================
--------------------
GridSearchCV with:
Pipe:
Pipeline(steps=[('CountVectorizer', CountVectorizer()),
                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),
                ('LinearSVC', LinearSVC())])
Params:
{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x7efeb6063880>, <function chi2 at 0x7efeb60639a0>, <function mutual_info_classif at 0x7efeb608e200>, <function f_regression at 0x7efeb6063ac0>, <function mutual_info_regression at 0x7efeb608e170>], 'SelectKBest__k': ['all'], 'LinearSVC__loss': ['squared_hinge'], 'LinearSVC__random_state': [42], 'LinearSVC__fit_intercept': [True, False], 'LinearSVC__class_weight': ['balanced'], 'LinearSVC__C': [0.01, 0.5, 1, 5, 10, 15, 20, 30, 50, 100], 'LinearSVC__max_iter': [400000, 500000, 600000, 700000, 800000, 900000, 1000000], 'LinearSVC__dual': [False]}
++++++++++++++++++++++++++++++
Fitting GridSearchCV
n_iterations: 4
n_required_iterations: 10
n_possible_iterations: 4
min_resources_: 120
max_resources_: 5380
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 35000
n_resources: 120
Fitting 30 folds for each of 35000 candidates, totalling 1050000 fits
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
########################################
Starting!
########################################
Searching for existing estimators in directory:
/home/nfatahelra/Study1_Code/data/classification models/Supervised Results/
  0%|                                                                                                                  | 0/56 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:00<00:00, 152223.61it/s]
  0%|                                                                                                                   | 0/2 [00:00<?, ?it/s]--------------------
============================== TRAINING DATASET OF LENGTH 5978 ON WARMTH ==============================
--------------------
Vectorizers to be used (3):
['CountVectorizer', 'TfidfVectorizer', 'FeatureUnion']
Total number of vectorizer parameters = 22
Selectors to be used (1):
['SelectKBest']
Total number of selector parameters = 2
Resamplers to be used (1):
['SMOTETomek']
Total number of resamplers parameters = 2
Classifers to be used (20):
['DummyClassifier', 'MultinomialNB', 'KNeighborsClassifier', 'LogisticRegression', 'LinearSVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'AdaBoostClassifier', 'XGBClassifier', 'MLPClassifier', 'MLPRegressor', 'PassiveAggressiveClassifier', 'Perceptron', 'BernoulliNB', 'GaussianNB', 'SGDClassifier', 'GradientBoostingClassifier', 'VotingClassifier', 'StackingClassifier']
Total number of classifers parameters = 85
====================
Splitting data into training and testing:
Ratios: train_size = 0.75, test size = 0.1
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================

  0%|                                                                                                                  | 0/60 [00:00<?, ?it/s][A--------------------
Already trained Warmth - CountVectorizer + DummyClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + MultinomialNB
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + KNeighborsClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + LogisticRegression
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
====================
Saving Xy df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Done saving Xy!
['df_train_data', 'df_test_data', 'df_val_data']
====================
--------------------
============================== Using GridSearchCV ==============================
--------------------
GridSearchCV with:
Pipe:
Pipeline(steps=[('CountVectorizer', CountVectorizer()),
                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),
                ('LinearSVC', LinearSVC())])
Params:
{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x7f9ce0f33880>, <function chi2 at 0x7f9ce0f339a0>, <function mutual_info_classif at 0x7f9ce0f56200>, <function f_regression at 0x7f9ce0f33ac0>, <function mutual_info_regression at 0x7f9ce0f56170>], 'SelectKBest__k': ['all'], 'LinearSVC__loss': ['squared_hinge'], 'LinearSVC__random_state': [42], 'LinearSVC__fit_intercept': [True, False], 'LinearSVC__class_weight': ['balanced'], 'LinearSVC__C': [0.01, 0.5, 1, 5, 10, 15, 20, 30, 50, 100], 'LinearSVC__max_iter': [400000, 500000, 600000, 700000, 800000, 900000, 1000000], 'LinearSVC__dual': [False]}
++++++++++++++++++++++++++++++
Fitting GridSearchCV
n_iterations: 4
n_required_iterations: 10
n_possible_iterations: 4
min_resources_: 120
max_resources_: 5380
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 35000
n_resources: 120
Fitting 30 folds for each of 35000 candidates, totalling 1050000 fits
Process LokyProcess-33:
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 391, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

Process LokyProcess-30:
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 391, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 123, in __call__
    return self.function(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 293, in fit
    Xt, yt = self._fit(X, y, **fit_params_steps)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 250, in _fit
    X, y, fitted_transformer = fit_resample_one_cached(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 422, in _fit_resample_one
    X_res, y_res = sampler.fit_resample(X, y, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/base.py", line 203, in fit_resample
    return super().fit_resample(X, y)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/base.py", line 88, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/combine/_smote_tomek.py", line 158, in _fit_resample
    return self.tomek_.fit_resample(X_res, y_res)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/base.py", line 203, in fit_resample
    return super().fit_resample(X, y)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/base.py", line 88, in fit_resample
    output = self._fit_resample(X, y)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/under_sampling/_prototype_selection/_tomek_links.py", line 149, in _fit_resample
    nns = nn.kneighbors(X, return_distance=False)[:, 1]
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 861, in kneighbors
    chunked_results = list(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/metrics/pairwise.py", line 1867, in pairwise_distances_chunked
    D_chunk = pairwise_distances(X_chunk, Y, metric=metric, n_jobs=n_jobs, **kwds)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/metrics/pairwise.py", line 2039, in pairwise_distances
    return _parallel_pairwise(X, Y, func, n_jobs, **kwds)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/metrics/pairwise.py", line 1579, in _parallel_pairwise
    return func(X, Y, **kwds)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/metrics/pairwise.py", line 328, in euclidean_distances
    return _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/metrics/pairwise.py", line 369, in _euclidean_distances
    distances = -2 * safe_sparse_dot(X, Y.T, dense_output=True)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/extmath.py", line 189, in safe_sparse_dot
    ret = a @ b
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/scipy/sparse/_base.py", line 630, in __matmul__
    return self._mul_dispatch(other)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/scipy/sparse/_base.py", line 541, in _mul_dispatch
    return self._mul_sparse_matrix(other)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/scipy/sparse/_compressed.py", line 533, in _mul_sparse_matrix
    fn(M, N, np.asarray(self.indptr, dtype=idx_dtype),
KeyboardInterrupt

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 625, in __call__
    raise WorkerInterrupt() from e
joblib.my_exceptions.WorkerInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 431, in _process_worker
    result_queue.put(_ResultItem(call_item.work_id, exception=exc))
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/queues.py", line 191, in put
    with self._wlock:
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/synchronize.py", line 112, in __enter__
    return self._semlock.acquire()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 123, in __call__
    return self.function(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 293, in fit
    Xt, yt = self._fit(X, y, **fit_params_steps)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 240, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/pipeline.py", line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/base.py", line 881, in fit_transform
    return self.fit(X, y, **fit_params).transform(X)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py", line 472, in fit
    score_func_ret = self.score_func(X, y)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 388, in mutual_info_regression
    return _estimate_mi(X, y, discrete_features, False, n_neighbors, copy, random_state)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 304, in _estimate_mi
    mi = [
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 305, in <listcomp>
    _compute_mi(x, y, discrete_feature, discrete_target, n_neighbors)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 161, in _compute_mi
    return _compute_mi_cd(y, x, n_neighbors)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 125, in _compute_mi_cd
    r = nn.kneighbors()[0]
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 815, in kneighbors
    n_jobs = effective_n_jobs(self.n_jobs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 436, in effective_n_jobs
    return backend.effective_n_jobs(n_jobs=n_jobs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 227, in effective_n_jobs
    def effective_n_jobs(self, n_jobs):
KeyboardInterrupt

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 625, in __call__
    raise WorkerInterrupt() from e
joblib.my_exceptions.WorkerInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 431, in _process_worker
    result_queue.put(_ResultItem(call_item.work_id, exception=exc))
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/queues.py", line 191, in put
    with self._wlock:
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/synchronize.py", line 112, in __enter__
    return self._semlock.acquire()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 391, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

Process LokyProcess-17:
Process LokyProcess-21:
Process LokyProcess-5:
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 391, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 391, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

Process LokyProcess-2:
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 123, in __call__
    return self.function(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 711, in _fit_and_score
    train_scores = _score(estimator, X_train, y_train, scorer, error_score)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 767, in _score
    scores = scorer(estimator, X_test, y_test)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 234, in __call__
    return self._score(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 276, in _score
    y_pred = method_caller(estimator, "predict", X)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    return getattr(estimator, method)(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/pipeline.py", line 480, in predict
    Xt = transform.transform(Xt)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py", line 1433, in transform
    _, X = self._count_vocab(raw_documents, fixed_vocab=True)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py", line 1275, in _count_vocab
    for feature in analyze(doc):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py", line 118, in _analyze
    doc = ngrams(doc)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py", line 271, in _word_ngrams
    tokens_append(space_join(original_tokens[i : i + n]))
KeyboardInterrupt

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 625, in __call__
    raise WorkerInterrupt() from e
joblib.my_exceptions.WorkerInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 431, in _process_worker
    result_queue.put(_ResultItem(call_item.work_id, exception=exc))
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/queues.py", line 191, in put
    with self._wlock:
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/synchronize.py", line 112, in __enter__
    return self._semlock.acquire()
KeyboardInterrupt
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 123, in __call__
    return self.function(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 293, in fit
    Xt, yt = self._fit(X, y, **fit_params_steps)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 240, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/pipeline.py", line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py", line 1388, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_extraction/text.py", line 1292, in _count_vocab
    vocabulary = dict(vocabulary)
KeyboardInterrupt

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 625, in __call__
    raise WorkerInterrupt() from e
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 123, in __call__
    return self.function(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
joblib.my_exceptions.WorkerInterrupt
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 293, in fit
    Xt, yt = self._fit(X, y, **fit_params_steps)

During handling of the above exception, another exception occurred:

  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 240, in _fit
    X, fitted_transformer = fit_transform_one_cached(
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/pipeline.py", line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/base.py", line 881, in fit_transform
    return self.fit(X, y, **fit_params).transform(X)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py", line 472, in fit
    score_func_ret = self.score_func(X, y)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 388, in mutual_info_regression
    return _estimate_mi(X, y, discrete_features, False, n_neighbors, copy, random_state)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 304, in _estimate_mi
    mi = [
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 431, in _process_worker
    result_queue.put(_ResultItem(call_item.work_id, exception=exc))
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 305, in <listcomp>
    _compute_mi(x, y, discrete_feature, discrete_target, n_neighbors)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/queues.py", line 191, in put
    with self._wlock:
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 152, in _compute_mi
    def _compute_mi(x, y, x_discrete, y_discrete, n_neighbors=3):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/synchronize.py", line 112, in __enter__
    return self._semlock.acquire()
  7%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                                                   | 4/60 [00:11<02:46,  2.98s/it]KeyboardInterrupt
KeyboardInterrupt

The above exception was the direct cause of the following exception:

Traceback (most recent call last):

  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 625, in __call__
    raise WorkerInterrupt() from e
joblib.my_exceptions.WorkerInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 431, in _process_worker
    result_queue.put(_ResultItem(call_item.work_id, exception=exc))
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/queues.py", line 191, in put
    with self._wlock:
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/synchronize.py", line 112, in __enter__
    return self._semlock.acquire()
KeyboardInterrupt
  0%|                                                                                                                   | 0/2 [00:12<?, ?it/s]
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 123, in __call__
    return self.function(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 293, in fit
    Xt, yt = self._fit(X, y, **fit_params_steps)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 240, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/pipeline.py", line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/base.py", line 881, in fit_transform
    return self.fit(X, y, **fit_params).transform(X)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py", line 472, in fit
    score_func_ret = self.score_func(X, y)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 388, in mutual_info_regression
    return _estimate_mi(X, y, discrete_features, False, n_neighbors, copy, random_state)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 304, in _estimate_mi
    mi = [
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 305, in <listcomp>
    _compute_mi(x, y, discrete_feature, discrete_target, n_neighbors)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 161, in _compute_mi
    return _compute_mi_cd(y, x, n_neighbors)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 125, in _compute_mi_cd
    r = nn.kneighbors()[0]
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 879, in kneighbors
    chunked_results = Parallel(n_jobs, prefer="threads")(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 688, in __init__
    self._ready_batches = queue.Queue()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/queue.py", line 42, in __init__
    self.mutex = threading.Lock()
KeyboardInterrupt

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 625, in __call__
    raise WorkerInterrupt() from e
joblib.my_exceptions.WorkerInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 431, in _process_worker
    result_queue.put(_ResultItem(call_item.work_id, exception=exc))
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/queues.py", line 192, in put
    self._writer.send_bytes(obj)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 975, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 567, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/concurrent/futures/_base.py", line 453, in result
    self._condition.wait(timeout)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/threading.py", line 320, in wait
    waiter.acquire()
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nfatahelra/Study1_Code/2. Trainning and Classification/1. supervised_estimators_train.py", line 757, in <module>
    searchcv = grid_search.fit(np.concatenate((X_train, X_val), axis=0), np.concatenate((y_train, y_val), axis=0))
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py", line 273, in fit
    super().fit(X, y=y, groups=groups, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 874, in fit
    self._run_search(evaluate_candidates)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_search_successive_halving.py", line 378, in _run_search
    results = evaluate_candidates(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py", line 821, in evaluate_candidates
    out = parallel(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 63, in __call__
    return super().__call__(iterable_with_config)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 1098, in __call__
    self.retrieve()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 997, in retrieve
    backend.abort_everything(ensure_ready=ensure_ready)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 586, in abort_everything
    self._workers.terminate(kill_workers=True)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/executor.py", line 74, in terminate
    self.shutdown(kill_workers=kill_workers)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 1199, in shutdown
    executor_manager_thread.join()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
Process LokyProcess-3:
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 391, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

Exception ignored in atexit callback: <function _exit_function at 0x7f9d86cb6ef0>
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 391, in _process_worker
    call_item = call_queue.get(block=True, timeout=timeout)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/queues.py", line 108, in get
    if not self._rlock.acquire(block, timeout):
KeyboardInterrupt

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/util.py", line 357, in _exit_function
Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 620, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in __call__
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/parallel.py", line 288, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py", line 123, in __call__
    return self.function(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 293, in fit
    Xt, yt = self._fit(X, y, **fit_params_steps)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/imblearn/pipeline.py", line 240, in _fit
    X, fitted_transformer = fit_transform_one_cached(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/memory.py", line 349, in __call__
    return self.func(*args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/pipeline.py", line 893, in _fit_transform_one
    res = transformer.fit_transform(X, y, **fit_params)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/utils/_set_output.py", line 140, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/base.py", line 881, in fit_transform
    return self.fit(X, y, **fit_params).transform(X)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py", line 472, in fit
    score_func_ret = self.score_func(X, y)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 388, in mutual_info_regression
    return _estimate_mi(X, y, discrete_features, False, n_neighbors, copy, random_state)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 304, in _estimate_mi
    mi = [
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 305, in <listcomp>
    _compute_mi(x, y, discrete_feature, discrete_target, n_neighbors)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 161, in _compute_mi
    return _compute_mi_cd(y, x, n_neighbors)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py", line 125, in _compute_mi_cd
    r = nn.kneighbors()[0]
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/neighbors/_base.py", line 824, in kneighbors
    results = ArgKmin.compute(
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py", line 277, in compute
    return ArgKmin64.compute(
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 76, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 341, in sklearn.metrics._pairwise_distances_reduction._argkmin.EuclideanArgKmin64.__init__
  File "sklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx", line 110, in sklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.__init__
  File "sklearn/metrics/_pairwise_distances_reduction/_base.pyx", line 145, in sklearn.metrics._pairwise_distances_reduction._base.BaseDistancesReduction64.__init__
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/sklearn/_config.py", line 30, in get_config
    def get_config():
KeyboardInterrupt

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 428, in _process_worker
    r = call_item()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 275, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py", line 625, in __call__
    raise WorkerInterrupt() from e
joblib.my_exceptions.WorkerInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py", line 431, in _process_worker
    result_queue.put(_ResultItem(call_item.work_id, exception=exc))
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/queues.py", line 191, in put
    with self._wlock:
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/synchronize.py", line 112, in __enter__
    return self._semlock.acquire()
KeyboardInterrupt
    p.join()
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py", line 77, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/home/nfatahelra/.conda/envs/study1_3.10/lib/python3.10/site-packages/joblib/externals/loky/backend/popen_loky_posix.py", line 56, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt:
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using CUDA
0it [00:00, ?it/s]0it [00:00, ?it/s]
########################################
Starting!
########################################
Searching for existing estimators in directory:
/home/nfatahelra/Study1_Code/data/classification models/Supervised Results/
  0%|                                                                                                           | 0/56 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 56/56 [00:00<00:00, 217683.99it/s]
  0%|                                                                                                            | 0/2 [00:00<?, ?it/s]--------------------
============================== TRAINING DATASET OF LENGTH 5978 ON WARMTH ==============================
--------------------
Vectorizers to be used (3):
['CountVectorizer', 'TfidfVectorizer', 'FeatureUnion']
Total number of vectorizer parameters = 22
Selectors to be used (1):
['SelectKBest']
Total number of selector parameters = 2
Resamplers to be used (1):
['SMOTETomek']
Total number of resamplers parameters = 2
Classifers to be used (20):
['DummyClassifier', 'MultinomialNB', 'KNeighborsClassifier', 'LogisticRegression', 'LinearSVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'AdaBoostClassifier', 'XGBClassifier', 'MLPClassifier', 'MLPRegressor', 'PassiveAggressiveClassifier', 'Perceptron', 'BernoulliNB', 'GaussianNB', 'SGDClassifier', 'GradientBoostingClassifier', 'VotingClassifier', 'StackingClassifier']
Total number of classifers parameters = 85
====================
Splitting data into training and testing:
Ratios: train_size = 0.75, test size = 0.1
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================

  0%|                                                                                                           | 0/60 [00:00<?, ?it/s][A--------------------
Already trained Warmth - CountVectorizer + DummyClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + MultinomialNB
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + KNeighborsClassifier
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
--------------------
Already trained Warmth - CountVectorizer + LogisticRegression
--------------------
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_val_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_train_data from /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4483,)
----------
Training set example:
Factors)
~~~~~~~~~~
Testing set shape: (598,)
----------
Testing set example:
You‚Äôll be part of an international consulting firm where people are lead by its values and inspired by our purpose;
~~~~~~~~~~
Validation set shape: (897,)
----------
Validation set example:
Also my client is HQ‚Äôd in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.34 (0 = 0.67, 1 = 1.97)
----------
Validation data class weights:
Ratio = 0.31 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!
--------------------
====================
Saving Xy df_train_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_train_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_test_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_test_data - Warmth - (Save_protocol=5).pkl
Saving Xy df_val_data at /home/nfatahelra/Study1_Code/data/classification models/Supervised Results/Supervised df_val_data - Warmth - (Save_protocol=5).pkl
Done saving Xy!
['df_train_data', 'df_test_data', 'df_val_data']
====================
--------------------
============================== Using GridSearchCV ==============================
--------------------
GridSearchCV with:
Pipe:
Pipeline(steps=[('CountVectorizer', CountVectorizer()),
                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),
                ('LinearSVC', LinearSVC())])
Params:
{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x7fc84fa43880>, <function chi2 at 0x7fc84fa439a0>, <function mutual_info_classif at 0x7fc84fa6e200>, <function f_regression at 0x7fc84fa43ac0>, <function mutual_info_regression at 0x7fc84fa6e170>], 'SelectKBest__k': ['all'], 'LinearSVC__loss': ['squared_hinge'], 'LinearSVC__random_state': [42], 'LinearSVC__fit_intercept': [True, False], 'LinearSVC__class_weight': ['balanced'], 'LinearSVC__C': [0.01, 0.5, 1, 5, 10, 15, 20, 30, 50, 100], 'LinearSVC__max_iter': [400000, 500000, 600000, 700000, 800000, 900000, 1000000], 'LinearSVC__dual': [False]}
++++++++++++++++++++++++++++++
Fitting GridSearchCV
n_iterations: 4
n_required_iterations: 10
n_possible_iterations: 4
min_resources_: 120
max_resources_: 5380
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 35000
n_resources: 120
Fitting 30 folds for each of 35000 candidates, totalling 1050000 fits
----------
iter: 1
n_candidates: 11667
n_resources: 360
Fitting 30 folds for each of 11667 candidates, totalling 350010 fits
----------
iter: 2
n_candidates: 3889
n_resources: 1080
Fitting 30 folds for each of 3889 candidates, totalling 116670 fits
----------
iter: 3
n_candidates: 1297
n_resources: 3240
Fitting 30 folds for each of 1297 candidates, totalling 38910 fits
----------
iter: 1
n_candidates: 11667
n_resources: 360
Fitting 30 folds for each of 11667 candidates, totalling 350010 fits
----------
iter: 2
n_candidates: 3889
n_resources: 1080
Fitting 30 folds for each of 3889 candidates, totalling 116670 fits
----------
iter: 3
n_candidates: 1297
n_resources: 3240
Fitting 30 folds for each of 1297 candidates, totalling 38910 fits
