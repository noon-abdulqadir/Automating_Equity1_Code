{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d4c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "import sys  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "from pathlib import Path  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "sys.path.append(code_dir)\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abbb866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c894ceb405f4d4cb744188dfedb2c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015963edce074ec7956356684604a182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from setup_module.imports import *  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
    "method = 'Transformers'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65134b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957f82c66f664372887cc9be9916753e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5391ab18873e4c9cb804484846522aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set random seed\n",
    "random_state = 42\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Variables\n",
    "results_save_path = f'{models_save_path}{method} Results/'\n",
    "done_xy_save_path = f'{results_save_path}Xy/'\n",
    "t = time.time()\n",
    "n_jobs = -1\n",
    "n_splits = 10\n",
    "n_repeats = 3\n",
    "random_state = 42\n",
    "refit = True\n",
    "class_weight = 'balanced'\n",
    "cv = RepeatedStratifiedKFold(\n",
    "    n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
    ")\n",
    "scoring = 'recall'\n",
    "scores = [\n",
    "    'recall', 'accuracy', 'f1', 'roc_auc',\n",
    "    'explained_variance', 'matthews_corrcoef'\n",
    "]\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score),\n",
    "}\n",
    "analysis_columns = ['Warmth', 'Competence']\n",
    "text_col = 'Job Description spacy_sentencized'\n",
    "metrics_dict = {\n",
    "    'Mean Cross Validation Train Score': np.nan,\n",
    "    f'Mean Cross Validation Train - {scoring.title()}': np.nan,\n",
    "    f'Mean Explained Train Variance - {scoring.title()}': np.nan,\n",
    "    'Mean Cross Validation Test Score': np.nan,\n",
    "    f'Mean Cross Validation Test - {scoring.title()}': np.nan,\n",
    "    f'Mean Explained Test Variance - {scoring.title()}': np.nan,\n",
    "    'Explained Variance': np.nan,\n",
    "    'Accuracy': np.nan,\n",
    "    'Balanced Accuracy': np.nan,\n",
    "    'Precision': np.nan,\n",
    "    'Recall': np.nan,\n",
    "    'F1-score': np.nan,\n",
    "    'Matthews Correlation Coefficient': np.nan,\n",
    "    'Fowlkes–Mallows Index': np.nan,\n",
    "    'R2 Score': np.nan,\n",
    "    'ROC': np.nan,\n",
    "    'AUC': np.nan,\n",
    "    f'{scoring.title()} Best Threshold': np.nan,\n",
    "    f'{scoring.title()} Best Score': np.nan,\n",
    "    'Log Loss/Cross Entropy': np.nan,\n",
    "    'Cohen’s Kappa': np.nan,\n",
    "    'Geometric Mean': np.nan,\n",
    "    'Classification Report': np.nan,\n",
    "    'Imbalanced Classification Report': np.nan,\n",
    "    'Confusion Matrix': np.nan,\n",
    "    'Normalized Confusion Matrix': np.nan\n",
    "}\n",
    "\n",
    "# Transformer variables\n",
    "max_length = 512\n",
    "returned_tensor = 'pt'\n",
    "cpu_counts = torch.multiprocessing.cpu_count()\n",
    "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available(\n",
    ") else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device_name = str(device.type)\n",
    "print(f'Using {device_name.upper()}')\n",
    "# Set random seed\n",
    "random_state = 42\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "cores = multiprocessing.cpu_count()\n",
    "accelerator = Accelerator()\n",
    "# BERT\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    bert_model_name, strip_accents=True\n",
    ")\n",
    "bert_model = BertForSequenceClassification.from_pretrained(\n",
    "    bert_model_name\n",
    ").to(device)\n",
    "optimizer = torch.optim.AdamW(bert_model.parameters(), lr=3e-5)\n",
    "\n",
    "# Plotting variables\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "tqdm.tqdm.pandas(desc='progress-bar')\n",
    "tqdm_auto.tqdm.pandas(desc='progress-bar')\n",
    "# tqdm.notebook.tqdm().pandas(desc='progress-bar')\n",
    "tqdm_auto.notebook_tqdm().pandas(desc='progress-bar')\n",
    "# pbar = progressbar.ProgressBar(maxval=10)\n",
    "mpl.style.use(f'{code_dir}/setup_module/apa.mplstyle-main/apa.mplstyle')\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "font = {'family': 'arial', 'weight': 'normal', 'size': 10}\n",
    "mpl.rc('font', **font)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "plt.set_cmap('Blues')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55afc383",
   "metadata": {},
   "source": [
    "# Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c0e7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weights_print_Xy(\n",
    "    X_train, y_train, bert_train_dataset,\n",
    "    X_test, y_test, bert_test_dataset,\n",
    "    X_val, y_val, bert_val_dataset,\n",
    "):\n",
    "    # Check for consistent length\n",
    "    check_consistent_length(X_train, y_train, bert_train_dataset)\n",
    "    check_consistent_length(X_test, y_test, bert_test_dataset)\n",
    "    check_consistent_length(X_val, y_val, bert_val_dataset)\n",
    "\n",
    "    # Check encodings\n",
    "    assert all(y_train == bert_train_dataset.encoded), 'y_train and bert_train_dataset encoded are not the same'\n",
    "    assert all(y_test == bert_test_dataset.encoded), 'y_test and bert_test_dataset encoded are not the same'\n",
    "\n",
    "    # Get train class weights\n",
    "    train_class_weights = compute_class_weight(class_weight=class_weight, classes=np.unique(y_train), y=y_train)\n",
    "    train_class_weights_ratio = train_class_weights[0]/train_class_weights[1]\n",
    "    train_class_weights_dict = dict(zip(np.unique(y_train), train_class_weights))\n",
    "\n",
    "    # Get train class weights\n",
    "    test_class_weights = compute_class_weight(class_weight=class_weight, classes=np.unique(y_train), y=y_test)\n",
    "    test_class_weights_ratio = test_class_weights[0]/test_class_weights[1]\n",
    "    test_class_weights_dict = dict(zip(np.unique(y_test), test_class_weights))\n",
    "\n",
    "    print('Done encoding training, testing, and validation sets.')\n",
    "    print('='*20)\n",
    "    print(f'Training set shape: {y_train.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Training set example:\\n{X_train[0]}')\n",
    "    print('-'*10)\n",
    "    print(f'Training set BERT encodings example:\\n{\" \".join(bert_train_dataset.encodings[0].tokens[:30])}')\n",
    "    print('-'*10)\n",
    "    print(f'Training set BERT encoded example: {set(bert_train_dataset.encoded)}')\n",
    "    print('~'*10)\n",
    "    print(f'Testing set shape: {y_test.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Testing set example:\\n{X_test[0]}')\n",
    "    print('-'*10)\n",
    "    print(f'Testing set BERT encodings example:\\n{\" \".join(bert_test_dataset.encodings[0].tokens[:30])}')\n",
    "    print('-'*10)\n",
    "    print(f'Testing set BERT encoded example: {set(bert_test_dataset.encoded)}')\n",
    "    print('~'*10)\n",
    "    print(f'Validation set shape: {y_val.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Validation set example:\\n{X_val[0]}')\n",
    "    print('-'*10)\n",
    "    print(\n",
    "        f'Validation set BERT encodings example:\\n{\" \".join(bert_val_dataset.encodings[0].tokens[:30])}')\n",
    "    print('-'*10)\n",
    "    print(f'Validation labels after BERT encoding: {set(bert_val_dataset.encoded)}')\n",
    "    print('~'*10)\n",
    "    print(f'Training data class weights:\\nRatio = {train_class_weights_ratio:.2f} (0 = {train_class_weights[0]:.2f}, 1 = {train_class_weights[1]:.2f})')\n",
    "    print('-'*10)\n",
    "    print(f'Testing data class weights:\\nRatio = {test_class_weights_ratio:.2f} (0 = {test_class_weights[0]:.2f}, 1 = {test_class_weights[1]:.2f})')\n",
    "    print('='*20)\n",
    "\n",
    "    return (\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395dffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, col, analysis_columns=analysis_columns, text_col=text_col):\n",
    "\n",
    "    train_ratio = 0.75\n",
    "    test_ratio = 0.10\n",
    "    validation_ratio = 0.15\n",
    "    test_split = test_size = 1 - train_ratio\n",
    "    validation_split = test_ratio / (test_ratio + validation_ratio)\n",
    "\n",
    "    # Split\n",
    "    print('='*20)\n",
    "    print('Splitting data into training, testing, and validation sets:')\n",
    "    print(\n",
    "        f'Ratios: train_size = {train_ratio}, test size = {test_ratio}, validation size = {validation_ratio}')\n",
    "\n",
    "    df = df.dropna(subset=analysis_columns, how='any')\n",
    "    df = df.loc[df[text_col].str.len() >= 5]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    train, test = train_test_split(\n",
    "        df, train_size=1-test_split, test_size=test_split, random_state=random_state\n",
    "    )\n",
    "\n",
    "    val, test = train_test_split(\n",
    "        test, test_size=validation_split, random_state=random_state\n",
    "    )\n",
    "\n",
    "    X_train = np.array(list(train[text_col].astype('str').values))\n",
    "    y_train = column_or_1d(train[col].astype('int64').values.tolist(), warn=True)\n",
    "\n",
    "    X_test = np.array(list(test[text_col].astype('str').values))\n",
    "    y_test = column_or_1d(test[col].astype('int64').values.tolist(), warn=True)\n",
    "\n",
    "    X_val = np.array(list(val[text_col].astype('str').values))\n",
    "    y_val = column_or_1d(val[col].astype('int64').values.tolist(), warn=True)\n",
    "\n",
    "    print('Done splitting data into training, testing, and validation sets.')\n",
    "\n",
    "    # Get encodings\n",
    "    (\n",
    "        X_train, X_train_bert_encodings, y_train, y_train_bert_encoded, bert_train_dataset,\n",
    "        X_test, X_test_bert_encodings, y_test, y_test_bert_encoded, bert_test_dataset,\n",
    "        X_val, X_val_bert_encodings, y_val, y_val_bert_encoded, bert_val_dataset,\n",
    "        bert_label2id, bert_id2label,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict\n",
    "    ) = encode_data(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        X_val, y_val,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        train, X_train, X_train_bert_encodings, y_train, y_train_bert_encoded, bert_train_dataset,\n",
    "        test, X_test, X_test_bert_encodings, y_test, y_test_bert_encoded, bert_test_dataset,\n",
    "        val, X_val, X_val_bert_encodings, y_val, y_val_bert_encoded, bert_val_dataset,\n",
    "        bert_label2id, bert_id2label,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f07a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, encoded):\n",
    "        self.encodings = encodings\n",
    "        self.encoded = encoded\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.encoded[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f3840ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    X_val, y_val,\n",
    "):\n",
    "\n",
    "    print('='*20)\n",
    "    print(f'Encoding training, testing, and validation sets with {bert_tokenizer.__class__.__name__}.from_pretrained using {bert_tokenizer.name_or_path}.')\n",
    "\n",
    "    bert_label2id = {label: id_ for id_, label in enumerate(set(y_train))}\n",
    "    bert_id2label = {id_: label for label, id_ in bert_label2id.items()}\n",
    "\n",
    "    X_train_bert_encodings = bert_tokenizer(\n",
    "        X_train.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
    "    ).to(device)\n",
    "    y_train_bert_encoded = [bert_label2id[y] for y in y_train]\n",
    "    bert_train_dataset = ToDataset(X_train_bert_encodings, y_train_bert_encoded)\n",
    "\n",
    "    X_test_bert_encodings = bert_tokenizer(\n",
    "        X_test.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
    "    ).to(device)\n",
    "    y_test_bert_encoded = [bert_label2id[y] for y in y_test]\n",
    "    bert_test_dataset = ToDataset(X_test_bert_encodings, y_test_bert_encoded)\n",
    "\n",
    "    X_val_bert_encodings = bert_tokenizer(\n",
    "        X_val.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
    "    ).to(device)\n",
    "    y_val_bert_encoded = [bert_label2id[y] for y in y_val]\n",
    "    bert_val_dataset = ToDataset(X_val_bert_encodings, y_val_bert_encoded)\n",
    "\n",
    "    (\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict\n",
    "    ) = class_weights_print_Xy(\n",
    "        X_train, y_train, bert_train_dataset,\n",
    "        X_test, y_test, bert_test_dataset,\n",
    "        X_val, y_val, bert_val_dataset,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        X_train, X_train_bert_encodings, y_train, y_train_bert_encoded, bert_train_dataset,\n",
    "        X_test, X_test_bert_encodings, y_test, y_test_bert_encoded, bert_test_dataset,\n",
    "        X_val, X_val_bert_encodings, y_val, y_val_bert_encoded, bert_val_dataset,\n",
    "        bert_label2id, bert_id2label,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ddcc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Xy(\n",
    "    col, results_save_path=results_save_path, method=method, done_xy_save_path=done_xy_save_path, protocol=None, path_suffix=None, data_dict=None,\n",
    "):\n",
    "    if protocol is None:\n",
    "        protocol = pickle.HIGHEST_PROTOCOL\n",
    "    if data_dict is None:\n",
    "        data_dict = {}\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {col} - (Save_protocol={protocol}).pkl'\n",
    "\n",
    "    print(f'Loading Xy from previous for {col}...')\n",
    "    # Read all dfs into\n",
    "    for file_path in glob.glob(f'{results_save_path}*{path_suffix}'):\n",
    "        file_name = file_path.split(f'{results_save_path}{method} ')[-1].split(path_suffix)[0]\n",
    "        print(f'Loading {file_name} from {file_path}')\n",
    "        if path_suffix in file_path and 'df_' in file_name:\n",
    "            data_dict[file_name] = pd.read_pickle(file_path)\n",
    "\n",
    "    # Train data\n",
    "    df_train_data = data_dict['df_train_data']\n",
    "    X_train = df_train_data['X_train'].values\n",
    "    y_train = df_train_data['y_train'].values\n",
    "    # Test data\n",
    "    df_test_data = data_dict['df_test_data']\n",
    "    X_test = df_test_data['X_test'].values\n",
    "    y_test = df_test_data['y_test'].values\n",
    "    # Val data\n",
    "    df_val_data = data_dict['df_val_data']\n",
    "    X_val = df_val_data['X_val'].values\n",
    "    y_val = df_val_data['y_val'].values\n",
    "\n",
    "    # Get encodings\n",
    "    (\n",
    "        X_train, X_train_bert_encodings, y_train, y_train_bert_encoded, bert_train_dataset,\n",
    "        X_test, X_test_bert_encodings, y_test, y_test_bert_encoded, bert_test_dataset,\n",
    "        X_val, X_val_bert_encodings, y_val, y_val_bert_encoded, bert_val_dataset,\n",
    "        bert_label2id, bert_id2label,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict\n",
    "    ) = encode_data(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        X_val, y_val,\n",
    "    )\n",
    "\n",
    "    print(f'Done loading Xy from previous for {col}!')\n",
    "\n",
    "    return (\n",
    "        X_train, X_train_bert_encodings, y_train, y_train_bert_encoded, bert_train_dataset,\n",
    "        X_test, X_test_bert_encodings, y_test, y_test_bert_encoded, bert_test_dataset,\n",
    "        X_val, X_val_bert_encodings, y_val, y_val_bert_encoded, bert_val_dataset,\n",
    "        bert_label2id, bert_id2label,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights, test_class_weights_ratio, test_class_weights_dict\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7c888f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_with_y_pred(\n",
    "    y_labels, y_pred,\n",
    "    pos_label=None, labels=None, zero_division=None, alpha=None\n",
    "):\n",
    "    if pos_label is None:\n",
    "        pos_label = 1\n",
    "    if labels is None:\n",
    "        labels = np.unique(y_pred)\n",
    "    if zero_division is None:\n",
    "        zero_division = 0\n",
    "    if alpha is None:\n",
    "        alpha = 0.1\n",
    "\n",
    "    print('Computing metrics using y_pred.')\n",
    "    # Using y_pred\n",
    "    explained_variance = metrics.explained_variance_score(y_labels, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_labels, y_pred)\n",
    "    balanced_accuracy = metrics.balanced_accuracy_score(y_labels, y_pred)\n",
    "    precision = metrics.precision_score(y_labels, y_pred, pos_label=pos_label, labels=labels, zero_division=zero_division)\n",
    "    recall = metrics.recall_score(y_labels, y_pred, pos_label=pos_label, labels=labels, zero_division=zero_division)\n",
    "    f1 = metrics.f1_score(y_labels, y_pred, pos_label=pos_label,labels=labels, zero_division=zero_division)\n",
    "    mcc = metrics.matthews_corrcoef(y_labels, y_pred)\n",
    "    fm = metrics.fowlkes_mallows_score(y_labels, y_pred)\n",
    "    kappa = metrics.cohen_kappa_score(y_labels, y_pred, labels=labels)\n",
    "    gmean_iba = imblearn.metrics.make_index_balanced_accuracy(alpha=alpha, squared=True)(geometric_mean_score)\n",
    "    gmean = gmean_iba(y_labels, y_pred)\n",
    "    report = metrics.classification_report(y_labels, y_pred, labels=labels, zero_division=zero_division)\n",
    "    imblearn_report = classification_report_imbalanced(y_labels, y_pred, labels=labels, zero_division=zero_division)\n",
    "    cm = metrics.confusion_matrix(y_labels, y_pred, labels=labels)\n",
    "    cm_normalized = metrics.confusion_matrix(y_labels, y_pred, normalize='true', labels=labels)\n",
    "\n",
    "    return (\n",
    "        explained_variance, accuracy, balanced_accuracy, precision,\n",
    "        recall, f1, mcc, fm, kappa, gmean, report, imblearn_report, cm, cm_normalized\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e2dcb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_with_y_pred_prob(\n",
    "    y_labels, y_pred_prob,\n",
    "    pos_label=None\n",
    "):\n",
    "    if pos_label is None:\n",
    "        pos_label = 1\n",
    "\n",
    "    print('Computing metrics using y_pred_prob.')\n",
    "    average_precision = metrics.average_precision_score(y_labels, y_pred_prob)\n",
    "    roc_auc = metrics.roc_auc_score(y_labels, y_pred_prob)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_labels, y_pred_prob, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    loss = metrics.log_loss(y_labels, y_pred_prob)\n",
    "    precision_pr, recall_pr, threshold_pr = metrics.precision_recall_curve(y_labels, y_pred_prob, pos_label=1)\n",
    "\n",
    "    return (\n",
    "        average_precision, roc_auc, auc,\n",
    "        fpr, tpr, threshold, loss,\n",
    "        precision_pr, recall_pr, threshold_pr\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28661d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_metrics_dict(metrics_dict, prefix_to_remove):\n",
    "    for metric_name in list(metrics_dict):\n",
    "        if metric_name.startswith(prefix_to_remove):\n",
    "            new_metric_name = ' '.join(metric_name.split(prefix_to_remove)[-1].split('_'))\n",
    "        if not new_metric_name[0].isupper():\n",
    "            new_metric_name = new_metric_name.title()\n",
    "        if new_metric_name == 'Loss':\n",
    "            metrics_dict['Log Loss/Cross Entropy'] = metrics_dict.pop(metric_name)\n",
    "        else:\n",
    "            metrics_dict[new_metric_name] = metrics_dict.pop(metric_name)\n",
    "\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "935f15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get y_pred and y_pred_prob\n",
    "def preprocess_logits_for_metrics_in_compute_metrics(y_pred_logits):\n",
    "\n",
    "    # Get y_pred\n",
    "    print('-'*20)\n",
    "    y_pred_logits_tensor = torch.tensor(y_pred_logits, device=device)\n",
    "    print('Getting y_pred through argmax of y_pred_logits...')\n",
    "    try:\n",
    "        y_pred_array = torch.argmax(y_pred_logits_tensor, axis=-1).clone().detach().cpu().numpy()\n",
    "        print('Using torch.argmax.')\n",
    "    except Exception:\n",
    "        y_pred_array = y_pred_logits.argmax(axis=-1)\n",
    "        print('Using np.argmax.')\n",
    "    print(f'y_pred_array shape: {y_pred_array.shape}')\n",
    "    print('-'*20)\n",
    "    print('Flattening y_pred...')\n",
    "    y_pred = [bert_label2id[l] for l in y_pred_array.flatten().tolist()]\n",
    "    print(f'y_pred length: {len(y_pred)}')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Get y_pred_prob\n",
    "    print('-'*20)\n",
    "    print('Getting y_pred_prob through softmax of y_pred_logits...')\n",
    "    try:\n",
    "        y_pred_prob_array = torch.nn.functional.softmax(y_pred_logits_tensor, dim=-1).clone().detach().cpu().numpy()\n",
    "        print('Using torch.nn.functional.softmax.')\n",
    "    except Exception:\n",
    "        y_pred_prob_array = scipy.special.softmax(y_pred_logits, axis=-1)\n",
    "        print('Using scipy.special.softmax.')\n",
    "    # from: https://discuss.huggingface.co/t/different-results-predicting-from-trainer-and-model/12922\n",
    "    assert all(y_pred_prob_array.argmax(axis=-1) == y_pred_array), 'Argmax of y_pred_prob_array does not match y_pred_array.'\n",
    "    print(f'y_pred_prob shape: {y_pred_prob_array.shape}')\n",
    "    print('-'*20)\n",
    "    print('Flattening y_pred_prob and extracting probabilities of 1...')\n",
    "    y_pred_prob = y_pred_prob_array[:, -1].flatten().tolist()\n",
    "    print(f'y_pred length: {len(y_pred_prob)}')\n",
    "    print('-'*20)\n",
    "\n",
    "    y_pred_logits_tensor.detach()\n",
    "\n",
    "    return (\n",
    "        y_pred_array, y_pred, y_pred_prob_array, y_pred_prob\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81d6916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_from_logits(\n",
    "    predicted_results_from_eval,\n",
    "):\n",
    "    # Get predictions\n",
    "    print('-'*20)\n",
    "    print(f'Getting y_pred logits and ids for {col}:')\n",
    "    y_pred_logits, y_labels = predicted_results_from_eval\n",
    "    print(f'y_pred_logits shape: {y_pred_logits.shape}')\n",
    "    print(f'y shape: {y_labels.shape}')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Get y_test_pred and y_test_pred_prob\n",
    "    (\n",
    "        y_pred_array, y_pred, y_pred_prob_array, y_pred_prob\n",
    "    ) = preprocess_logits_for_metrics_in_compute_metrics(y_pred_logits)\n",
    "\n",
    "    # Get metrics\n",
    "    print('='*20)\n",
    "    # Using y_test_pred\n",
    "    if with_y_pred:\n",
    "        print('-'*20)\n",
    "        (\n",
    "            explained_variance, accuracy, balanced_accuracy, precision,\n",
    "            recall, f1, mcc, fm, kappa, gmean, report, imblearn_report, cm, cm_normalized\n",
    "        ) = compute_metrics_with_y_pred(\n",
    "            y_labels, y_pred\n",
    "        )\n",
    "    # Using y_pred_prob\n",
    "    if with_y_pred_prob:\n",
    "        print('-'*20)\n",
    "        (\n",
    "            average_precision, roc_auc, auc,\n",
    "            fpr, tpr, threshold, loss,\n",
    "            precision_pr, recall_pr, threshold_pr\n",
    "        ) = compute_metrics_with_y_pred_prob(\n",
    "            y_labels, y_pred_prob\n",
    "        )\n",
    "\n",
    "    # Place metrics into dict\n",
    "    print('-'*20)\n",
    "    print('Appending metrics to dict.')\n",
    "    metrics_dict = {\n",
    "        # f'{scoring.title()} Best Score': float(best_train_score),\n",
    "        # f'{scoring.title()} Best Threshold': threshold,\n",
    "        # 'Train - Mean Cross Validation Score': float(cv_train_scores),\n",
    "        # f'Train - Mean Cross Validation - {scoring.title()}': float(cv_train_recall),\n",
    "        # f'Train - Mean Explained Variance - {scoring.title()}': float(cv_train_explained_variance_recall),\n",
    "        # 'Test - Mean Cross Validation Score': float(cv_test_scores),\n",
    "        # f'Test - Mean Cross Validation - {scoring.title()}': float(cv_test_recall),\n",
    "        # f'Test - Mean Explained Variance - {scoring.title()}': float(cv_test_explained_variance_recall),\n",
    "        'Explained Variance': float(explained_variance),\n",
    "        'Accuracy': float(accuracy),\n",
    "        'Balanced Accuracy': float(balanced_accuracy),\n",
    "        'Precision': float(precision),\n",
    "        'Average Precision': float(average_precision),\n",
    "        'Recall': float(recall),\n",
    "        'F1-score': float(f1),\n",
    "        'Matthews Correlation Coefficient': float(mcc),\n",
    "        'Fowlkes–Mallows Index': float(fm),\n",
    "        'R2 Score': float(r2),\n",
    "        'ROC': float(roc_auc),\n",
    "        'AUC': float(auc),\n",
    "        'Log Loss/Cross Entropy': float(loss),\n",
    "        'Cohen’s Kappa': float(kappa),\n",
    "        'Geometric Mean': float(gmean),\n",
    "        'Classification Report': report,\n",
    "        'Imbalanced Classification Report': imblearn_report,\n",
    "        'Confusion Matrix': cm,\n",
    "        'Normalized Confusion Matrix': cm_normalized,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_prob': y_pred_prob,\n",
    "    }\n",
    "\n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c44994c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(\n",
    "    metrics_dict, df_metrics,\n",
    "    col, vectorizer_name, classifier_name\n",
    "):\n",
    "    # Print metrics\n",
    "    print('=' * 20)\n",
    "    print('~' * 20)\n",
    "    print(' Metrics:')\n",
    "    print('~' * 20)\n",
    "    print(f'Classification Report:\\n {metrics_dict[\"Classification Report\"]}')\n",
    "    print('-' * 20)\n",
    "    for metric_name, metric_value in metrics_dict.items():\n",
    "        if metric_name not in ['Runtime', 'Samples Per Second', 'Steps Per Second']:\n",
    "            with contextlib.suppress(TypeError, ValueError):\n",
    "                metric_value = float(metric_value)\n",
    "            if isinstance(metric_name, (int, float)):\n",
    "                df_metrics.loc[\n",
    "                    (classifier_name), (col, vectorizer_name, metric_name)\n",
    "                ] = metric_value\n",
    "                print(f'{metric_name}: {round(metric_value, 2)}')\n",
    "            else:\n",
    "                df_metrics.loc[\n",
    "                    (classifier_name), (col, vectorizer_name, metric_name)\n",
    "                ] = str(metric_value)\n",
    "                print(f'{metric_name}: {metric_value}')\n",
    "            print('-' * 20)\n",
    "\n",
    "    print('=' * 20)\n",
    "\n",
    "    # Plot Metrics\n",
    "    plot_metrics(\n",
    "        estimator, X_test, y_test, y_test_pred, y_test_pred_prob,\n",
    "        col, vectorizer_name, classifier_name,\n",
    "    )\n",
    "\n",
    "    return df_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e70db7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to place Xy and CV data in df and save\n",
    "def save_Xy(\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    X_val, y_val,\n",
    "    col,\n",
    "    results_save_path=results_save_path,\n",
    "    method=method, done_xy_save_path=done_xy_save_path,\n",
    "    compression=None, protocol=None, path_suffix=None, data_dict=None\n",
    "):\n",
    "\n",
    "    if compression is None:\n",
    "        compression = False\n",
    "    if protocol is None:\n",
    "        protocol = pickle.HIGHEST_PROTOCOL\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {col} - (Save_protocol={protocol}).pkl'\n",
    "    if data_dict is None:\n",
    "        data_dict = {}\n",
    "\n",
    "    # Make df_train_data\n",
    "    df_train_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "        },\n",
    "    )\n",
    "    # Make df_test_data\n",
    "    df_test_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "        },\n",
    "    )\n",
    "    # Make df_test_data\n",
    "    df_val_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_val': X_val,\n",
    "            'y_val': y_val,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Assign dfs to variables\n",
    "    data_dict['df_train_data'] = df_train_data\n",
    "    data_dict['df_test_data'] = df_test_data\n",
    "    data_dict['df_val_data'] = df_val_data\n",
    "\n",
    "    # Save files\n",
    "    print('='*20)\n",
    "    for file_name, file_ in data_dict.items():\n",
    "        save_path = f'{results_save_path}{method} {file_name}{path_suffix}'\n",
    "        print(f'Saving Xy {file_name} at {save_path}')\n",
    "        file_.to_pickle(\n",
    "            save_path, protocol=protocol\n",
    "        )\n",
    "    print(f'Done saving Xy!\\n{list(data_dict.keys())}')\n",
    "    print('='*20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93960eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to place Xy and CV data in df and save\n",
    "def save_Xy_estimator(\n",
    "    X_train, y_train, bert_train_dataset,\n",
    "    X_test, y_test, bert_test_dataset, y_test_pred, y_test_pred_prob,\n",
    "    X_val, y_val, bert_val_dataset, y_val_pred, y_val_pred_prob,\n",
    "    bert_label2id, bert_id2label,\n",
    "    # train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "    # test_class_weights, test_class_weights_ratio, test_class_weights_dict,\n",
    "    estimator,\n",
    "    col, vectorizer_name, classifier_name,\n",
    "    results_save_path=results_save_path,\n",
    "    method=method, done_xy_save_path=done_xy_save_path,\n",
    "    compression=None, protocol=None,\n",
    "    path_suffix=None, data=None\n",
    "):\n",
    "    if compression is None:\n",
    "        compression = False\n",
    "    if protocol is None:\n",
    "        protocol = pickle.HIGHEST_PROTOCOL\n",
    "    if path_suffix is None:\n",
    "        path_suffix = f' - {col} - {vectorizer_name} + {classifier_name} (Save_protocol={protocol}).pkl'\n",
    "    if data is None:\n",
    "        data = {}\n",
    "\n",
    "    # Make df_train_data\n",
    "    df_train_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "            'bert_train_dataset': bert_train_dataset,\n",
    "            # 'train_class_weights': train_class_weights,\n",
    "            # 'train_class_weights_ratio': train_class_weights_ratio,\n",
    "            # 'train_class_weights_dict': train_class_weights_dict,\n",
    "        },\n",
    "    )\n",
    "    # Make df_test_data\n",
    "    df_test_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'bert_test_dataset': bert_test_dataset,\n",
    "            'y_test_pred': y_test_pred,\n",
    "            'y_test_pred_prob': y_test_pred_prob,\n",
    "            # 'test_class_weights': test_class_weights,\n",
    "            # 'test_class_weights_ratio': test_class_weights_ratio,\n",
    "            # 'test_class_weights_dict': test_class_weights_dict,\n",
    "        },\n",
    "    )\n",
    "    # Make df_val_data\n",
    "    df_val_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_val': X_val,\n",
    "            'y_val': y_val,\n",
    "            'bert_val_dataset': bert_val_dataset,\n",
    "            'y_val_pred': y_val_pred,\n",
    "            'y_val_pred_prob': y_val_pred_prob,\n",
    "        },\n",
    "    )\n",
    "    # Make df_labels\n",
    "    df_labels = pd.DataFrame(\n",
    "        {\n",
    "            'bert_label2id': bert_label2id,\n",
    "            'bert_id2label': bert_id2label,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Make data dict\n",
    "    data['df_train_data'] = df_train_data\n",
    "    data['df_test_data'] = df_test_data\n",
    "    data['df_val_data'] = df_val_data\n",
    "    data['df_labels'] = df_labels\n",
    "    data['Estimator'] = estimator\n",
    "\n",
    "    # Save files\n",
    "    print('='*20)\n",
    "    for file_name, file_ in data.items():\n",
    "        save_path = done_xy_save_path if file_name != 'Estimator' else results_save_path\n",
    "        print(f'Saving Xy, labels and estimator {file_name} at {save_path}')\n",
    "        if not isinstance(file_, pd.DataFrame) and file_name == 'Estimator' and 'df_' not in file_name:\n",
    "            # Save as .model\n",
    "            file_.save_model(f'{save_path}{method} {file_name}{path_suffix.replace(\"pkl\", \"model\")}')\n",
    "        elif isinstance(file_, pd.DataFrame) and file_name != 'Estimator' and 'df_' in file_name:\n",
    "            file_.to_pickle(\n",
    "                f'{save_path}{method} {file_name}{path_suffix}', protocol=protocol\n",
    "            )\n",
    "    print(f'Done saving Xy, labels and estimator!\\n{list(data.keys())}')\n",
    "    print('='*20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10f64ab3",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52fe8e7a",
   "metadata": {},
   "source": [
    "### READ DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7fbe29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_trainning.pkl').reset_index(drop=True)\n",
    "# HACK REMOVE THIS!!!!!!\n",
    "df_manual = df_manual.groupby(analysis_columns).sample(n=200).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ea2f60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Starting!\n",
      "########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "============================== TRAINING DATASET OF LENGTH 800 ON WARMTH ==============================\n",
      "--------------------\n",
      "====================\n",
      "Splitting data into training, testing, and validation sets:\n",
      "Ratios: train_size = 0.75, test size = 0.1, validation size = 0.15\n",
      "Done splitting data into training, testing, and validation sets.\n",
      "====================\n",
      "Encoding training, testing, and validation sets with BertTokenizerFast.from_pretrained using bert-base-uncased.\n",
      "Done encoding training, testing, and validation sets.\n",
      "====================\n",
      "Training set shape: (600,)\n",
      "----------\n",
      "Training set example:\n",
      "Automate) who will be responsible for preparation and execution of improvements working with the RPA and Microsoft Power\n",
      "----------\n",
      "Training set BERT encodings example:\n",
      "[CLS] auto ##mate ) who will be responsible for preparation and execution of improvements working with the r ##pa and microsoft power [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "----------\n",
      "Training set BERT encoded example: {0, 1}\n",
      "~~~~~~~~~~\n",
      "Testing set shape: (80,)\n",
      "----------\n",
      "Testing set example:\n",
      "self-motivation and a clear dedication to your profession.\n",
      "----------\n",
      "Testing set BERT encodings example:\n",
      "[CLS] self - motivation and a clear dedication to your profession . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "----------\n",
      "Testing set BERT encoded example: {0, 1}\n",
      "~~~~~~~~~~\n",
      "Validation set shape: (120,)\n",
      "----------\n",
      "Validation set example:\n",
      "Create your own nutrition formula with a discount on our products!\n",
      "----------\n",
      "Validation set BERT encodings example:\n",
      "[CLS] create your own nutrition formula with a discount on our products ! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "----------\n",
      "Validation labels after BERT encoding: {0, 1}\n",
      "~~~~~~~~~~\n",
      "Training data class weights:\n",
      "Ratio = 0.99 (0 = 0.99, 1 = 1.01)\n",
      "----------\n",
      "Testing data class weights:\n",
      "Ratio = 0.78 (0 = 0.89, 1 = 1.14)\n",
      "====================\n",
      "====================\n",
      "Saving Xy df_train_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Transformers df_train_data - Warmth - (Save_protocol=5).pkl\n",
      "Saving Xy df_test_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Transformers df_test_data - Warmth - (Save_protocol=5).pkl\n",
      "Saving Xy df_val_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Transformers df_val_data - Warmth - (Save_protocol=5).pkl\n",
      "Done saving Xy!\n",
      "['df_train_data', 'df_test_data', 'df_val_data']\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "The speedups for torchdynamo mostly come wih GPU Ampere or higher and which is not detected here.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Initializing BERT Trainer using BertBaseUncased + BertForSequenceClassification for Warmth\n",
      "--------------------\n",
      "Passing arguments to Trainer.\n",
      "--------------------\n",
      "Starting training for Warmth.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d25cfb90b34a618d8525d253c8f5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "  0%|          | 0/2 [01:54<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5763, 'learning_rate': 5e-05, 'epoch': 2.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d48f3fc7c04a00a427fda671450ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [02:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Getting y_pred logits and ids for Warmth:\n",
      "y_pred_logits shape: (120, 2)\n",
      "y shape: (120,)\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred through argmax of y_pred_logits...\n",
      "Using torch.argmax.\n",
      "y_pred_array shape: (120,)\n",
      "--------------------\n",
      "Flattening y_pred...\n",
      "y_pred length: 120\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits...\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob shape: (120, 2)\n",
      "--------------------\n",
      "Flattening y_pred_prob and extracting probabilities of 1...\n",
      "y_pred length: 120\n",
      "--------------------\n",
      "====================\n",
      "--------------------\n",
      "Computing metrics using y_pred.\n",
      "--------------------\n",
      "Computing metrics using y_pred_prob.\n",
      "--------------------\n",
      "Appending metrics to dict.\n",
      "{'eval_loss': 0.3868646025657654, 'eval_Explained Variance': 0.3522951281329203, 'eval_Accuracy': 0.8333333333333334, 'eval_Balanced Accuracy': 0.8211771332019149, 'eval_Precision': 0.8051948051948052, 'eval_Average Precision': 0.8984501428570097, 'eval_Recall': 0.9253731343283582, 'eval_F1-score': 0.8611111111111112, 'eval_Matthews Correlation Coefficient': 0.6652277518598416, 'eval_Fowlkes–Mallows Index': 0.7307681197287689, 'eval_ROC': 0.8941143339904252, 'eval_AUC': 0.8941143339904252, 'eval_Log Loss/Cross Entropy': 0.3868645219135425, 'eval_Cohen’s Kappa': 0.6552714737144498, 'eval_Geometric Mean': 0.6634750774429737, 'eval_Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.88      0.72      0.79        53\\n           1       0.81      0.93      0.86        67\\n\\n    accuracy                           0.83       120\\n   macro avg       0.84      0.82      0.83       120\\nweighted avg       0.84      0.83      0.83       120\\n', 'eval_Imbalanced Classification Report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n          0       0.88      0.72      0.93      0.79      0.81      0.65        53\\n          1       0.81      0.93      0.72      0.86      0.81      0.68        67\\n\\navg / total       0.84      0.83      0.81      0.83      0.81      0.67       120\\n', 'eval_Confusion Matrix': array([[38, 15],\n",
      "       [ 5, 62]]), 'eval_Normalized Confusion Matrix': array([[0.71698113, 0.28301887],\n",
      "       [0.07462687, 0.92537313]]), 'eval_y_pred': [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0], 'eval_y_pred_prob': [0.2832566201686859, 0.7518991231918335, 0.948094367980957, 0.9385717511177063, 0.9238379001617432, 0.9285927414894104, 0.9303168058395386, 0.9219849109649658, 0.7044580578804016, 0.8919205069541931, 0.6668444275856018, 0.900651216506958, 0.9172154664993286, 0.3088337481021881, 0.9229251742362976, 0.9229855537414551, 0.9388033747673035, 0.035338547080755234, 0.9127945899963379, 0.5622942447662354, 0.05397694185376167, 0.8808030486106873, 0.8930547833442688, 0.8404813408851624, 0.041329942643642426, 0.16775743663311005, 0.08510097861289978, 0.3353556990623474, 0.09623958170413971, 0.03939172998070717, 0.0388680100440979, 0.8401387333869934, 0.9372201561927795, 0.9438669681549072, 0.877231776714325, 0.9398012757301331, 0.6889868974685669, 0.8871477842330933, 0.9231633543968201, 0.6268996596336365, 0.029290203005075455, 0.661873996257782, 0.9354739189147949, 0.9157829284667969, 0.034360505640506744, 0.8377209305763245, 0.806165337562561, 0.7249496579170227, 0.025471141561865807, 0.2555067837238312, 0.08396564424037933, 0.9399568438529968, 0.9213053584098816, 0.8435171842575073, 0.029492121189832687, 0.9236075282096863, 0.3638325333595276, 0.024440033361315727, 0.9293442964553833, 0.7473911046981812, 0.9215850234031677, 0.922617495059967, 0.21893206238746643, 0.5041505098342896, 0.9127197265625, 0.05071404576301575, 0.9133379459381104, 0.9140781164169312, 0.8753570914268494, 0.0950576588511467, 0.18314705789089203, 0.9183080196380615, 0.8767986297607422, 0.6313743591308594, 0.03196871280670166, 0.05339064821600914, 0.15493209660053253, 0.02304779179394245, 0.029713617637753487, 0.9314956068992615, 0.9294772148132324, 0.029345080256462097, 0.4684927761554718, 0.8620914220809937, 0.8863852024078369, 0.5140134692192078, 0.8545551896095276, 0.021323880180716515, 0.8708786368370056, 0.9170082211494446, 0.8998093008995056, 0.37591293454170227, 0.5450318455696106, 0.022694751620292664, 0.059151582419872284, 0.7302067875862122, 0.9395665526390076, 0.6580466628074646, 0.2806968092918396, 0.9062422513961792, 0.9417273998260498, 0.9595440030097961, 0.8786396980285645, 0.9376789331436157, 0.02178734913468361, 0.024848854169249535, 0.9041395783424377, 0.9193084836006165, 0.3904644548892975, 0.0374443456530571, 0.30062752962112427, 0.8935126662254333, 0.9228193759918213, 0.9319341778755188, 0.021503301337361336, 0.06967239826917648, 0.7748748064041138, 0.9127469062805176, 0.8397418856620789, 0.3567814230918884], 'eval_runtime': 6.4398, 'eval_samples_per_second': 18.634, 'eval_steps_per_second': 0.932, 'epoch': 2.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [02:16<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 134.0699, 'train_samples_per_second': 13.426, 'train_steps_per_second': 0.85, 'train_loss': 0.5490633228368926, 'epoch': 3.0}\n",
      "Done training!\n",
      "--------------------\n",
      "--------------------\n",
      "Evaluating estimator for Warmth.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb38bc0b63b64d5e984b31509b83cf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Getting y_pred logits and ids for Warmth:\n",
      "y_pred_logits shape: (120, 2)\n",
      "y shape: (120,)\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred through argmax of y_pred_logits...\n",
      "Using torch.argmax.\n",
      "y_pred_array shape: (120,)\n",
      "--------------------\n",
      "Flattening y_pred...\n",
      "y_pred length: 120\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits...\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob shape: (120, 2)\n",
      "--------------------\n",
      "Flattening y_pred_prob and extracting probabilities of 1...\n",
      "y_pred length: 120\n",
      "--------------------\n",
      "====================\n",
      "--------------------\n",
      "Computing metrics using y_pred.\n",
      "--------------------\n",
      "Computing metrics using y_pred_prob.\n",
      "--------------------\n",
      "Appending metrics to dict.\n",
      "Done evaluating!\n",
      "Getting prediction results for Warmth.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f263e1eb2fb84c87b25aad97bcde5c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Getting y_pred logits and ids for Warmth:\n",
      "y_pred_logits shape: (80, 2)\n",
      "y shape: (80,)\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred through argmax of y_pred_logits...\n",
      "Using torch.argmax.\n",
      "y_pred_array shape: (80,)\n",
      "--------------------\n",
      "Flattening y_pred...\n",
      "y_pred length: 80\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits...\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob shape: (80, 2)\n",
      "--------------------\n",
      "Flattening y_pred_prob and extracting probabilities of 1...\n",
      "y_pred length: 80\n",
      "--------------------\n",
      "====================\n",
      "--------------------\n",
      "Computing metrics using y_pred.\n",
      "--------------------\n",
      "Computing metrics using y_pred_prob.\n",
      "--------------------\n",
      "Appending metrics to dict.\n",
      "Done predicting!\n",
      "--------------------\n",
      "--------------------\n",
      "Saving model for Warmth.\n",
      "====================\n",
      "Saving Xy, labels and estimator df_train_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Xy/\n",
      "Saving Xy, labels and estimator df_test_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Xy/\n",
      "Saving Xy, labels and estimator df_val_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Xy/\n",
      "Saving Xy, labels and estimator df_labels at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Xy/\n",
      "Saving Xy, labels and estimator Estimator at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [02:25<02:25, 145.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving Xy, labels and estimator!\n",
      "['df_train_data', 'df_test_data', 'df_val_data', 'df_labels', 'Estimator']\n",
      "====================\n",
      "Done training!\n",
      "--------------------\n",
      "--------------------\n",
      "============================== TRAINING DATASET OF LENGTH 800 ON COMPETENCE ==============================\n",
      "--------------------\n",
      "====================\n",
      "Splitting data into training, testing, and validation sets:\n",
      "Ratios: train_size = 0.75, test size = 0.1, validation size = 0.15\n",
      "Done splitting data into training, testing, and validation sets.\n",
      "====================\n",
      "Encoding training, testing, and validation sets with BertTokenizerFast.from_pretrained using bert-base-uncased.\n",
      "Done encoding training, testing, and validation sets.\n",
      "====================\n",
      "Training set shape: (600,)\n",
      "----------\n",
      "Training set example:\n",
      "Automate) who will be responsible for preparation and execution of improvements working with the RPA and Microsoft Power\n",
      "----------\n",
      "Training set BERT encodings example:\n",
      "[CLS] auto ##mate ) who will be responsible for preparation and execution of improvements working with the r ##pa and microsoft power [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "----------\n",
      "Training set BERT encoded example: {0, 1}\n",
      "~~~~~~~~~~\n",
      "Testing set shape: (80,)\n",
      "----------\n",
      "Testing set example:\n",
      "self-motivation and a clear dedication to your profession.\n",
      "----------\n",
      "Testing set BERT encodings example:\n",
      "[CLS] self - motivation and a clear dedication to your profession . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "----------\n",
      "Testing set BERT encoded example: {0, 1}\n",
      "~~~~~~~~~~\n",
      "Validation set shape: (120,)\n",
      "----------\n",
      "Validation set example:\n",
      "Create your own nutrition formula with a discount on our products!\n",
      "----------\n",
      "Validation set BERT encodings example:\n",
      "[CLS] create your own nutrition formula with a discount on our products ! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "----------\n",
      "Validation labels after BERT encoding: {0, 1}\n",
      "~~~~~~~~~~\n",
      "Training data class weights:\n",
      "Ratio = 0.94 (0 = 0.97, 1 = 1.03)\n",
      "----------\n",
      "Testing data class weights:\n",
      "Ratio = 1.05 (0 = 1.03, 1 = 0.98)\n",
      "====================\n",
      "====================\n",
      "Saving Xy df_train_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Transformers df_train_data - Competence - (Save_protocol=5).pkl\n",
      "Saving Xy df_test_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Transformers df_test_data - Competence - (Save_protocol=5).pkl\n",
      "Saving Xy df_val_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Transformers df_val_data - Competence - (Save_protocol=5).pkl\n",
      "Done saving Xy!\n",
      "['df_train_data', 'df_test_data', 'df_val_data']\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "The speedups for torchdynamo mostly come wih GPU Ampere or higher and which is not detected here.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Initializing BERT Trainer using BertBaseUncased + BertForSequenceClassification for Competence\n",
      "--------------------\n",
      "Passing arguments to Trainer.\n",
      "--------------------\n",
      "Starting training for Competence.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda6469a8fe84dfdb9bc241f9b17938d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [04:22<02:25, 145.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5747, 'learning_rate': 5e-05, 'epoch': 2.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad70d3f551b7403abbb7b2cfa04b8eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [04:28<02:25, 145.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Getting y_pred logits and ids for Competence:\n",
      "y_pred_logits shape: (120, 2)\n",
      "y shape: (120,)\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred through argmax of y_pred_logits...\n",
      "Using torch.argmax.\n",
      "y_pred_array shape: (120,)\n",
      "--------------------\n",
      "Flattening y_pred...\n",
      "y_pred length: 120\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits...\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob shape: (120, 2)\n",
      "--------------------\n",
      "Flattening y_pred_prob and extracting probabilities of 1...\n",
      "y_pred length: 120\n",
      "--------------------\n",
      "====================\n",
      "--------------------\n",
      "Computing metrics using y_pred.\n",
      "--------------------\n",
      "Computing metrics using y_pred_prob.\n",
      "--------------------\n",
      "Appending metrics to dict.\n",
      "{'eval_loss': 0.5170201063156128, 'eval_Explained Variance': 0.055413469735720144, 'eval_Accuracy': 0.7666666666666667, 'eval_Balanced Accuracy': 0.7536231884057971, 'eval_Precision': 0.7733333333333333, 'eval_Average Precision': 0.8676596744484972, 'eval_Recall': 0.8405797101449275, 'eval_F1-score': 0.8055555555555556, 'eval_Matthews Correlation Coefficient': 0.517954604791577, 'eval_Fowlkes–Mallows Index': 0.6513558650284117, 'eval_ROC': 0.8283603296391021, 'eval_AUC': 0.8283603296391021, 'eval_Log Loss/Cross Entropy': 0.5170200513018027, 'eval_Cohen’s Kappa': 0.5151515151515151, 'eval_Geometric Mean': 0.5603864734299516, 'eval_Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.76      0.67      0.71        51\\n           1       0.77      0.84      0.81        69\\n\\n    accuracy                           0.77       120\\n   macro avg       0.76      0.75      0.76       120\\nweighted avg       0.77      0.77      0.76       120\\n', 'eval_Imbalanced Classification Report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n          0       0.76      0.67      0.84      0.71      0.75      0.55        51\\n          1       0.77      0.84      0.67      0.81      0.75      0.57        69\\n\\navg / total       0.77      0.77      0.74      0.76      0.75      0.56       120\\n', 'eval_Confusion Matrix': array([[34, 17],\n",
      "       [11, 58]]), 'eval_Normalized Confusion Matrix': array([[0.66666667, 0.33333333],\n",
      "       [0.15942029, 0.84057971]]), 'eval_y_pred': [1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0], 'eval_y_pred_prob': [0.5819569230079651, 0.573086142539978, 0.28392958641052246, 0.916828453540802, 0.38957202434539795, 0.9346802830696106, 0.9094096422195435, 0.9070342183113098, 0.08956311643123627, 0.9178950786590576, 0.9149714112281799, 0.8911496996879578, 0.9038661122322083, 0.5495551824569702, 0.7481755018234253, 0.22097647190093994, 0.9098314642906189, 0.3144232928752899, 0.5382605791091919, 0.8844329118728638, 0.348101943731308, 0.4634615182876587, 0.12327122688293457, 0.770187497138977, 0.885810136795044, 0.07680781930685043, 0.157244473695755, 0.07168208062648773, 0.4058281481266022, 0.07038301229476929, 0.06625877320766449, 0.8895822167396545, 0.6843962073326111, 0.9079577326774597, 0.8814377784729004, 0.4878934323787689, 0.8156570196151733, 0.4599893093109131, 0.921463668346405, 0.927328884601593, 0.5044960379600525, 0.9082517027854919, 0.27365612983703613, 0.5608073472976685, 0.8220005035400391, 0.918481707572937, 0.42022013664245605, 0.9085512161254883, 0.0939711332321167, 0.2332048863172531, 0.5525336861610413, 0.5078920722007751, 0.7195537686347961, 0.49569618701934814, 0.1760864555835724, 0.9216240048408508, 0.06907570362091064, 0.815815806388855, 0.9238954782485962, 0.862185001373291, 0.9241620898246765, 0.8951689004898071, 0.8026055693626404, 0.12479391694068909, 0.4387950003147125, 0.09657856822013855, 0.3399634063243866, 0.17204707860946655, 0.9237924218177795, 0.1265956312417984, 0.08441609144210815, 0.3446844518184662, 0.6977187991142273, 0.7949556112289429, 0.06264462321996689, 0.09665968269109726, 0.6201581358909607, 0.8989599347114563, 0.8229277729988098, 0.9011445641517639, 0.44309723377227783, 0.8786423206329346, 0.8613767623901367, 0.8280046582221985, 0.8482217788696289, 0.9094160199165344, 0.46733587980270386, 0.5957737565040588, 0.9236494898796082, 0.8925965428352356, 0.2970510721206665, 0.8967410326004028, 0.09213414788246155, 0.7360941767692566, 0.9226651787757874, 0.6591505408287048, 0.9091370105743408, 0.9337394833564758, 0.9131726026535034, 0.2201588749885559, 0.44554126262664795, 0.8780508637428284, 0.9091600775718689, 0.5566244125366211, 0.8496634364128113, 0.09617133438587189, 0.5569726824760437, 0.7918840050697327, 0.2353184074163437, 0.164229154586792, 0.9105998873710632, 0.2526160478591919, 0.5892212986946106, 0.89471834897995, 0.07073478400707245, 0.7128798365592957, 0.87347412109375, 0.7000108361244202, 0.8053856492042542, 0.08420965075492859], 'eval_runtime': 6.3868, 'eval_samples_per_second': 18.789, 'eval_steps_per_second': 0.939, 'epoch': 2.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [04:43<02:25, 145.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 136.9761, 'train_samples_per_second': 13.141, 'train_steps_per_second': 0.832, 'train_loss': 0.557861746403209, 'epoch': 3.0}\n",
      "Done training!\n",
      "--------------------\n",
      "--------------------\n",
      "Evaluating estimator for Competence.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88802b6934443c8b28452e7c5c3c6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Getting y_pred logits and ids for Competence:\n",
      "y_pred_logits shape: (120, 2)\n",
      "y shape: (120,)\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred through argmax of y_pred_logits...\n",
      "Using torch.argmax.\n",
      "y_pred_array shape: (120,)\n",
      "--------------------\n",
      "Flattening y_pred...\n",
      "y_pred length: 120\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits...\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob shape: (120, 2)\n",
      "--------------------\n",
      "Flattening y_pred_prob and extracting probabilities of 1...\n",
      "y_pred length: 120\n",
      "--------------------\n",
      "====================\n",
      "--------------------\n",
      "Computing metrics using y_pred.\n",
      "--------------------\n",
      "Computing metrics using y_pred_prob.\n",
      "--------------------\n",
      "Appending metrics to dict.\n",
      "Done evaluating!\n",
      "Getting prediction results for Competence.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25a6c47f6d44f238995e2bb967181a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Getting y_pred logits and ids for Competence:\n",
      "y_pred_logits shape: (80, 2)\n",
      "y shape: (80,)\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred through argmax of y_pred_logits...\n",
      "Using torch.argmax.\n",
      "y_pred_array shape: (80,)\n",
      "--------------------\n",
      "Flattening y_pred...\n",
      "y_pred length: 80\n",
      "--------------------\n",
      "--------------------\n",
      "Getting y_pred_prob through softmax of y_pred_logits...\n",
      "Using torch.nn.functional.softmax.\n",
      "y_pred_prob shape: (80, 2)\n",
      "--------------------\n",
      "Flattening y_pred_prob and extracting probabilities of 1...\n",
      "y_pred length: 80\n",
      "--------------------\n",
      "====================\n",
      "--------------------\n",
      "Computing metrics using y_pred.\n",
      "--------------------\n",
      "Computing metrics using y_pred_prob.\n",
      "--------------------\n",
      "Appending metrics to dict.\n",
      "Done predicting!\n",
      "--------------------\n",
      "--------------------\n",
      "Saving model for Competence.\n",
      "====================\n",
      "Saving Xy, labels and estimator df_train_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Xy/\n",
      "Saving Xy, labels and estimator df_test_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Xy/\n",
      "Saving Xy, labels and estimator df_val_data at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Xy/\n",
      "Saving Xy, labels and estimator df_labels at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/Xy/\n",
      "Saving Xy, labels and estimator Estimator at /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Transformers Results/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [04:53<00:00, 146.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving Xy, labels and estimator!\n",
      "['df_train_data', 'df_test_data', 'df_val_data', 'df_labels', 'Estimator']\n",
      "====================\n",
      "Done training!\n",
      "--------------------\n",
      "########################################\n",
      "DONE!\n",
      "########################################\n",
      "CPU times: user 1min 31s, sys: 21.3 s, total: 1min 52s\n",
      "Wall time: 4min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('#'*40)\n",
    "print('Starting!')\n",
    "print('#'*40)\n",
    "\n",
    "analysis_columns = ['Warmth', 'Competence']\n",
    "text_col = 'Job Description spacy_sentencized'\n",
    "\n",
    "for col in tqdm.tqdm(analysis_columns):\n",
    "\n",
    "    assert len(df_manual[df_manual[str(col)].map(df_manual[str(col)].value_counts() > 1)]) != 0, f'Dataframe has no {col} values!'\n",
    "    print('-'*20)\n",
    "    print(f'{\"=\"*30} TRAINING DATASET OF LENGTH {len(df_manual)} ON {col.upper()} {\"=\"*30}')\n",
    "    print('-'*20)\n",
    "\n",
    "    # Split\n",
    "    (\n",
    "        train, X_train, X_train_bert_encodings, y_train, y_train_bert_encoded, bert_train_dataset,\n",
    "        test, X_test, X_test_bert_encodings, y_test, y_test_bert_encoded, bert_test_dataset,\n",
    "        val, X_val, X_val_bert_encodings, y_val, y_val_bert_encoded, bert_val_dataset,\n",
    "        bert_label2id, bert_id2label,\n",
    "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "        test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict\n",
    "    ) = split_data(\n",
    "        df=df_manual, col=col, analysis_columns=analysis_columns, text_col=text_col\n",
    "    )\n",
    "    # Save Xy data\n",
    "    if len(glob.glob(f'{results_save_path}{method} df_* - {col} - (Save_protocol={pickle.HIGHEST_PROTOCOL}).pkl')) != 3:\n",
    "        save_Xy(\n",
    "            X_train, y_train,\n",
    "            X_test, y_test,\n",
    "            X_val, y_val,\n",
    "            col,\n",
    "        )\n",
    "    else:\n",
    "        print('Loading existing Xy data.')\n",
    "        (\n",
    "            X_train, X_train_bert_encodings, y_train, y_train_bert_encoded, bert_train_dataset,\n",
    "            X_test, X_test_bert_encodings, y_test, y_test_bert_encoded, bert_test_dataset,\n",
    "            X_val, X_val_bert_encodings, y_val, y_val_bert_encoded, bert_val_dataset,\n",
    "            bert_label2id, bert_id2label,\n",
    "            train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "            test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict\n",
    "        ) = load_Xy(col)\n",
    "\n",
    "    # Load pre-trained BERT model\n",
    "    bert_model = BertForSequenceClassification.from_pretrained(\n",
    "        bert_model_name, num_labels=len(bert_id2label)\n",
    "    ).to(device)\n",
    "    optimizer = AdamW(bert_model.parameters(), lr=3e-5)\n",
    "\n",
    "    # Accelerate model\n",
    "    (\n",
    "        bert_model, bert_train_dataset, bert_test_dataset, bert_val_dataset\n",
    "    ) = accelerator.prepare(\n",
    "        bert_model, bert_train_dataset, bert_test_dataset, bert_val_dataset\n",
    "    )\n",
    "    # bert_model.eval()\n",
    "\n",
    "    # Initialize BERT Trainer\n",
    "    print('='*30)\n",
    "    vectorizer_name = ''.join(s.title() for s in bert_model.name_or_path.split('-'))\n",
    "    classifier_name = bert_model.__class__.__name__\n",
    "    print(f'Initializing BERT Trainer using {vectorizer_name} + {classifier_name} for {col}')\n",
    "\n",
    "    # Set BERT fine-tuning parameters\n",
    "    bert_training_args = TrainingArguments(\n",
    "        output_dir=f'{results_save_path}{method} Results',\n",
    "        logging_dir=f'{results_save_path}{method} Logs',\n",
    "        seed=random_state,\n",
    "        torch_compile=True,\n",
    "        use_mps_device=True if device_name == 'mps' else False,\n",
    "        optim='adamw_torch',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=20,\n",
    "        learning_rate=5e-5,\n",
    "        warmup_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=100,\n",
    "        evaluation_strategy='steps',\n",
    "        save_strategy='no',\n",
    "        save_total_limit = 2,\n",
    "        load_best_model_at_end=False,\n",
    "    )\n",
    "\n",
    "    # Pass data to trainer\n",
    "    print('-'*20)\n",
    "    print('Passing arguments to Trainer.')\n",
    "    with joblib.parallel_backend(backend='loky', n_jobs=n_jobs):\n",
    "        estimator = Trainer(\n",
    "            model=bert_model,\n",
    "            tokenizer=bert_tokenizer,\n",
    "            args=bert_training_args,\n",
    "            train_dataset=bert_train_dataset,\n",
    "            eval_dataset=bert_val_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "        if estimator.place_model_on_device:\n",
    "            estimator.model.to(device)\n",
    "\n",
    "        # Train trainer\n",
    "        print('-'*20)\n",
    "        print(f'Starting training for {col}.')\n",
    "        estimator.train()\n",
    "        estimator.save_model(f'{results_save_path}{method} Estimator - {col} - {vectorizer_name} + {classifier_name} (Save_protocol={pickle.HIGHEST_PROTOCOL}).model')\n",
    "        print('Done training!')\n",
    "        print('-'*20)\n",
    "\n",
    "        # Evaluate\n",
    "        print('-'*20)\n",
    "        print(f'Evaluating estimator for {col}.')\n",
    "        eval_metrics_dict = estimator.evaluate()\n",
    "        y_val_pred = eval_metrics_dict.pop('eval_y_pred')\n",
    "        y_val_pred_prob = eval_metrics_dict.pop('eval_y_pred_prob')\n",
    "        eval_metrics_dict = clean_metrics_dict(eval_metrics_dict, list(eval_metrics_dict.keys())[0].split('_')[0])\n",
    "        print('Done evaluating!')\n",
    "\n",
    "        # Get predictions\n",
    "        print(f'Getting prediction results for {col}.')\n",
    "        y_test_pred_logits, y_test_labels, test_metrics_dict = estimator.predict(bert_test_dataset)\n",
    "        y_test_pred = test_metrics_dict.pop('test_y_pred')\n",
    "        y_test_pred_prob = test_metrics_dict.pop('test_y_pred_prob')\n",
    "        test_metrics_dict = clean_metrics_dict(test_metrics_dict, list(test_metrics_dict.keys())[0].split('_')[0])\n",
    "        print('Done predicting!')\n",
    "        print('-'*20)\n",
    "\n",
    "        # Save model\n",
    "        print('-'*20)\n",
    "        print(f'Saving model for {col}.')\n",
    "        save_Xy_estimator(\n",
    "            X_train, y_train, bert_train_dataset,\n",
    "            X_test, y_test, bert_test_dataset, y_test_pred, y_test_pred_prob,\n",
    "            X_val, y_val, bert_val_dataset, y_val_pred, y_val_pred_prob,\n",
    "            bert_label2id, bert_id2label,\n",
    "            # train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
    "            # test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict,\n",
    "            estimator,\n",
    "            col, vectorizer_name, classifier_name,\n",
    "        )\n",
    "        print('Done training!')\n",
    "        print('-'*20)\n",
    "\n",
    "print('#'*40)\n",
    "print('DONE!')\n",
    "print('#'*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1b56f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
