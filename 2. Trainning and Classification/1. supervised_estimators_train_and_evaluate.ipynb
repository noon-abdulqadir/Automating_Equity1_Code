{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "50d4c434",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import importlib\n",
                "from pathlib import Path\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fef3f604",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import *\n",
                "from setup_module.noon_plot_metric import plot_metric as n_plot_metric\n",
                "from setup_module.noon_plot_metric.plot_metric.functions import BinaryClassification\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9cd6aa58",
            "metadata": {},
            "outputs": [],
            "source": [
                "# # ML imports\n",
                "# import sklearn\n",
                "# from sklearn import feature_selection, metrics, set_config, svm, utils\n",
                "# from sklearn.utils import (check_consistent_length, check_random_state, check_X_y, parallel_backend)\n",
                "# from sklearn.utils.validation import (check_is_fitted, column_or_1d,\n",
                "#                                       has_fit_parameter)\n",
                "# from sklearn.utils.class_weight import compute_class_weight\n",
                "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
                "# from sklearn.dummy import DummyClassifier\n",
                "# from sklearn.pipeline import FeatureUnion, make_pipeline, Pipeline\n",
                "# from sklearn.feature_selection import (SelectFdr, SelectFpr,\n",
                "#                                        SelectFwe, SelectKBest, SelectPercentile,\n",
                "#                                        chi2, f_classif, f_regression,\n",
                "#                                        mutual_info_classif,\n",
                "#                                        mutual_info_regression,\n",
                "#                                        SelectFromModel)\n",
                "# from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
                "# from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
                "# from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
                "# from sklearn.linear_model import (LogisticRegression,\n",
                "#                                   PassiveAggressiveClassifier, Perceptron,\n",
                "#                                   SGDClassifier)\n",
                "# from sklearn.svm import SVC, LinearSVC\n",
                "# from sklearn.tree import DecisionTreeClassifier\n",
                "# from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier,\n",
                "#                               BaggingRegressor, ExtraTreesClassifier,\n",
                "#                               GradientBoostingClassifier,\n",
                "#                               RandomForestClassifier, StackingClassifier,\n",
                "#                               StackingRegressor, VotingClassifier,\n",
                "#                               VotingRegressor)\n",
                "# from sklearn.model_selection import (GridSearchCV, KFold, LeaveOneOut,\n",
                "#                                      RandomizedSearchCV,\n",
                "#                                      RepeatedStratifiedKFold, ShuffleSplit,\n",
                "#                                      StratifiedKFold, StratifiedShuffleSplit,\n",
                "#                                      cross_val_score, cross_val_predict, cross_validate, validation_curve,\n",
                "#                                      LearningCurveDisplay, learning_curve, train_test_split)\n",
                "# from sklearn.metrics import (ConfusionMatrixDisplay,accuracy_score, balanced_accuracy_score,\n",
                "#                              brier_score_loss, classification_report, cohen_kappa_score,\n",
                "#                              confusion_matrix, f1_score, log_loss,\n",
                "#                              make_scorer, matthews_corrcoef, fowlkes_mallows_score,\n",
                "#                              precision_recall_curve, precision_score,\n",
                "#                              recall_score, roc_auc_score)\n",
                "# from sklearn.calibration import CalibrationDisplay\n",
                "# import imblearn\n",
                "# from imblearn.metrics import geometric_mean_score, make_index_balanced_accuracy\n",
                "# from imblearn.combine import SMOTEENN, SMOTETomek\n",
                "# from imblearn.over_sampling import SMOTE, SMOTENC, RandomOverSampler\n",
                "# from imblearn.under_sampling import (EditedNearestNeighbours, NearMiss,\n",
                "#                                      RandomUnderSampler, TomekLinks)\n",
                "# from xgboost import XGBClassifier\n",
                "# from setup_module.noon_plot_metric import plot_metric as n_plot_metric\n",
                "# from setup_module.noon_plot_metric.plot_metric.functions import BinaryClassification\n",
                "\n",
                "# # Set up Bert\n",
                "# import torch\n",
                "# import torch.nn.functional as F\n",
                "# from transformers import (\n",
                "#     AutoTokenizer, AutoModelForTokenClassification, TokenClassificationPipeline,\n",
                "#     BertTokenizer, BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments,\n",
                "#     DistilBertTokenizerFast, DistilBertForSequenceClassification, BertForPreTraining, BertConfig, BertModel\n",
                "# )\n",
                "# random_state = 42\n",
                "# random.seed(random_state)\n",
                "# np.random.seed(random_state)\n",
                "# torch.manual_seed(random_state)\n",
                "# max_length = 512\n",
                "# cpu_counts = torch.multiprocessing.cpu_count()\n",
                "# device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available() else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "# device_name = str(device.type)\n",
                "# print(f'Using {device_name.upper()}')\n",
                "\n",
                "# bert_model_name = 'bert-base-uncased'\n",
                "# bert_tokenizer = BertTokenizerFast.from_pretrained(bert_model_name, strip_accents = True)\n",
                "# bert_model = BertForSequenceClassification.from_pretrained(bert_model_name).to(device)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "55afc383",
            "metadata": {},
            "source": [
                "### READ DATA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7b36fe18",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Variables\n",
                "random_state = 42\n",
                "random.seed(random_state)\n",
                "np.random.seed(random_state)\n",
                "torch.manual_seed(random_state)\n",
                "DetectorFactory.seed = random_state\n",
                "method = 'Supervised'\n",
                "n_jobs = -1\n",
                "cv = RepeatedStratifiedKFold(\n",
                "    n_splits=10, n_repeats=3, random_state=random_state)\n",
                "t = time.time()\n",
                "cores = multiprocessing.cpu_count()\n",
                "scoring = 'recall'\n",
                "scores = ['recall', 'accuracy', 'f1', 'roc_auc',\n",
                "          'explained_variance', 'matthews_corrcoef']\n",
                "scorers = {\n",
                "    'precision_score': make_scorer(precision_score),\n",
                "    'recall_score': make_scorer(recall_score),\n",
                "    'accuracy_score': make_scorer(accuracy_score),\n",
                "}\n",
                "analysis_columns = ['Warmth', 'Competence']\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "metrics_dict = {\n",
                "    'Explained Variance': np.nan,\n",
                "    f'Explained Variance - {scoring.title()}': np.nan,\n",
                "    'Accuracy': np.nan,\n",
                "    'Balanced Accuracy': np.nan,\n",
                "    'Precision': np.nan,\n",
                "    'Recall': np.nan,\n",
                "    'F1-score': np.nan,\n",
                "    'Matthews Correlation Coefficient': np.nan,\n",
                "    'Fowlkes–Mallows Index': np.nan,\n",
                "    'ROC': np.nan,\n",
                "    'AUC': np.nan,\n",
                "    f'Best Threshold - {scoring.title()}': np.nan,\n",
                "    f'Best Score - {scoring.title()}': np.nan,\n",
                "    'Log Loss/Cross Entropy': np.nan,\n",
                "    'Cohen’s Kappa': np.nan,\n",
                "    'Geometric Mean': np.nan,\n",
                "    'Classification Report': np.nan,\n",
                "    'Confusion Matrix': np.nan,\n",
                "    'Normalized Confusion Matrix': np.nan\n",
                "}\n",
                "\n",
                "# Plotting\n",
                "plt.style.use('tableau-colorblind10')\n",
                "plt.set_cmap('PuBu_r')\n",
                "pd.set_option('display.max_rows', None)\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.width', 5000)\n",
                "pd.set_option('display.colheader_justify', 'center')\n",
                "pd.set_option('display.precision', 3)\n",
                "pd.set_option('display.float_format', '{:.2f}'.format)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1df119b8",
            "metadata": {},
            "source": [
                "## Vectorizers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3ec7307d",
            "metadata": {},
            "outputs": [],
            "source": [
                "### CountVectorizer\n",
                "count_ = CountVectorizer()\n",
                "count_params = {\n",
                "#     'TfidfVectorizer__stop_words': ['english'],\n",
                "    'CountVectorizer__analyzer': ['word'],\n",
                "    'CountVectorizer__ngram_range': [(1, 3)],\n",
                "    'CountVectorizer__lowercase': [True, False],\n",
                "    'CountVectorizer__max_df': [0.90, 0.85, 0.80, 0.75, 0.70],\n",
                "    'CountVectorizer__min_df': [0.10, 0.15, 0.20, 0.25, 0.30],\n",
                "}\n",
                "count = [count_, count_params]\n",
                "\n",
                "### TfidfVectorizer\n",
                "tfidf_ = TfidfVectorizer()\n",
                "tfidf_params = {\n",
                "#     'TfidfVectorizer__stop_words': ['english'],\n",
                "    'TfidfVectorizer__analyzer': ['word'],\n",
                "    'TfidfVectorizer__ngram_range': [(1, 3)],\n",
                "    'TfidfVectorizer__lowercase': [True, False],\n",
                "    'TfidfVectorizer___use_idf': [True, False],\n",
                "    'TfidfVectorizer__max_df': [0.90, 0.85, 0.80, 0.75, 0.70],\n",
                "    'TfidfVectorizer__min_df': [0.10, 0.15, 0.20, 0.25, 0.30],\n",
                "}\n",
                "tfidf = [tfidf_, tfidf_params]\n",
                "\n",
                "## Vectorizers List\n",
                "vectorizers_list = [\n",
                "    count, \n",
                "    tfidf\n",
                "]\n",
                "\n",
                "### BOW FeatureUnion\n",
                "transformer_list = []\n",
                "bow_params = {}\n",
                "for vectorizer_and_params in vectorizers_list:\n",
                "    transformer_list.append(\n",
                "        (vectorizer_and_params[0].__class__.__name__, vectorizer_and_params[0])\n",
                "    )\n",
                "    for k, v in vectorizer_and_params[1].items():\n",
                "        bow_params[f'FeatureUnion__{k}'] = v\n",
                "\n",
                "bow_ = FeatureUnion(\n",
                "    transformer_list=[transformer_list]\n",
                ")\n",
                "bow = [bow_, bow_params]\n",
                "\n",
                "## Vectorizers List append bow\n",
                "vectorizers_list.append(bow)\n",
                "\n",
                "## Vectorizers Dict\n",
                "vectorizers_pipe = {\n",
                "    vectorizer_and_params[0].__class__.__name__: vectorizer_and_params\n",
                "    for vectorizer_and_params in vectorizers_list\n",
                "}\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4aaff38f",
            "metadata": {},
            "source": [
                "## Selectors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "224d8273",
            "metadata": {},
            "outputs": [],
            "source": [
                "### SelectKBest\n",
                "selectkbest_ = SelectKBest()\n",
                "selectkbest_params = {\n",
                "    'SelectKBest__score_func': [f_classif, chi2, mutual_info_classif, f_regression, mutual_info_regression],\n",
                "    'SelectKBest__k': ['all'],\n",
                "}\n",
                "selectkbest = [selectkbest_, selectkbest_params]\n",
                "\n",
                "### SelectPercentile\n",
                "selectperc_ = SelectPercentile()\n",
                "selectperc_params = {\n",
                "    'SelectPercentile__score_func': [f_classif, chi2, mutual_info_classif, f_regression, mutual_info_regression],\n",
                "    'SelectPercentile__percentile': [30, 40, 50, 60, 70, 80],\n",
                "}\n",
                "selectperc = [selectperc_, selectperc_params]\n",
                "\n",
                "### SelectFpr\n",
                "selectfpr_ = SelectFpr()\n",
                "selectfpr_params = {\n",
                "    'SelectFpr__score_func': [f_classif, chi2, mutual_info_classif, f_regression, mutual_info_regression],\n",
                "}\n",
                "selectfpr = [selectfpr_, selectfpr_params]\n",
                "\n",
                "### SelectFdr\n",
                "selectfdr_ = SelectFdr()\n",
                "selectfdr_params = {\n",
                "    'SelectFdr__score_func': [f_classif, chi2, mutual_info_classif, f_regression, mutual_info_regression],\n",
                "}\n",
                "selectfdr = [selectfdr_, selectfdr_params]\n",
                "\n",
                "### SelectFwe\n",
                "selectfwe_ = SelectFwe()\n",
                "selectfwe_params = {\n",
                "    'SelectFwe__score_func': [f_classif, chi2, mutual_info_classif, f_regression, mutual_info_regression],\n",
                "}\n",
                "selectfwe = [selectfwe_, selectfwe_params]\n",
                "\n",
                "## Selectors List\n",
                "selectors_list = [\n",
                "    selectkbest, selectperc,\n",
                "    # selectfpr, selectfdr, selectfwe\n",
                "]\n",
                "## Selectors Dict\n",
                "selectors_pipe = {\n",
                "    selector_and_params[0].__class__.__name__: selector_and_params\n",
                "    for selector_and_params in selectors_list\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e4da5a77",
            "metadata": {},
            "source": [
                "## Resamplers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b3ed119d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Resamplers\n",
                "### SMOTETomek Resampler\n",
                "smotetomek_ = SMOTETomek()\n",
                "smotetomek_params = {\n",
                "    'SMOTETomek__random_state': [random_state],\n",
                "    'SMOTETomek__tomek': [TomekLinks(sampling_strategy='majority')],\n",
                "}\n",
                "smotetomek = [smotetomek_, smotetomek_params]\n",
                "\n",
                "## Resampler List\n",
                "resamplers_list = [\n",
                "    smotetomek,\n",
                "]\n",
                "\n",
                "## Resampler Dict\n",
                "resamplers_pipe = {\n",
                "    resampler_and_params[0].__class__.__name__: resampler_and_params\n",
                "    for resampler_and_params in resamplers_list\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "78ab6d49",
            "metadata": {},
            "source": [
                "## Classifiers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2222fd23",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Classifiers\n",
                "### Dummy Classifier\n",
                "dummy_ = DummyClassifier()\n",
                "dummy_params = {\n",
                "    'DummyClassifier__strategy': [\n",
                "        'stratified',\n",
                "        'most_frequent',\n",
                "        'prior',\n",
                "        'uniform',\n",
                "    ],\n",
                "    'DummyClassifier__random_state': [random_state],\n",
                "}\n",
                "\n",
                "dummy = [dummy_, dummy_params]\n",
                "\n",
                "### Multinomial Naive Bayes\n",
                "nb_ = MultinomialNB()\n",
                "nb_params = {\n",
                "    'MultinomialNB__fit_prior': [True, False],\n",
                "    # 'MultinomialNB__alpha': [0.1, 0.2, 0.3],\n",
                "}\n",
                "\n",
                "nb = [nb_, nb_params]\n",
                "\n",
                "### Bernoulli Naive Bayes\n",
                "bnb_ = BernoulliNB()\n",
                "bnb_params = {\n",
                "    'BernoulliNB__fit_prior': [True],\n",
                "    'BernoulliNB__alpha': [0.1, 0.2, 0.3],\n",
                "}\n",
                "\n",
                "bnb = [bnb_, bnb_params]\n",
                "\n",
                "### Gaussian Naive Bayes\n",
                "gnb_ = GaussianNB()\n",
                "gnb_params = {\n",
                "    'GaussianNB__var_smoothing': [1e-9],\n",
                "}\n",
                "\n",
                "gnb = [gnb_, gnb_params]\n",
                "\n",
                "### KNeighbors Classifier\n",
                "knn_ = KNeighborsClassifier()\n",
                "knn_params = {\n",
                "    'KNeighborsClassifier__weights': ['uniform', 'distance'],\n",
                "    'KNeighborsClassifier__n_neighbors': [2, 5, 15],\n",
                "    'KNeighborsClassifier__algorithm': ['auto'],\n",
                "    # 'KNeighborsClassifier__leaf_size': [30, 50, 100, 200, 300, 500],\n",
                "    'KNeighborsClassifier__p': [1, 2, 3, 4, 5],\n",
                "    # 'KNeighborsClassifier__metric': [\n",
                "    #     'minkowski',\n",
                "    #     'euclidean',\n",
                "    #     'cosine',\n",
                "    #     'correlation',\n",
                "    # ],\n",
                "    # 'KNeighborsClassifier__metric_params': [None, {'p': 2}, {'p': 3}],\n",
                "}\n",
                "\n",
                "knn = [knn_, knn_params]\n",
                "\n",
                "### Logistic Regression\n",
                "lr_ = LogisticRegression()\n",
                "lr_params = {\n",
                "    'LogisticRegression__penalty': ['elasticnet'],\n",
                "    'LogisticRegression__class_weight': ['balanced'],\n",
                "    'LogisticRegression__random_state': [random_state],\n",
                "    'LogisticRegression__algorithm': ['auto'],\n",
                "    'LogisticRegression__fit_intercept': [True, False],\n",
                "    'LogisticRegression__multi_class': ['auto'],\n",
                "    'LogisticRegression__solver': ['liblinear'],\n",
                "    'LogisticRegression__C': [0.01, 1, 100],\n",
                "    # 'LogisticRegression__max_iter': [100, 200, 300, 500, 1000],\n",
                "}\n",
                "\n",
                "lr = [lr_, lr_params]\n",
                "\n",
                "### Passive Aggressive\n",
                "pa_ = PassiveAggressiveClassifier()\n",
                "pa_params = {\n",
                "    'PassiveAggressiveClassifier__loss': ['hinge', 'squared_hinge'],\n",
                "    'PassiveAggressiveClassifier__random_state': [random_state],\n",
                "    'PassiveAggressiveClassifier__fit_intercept': [True, False],\n",
                "    'PassiveAggressiveClassifier__class_weight': ['balanced'],\n",
                "    'PassiveAggressiveClassifier__shuffle': [True, False],\n",
                "    'PassiveAggressiveClassifier__C': [0.01, 1, 100],\n",
                "    # 'PassiveAggressiveClassifier__max_iter': [100, 200, 300, 500, 1000],\n",
                "}\n",
                "\n",
                "pa = [pa_, pa_params]\n",
                "\n",
                "### Perceptron\n",
                "ptron_ = Perceptron()\n",
                "ptron_params = {\n",
                "    'Perceptron__penalty': ['elasticnet'],\n",
                "    'Perceptron__random_state': [random_state],\n",
                "    'Perceptron__fit_intercept': [True, False],\n",
                "    'Perceptron__class_weight': ['balanced'],\n",
                "    'Perceptron__shuffle': [True, False],\n",
                "    'Perceptron__C': [0.01, 1, 100],\n",
                "    # 'Perceptron__max_iter': [100, 200, 300, 500, 1000],\n",
                "}\n",
                "\n",
                "ptron = [ptron_, ptron_params]\n",
                "\n",
                "### Stochastic Gradient Descent Aggressive\n",
                "sgd_ = SGDClassifier()\n",
                "sgd_params = {\n",
                "    'SGDClassifier__loss': ['hinge', 'squared_hinge'],\n",
                "    'SGDClassifier__random_state': [random_state],\n",
                "    'SGDClassifier__fit_intercept': [True, False],\n",
                "    'SGDClassifier__class_weight': ['balanced'],\n",
                "    # 'SGDClassifier__max_iter': [100, 200, 300, 500, 1000],\n",
                "}\n",
                "\n",
                "sgd = [sgd_, sgd_params]\n",
                "\n",
                "### SVM\n",
                "svm_ = LinearSVC()\n",
                "svm_params = {\n",
                "    'LinearSVC__penalty': ['elasticnet'],\n",
                "    'LinearSVC__loss': ['hinge', 'squared_hinge'],\n",
                "    'LinearSVC__random_state': [random_state],\n",
                "    'LinearSVC__fit_intercept': [True, False],\n",
                "    'LinearSVC__class_weight': ['balanced'],\n",
                "    # 'LinearSVC__multi_class': ['ovr', 'crammer_singer'],\n",
                "    # 'LinearSVC__max_iter': [100, 200, 300, 500, 1000],\n",
                "}\n",
                "\n",
                "svm = [svm_, svm_params]\n",
                "\n",
                "### Decision Tree\n",
                "dt_ = DecisionTreeClassifier()\n",
                "dt_params = {\n",
                "    # 'DecisionTreeClassifier__max_depth': [5, 10],\n",
                "    'DecisionTreeClassifier__criterion': ['gini', 'entropy', 'log_loss'],\n",
                "    'DecisionTreeClassifier__random_state': [random_state],\n",
                "    'DecisionTreeClassifier__splitter': ['best', 'random'],\n",
                "    'DecisionTreeClassifier__max_features': ['auto'],\n",
                "    'DecisionTreeClassifier__class_weight': ['balanced'],\n",
                "}\n",
                "\n",
                "dt = [dt_, dt_params]\n",
                "\n",
                "### Random Forest\n",
                "rf_ = RandomForestClassifier()\n",
                "rf_params = {\n",
                "    'RandomForestClassifier__n_estimators': [10, 20],\n",
                "    'RandomForestClassifier__max_feature': [*np.arange(0.1, 1.1, 0.1)],\n",
                "    'RandomForestClassifier__random_state': [random_state],\n",
                "    'RandomForestClassifier__class_weight': ['balanced'],\n",
                "    'RandomForestClassifier__oob_score': [True],\n",
                "}\n",
                "\n",
                "rf = [rf_, rf_params]\n",
                "\n",
                "### Extra Trees\n",
                "et_ = ExtraTreesClassifier()\n",
                "et_params = {\n",
                "    'ExtraTreesClassifier__max_feature': ['sqrt'],\n",
                "    'ExtraTreesClassifier__random_state': [random_state],\n",
                "    'ExtraTreesClassifier__criterion': ['gini', 'entropy', 'log_loss'],\n",
                "    'ExtraTreesClassifier__class_weight': ['balanced'],\n",
                "}\n",
                "\n",
                "et = [et_, et_params]\n",
                "\n",
                "### Gradient Boosting\n",
                "gbc_ = GradientBoostingClassifier()\n",
                "gbc_params = {\n",
                "    'GradientBoostingClassifier__random_state': [random_state],\n",
                "    'GradientBoostingClassifier__loss': ['log_loss', 'deviance', 'exponential'],\n",
                "    'GradientBoostingClassifier__max_features': ['auto'],\n",
                "}\n",
                "\n",
                "gbc = [gbc_, gbc_params]\n",
                "\n",
                "### AdaBoost\n",
                "ada_ = AdaBoostClassifier()\n",
                "ada_params = {\n",
                "    'AdaBoostClassifier__criterion': ['gini', 'entropy'],\n",
                "    'AdaBoostClassifier__random_state': [random_state],\n",
                "    'AdaBoostClassifier__n_estimators': [50, 100, 150],\n",
                "    'AdaBoostClassifier__base_estimator': [\n",
                "        SVC(kernel='linear'),\n",
                "        LogisticRegression(),\n",
                "        MultinomialNB(),\n",
                "        DecisionTreeClassifier(),\n",
                "    ],\n",
                "}\n",
                "\n",
                "ada = [ada_, ada_params]\n",
                "\n",
                "### XGBoost\n",
                "xgb_ = XGBClassifier()\n",
                "xgb_params = {\n",
                "    'XGBClassifier__seed': [random_state],\n",
                "    'XGBClassifier__eval_metric': ['logloss'],\n",
                "    'XGBClassifier__objective': ['binary:logistic'],\n",
                "}\n",
                "\n",
                "xgb = [xgb_, xgb_params]\n",
                "\n",
                "### MLP Classifier\n",
                "mlpc_ = MLPClassifier()\n",
                "mlpc_params = {\n",
                "    'MLPClassifier__hidden_layer_sizes': [(100,), (50,), (25,), (10,), (5,), (1,)],\n",
                "    'MLPClassifier__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
                "    'MLPClassifier__solver': ['lbfgs', 'sgd', 'adam'],\n",
                "    'MLPClassifier__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
                "    'MLPClassifier__random_state': [random_state],\n",
                "}\n",
                "\n",
                "mlpc = [mlpc_, mlpc_params]\n",
                "\n",
                "### MLP Regressor\n",
                "mlpr_ = MLPRegressor()\n",
                "mlpr_params = {\n",
                "    'MLPRegressor__hidden_layer_sizes': [(100,), (50,), (25,), (10,), (5,), (1,)],\n",
                "    'MLPRegressor__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
                "    'MLPRegressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
                "    'MLPRegressor__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
                "    'MLPRegressor__random_state': [random_state],\n",
                "}\n",
                "\n",
                "mlpr = [mlpr_, mlpr_params]\n",
                "\n",
                "## Classifiers List\n",
                "classifers_list = [\n",
                "    dummy, nb, knn, lr, pa, ptron, svm, dt, rf, ada, xgb, mlpc, \n",
                "    # bnb, gnb, sgd, et, gbc, mlpr\n",
                "]\n",
                "\n",
                "## Classifiers Dict\n",
                "classifiers_pipe = {\n",
                "    classifier_and_params[0].__class__.__name__: classifier_and_params\n",
                "    for classifier_and_params in classifers_list\n",
                "}\n",
                "\n",
                "## Voting and Stacking Classifiers\n",
                "# Estimators for Voting and Stacking Classifiers\n",
                "voting_stacking_estimators = [\n",
                "    (classifier_and_params[0].__class__.__name__, classifier_and_params[0])\n",
                "    for classifier_and_params in classifers_list\n",
                "]\n",
                "\n",
                "### Voting Classifier\n",
                "voting_ = VotingClassifier(estimators = voting_stacking_estimators)\n",
                "voting_params = {\n",
                "    'VotingClassifier__voting': ['soft', 'hard'],\n",
                "    'VotingClassifier__weights': [None],\n",
                "}\n",
                "\n",
                "voting = [voting_, voting_params]\n",
                "\n",
                "### Stacking Classifier\n",
                "stacking_ = StackingClassifier(estimators = voting_stacking_estimators)\n",
                "stacking_params = {\n",
                "    'StackingClassifier__stack_method': ['auto', 'predict_proba', 'decision_function', 'predict'],\n",
                "    'StackingClassifier__passthrough': [True, False],\n",
                "}\n",
                "\n",
                "stacking = [stacking_, stacking_params]\n",
                "\n",
                "# Add stacking and voting classifiers to classifiers pipe dict\n",
                "classifiers_pipe[voting[0].__class__.__name__] = voting\n",
                "classifiers_pipe[stacking[0].__class__.__name__] = stacking\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3f3840ba",
            "metadata": {},
            "outputs": [],
            "source": [
                "def split_data(df, col, analysis_columns, text_col=None):\n",
                "\n",
                "    if text_col is None:\n",
                "        text_col = 'Job Description spacy_sentencized'\n",
                "\n",
                "    train_ratio = 0.75\n",
                "    test_ratio = 0.10\n",
                "    validation_ratio = 0.15\n",
                "    test_split = test_size = 1 - train_ratio\n",
                "    validation_split = test_ratio / (test_ratio + validation_ratio)\n",
                "\n",
                "    # Split\n",
                "    print('='*20)\n",
                "    print('Splitting data into training, testing, and validation sets:')\n",
                "    print(f'Ratios: train_size = {train_ratio}, test size = {test_ratio}, validation size = {validation_ratio}')\n",
                "\n",
                "    df.dropna(subset=analysis_columns, how='any', inplace=True)\n",
                "    df.reset_index(drop=True, inplace=True)\n",
                "\n",
                "    train, test = train_test_split(\n",
                "        df, train_size = 1-test_split, test_size = test_split, random_state=random_state\n",
                "    )\n",
                "\n",
                "    val, test = train_test_split(\n",
                "        test, test_size=validation_split, random_state=random_state\n",
                "    )\n",
                "\n",
                "    X_train = np.array(list(train[text_col].astype('str').values))\n",
                "    y_train = column_or_1d(train[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "    X_test = np.array(list(test[text_col].astype('str').values))\n",
                "    y_test = column_or_1d(test[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "    X_val = np.array(list(val[text_col].astype('str').values))\n",
                "    y_val = column_or_1d(val[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "    class_weights = compute_class_weight(class_weight = 'balanced', classes = [0,1], y = y_train)\n",
                "    class_weights_ratio = class_weights[0]/class_weights[1]\n",
                "    class_weights_dict = dict(zip(np.unique(y_train), class_weights))\n",
                "\n",
                "    print('Done splitting data into training, testing, and validation sets.')\n",
                "    print('='*20)\n",
                "    print(f'Training set shape: {y_train.shape}')\n",
                "    print('-'*10)\n",
                "    print(f'Training set example:\\n{X_train[0]}')\n",
                "    print('~'*10)\n",
                "    print(f'Testing set shape: {y_test.shape}')\n",
                "    print('-'*10)\n",
                "    print(f'Testing set example:\\n{X_test[0]}')\n",
                "    print('~'*10)\n",
                "    print(f'Validation set shape: {y_val.shape}')\n",
                "    print('-'*10)\n",
                "    print(f'Validation set example:\\n{X_val[0]}')\n",
                "    print('~'*10)\n",
                "    print(f'Class weights:\\nRatio = {class_weights_ratio:.2f} (0 = {class_weights[0]:.2f}, 1 = {class_weights[1]:.2f})')\n",
                "    print('='*20)\n",
                "\n",
                "    return (\n",
                "        train, X_train, y_train,\n",
                "        test, X_test, y_test,\n",
                "        val, X_val, y_val,\n",
                "        class_weights,\n",
                "        class_weights_ratio,\n",
                "        class_weights_dict\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "38a135ab",
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_df_metrics(vectorizers_pipe, classifiers_pipe, analysis_columns, metrics_list):\n",
                "\n",
                "    index = pd.MultiIndex.from_product(\n",
                "        [list(map(lambda classifier: classifier, classifiers_pipe.keys()))],\n",
                "        names=['Classifiers'],\n",
                "    )\n",
                "    columns = pd.MultiIndex.from_product(\n",
                "        [\n",
                "            analysis_columns,\n",
                "            list(map(lambda vectorizer: vectorizer, vectorizers_pipe.keys())),\n",
                "            metrics_list,\n",
                "        ],\n",
                "        names=['Variable', 'Vectorizer', 'Measures'],\n",
                "    )\n",
                "    return pd.DataFrame(index=index, columns=columns)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "162b0699",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_metrics(estimator, X_test, y_test, y_test_pred, y_test_pred_prob):\n",
                "\n",
                "    # Get metrics\n",
                "    # Using estimator\n",
                "    cv_score_noscoring = cross_validate(\n",
                "        estimator,\n",
                "        X_test,\n",
                "        y_test,\n",
                "        cv=cv,\n",
                "        return_train_score=True,\n",
                "    )\n",
                "    cv_score = cross_validate(\n",
                "        estimator,\n",
                "        X_test,\n",
                "        y_test,\n",
                "        cv=cv,\n",
                "        return_train_score=True,\n",
                "        scoring=scores,\n",
                "    )\n",
                "    mean_validation_score = cv_score_noscoring['test_score'].mean()\n",
                "    mean_validation_explained_variance_recall = cv_score['test_explained_variance'].mean()\n",
                "    \n",
                "    # Using y_pred\n",
                "    explained_variance = metrics.explained_variance_score(y_test, y_test_pred)\n",
                "    accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
                "    balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_test_pred)\n",
                "    precision = metrics.precision_score(y_test, y_test_pred, pos_label=1, labels=[1, 0])\n",
                "    recall = metrics.recall_score(y_test, y_test_pred, pos_label=1, labels=[1, 0])\n",
                "    f1 = metrics.f1_score(y_test, y_test_pred)\n",
                "    mcc = metrics.matthews_corrcoef(y_test, y_test_pred)\n",
                "    fm = metrics.fowlkes_mallows_score(y_test, y_test_pred)\n",
                "    kappa = metrics.cohen_kappa_score(y_test, y_test_pred)\n",
                "    gmean_iba = imblearn.metrics.make_index_balanced_accuracy(alpha=0.1, squared=True)(geometric_mean_score)\n",
                "    gmean = gmean_iba(y_test, y_test_pred)\n",
                "    report = metrics.classification_report(y_test, y_test_pred)\n",
                "    cm = metrics.confusion_matrix(y_test, y_test_pred)\n",
                "    cm_normalized = metrics.confusion_matrix(y_test, y_test_pred, normalize='true')\n",
                "\n",
                "    # Using y_pred_prob\n",
                "    loss = metrics.log_loss(y_test, y_test_pred_prob)\n",
                "    roc_auc = metrics.roc_auc_score(y_test, y_test_pred_prob)\n",
                "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_test_pred_prob, pos_label=1)\n",
                "    auc = metrics.auc(fpr, tpr)\n",
                "    precision_pr, recall_pr, threshold_pr = metrics.precision_recall_curve(y_test, y_test_pred_prob, pos_label=1)\n",
                "\n",
                "    # Displays\n",
                "    close_plots()\n",
                "    cm_curve = metrics.ConfusionMatrixDisplay.from_predictions(\n",
                "        y_test, y_test_pred\n",
                "    )\n",
                "    cm_normalized_curve = metrics.ConfusionMatrixDisplay.from_predictions(\n",
                "        y_test, y_test_pred, normalize='true'\n",
                "    )\n",
                "    roc_curve = metrics.RocCurveDisplay.from_predictions(\n",
                "        y_test, y_test_pred, pos_label=1\n",
                "    )\n",
                "    pr_curve = metrics.PrecisionRecallDisplay.from_predictions(\n",
                "        y_test, y_test_pred, pos_label=1\n",
                "    )\n",
                "    calibration_curve = CalibrationDisplay.from_predictions(\n",
                "        y_test, y_test_pred, pos_label=1\n",
                "    )\n",
                "    close_plots()\n",
                "\n",
                "    #Place metrics into dict\n",
                "    metrics_dict = {\n",
                "        'Mean Cross Validation Score': float(mean_validation_score),\n",
                "        'Explained Variance': float(explained_variance),\n",
                "        f'Explained Variance - {scoring.title()}': float(mean_validation_explained_variance_recall),\n",
                "        'Accuracy': float(accuracy),\n",
                "        'Balanced Accuracy': float(balanced_accuracy),\n",
                "        'Precision': float(precision),\n",
                "        'Recall': float(recall),\n",
                "        'F1-score': float(f1),\n",
                "        'Matthews Correlation Coefficient': float(mcc),\n",
                "        'Fowlkes–Mallows Index': float(fm),\n",
                "        'ROC': float(roc_auc),\n",
                "        'AUC': float(auc),\n",
                "        f'{scoring.title()} Best Threshold': threshold,\n",
                "        f'{scoring.title()}  Best Score': float(best_score),\n",
                "        'Log Loss/Cross Entropy': float(loss),\n",
                "        'Cohen’s Kappa': float(kappa),\n",
                "        'Geometric Mean': float(gmean),\n",
                "        'Classification Report': report,\n",
                "        'Confusion Matrix': cm,\n",
                "        'Normalized Confusion Matrix': cm_normalized\n",
                "    }\n",
                "\n",
                "    # Visualisation with plot_metric\n",
                "    bc = n_plot_metric.functions.BinaryClassification(y_test, y_test_pred, labels=[0, 1])\n",
                "\n",
                "    # Figures\n",
                "    fig = plt.figure(figsize=(15,10))\n",
                "    plt.subplot2grid((2,6), (1,1), colspan=2)\n",
                "    bc.plot_confusion_matrix(colorbar=True)\n",
                "    plt.subplot2grid((2,6), (1,3), colspan=2)\n",
                "    bc.plot_confusion_matrix(normalize=True, colorbar=True)\n",
                "    plt.subplot2grid(shape=(2,6), loc=(0,0), colspan=2)\n",
                "    bc.plot_roc_curve()\n",
                "    plt.subplot2grid((2,6), (0,2), colspan=2)\n",
                "    bc.plot_precision_recall_curve()\n",
                "    plt.subplot2grid((2,6), (0,4), colspan=2)\n",
                "    bc.plot_class_distribution()\n",
                "    show_and_close_plots()\n",
                "    bc.print_report()\n",
                "    for image_save_format in ['eps', 'png']:\n",
                "        fig.savefig(\n",
                "            f'{plot_save_path}{method} plot_metric Curves {str(col)} - {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
                "            format=image_save_format,\n",
                "            dpi=3000, bbox_inches='tight'\n",
                "        )\n",
                "\n",
                "    return (\n",
                "        metrics_dict, cv_score_noscoring, cv_score,\n",
                "        mean_validation_score, mean_validation_explained_variance_recall, explained_variance,\n",
                "        accuracy, balanced_accuracy, precision, recall,\n",
                "        f1, mcc, fm, loss, kappa, gmean_iba, gmean, report,\n",
                "        cm, cm_normalized, roc_auc, fpr, tpr, threshold, auc,\n",
                "        precision_pr, recall_pr, threshold_pr,\n",
                "        cm_curve, cm_normalized_curve, roc_curve, pr_curve, calibration_curve\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8278ce83",
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluation(\n",
                "    col, vectorizer_name, classifier_name, estimator,\n",
                "    X_test, y_test, y_test_pred, y_test_pred_prob,\n",
                "    best_score, scoring, df_metrics\n",
                "):\n",
                "\n",
                "    # Get metrics dict\n",
                "    (\n",
                "        metrics_dict, cv_score_noscoring, cv_score,\n",
                "        mean_validation_score, mean_validation_explained_variance_recall, explained_variance,\n",
                "        accuracy, balanced_accuracy, precision, recall,\n",
                "        f1, mcc, fm, loss, kappa, gmean_iba, gmean, report,\n",
                "        cm, cm_normalized, roc_auc, fpr, tpr, threshold, auc,\n",
                "        precision_pr, recall_pr, threshold_pr,\n",
                "        cm_curve, cm_normalized_curve, roc_curve, pr_curve, calibration_curve\n",
                "    ) = compute_metrics(estimator, X_test, y_test, y_test_pred, y_test_pred_prob)\n",
                "\n",
                "    # Print metrics\n",
                "    print('=' * 20)\n",
                "    print('~' * 20)\n",
                "    print(f' Metrics for {str(col)} - {vectorizer_name} + {classifier_name}')\n",
                "    print('~' * 20)\n",
                "    print(f'Classification Report:\\n {metrics_dict[\"Classification Report\"]}')\n",
                "    print('-' * 20)\n",
                "    for metric_name, metric_value in metrics_dict.items():\n",
                "        if isinstance(metric_name, float):\n",
                "            print(f'{metric_name}: {round(float(metric_value), 2)}')\n",
                "        else:\n",
                "            print(f'{metric_name}: {metric_value}')\n",
                "        print('-' * 20)\n",
                "\n",
                "        # Fill Table DF\n",
                "        if isinstance(metric_value, float):\n",
                "            df_metrics.loc[\n",
                "                (classifier_name), (col, vectorizer_name, metric_name)\n",
                "            ] = metric_value\n",
                "        else:\n",
                "            df_metrics.loc[\n",
                "                (classifier_name), (col, vectorizer_name, metric_name)\n",
                "            ] = str(metric_value)\n",
                "\n",
                "    print('=' * 20)\n",
                "\n",
                "    # Plot Metrics\n",
                "    plot_metrics(\n",
                "        cm_curve, cm_normalized_curve, roc_curve, pr_curve, calibration_curve, col, vectorizer_name, classifier_name\n",
                "    )\n",
                "\n",
                "    return df_metrics, metrics_dict\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b4a26e56",
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_and_close_plots():\n",
                "    plt.show()\n",
                "    plt.clf()\n",
                "    plt.cla()\n",
                "    plt.close()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "675cf660",
            "metadata": {},
            "outputs": [],
            "source": [
                "def close_plots():\n",
                "    plt.clf()\n",
                "    plt.cla()\n",
                "    plt.close()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "42fdf3c3",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_metrics(cm_curve, cm_normalized_curve, roc_curve, pr_curve, calibration_curve, col, vectorizer_name, classifier_name):\n",
                "\n",
                "    # Plots\n",
                "    plots_dict = {\n",
                "        'Confusion Matrix': cm_curve,\n",
                "        'Normalized Confusion Matrix': cm_normalized_curve,\n",
                "        'ROC Curve': roc_curve,\n",
                "        'Precision-Recall Curve': pr_curve,\n",
                "        'Calibration Curve': calibration_curve,\n",
                "    }\n",
                "\n",
                "    \n",
                "    print('=' * 20)\n",
                "    close_plots()\n",
                "    print('Plotting:')\n",
                "\n",
                "    for plot_name, plot_ in plots_dict.items():\n",
                "        print(f'Plotting {plot_name}:')\n",
                "        fig, ax = plt.subplots()\n",
                "        ax.set_title(f'{str(col)} - {plot_name} {vectorizer_name} + {classifier_name}')\n",
                "        if plot_name == 'ROC Curve':\n",
                "            ax.plot([0, 1], [0, 1],'r--', lw=1)\n",
                "        plot_.plot(ax=ax)\n",
                "        show_and_close_plots()\n",
                "        print('=' * 20)\n",
                "\n",
                "        # Save Plots\n",
                "        print(f'Saving {plot_name}...')\n",
                "        for image_save_format in ['eps', 'png']:\n",
                "            fig.savefig(\n",
                "                f'{plot_save_path}{method} {str(col)} - {plot_name} {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
                "                format=image_save_format, dpi=3000, bbox_inches='tight'\n",
                "            )\n",
                "        print(f'Saved {plot_name}!')\n",
                "        print('=' * 20)\n",
                "\n",
                "    # ## Confusion Matrix\n",
                "    # print('-' * 20)\n",
                "    # print('Confusion Matrix:')\n",
                "    # fig, ax = plt.subplots()\n",
                "    # ax.set_title(f'{str(col)} - Confusion Matrix {vectorizer_name} + {classifier_name}')\n",
                "    # cm_curve.plot(ax=ax)\n",
                "    # show_and_close_plots()\n",
                "\n",
                "    # ## Normalized Confusion Matrix\n",
                "    # print('-' * 20)\n",
                "    # print('Normalized Confusion Matrix:')\n",
                "    # fig, ax = plt.subplots()\n",
                "    # ax.set_title(f'{str(col)} - Normalized Confusion Matrix {vectorizer_name} + {classifier_name}')\n",
                "    # cm_normalized_curve.plot(ax=ax)\n",
                "    # show_and_close_plots()\n",
                "    # ## ROC Curve\n",
                "    # print('-' * 20)\n",
                "    # print('ROC Curve:')\n",
                "    # fig, ax = plt.subplots()\n",
                "    # ax.set_title(f'ROC Curve {str(col)} - {vectorizer_name} + {classifier_name}')\n",
                "    # roc_curve.plot(ax=ax)\n",
                "    # ax.plot([0, 1], [0, 1],'r--', lw=1)\n",
                "    # show_and_close_plots()\n",
                "\n",
                "    # ## PR Curve\n",
                "    # print('-' * 20)\n",
                "    # print('Precision Recall Curve:')\n",
                "    # fig, ax = plt.subplots()\n",
                "    # ax.set_title(f'{str(col)} - Precision-Recall Curve {vectorizer_name} + {classifier_name}')\n",
                "    # pr_curve.plot(ax=ax)\n",
                "    # show_and_close_plots()\n",
                "    \n",
                "    # ## Calibration Curve\n",
                "    # print('-' * 20)\n",
                "    # print('Calibration Curve:')\n",
                "    # fig, ax = plt.subplots()\n",
                "    # ax.set_title(f'{str(col)} - Calibration Curve {vectorizer_name} + {classifier_name}')\n",
                "    # calibration_curve.plot(ax=ax)\n",
                "    # show_and_close_plots()\n",
                "    # print('=' * 20)\n",
                "\n",
                "    # # Save Plots\n",
                "    # print('Saving plots...')\n",
                "    # for image_save_format in ['eps', 'png']:\n",
                "    #     cm_curve.figure_.savefig(\n",
                "    #         f'{plot_save_path}{method} {str(col)} - Confusion Matrix {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
                "    #         format=image_save_format,\n",
                "    #         dpi=3000, bbox_inches='tight'\n",
                "    #     )\n",
                "\n",
                "    #     cm_normalized_curve.figure_.savefig(\n",
                "    #         f'{plot_save_path}{method} {str(col)} - Normalized Confusion Matrix {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
                "    #         format=image_save_format,\n",
                "    #         dpi=3000, bbox_inches='tight'\n",
                "    #     )\n",
                "\n",
                "    #     roc_curve.figure_.savefig(\n",
                "    #         f'{plot_save_path}{method} {str(col)} - ROC Curve {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
                "    #         format=image_save_format,\n",
                "    #         dpi=3000, bbox_inches='tight'\n",
                "    #     )\n",
                "\n",
                "    #     pr_curve.figure_.savefig(\n",
                "    #         f'{plot_save_path}{method} {str(col)} - Precision Recall Curve {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
                "    #         format=image_save_format,\n",
                "    #         dpi=3000, bbox_inches='tight'\n",
                "    #     )\n",
                "\n",
                "    #     calibration_curve.figure_.savefig(\n",
                "    #         f'{plot_save_path}{method} {str(col)} - Calibration Curve {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
                "    #         format=image_save_format,\n",
                "    #         dpi=3000, bbox_inches='tight'\n",
                "    #     )\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c44994c4",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4b48de3a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save Model\n",
                "def saving_model_and_table(df_metrics, estimator, col, vectorizer_name, classifier_name):\n",
                "\n",
                "    # Save metrics df\n",
                "    print(f'Saving Model and Table for {vectorizer_name} + {classifier_name}.')\n",
                "    df_metrics.to_csv(f'{table_save_path}Classifiers Table.csv')\n",
                "    df_metrics.to_pickle(f'{table_save_path}Classifiers Table.pkl')\n",
                "    df_metrics.to_excel(f'{table_save_path}Classifiers Table.xlsx')\n",
                "    df_metrics.style.to_latex(f'{table_save_path}Classifiers Table.tex')\n",
                "    df_metrics.to_markdown(f'{table_save_path}Classifiers Table.md')\n",
                "\n",
                "    # Save estimator\n",
                "    with open(f'{models_save_path}{method} Estimator {str(col)} - {vectorizer_name} + {classifier_name}.pkl', 'wb') as f:\n",
                "        joblib.dump(estimator, f)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8fc524e4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save Model\n",
                "def get_fitted_estimators():\n",
                "    \n",
                "    estimators_list = []\n",
                "\n",
                "    for model_path in glob.glob(f'{models_save_path}*.pkl'):\n",
                "        with open(model_path, 'rb') as f:\n",
                "            estimators_list.append(joblib.load(f))\n",
                "\n",
                "    return estimators_list\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "34e44624",
            "metadata": {},
            "outputs": [],
            "source": [
                "def comparison_plots(estimators_list, X_test, y_test, col, curves_dict=None, cmap=plt.cm.Blues):\n",
                "\n",
                "    curves_dict = {\n",
                "        'ROC Curve': metrics.RocCurveDisplay,\n",
                "        'Precision Recall Curve': metrics.PrecisionRecallDisplay,\n",
                "        'Calibration Curve': metrics.CalibrationDisplay,\n",
                "    }\n",
                "\n",
                "    assert len(estimators_list) != 0\n",
                "\n",
                "    for curve_name, curve_package in curves_dict.items():\n",
                "        print('-' * 20)\n",
                "        print(f'{str(curve_name)}: {str(col)}')\n",
                "        fig, ax = plt.subplots()\n",
                "        ax.set_title(f'{str(curve_name)}: {str(col)}')\n",
                "        for estimator in estimators_list:\n",
                "            curve = curve_package.from_estimator(\n",
                "                estimator, X_test, y_test, pos_label=1, ax=ax, cmap=cmap,\n",
                "                name=f'{estimator.steps[0][0]} + {estimator.steps[1][0]} + {estimator.steps[-1][0]}'\n",
                "            )\n",
                "        show_and_close_plots()\n",
                "\n",
                "        # Save Plots\n",
                "        print('Saving plots.')\n",
                "        for image_save_format in ['eps', 'png']:\n",
                "            curve.figure_.savefig(\n",
                "                f'{plot_save_path}{method} {str(col)} - All {str(curve_name)}s.{image_save_format}',\n",
                "                format=image_save_format,\n",
                "                dpi=3000, bbox_inches='tight'\n",
                "            )\n",
                "\n",
                "    # print('=' * 20)\n",
                "    # ## ROC Curve\n",
                "    # print('-' * 20)\n",
                "    # print(f'ROC Curve: {str(col)}')\n",
                "    # fig, ax = plt.subplots()\n",
                "    # ax.set_title(f'ROC Curve: {str(col)}')\n",
                "    # for estimator in estimators_list:\n",
                "    #     roc_curve = metrics.RocCurveDisplay.from_estimator(\n",
                "    #         estimator, X_test, y_test, pos_label=1, ax=ax,\n",
                "    #         name=f'{estimator.steps[0][0]} + {estimator.steps[1][0]} + {estimator.steps[-1][0]}'\n",
                "    #     )\n",
                "    # show_and_close_plots()\n",
                "\n",
                "    # ## PR Curve\n",
                "    # print('-' * 20)\n",
                "    # print(f'Precision Recall Curve: {str(col)}')\n",
                "    # fig, ax = plt.subplots()\n",
                "    # ax.set_title(f'Precision Recall Curve: {str(col)}')\n",
                "    # ax.set_ylabel('Precision')\n",
                "    # ax.set_xlabel('Recall')\n",
                "    # for estimator in estimators_list:\n",
                "    #     pr_curve = metrics.PrecisionRecallDisplay.from_estimator(\n",
                "    #         estimator, X_test, y_test, pos_label=1, ax=ax,\n",
                "    #         name=f'{estimator.steps[0][0]} + {estimator.steps[1][0]} + {estimator.steps[-1][0]}'\n",
                "    #     )\n",
                "    # show_and_close_plots()\n",
                "\n",
                "    # ## Calibration Curve\n",
                "    # print('-' * 20)\n",
                "    # print(f'Calibration Curve: {str(col)}')\n",
                "    # fig, ax = plt.subplots()\n",
                "    # ax.set_title(f'Calibration Curve: {str(col)}')\n",
                "    # for estimator in estimators_list:\n",
                "    #     calibration_curve = CalibrationDisplay.from_estimator(\n",
                "    #         estimator, X_test, y_test, pos_label=1, ax=ax, name=f'{estimator.steps[0][0]} + {estimator.steps[1][0]} + {estimator.steps[-1][0]}'\n",
                "    #     )\n",
                "    # show_and_close_plots()\n",
                "    # print('=' * 20)\n",
                "\n",
                "    # # Save Plots\n",
                "    # print('Saving plots.')\n",
                "    # for image_save_format in ['eps', 'png']:\n",
                "    #     roc_curve.figure_.savefig(\n",
                "    #         f'{plot_save_path}{method} All ROC Curve {str(col)}.{image_save_format}',\n",
                "    #         format=image_save_format,\n",
                "    #         dpi=3000, bbox_inches='tight'\n",
                "    #     )\n",
                "\n",
                "    #     pr_curve.figure_.savefig(\n",
                "    #         f'{plot_save_path}{method} All Precision Recall Curve {str(col)}.{image_save_format}',\n",
                "    #         format=image_save_format,\n",
                "    #         dpi=3000, bbox_inches='tight'\n",
                "    #     )\n",
                "\n",
                "    #     calibration_curve.figure_.savefig(\n",
                "    #         f'{plot_save_path}{method} All Calibration Curve {str(col)}.{image_save_format}',\n",
                "    #         format=image_save_format,\n",
                "    #         dpi=3000, bbox_inches='tight'\n",
                "    #     )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "52fe8e7a",
            "metadata": {},
            "source": [
                "### READ DATA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f7fbe29f",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_trainning.pkl').reset_index(drop=True)\n",
                "# TODO REMOVE THIS!!!!!!\n",
                "df_manual = df_manual.groupby(analysis_columns).sample(n=50).reset_index(drop = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a0212dc9",
            "metadata": {
                "code_folding": [],
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "%%time\n",
                "print('#'*40)\n",
                "print('Starting!')\n",
                "print('#'*40)\n",
                "\n",
                "analysis_columns = ['Warmth', 'Competence']\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "\n",
                "# Load Table DF\n",
                "df_metrics = make_df_metrics(vectorizers_pipe, classifiers_pipe, analysis_columns, list(metrics_dict.keys()))\n",
                "\n",
                "for col in analysis_columns:\n",
                "\n",
                "    print('-'*20)\n",
                "    print(f'{\"=\"*30} TRAINING {col.upper()} {\"=\"*30}')\n",
                "    print('-'*20)\n",
                "    print(f'Vectorizers to be used ({len(list(vectorizers_pipe.values()))}):\\n{list(vectorizers_pipe.keys())}')\n",
                "    print(f'Total number of vectorizer parameters = {sum([len(list(vectorizers_pipe.values())[i][1]) for i in range(len(vectorizers_pipe))])}')\n",
                "    print(f'Selectors to be used ({len(list(selectors_pipe.values()))}):\\n{list(selectors_pipe.keys())}')\n",
                "    print(f'Total number of selector parameters = {sum([len(list(selectors_pipe.values())[i][1]) for i in range(len(selectors_pipe))])}')\n",
                "    print(f'Resamplers to be used ({len(list(resamplers_pipe.keys()))}):\\n{list(resamplers_pipe.keys())}')\n",
                "    print(f'Total number of resamplers parameters = {sum([len(list(resamplers_pipe.values())[i][1]) for i in range(len(resamplers_pipe))])}')\n",
                "    print(f'Classifers to be used ({len(list(classifiers_pipe.keys()))}):\\n{list(classifiers_pipe.keys())}')\n",
                "    print(f'Total number of classifers parameters = {sum([len(list(classifiers_pipe.values())[i][1]) for i in range(len(classifiers_pipe))])}')\n",
                "    \n",
                "\n",
                "    assert len(df_manual[df_manual[str(col)].map(df_manual[str(col)].value_counts() > 1)]) != 0\n",
                "\n",
                "    # Split\n",
                "    (\n",
                "        train, X_train, y_train,\n",
                "        test, X_test, y_test,\n",
                "        val, X_val, y_val,\n",
                "        class_weights,\n",
                "        class_weights_ratio,\n",
                "        class_weights_dict\n",
                "    ) = split_data(\n",
                "        df=df_manual, col=col, analysis_columns=analysis_columns, text_col=text_col\n",
                "    )\n",
                "\n",
                "    for (\n",
                "        vectorizer_name, vectorizer_and_params\n",
                "    ), (\n",
                "        selector_name, selector_and_params\n",
                "    ), (\n",
                "        resampler_name, resampler_and_params\n",
                "    ), (\n",
                "        classifier_name, classifier_and_params\n",
                "    ) in itertools.product(\n",
                "        vectorizers_pipe.items(), selectors_pipe.items(), resamplers_pipe.items(), classifiers_pipe.items()\n",
                "    ):\n",
                "\n",
                "        vectorizer = vectorizer_and_params[0]\n",
                "        vectorizer_params = vectorizer_and_params[1]\n",
                "\n",
                "        selector = selector_and_params[0]\n",
                "        selector_params = selector_and_params[1]\n",
                "\n",
                "        resampler = resampler_and_params[0]\n",
                "        resampler_params = resampler_and_params[1]\n",
                "\n",
                "        classifier = classifier_and_params[0]\n",
                "        classifier_params = classifier_and_params[1]\n",
                "\n",
                "        # Pipeline\n",
                "        ## Steps\n",
                "        if col == 'Warmth':\n",
                "            steps = [\n",
                "                (vectorizer_name, vectorizer),\n",
                "                (selector_name, selector),\n",
                "                (resampler_name, resampler),\n",
                "                (classifier_name, classifier)\n",
                "            ]\n",
                "        else:\n",
                "            steps = [\n",
                "                (vectorizer_name, vectorizer),\n",
                "                (selector_name, selector),\n",
                "                (classifier_name, classifier)\n",
                "            ]\n",
                "\n",
                "        ## Params\n",
                "        param_grid = {\n",
                "            **vectorizer_params,\n",
                "            **selector_params,\n",
                "            **classifier_params,\n",
                "        }\n",
                "\n",
                "        ## Pipeline\n",
                "        pipe = imblearn.pipeline.Pipeline(steps=steps)\n",
                "\n",
                "        # Search\n",
                "        print('-'*20)\n",
                "        print(f'{\"=\"*30} Using GridSearchCV {\"=\"*30}')\n",
                "        print('-'*20)\n",
                "        print(f'GridSearchCV with:\\nPipe:\\n{pipe}\\nParams:\\n{param_grid}')\n",
                "        print('+'*30)\n",
                "        search = GridSearchCV(\n",
                "            estimator=pipe,\n",
                "            param_grid=param_grid,\n",
                "            n_jobs=n_jobs,\n",
                "            scoring=scores,\n",
                "            cv=cv,\n",
                "            refit=scoring,\n",
                "            return_train_score=True,\n",
                "        )\n",
                "\n",
                "        # Fit SearchCV\n",
                "        with joblib.parallel_backend(backend='threading', n_jobs=n_jobs):\n",
                "            searchcv = search.fit(X_train, y_train)\n",
                "\n",
                "        # HACK REMOVE THIS!!!!!!\n",
                "        sys.exit(0)\n",
                "        # Best Parameters on CV\n",
                "        best_index = searchcv.best_index_\n",
                "        mean_train_recall = searchcv.cv_results_['mean_train_recall'][best_index]\n",
                "        std_train_recall = searchcv.cv_results_['std_train_recall'][best_index]\n",
                "        mean_test_recall = searchcv.cv_results_['mean_test_recall'][best_index]\n",
                "        std_test_recall = searchcv.cv_results_['std_test_recall'][best_index]\n",
                "        best_params = searchcv.best_params_\n",
                "        best_score = searchcv.best_score_\n",
                "        n_splits = searchcv.n_splits_\n",
                "        estimator = searchcv.best_estimator_\n",
                "        y_train_pred = estimator.predict(X_train)\n",
                "\n",
                "        # Identify and name steps in estimator\n",
                "        vectorizer = estimator[0]\n",
                "        vectorizer_name = vectorizer.__class__.__name__\n",
                "        selector = estimator[1]\n",
                "        selector_name = selector.__class__.__name__\n",
                "        classifier = estimator[-1]\n",
                "        classifier_name = classifier.__class__.__name__\n",
                "        if col == 'Warmth':\n",
                "            resampler = estimator[-2]\n",
                "            resampler_name = resampler.__class__.__name__\n",
                "\n",
                "        print('=' * 20)\n",
                "        print(f'Best mean train for {scores[0].title()}: M = {mean_train_recall:.2f}, SD = {std_train_recall:.2f}')\n",
                "        print(f'Best mean test for {scores[0].title()}: M = {mean_test_recall:.2f}, SD = {std_test_recall:.2f}')\n",
                "        print(f'Best score for {scores[0].title()}: {best_score:.2f}')\n",
                "        print(f'Number of splits for {scores[0].title()}: {n_splits}')\n",
                "        print(f'Best estimator and parameters for {scores[0].title()}: {estimator}')\n",
                "        print('-' * 20)\n",
                "\n",
                "        print('-' * 20)\n",
                "        train_report = classification_report(y_train, y_train_pred)\n",
                "        print(f'Training Classification Report:\\n{train_report}')\n",
                "        print('Training Confusion Matrix:')\n",
                "        fig, ax = plt.subplots()\n",
                "        ax.set_title(f'Training Confusion Matrix {str(col)} - {vectorizer_name} + {classifier_name}')\n",
                "        train_cm = metrics.ConfusionMatrixDisplay.from_estimator(\n",
                "            estimator, X_train, y_train, ax=ax, cmap=plt.cm.Blues\n",
                "        )\n",
                "        show_and_close_plots()\n",
                "        print('=' * 20)\n",
                "\n",
                "        # Make predictions\n",
                "        if hasattr(searchcv, 'predict_proba'):\n",
                "            searchcv_predict_attr = searchcv.predict_proba\n",
                "        elif hasattr(searchcv, '_predict_proba_lr'):\n",
                "            searchcv_predict_attr = searchcv._predict_proba_lr\n",
                "        score = searchcv.score(X_test, y_test)\n",
                "        y_test_pred = searchcv.predict(X_test)\n",
                "        y_test_pred_prob = searchcv_predict_attr(X_test)[:, 1]\n",
                "\n",
                "        # Fit best model on testing set with SelectFromModel\n",
                "        print(f'Fitting {estimator}.')\n",
                "        estimator.set_params(**estimator.get_params())\n",
                "        estimator = estimator.fit(X_test, y_test)\n",
                "\n",
                "        # Evaluate Model\n",
                "        df_metrics, metrics_dict = evaluation(\n",
                "            col, vectorizer_name, classifier_name, estimator,\n",
                "            X_test, y_test, y_test_pred, y_test_pred_prob,\n",
                "            best_score, scoring, df_metrics\n",
                "        )\n",
                "\n",
                "        # Save Vectorizer, Selector, and Classifier\n",
                "        saving_model_and_table(df_metrics, estimator, col, vectorizer_name, classifier_name)\n",
                "\n",
                "    # Compare Estimators\n",
                "    print('='*20)\n",
                "    print(f'Comparing Estimators for {col}')\n",
                "    comparison_plots(get_fitted_estimators(), X_test, y_test, col)\n",
                "    print('='*20)\n",
                "\n",
                "print('#'*40)\n",
                "print('DONE!')\n",
                "print('#'*40)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2f029ed9",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Best Parameters on CV\n",
                "best_index = searchcv.best_index_\n",
                "mean_train_recall = searchcv.cv_results_['mean_train_recall'][best_index]\n",
                "std_train_recall = searchcv.cv_results_['std_train_recall'][best_index]\n",
                "mean_test_recall = searchcv.cv_results_['mean_test_recall'][best_index]\n",
                "std_test_recall = searchcv.cv_results_['std_test_recall'][best_index]\n",
                "best_params = searchcv.best_params_\n",
                "best_score = searchcv.best_score_\n",
                "n_splits = searchcv.n_splits_\n",
                "estimator = searchcv.best_estimator_\n",
                "y_train_pred = estimator.predict(X_train)\n",
                "\n",
                "# Identify and name steps in estimator\n",
                "vectorizer = estimator[0]\n",
                "vectorizer_name = vectorizer.__class__.__name__\n",
                "selector = estimator[1]\n",
                "selector_name = selector.__class__.__name__\n",
                "classifier = estimator[-1]\n",
                "classifier_name = classifier.__class__.__name__\n",
                "if col == 'Warmth':\n",
                "    resampler = estimator[-2]\n",
                "    resampler_name = resampler.__class__.__name__\n",
                "\n",
                "print('=' * 20)\n",
                "print(f'Best mean train for {scores[0].title()}: M = {mean_train_recall:.2f}, SD = {std_train_recall:.2f}')\n",
                "print(f'Best mean test for {scores[0].title()}: M = {mean_test_recall:.2f}, SD = {std_test_recall:.2f}')\n",
                "print(f'Best score for {scores[0].title()}: {best_score:.2f}')\n",
                "print(f'Number of splits for {scores[0].title()}: {n_splits}')\n",
                "print(f'Best estimator and parameters for {scores[0].title()}: {estimator}')\n",
                "print('-' * 20)\n",
                "\n",
                "print('-' * 20)\n",
                "train_report = classification_report(y_train, y_train_pred)\n",
                "print(f'Training Classification Report:\\n{train_report}')\n",
                "print('Training Confusion Matrix:')\n",
                "fig, ax = plt.subplots()\n",
                "ax.set_title(f'Training Confusion Matrix {str(col)} - {vectorizer_name} + {classifier_name}')\n",
                "train_cm = metrics.ConfusionMatrixDisplay.from_estimator(\n",
                "    estimator, X_train, y_train, ax=ax, cmap=plt.cm.Blues\n",
                ")\n",
                "show_and_close_plots()\n",
                "print('=' * 20)\n",
                "\n",
                "# Make predictions\n",
                "if hasattr(searchcv, 'predict_proba'):\n",
                "    searchcv_predict_attr = searchcv.predict_proba\n",
                "elif hasattr(searchcv, '_predict_proba_lr'):\n",
                "    searchcv_predict_attr = searchcv._predict_proba_lr\n",
                "score = searchcv.score(X_test, y_test)\n",
                "y_test_pred = searchcv.predict(X_test)\n",
                "y_test_pred_prob = searchcv_predict_attr(X_test)[:, 1]\n",
                "\n",
                "# Fit best model on testing set with SelectFromModel\n",
                "print(f'Fitting {estimator}.')\n",
                "estimator.set_params(**estimator.get_params())\n",
                "estimator = estimator.fit(X_test, y_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "368c62ff",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate the models using crossvalidation\n",
                "def true_fun(X):\n",
                "    return np.cos(1.5 * np.pi * X)\n",
                "\n",
                "degrees = [1, 4, 15]\n",
                "\n",
                "\n",
                "plt.figure(figsize=(14, 5))\n",
                "for i in range(len(degrees)):\n",
                "    cross_val_scores = cross_val_score(\n",
                "        estimator, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=10\n",
                "    )\n",
                "\n",
                "    plt.plot(X_test, y_test_pred, label=\"Model\")\n",
                "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
                "    plt.scatter(X_train, y_train, edgecolor=\"b\", s=20, label=\"Samples\")\n",
                "    plt.xlabel(\"x\")\n",
                "    plt.ylabel(\"y\")\n",
                "    plt.xlim((0, 1))\n",
                "    plt.ylim((-2, 2))\n",
                "    plt.legend(loc=\"best\")\n",
                "    plt.title(\n",
                "        \"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n",
                "            degrees[i], -cross_val_scores.mean(), cross_val_scores.std()\n",
                "        )\n",
                "    )\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ab9903b7",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.preprocessing import PolynomialFeatures\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.model_selection import cross_val_score\n",
                "\n",
                "\n",
                "def true_fun(X):\n",
                "    return np.cos(1.5 * np.pi * X)\n",
                "\n",
                "\n",
                "np.random.seed(0)\n",
                "\n",
                "n_samples = 30\n",
                "degrees = [1, 4, 15]\n",
                "\n",
                "X = np.sort(np.random.rand(n_samples))\n",
                "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
                "\n",
                "plt.figure(figsize=(14, 5))\n",
                "for i in range(len(degrees)):\n",
                "    ax = plt.subplot(1, len(degrees), i + 1)\n",
                "    plt.setp(ax, xticks=(), yticks=())\n",
                "\n",
                "    polynomial_features = PolynomialFeatures(\n",
                "        degree=degrees[i], include_bias=False)\n",
                "    linear_regression = LinearRegression()\n",
                "    pipeline = Pipeline(\n",
                "        [\n",
                "            (\"polynomial_features\", polynomial_features),\n",
                "            (\"linear_regression\", linear_regression),\n",
                "        ]\n",
                "    )\n",
                "    pipeline.fit(X[:, np.newaxis], y)\n",
                "\n",
                "    # Evaluate the models using crossvalidation\n",
                "    cross_val_scores = cross_val_score(\n",
                "        pipeline, X[:, np.newaxis], y, scoring=\"neg_mean_squared_error\", cv=10\n",
                "    )\n",
                "\n",
                "    X_test = np.linspace(0, 1, 100)\n",
                "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
                "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
                "    plt.scatter(X, y, edgecolor=\"b\", s=20, label=\"Samples\")\n",
                "    plt.xlabel(\"x\")\n",
                "    plt.ylabel(\"y\")\n",
                "    plt.xlim((0, 1))\n",
                "    plt.ylim((-2, 2))\n",
                "    plt.legend(loc=\"best\")\n",
                "    plt.title(\n",
                "        \"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n",
                "            degrees[i], -cross_val_scores.mean(), cross_val_scores.std()\n",
                "        )\n",
                "    )\n",
                "plt.show()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "study1_3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        },
        "varInspector": {
            "cols": {
                "lenName": 16,
                "lenType": 16,
                "lenVar": 40
            },
            "kernels_config": {
                "python": {
                    "delete_cmd_postfix": "",
                    "delete_cmd_prefix": "del ",
                    "library": "var_list.py",
                    "varRefreshCmd": "print(var_dic_list())"
                },
                "r": {
                    "delete_cmd_postfix": ") ",
                    "delete_cmd_prefix": "rm(",
                    "library": "var_list.r",
                    "varRefreshCmd": "cat(var_dic_list()) "
                }
            },
            "types_to_exclude": [
                "module",
                "function",
                "builtin_function_or_method",
                "instance",
                "_Feature"
            ],
            "window_display": false
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
