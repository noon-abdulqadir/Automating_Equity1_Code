{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 167,
            "id": "50d4c434",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 168,
            "id": "3abbb866",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import *  # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 169,
            "id": "65134b3c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using MPS\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
                        "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
                        "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
                        "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
                        "/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a7b57d7344a4426ea7fdf5bd936b002c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "24d0c8b36ec341dca85f0301fcea506f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Transformer variables\n",
                "method = 'BERT'\n",
                "results_save_path = f'{models_save_path}{method} Results/'\n",
                "t = time.time()\n",
                "n_jobs = -1\n",
                "n_splits = 10\n",
                "n_repeats = 3\n",
                "random_state = 42\n",
                "refit = True\n",
                "class_weight = 'balanced'\n",
                "cv = RepeatedStratifiedKFold(\n",
                "    n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
                ")\n",
                "scoring = 'recall'\n",
                "scores = [\n",
                "    'recall', 'accuracy', 'f1', 'roc_auc',\n",
                "    'explained_variance', 'matthews_corrcoef'\n",
                "]\n",
                "scorers = {\n",
                "    'precision_score': make_scorer(precision_score),\n",
                "    'recall_score': make_scorer(recall_score),\n",
                "    'accuracy_score': make_scorer(accuracy_score),\n",
                "}\n",
                "analysis_columns = ['Warmth', 'Competence']\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "metrics_dict = {\n",
                "    'Mean Cross Validation Train Score': np.nan,\n",
                "    f'Mean Cross Validation Train - {scoring.title()}': np.nan,\n",
                "    f'Mean Explained Train Variance - {scoring.title()}': np.nan,\n",
                "    'Mean Cross Validation Test Score': np.nan,\n",
                "    f'Mean Cross Validation Test - {scoring.title()}': np.nan,\n",
                "    f'Mean Explained Test Variance - {scoring.title()}': np.nan,\n",
                "    'Explained Variance': np.nan,\n",
                "    'Accuracy': np.nan,\n",
                "    'Balanced Accuracy': np.nan,\n",
                "    'Precision': np.nan,\n",
                "    'Recall': np.nan,\n",
                "    'F1-score': np.nan,\n",
                "    'Matthews Correlation Coefficient': np.nan,\n",
                "    'Fowlkes–Mallows Index': np.nan,\n",
                "    'ROC': np.nan,\n",
                "    'AUC': np.nan,\n",
                "    f'{scoring.title()} Best Threshold': np.nan,\n",
                "    f'{scoring.title()} Best Score': np.nan,\n",
                "    'Log Loss/Cross Entropy': np.nan,\n",
                "    'Cohen’s Kappa': np.nan,\n",
                "    'Geometric Mean': np.nan,\n",
                "    'Classification Report': np.nan,\n",
                "    'Imbalanced Classification Report': np.nan,\n",
                "    'Confusion Matrix': np.nan,\n",
                "    'Normalized Confusion Matrix': np.nan\n",
                "}\n",
                "\n",
                "# Transformer variables\n",
                "max_length = 512\n",
                "returned_tensor = 'pt'\n",
                "cpu_counts = torch.multiprocessing.cpu_count()\n",
                "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available(\n",
                ") else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "device_name = str(device.type)\n",
                "print(f'Using {device_name.upper()}')\n",
                "# Set random seed\n",
                "random.seed(random_state)\n",
                "np.random.seed(random_state)\n",
                "torch.manual_seed(random_state)\n",
                "DetectorFactory.seed = random_state\n",
                "cores = multiprocessing.cpu_count()\n",
                "bert_model_name = 'bert-base-uncased'\n",
                "bert_tokenizer = BertTokenizerFast.from_pretrained(\n",
                "    bert_model_name, strip_accents=True\n",
                ")\n",
                "bert_model = BertForSequenceClassification.from_pretrained(\n",
                "    bert_model_name\n",
                ").to(device)\n",
                "accelerator = Accelerator()\n",
                "optimizer = AdamW(bert_model.parameters(), lr=3e-5)\n",
                "\n",
                "# Plotting variables\n",
                "pp = pprint.PrettyPrinter(indent=4)\n",
                "tqdm.tqdm.pandas(desc='progress-bar')\n",
                "tqdm_auto.tqdm.pandas(desc='progress-bar')\n",
                "tqdm.notebook.tqdm().pandas(desc='progress-bar')\n",
                "tqdm_auto.notebook_tqdm().pandas(desc='progress-bar')\n",
                "# pbar = progressbar.ProgressBar(maxval=10)\n",
                "mpl.use('MacOSX')\n",
                "mpl.style.use(f'{code_dir}/setup_module/apa.mplstyle-main/apa.mplstyle')\n",
                "mpl.rcParams['text.usetex'] = True\n",
                "font = {'family': 'arial', 'weight': 'normal', 'size': 10}\n",
                "mpl.rc('font', **font)\n",
                "plt.style.use('tableau-colorblind10')\n",
                "plt.set_cmap('Blues')\n",
                "pd.set_option('display.max_rows', None)\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.width', 5000)\n",
                "pd.set_option('display.colheader_justify', 'center')\n",
                "pd.set_option('display.precision', 3)\n",
                "pd.set_option('display.float_format', '{:.2f}'.format)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "55afc383",
            "metadata": {},
            "source": [
                "# Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 170,
            "id": "fe416deb",
            "metadata": {},
            "outputs": [],
            "source": [
                "def show_and_close_plots():\n",
                "    plt.show()\n",
                "    plt.clf()\n",
                "    plt.cla()\n",
                "    plt.close()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 171,
            "id": "039b8517",
            "metadata": {},
            "outputs": [],
            "source": [
                "def close_plots():\n",
                "    plt.clf()\n",
                "    plt.cla()\n",
                "    plt.close()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 172,
            "id": "7c0e7a8c",
            "metadata": {},
            "outputs": [],
            "source": [
                "def class_weights_print_Xy(\n",
                "    X_train, y_train, X_train_bert_encodings, y_train_bert_encoded, bert_train_dataset,\n",
                "    X_test, y_test, X_test_bert_encodings, y_test_bert_encoded, bert_test_dataset,\n",
                "    X_val, y_val, X_val_bert_encodings, y_val_bert_encoded, bert_val_dataset,\n",
                "):\n",
                "    # Check for consistent length\n",
                "    check_consistent_length(X_train, y_train, X_train_bert_encodings['input_ids'], y_train_bert_encoded, bert_train_dataset)\n",
                "    check_consistent_length(X_test, y_test, X_test_bert_encodings['input_ids'], y_test_bert_encoded, bert_test_dataset)\n",
                "    check_consistent_length(\n",
                "        X_val, y_val, X_val_bert_encodings['input_ids'], y_val_bert_encoded, bert_val_dataset)\n",
                "\n",
                "    # Get train class weights\n",
                "    train_class_weights = compute_class_weight(class_weight = class_weight, classes = np.unique(y_train), y = y_train)\n",
                "    train_class_weights_ratio = train_class_weights[0]/train_class_weights[1]\n",
                "    train_class_weights_dict = dict(zip(np.unique(y_train), train_class_weights))\n",
                "\n",
                "    # Get train class weights\n",
                "    test_class_weights = compute_class_weight(class_weight = class_weight, classes = np.unique(y_train), y = y_test)\n",
                "    test_class_weights_ratio = test_class_weights[0]/test_class_weights[1]\n",
                "    test_class_weights_dict = dict(zip(np.unique(y_test), test_class_weights))\n",
                "\n",
                "    print('Done encoding training, testing, and validation sets.')\n",
                "    print('='*20)\n",
                "    print(f'Training set shape: {y_train.shape}')\n",
                "    print('-'*10)\n",
                "    print(f'Training set example:\\n{X_train[0]}')\n",
                "    print('-'*10)\n",
                "    print(f'Training set BERT encodings example:\\n{\" \".join(bert_train_dataset.encodings[0].tokens[:30])}')\n",
                "    print('-'*10)\n",
                "    print(f'Training labels after BERT encoding: {set(y_train_bert_encoded)}')\n",
                "    print('~'*10)\n",
                "    print(f'Testing set shape: {y_test.shape}')\n",
                "    print('-'*10)\n",
                "    print(f'Testing set example:\\n{X_test[0]}')\n",
                "    print('-'*10)\n",
                "    print(f'Testing set BERT encodings example:\\n{\" \".join(bert_test_dataset.encodings[0].tokens[:30])}')\n",
                "    print('-'*10)\n",
                "    print(f'Testing labels after BERT encoding: {set(y_test_bert_encoded)}')\n",
                "    print('~'*10)\n",
                "    print(f'Validation set shape: {y_val.shape}')\n",
                "    print('-'*10)\n",
                "    print(f'Validation set example:\\n{X_val[0]}')\n",
                "    print('-'*10)\n",
                "    print(f'Validation set BERT encodings example:\\n{\" \".join(bert_val_dataset.encodings[0].tokens[:30])}')\n",
                "    print('-'*10)\n",
                "    print(f'Validation labels after BERT encoding: {set(y_val_bert_encoded)}')\n",
                "    print('~'*10)\n",
                "    print(f'Training data class weights:\\nRatio = {train_class_weights_ratio:.2f} (0 = {train_class_weights[0]:.2f}, 1 = {train_class_weights[1]:.2f})')\n",
                "    print('-'*10)\n",
                "    print(f'Testing data class weights:\\nRatio = {test_class_weights_ratio:.2f} (0 = {test_class_weights[0]:.2f}, 1 = {test_class_weights[1]:.2f})')\n",
                "    print('='*20)\n",
                "\n",
                "    return (\n",
                "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
                "        test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 173,
            "id": "395dffa9",
            "metadata": {},
            "outputs": [],
            "source": [
                "def split_data(df, col, analysis_columns, text_col=text_col):\n",
                "\n",
                "    train_ratio = 0.75\n",
                "    test_ratio = 0.10\n",
                "    validation_ratio = 0.15\n",
                "    test_split = test_size = 1 - train_ratio\n",
                "    validation_split = test_ratio / (test_ratio + validation_ratio)\n",
                "\n",
                "    # Split\n",
                "    print('='*20)\n",
                "    print('Splitting data into training, testing, and validation sets:')\n",
                "    print(f'Ratios: train_size = {train_ratio}, test size = {test_ratio}, validation size = {validation_ratio}')\n",
                "\n",
                "    df = df.dropna(subset=analysis_columns, how='any')\n",
                "    df = df.reset_index(drop=True)\n",
                "\n",
                "    train, test = train_test_split(\n",
                "        df, train_size = 1-test_split, test_size = test_split, random_state=random_state\n",
                "    )\n",
                "\n",
                "    val, test = train_test_split(\n",
                "        test, test_size=validation_split, random_state=random_state\n",
                "    )\n",
                "\n",
                "    X_train = np.array(list(train[text_col].astype('str').values))\n",
                "    y_train = column_or_1d(train[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "    X_test = np.array(list(test[text_col].astype('str').values))\n",
                "    y_test = column_or_1d(test[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "    X_val = np.array(list(val[text_col].astype('str').values))\n",
                "    y_val = column_or_1d(val[col].astype('int64').values.tolist(), warn=True)\n",
                "\n",
                "    print('Done splitting data into training, testing, and validation sets.')\n",
                "\n",
                "    return (\n",
                "        train, X_train, y_train,\n",
                "        test, X_test, y_test,\n",
                "        val, X_val, y_val,\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 174,
            "id": "679eb14f",
            "metadata": {},
            "outputs": [],
            "source": [
                "class MyDataset(torch.utils.data.Dataset):\n",
                "    def __init__(self, encodings, encoded):\n",
                "        self.encodings = encodings\n",
                "        self.encoded = encoded\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        item = {key: torch.tensor(val[idx], device=device) for key, val in self.encodings.items()}\n",
                "        item['labels'] = torch.tensor(self.encoded[idx], device=device)\n",
                "        return item\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.encoded)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 175,
            "id": "3f3840ba",
            "metadata": {},
            "outputs": [],
            "source": [
                "def encode_data(df, col, analysis_columns, text_col=text_col):\n",
                "\n",
                "    # Split\n",
                "    (\n",
                "        train, X_train, y_train,\n",
                "        test, X_test, y_test,\n",
                "        val, X_val, y_val,\n",
                "    ) = split_data(\n",
                "        df=df_manual, col=col, analysis_columns=analysis_columns, text_col=text_col\n",
                "    )\n",
                "\n",
                "    print('='*20)\n",
                "    print(f'Encoding training, testing, and validation sets with {bert_tokenizer.__class__.__name__}.from_pretrained using {bert_tokenizer.name_or_path}.')\n",
                "\n",
                "    bert_label2id = {label: id_ for id_, label in enumerate(set(y_train))}\n",
                "    bert_id2label = {id_: label for label, id_ in bert_label2id.items()}\n",
                "\n",
                "    X_train_bert_encodings = bert_tokenizer(\n",
                "        X_train.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
                "    ).to(device)\n",
                "    y_train_bert_encoded = [bert_label2id[y] for y in y_train]\n",
                "    bert_train_dataset = MyDataset(X_train_bert_encodings, y_train_bert_encoded)\n",
                "\n",
                "    X_test_bert_encodings = bert_tokenizer(\n",
                "        X_test.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
                "    ).to(device)\n",
                "    y_test_bert_encoded = [bert_label2id[y] for y in y_test]\n",
                "    bert_test_dataset = MyDataset(X_test_bert_encodings, y_test_bert_encoded)\n",
                "\n",
                "    X_val_bert_encodings = bert_tokenizer(\n",
                "        X_val.tolist(), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
                "    ).to(device)\n",
                "    y_val_bert_encoded = [bert_label2id[y] for y in y_val]\n",
                "    bert_val_dataset = MyDataset(X_val_bert_encodings, y_val_bert_encoded)\n",
                "\n",
                "    (\n",
                "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
                "        test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict\n",
                "    ) = class_weights_print_Xy(\n",
                "        X_train, y_train, X_train_bert_encodings, y_train_bert_encoded, bert_train_dataset,\n",
                "        X_test, y_test, X_test_bert_encodings, y_test_bert_encoded, bert_test_dataset,\n",
                "        X_val, y_val, X_val_bert_encodings, y_val_bert_encoded, bert_val_dataset,\n",
                "    )\n",
                "\n",
                "    return (\n",
                "        train, X_train, X_train_bert_encodings, y_train, y_train_bert_encoded, bert_train_dataset,\n",
                "        test, X_test, X_test_bert_encodings, y_test, y_test_bert_encoded, bert_test_dataset,\n",
                "        val, X_val, X_val_bert_encodings, y_val, y_val_bert_encoded, bert_val_dataset,\n",
                "        bert_label2id, bert_id2label,\n",
                "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
                "        test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 176,
            "id": "6ddcc7c0",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_Xy(\n",
                "    col, results_save_path=results_save_path, method=method, protocol=None, path_suffix=None, data=None,\n",
                "):\n",
                "    if protocol is None:\n",
                "        protocol = pickle.HIGHEST_PROTOCOL\n",
                "    if path_suffix is None:\n",
                "        path_suffix = f' - {str(col)} - {vectorizer_name} + {classifier_name} (Save_protocol={protocol}).pkl'\n",
                "    if data_dict is None:\n",
                "        data_dict = {}\n",
                "\n",
                "    print(f'Loading Xy from previous for {col}...')\n",
                "    # Read all dfs into\n",
                "    for file_path in glob.glob(f'{results_save_path}*'):\n",
                "        file_name = file_path.split(f'{results_save_path}{method} ')[-1].split(path_suffix)[0]\n",
                "        if 'df_' in file_name and 'cv_results' not in file_name and classifier_name not in ignore_classifiers_list:\n",
                "            data_dict[file_name] = pd.read_pickle(file_path)\n",
                "\n",
                "    try:\n",
                "        # Train data\n",
                "        df_train_data = data_dict['df_train_data']\n",
                "        X_train = df_train_data['X_train'].values\n",
                "        y_train = df_train_data['y_train'].values\n",
                "        X_train_bert_encodings = df_train_data['X_train_bert_encodings'].values\n",
                "        y_train_bert_encoded = df_train_data['y_train_bert_encoded'].values\n",
                "        bert_train_dataset = df_train_data['bert_train_dataset'].values\n",
                "        # Test data\n",
                "        df_test_data = data_dict['df_test_data']\n",
                "        X_test = df_test_data['X_test'].values\n",
                "        y_test = df_test_data['y_test'].values\n",
                "        X_test_bert_encodings = df_test_data['X_test_bert_encodings'].values\n",
                "        y_test_bert_encoded = df_test_data['y_test_bert_encoded'].values\n",
                "        bert_test_dataset = df_test_data['bert_test_dataset'].values\n",
                "        # Val data\n",
                "        df_val_data = data_dict['df_val_data']\n",
                "        X_val = df_val_data['X_val'].values\n",
                "        y_val = df_val_data['y_val'].values\n",
                "        X_val_bert_encodings = df_val_data['X_val_bert_encodings'].values\n",
                "        y_val_bert_encoded = df_val_data['y_val_bert_encoded'].values\n",
                "        bert_val_dataset = df_val_data['bert_val_dataset'].values\n",
                "        # Labels\n",
                "        df_labels = data_dict['df_labels']\n",
                "        bert_label2id = df_labels['bert_label2id'].values\n",
                "        bert_id2label = df_labels['bert_id2label'].values \n",
                "\n",
                "        print(f'Done loading Xy from previous for {col}!')\n",
                "\n",
                "        # Get class weights and print info\n",
                "        (\n",
                "            train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
                "            test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict\n",
                "        ) = class_weights_print_Xy(\n",
                "            X_train, y_train, X_train_bert_encodings, y_train_bert_encoded, bert_train_dataset,\n",
                "            X_test, y_test, X_test_bert_encodings, y_test_bert_encoded, bert_test_dataset,\n",
                "            X_val, y_val, X_val_bert_encodings, y_val_bert_encoded, bert_val_dataset,\n",
                "        )\n",
                "\n",
                "        return (\n",
                "            X_train, y_train, X_train_bert_encodings, y_train_bert_encoded, bert_train_dataset,\n",
                "            X_test, y_test, X_test_bert_encodings, y_test_bert_encoded, bert_test_dataset,\n",
                "            X_val, y_val, X_val_bert_encodings, y_val_bert_encoded, bert_val_dataset,\n",
                "            bert_label2id, bert_id2label, \n",
                "            train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
                "            test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict\n",
                "        )\n",
                "    except Exception:\n",
                "        print(f'Error loading Xy from previous for {col}!')\n",
                "        return None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 177,
            "id": "d7c888f5",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_metrics_with_y_pred(\n",
                "    y_test, y_test_pred,\n",
                "    pos_label=None, labels=None, zero_division=None, alpha=None\n",
                "):\n",
                "    if pos_label is None:\n",
                "        pos_label = 1\n",
                "    if labels is None:\n",
                "        labels = np.unique(y_test_pred)\n",
                "    if zero_division is None:\n",
                "        zero_division = 0\n",
                "    if alpha is None:\n",
                "        alpha = 0.1\n",
                "\n",
                "    # Using y_pred\n",
                "    explained_variance = metrics.explained_variance_score(y_test, y_test_pred)\n",
                "    accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
                "    balanced_accuracy = metrics.balanced_accuracy_score(y_test, y_test_pred)\n",
                "    precision = metrics.precision_score(y_test, y_test_pred, pos_label=pos_label, labels=labels, zero_division=zero_division)\n",
                "    recall = metrics.recall_score(y_test, y_test_pred, pos_label=pos_label, labels=labels, zero_division=zero_division)\n",
                "    f1 = metrics.f1_score(y_test, y_test_pred, pos_label=pos_label, labels=labels, zero_division=zero_division)\n",
                "    mcc = metrics.matthews_corrcoef(y_test, y_test_pred)\n",
                "    fm = metrics.fowlkes_mallows_score(y_test, y_test_pred)\n",
                "    kappa = metrics.cohen_kappa_score(y_test, y_test_pred, labels=labels)\n",
                "    gmean_iba = imblearn.metrics.make_index_balanced_accuracy(alpha=alpha, squared=True)(geometric_mean_score)\n",
                "    gmean = gmean_iba(y_test, y_test_pred)\n",
                "    report = metrics.classification_report(y_test, y_test_pred, labels=labels, zero_division=zero_division)\n",
                "    imblearn_report = classification_report_imbalanced(y_test, y_test_pred, labels=labels, zero_division=zero_division)\n",
                "    cm = metrics.confusion_matrix(y_test, y_test_pred, labels=labels)\n",
                "    cm_normalized = metrics.confusion_matrix(y_test, y_test_pred, normalize='true', labels=labels)\n",
                "\n",
                "    return (\n",
                "        explained_variance, accuracy, balanced_accuracy, precision,\n",
                "        recall, f1, mcc, fm, kappa, gmean, report, imblearn_report, cm, cm_normalized\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 178,
            "id": "82f234a5",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_metrics_with_y_pred(\n",
                "    y_test, y_test_pred, col, vectorizer_name, classifier_name,\n",
                "    pos_label=None, labels=None\n",
                "):\n",
                "    if pos_label is None:\n",
                "        pos_label = 1\n",
                "    if labels is None:\n",
                "        labels = np.unique(y_test_pred)\n",
                "\n",
                "    # Displays\n",
                "    close_plots()\n",
                "    cm_curve = metrics.ConfusionMatrixDisplay.from_predictions(\n",
                "        y_test, y_test_pred, display_labels=labels, cmap=plt.cm.Blues\n",
                "    )\n",
                "    cm_normalized_curve = metrics.ConfusionMatrixDisplay.from_predictions(\n",
                "        y_test, y_test_pred, normalize='true', display_labels=labels, cmap=plt.cm.Blues\n",
                "    )\n",
                "    roc_curve = metrics.RocCurveDisplay.from_predictions(\n",
                "        y_test, y_test_pred, pos_label=pos_label\n",
                "    )\n",
                "    pr_curve = metrics.PrecisionRecallDisplay.from_predictions(\n",
                "        y_test, y_test_pred, pos_label=pos_label\n",
                "    )\n",
                "    calibration_curve = CalibrationDisplay.from_predictions(\n",
                "        y_test, y_test_pred, pos_label=pos_label\n",
                "    )\n",
                "    show_and_close_plots()\n",
                "\n",
                "    # Plots\n",
                "    plots_dict = {\n",
                "        'Confusion Matrix': cm_curve,\n",
                "        'Normalized Confusion Matrix': cm_normalized_curve,\n",
                "        'ROC Curve': roc_curve,\n",
                "        'Precision-Recall Curve': pr_curve,\n",
                "        'Calibration Curve': calibration_curve,\n",
                "    }\n",
                "\n",
                "    print('=' * 20)\n",
                "    close_plots()\n",
                "    print('Plotting metrics with y_pred_prob:')\n",
                "    print('='*20)\n",
                "\n",
                "    for plot_name, plot_ in plots_dict.items():\n",
                "        close_plots()\n",
                "        print(f'Plotting {plot_name}:')\n",
                "        fig, ax = plt.subplots()\n",
                "        ax.set_title(\n",
                "            f'{str(col)} - {plot_name} - {vectorizer_name} + {classifier_name}'\n",
                "            )\n",
                "        if plot_name == 'ROC Curve':\n",
                "            ax.plot([0, 1], [0, 1], 'r--', lw=1)\n",
                "        try:\n",
                "            plot_.plot(ax=ax, cmap=plt.cm.Blues)\n",
                "        except Exception:\n",
                "            plot_.plot(ax=ax)\n",
                "        print('=' * 20)\n",
                "\n",
                "        # Save Plots\n",
                "        print(f'Saving {plot_name}...')\n",
                "        for image_save_format in ['eps', 'png', 'svg']:\n",
                "            plt.savefig(\n",
                "                f'{plot_save_path}{method} {str(col)} - {plot_name} - {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
                "                format=image_save_format, dpi=3000, bbox_inches='tight'\n",
                "            )\n",
                "        show_and_close_plots()\n",
                "        print(f'Saved {plot_name}!')\n",
                "        print('=' * 20)\n",
                "\n",
                "    # Visualisation with plot_metric\n",
                "    bc = plot_metric.functions.BinaryClassification(y_test, y_test_pred, labels=[0, 1])\n",
                "\n",
                "    # Figures\n",
                "    close_plots()\n",
                "    fig = plt.figure(figsize=(15, 10))\n",
                "    plt.subplot2grid((2, 6), (1, 1), colspan=2)\n",
                "    bc.plot_confusion_matrix(colorbar=True)\n",
                "    plt.subplot2grid((2, 6), (1, 3), colspan=2)\n",
                "    bc.plot_confusion_matrix(normalize=True, colorbar=True)\n",
                "    plt.subplot2grid(shape=(2, 6), loc=(0, 0), colspan=2)\n",
                "    bc.plot_roc_curve()\n",
                "    plt.subplot2grid((2, 6), (0, 2), colspan=2)\n",
                "    bc.plot_precision_recall_curve()\n",
                "    plt.subplot2grid((2, 6), (0, 4), colspan=2)\n",
                "    bc.plot_class_distribution()\n",
                "    bc.print_report()\n",
                "    for image_save_format in ['eps', 'png', 'svg']:\n",
                "        plt.savefig(\n",
                "            f'{plot_save_path}{method} {str(col)} - plot_metric Curves - {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
                "            format=image_save_format,\n",
                "            dpi=3000, bbox_inches='tight'\n",
                "        )\n",
                "    show_and_close_plots()\n",
                "\n",
                "    # Heatmap\n",
                "    print('Plotting Heatmap:')\n",
                "    close_plots()\n",
                "    classifications_dict = defaultdict(int)\n",
                "    for _y_test, _y_test_pred in zip(y_test, y_test_pred):\n",
                "        if _y_test != _y_test_pred:\n",
                "            classifications_dict[(_y_test, _y_test_pred)] += 1\n",
                "\n",
                "    dicts_to_plot = [\n",
                "        {\n",
                "            f'True {str(col)} value': _y_test,\n",
                "            f'Predicted {str(col)} value': _y_test_pred,\n",
                "            'Number of Classifications': _count,\n",
                "        }\n",
                "        for (_y_test, _y_test_pred), _count in classifications_dict.items()\n",
                "    ]\n",
                "    df_to_plot = pd.DataFrame(dicts_to_plot)\n",
                "    df_wide = df_to_plot.pivot_table(\n",
                "        index=f'True {str(col)} value', \n",
                "        columns=f'Predicted {str(col)} value', \n",
                "        values='Number of Classifications'\n",
                "    )\n",
                "    plt.figure(figsize=(9,7))\n",
                "    sns.set(style='ticks', font_scale=1.2)\n",
                "    sns.heatmap(df_wide, linewidths=1, cmap=plt.cm.Blues, annot=True)    \n",
                "    plt.xticks(rotation=45, ha='right')\n",
                "    plt.yticks(rotation=0)\n",
                "    plt.tight_layout()\n",
                "    plt.suptitle(f'{str(col)} Heatmap - {vectorizer_name} + {classifier_name}')\n",
                "    print('Saving Heatmap...')\n",
                "    for image_save_format in ['eps', 'png', 'svg']:\n",
                "        plt.savefig(\n",
                "            f'{plot_save_path}{method} {str(col)} - Heatmap - {vectorizer_name} + {classifier_name}.{image_save_format}',\n",
                "            format=image_save_format,\n",
                "            dpi=3000, bbox_inches='tight'\n",
                "        )\n",
                "    print('Saved Heatmap!')\n",
                "    show_and_close_plots()\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 179,
            "id": "1e2dcb5c",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_metrics_with_y_pred_prob(\n",
                "    y_test, y_test_pred_prob,\n",
                "    pos_label=None\n",
                "):\n",
                "    if pos_label is None:\n",
                "        pos_label = 1\n",
                "\n",
                "    # Using y_pred_prob\n",
                "    average_precision = metrics.average_precision_score(y_test, y_test_pred_prob)\n",
                "    roc_auc = metrics.roc_auc_score(y_test, y_test_pred_prob)\n",
                "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_test_pred_prob, pos_label=1)\n",
                "    auc = metrics.auc(fpr, tpr)\n",
                "    loss = metrics.log_loss(y_test, y_test_pred_prob)\n",
                "    precision_pr, recall_pr, threshold_pr = metrics.precision_recall_curve(y_test, y_test_pred_prob, pos_label=1)\n",
                "\n",
                "    return (\n",
                "        average_precision, roc_auc, auc,\n",
                "        fpr, tpr, threshold,loss,\n",
                "        precision_pr, recall_pr, threshold_pr\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 180,
            "id": "81d6916f",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_metrics(\n",
                "    predicted_results,\n",
                "    with_y_pred=None,\n",
                "    with_y_pred_prob=None\n",
                "):\n",
                "    if with_y_pred is None:\n",
                "        with_y_pred = True\n",
                "    if with_y_pred_prob is None:\n",
                "        with_y_pred_prob = True\n",
                "\n",
                "    # Get predictions\n",
                "    print(f'Getting prediction results for {col}.')\n",
                "    y_test_pred_prob, y_test_pred, metrics_dict, = predicted_results\n",
                "    # for metric_name, metric_value in metrics_dict.items():\n",
                "    #     if 'loss' not in metric_name:\n",
                "    #         metrics_dict[f'{metric_name.split(\"test_\")[1]}'] = metrics_dict.pop(metric_name)\n",
                "    #     else:\n",
                "    #         metrics_dict['Log Loss/Cross Entropy'] = metrics_dict.pop(metric_name)\n",
                "    print(f'Predictions shape for {col}: {y_test_pred.shape}')\n",
                "    print('-'*20)\n",
                "\n",
                "    # Get y_test_pred\n",
                "    print('-'*20)\n",
                "    print(f'Find argmax and flattening y_test_pred for {col}')\n",
                "    y_test_pred = [bert_label2id[l] for l in torch.tensor(y_test_pred, device=device).argmax(axis=-1).clone().detach().flatten().tolist()]\n",
                "    print(f'Length of y_test_pred: {len(y_test_pred)}')\n",
                "    print('-'*20)\n",
                "\n",
                "    # Get y_test_pred_prob\n",
                "    print('-'*20)\n",
                "    print(f'Find softmax and flattening y_test_pred for {col}')\n",
                "    try:\n",
                "        y_test_pred_prob = torch.nn.functional.softmax(torch.tensor(\n",
                "            y_test_pred_prob[:, 1], device=device), dim=-1).clone().detach()\n",
                "        print('Using torch.nn.functional.softmax')\n",
                "    except Exception:\n",
                "        y_test_pred_prob = scipy.special.softmax(\n",
                "            y_test_pred_prob[:, 1], axis=-1)\n",
                "        print('Using scipy.special.softmax')\n",
                "    finally:\n",
                "        y_test_pred_prob = y_test_pred_prob.flatten().tolist()\n",
                "    print(f'Length of y_test_pred_prob: {len(y_test_pred_prob)}')\n",
                "    print('-'*20)\n",
                "\n",
                "    # Get metrics\n",
                "    print('='*20)\n",
                "    # Using y_test_pred\n",
                "    if with_y_pred:\n",
                "        print('-'*20)\n",
                "        print('Computing metrics using y_test_pred.')\n",
                "        (\n",
                "            explained_variance, accuracy, balanced_accuracy, precision,\n",
                "            recall, f1, mcc, fm, kappa, gmean, report, imblearn_report, cm, cm_normalized\n",
                "        ) = compute_metrics_with_y_pred(\n",
                "            y_test, y_test_pred\n",
                "        )\n",
                "    # Using y_test_pred_prob\n",
                "    if with_y_pred_prob:\n",
                "        print('-'*20)\n",
                "        print('Computing metrics using y_test_pred_prob.')\n",
                "        (\n",
                "            average_precision, roc_auc, auc,\n",
                "            fpr, tpr, threshold, loss,\n",
                "            precision_pr, recall_pr, threshold_pr\n",
                "        ) = compute_metrics_with_y_pred_prob(\n",
                "            y_test, y_test_pred_prob\n",
                "        )\n",
                "\n",
                "    # Place metrics into dict\n",
                "    print('-'*20)\n",
                "    print('Appending metrics to dict.')\n",
                "    metrics_dict = {\n",
                "        'Train - Mean Cross Validation Score': float(cv_train_scores),\n",
                "        f'Train - Mean Cross Validation - {scoring.title()}': float(cv_train_recall),\n",
                "        f'Train - Mean Explained Variance - {scoring.title()}': float(cv_train_explained_variance_recall),\n",
                "        'Test - Mean Cross Validation Score': float(cv_test_scores),\n",
                "        f'Test - Mean Cross Validation - {scoring.title()}': float(cv_test_recall),\n",
                "        f'Test - Mean Explained Variance - {scoring.title()}': float(cv_test_explained_variance_recall),\n",
                "        'Explained Variance': float(explained_variance),\n",
                "        'Accuracy': float(accuracy),\n",
                "        'Balanced Accuracy': float(balanced_accuracy),\n",
                "        'Precision': float(precision),\n",
                "        'Average Precision': float(average_precision),\n",
                "        'Recall': float(recall),\n",
                "        'F1-score': float(f1),\n",
                "        'Matthews Correlation Coefficient': float(mcc),\n",
                "        'Fowlkes–Mallows Index': float(fm),\n",
                "        'ROC': float(roc_auc),\n",
                "        'AUC': float(auc),\n",
                "        f'{scoring.title()} Best Threshold': threshold,\n",
                "        f'{scoring.title()} Best Score': float(best_train_score),\n",
                "        'Log Loss/Cross Entropy': float(loss),\n",
                "        'Cohen’s Kappa': float(kappa),\n",
                "        'Geometric Mean': float(gmean),\n",
                "        'Classification Report': report,\n",
                "        'Imbalanced Classification Report': imblearn_report,\n",
                "        'Confusion Matrix': cm,\n",
                "        'Normalized Confusion Matrix': cm_normalized\n",
                "    }\n",
                "\n",
                "    return metrics_dict\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 181,
            "id": "f2d3da10",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_metrics(\n",
                "    estimator, X_test, y_test, y_test_pred, y_test_pred_prob,\n",
                "    col, vectorizer_name, classifier_name, \n",
                "    with_y_pred=None, with_y_pred_prob=None\n",
                "):\n",
                "    if with_y_pred is None:\n",
                "        with_y_pred = True\n",
                "    if with_y_pred_prob is None:\n",
                "        with_y_pred_prob = False\n",
                "\n",
                "    # Plotting\n",
                "    # Using y_test_pred\n",
                "    if with_y_pred:\n",
                "        (\n",
                "            cm_curve, cm_normalized_curve, roc_curve, pr_curve, calibration_curve\n",
                "        ) = plot_metrics_with_y_pred(\n",
                "            y_test, y_test_pred,\n",
                "            col, vectorizer_name, classifier_name, \n",
                "        )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 182,
            "id": "c44994c4",
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluation(\n",
                "    metrics_dict, df_metrics,\n",
                "    col, vectorizer_name, classifier_name\n",
                "):\n",
                "\n",
                "    # Print metrics\n",
                "    print('=' * 20)\n",
                "    print('~' * 20)\n",
                "    print(' Metrics:')\n",
                "    print('~' * 20)\n",
                "    print(f'Classification Report:\\n {metrics_dict[\"Classification Report\"]}')\n",
                "    print('-' * 20)\n",
                "    for test_metric_name, metric_value in metrics_dict.items():\n",
                "        if 'Threshold' not in metric_name and test_metric_name not in ['test_runtime', 'test_samples_per_second', 'test_steps_per_second']:\n",
                "            metric_name = test_metric_name.split(\"test_\")[1].replace('_', ' ').title()\n",
                "            with contextlib.suppress(TypeError, ValueError):\n",
                "                metric_value = float(metric_value)\n",
                "            if isinstance(metric_name, (int, float)):\n",
                "                print(f'{metric_name}: {round(metric_value, 2)}')\n",
                "            else:\n",
                "                print(f'{metric_name}: {metric_value}')\n",
                "            print('-' * 20)\n",
                "\n",
                "            # Fill Table DF\n",
                "            if isinstance(metric_value, float):\n",
                "                df_metrics.loc[\n",
                "                    (classifier_name), (col, vectorizer_name, metric_name)\n",
                "                ] = metric_value\n",
                "            else:\n",
                "                df_metrics.loc[\n",
                "                    (classifier_name), (col, vectorizer_name, metric_name)\n",
                "                ] = str(metric_value)\n",
                "\n",
                "    print('=' * 20)\n",
                "\n",
                "    # Plot Metrics\n",
                "    plot_metrics(\n",
                "        estimator, X_test, y_test, y_test_pred, y_test_pred_prob,\n",
                "        col, vectorizer_name, classifier_name, \n",
                "    )\n",
                "\n",
                "    return df_metrics\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 183,
            "id": "93960eda",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to place Xy and CV data in df and save\n",
                "def save_Xy_estimator(\n",
                "    X_train, y_train, X_train_bert_encodings, y_train_bert_encoded, bert_train_dataset,\n",
                "    X_test, y_test, X_test_bert_encodings, y_test_bert_encoded, bert_test_dataset,\n",
                "    X_val, y_val, X_val_bert_encodings, y_val_bert_encoded, bert_val_dataset,\n",
                "    bert_label2id, bert_id2label,\n",
                "    estimator,\n",
                "    col, vectorizer_name, classifier_name,\n",
                "    results_save_path=results_save_path,\n",
                "    method=method, xy_save_path=None,\n",
                "    compression=None, protocol=None,\n",
                "    path_suffix=None, data=None\n",
                "):\n",
                "\n",
                "    if xy_save_path is None:\n",
                "        xy_save_path = f'{results_save_path}Xy/'\n",
                "    if compression is None:\n",
                "        compression = False\n",
                "    if protocol is None:\n",
                "        protocol = pickle.HIGHEST_PROTOCOL\n",
                "    if path_suffix is None:\n",
                "        path_suffix = f' - {str(col)} - {vectorizer_name} + {classifier_name}.pkl'\n",
                "    if data is None:\n",
                "        data = {}\n",
                "\n",
                "    # Make df_train_data\n",
                "    df_train_data = pd.DataFrame(\n",
                "        {\n",
                "            'X_train': X_train,\n",
                "            'y_train': y_train,\n",
                "            'X_train_bert_encodings': X_train_bert_encodings,\n",
                "            'y_train_bert_encoded': y_train_bert_encoded,\n",
                "            'bert_train_dataset': bert_train_dataset,\n",
                "            'y_train_pred': y_train_pred,\n",
                "        },\n",
                "    )\n",
                "    # Make df_test_data\n",
                "    df_test_data = pd.DataFrame(\n",
                "        {\n",
                "            'X_test': X_test,\n",
                "            'y_test': y_test,\n",
                "            'X_test_bert_encodings': X_test_bert_encodings,\n",
                "            'y_test_bert_encoded': y_test_bert_encoded,\n",
                "            'y_test_pred': y_test_pred,\n",
                "            'y_test_pred_prob': y_test_pred_prob,\n",
                "        },\n",
                "    )\n",
                "    # Make df_val_data\n",
                "    df_val_data = pd.DataFrame(\n",
                "        {\n",
                "            'X_val': X_val,\n",
                "            'y_val': y_val,\n",
                "            'X_val_bert_encodings': X_val_bert_encodings,\n",
                "            'y_val_bert_encoded': y_val_bert_encoded,\n",
                "        },\n",
                "    )\n",
                "    # Make df_labels\n",
                "    df_labels = pd.DataFrame(\n",
                "        {\n",
                "            'bert_label2id': bert_label2id,\n",
                "            'bert_id2label': bert_id2label,\n",
                "        },\n",
                "    )\n",
                "\n",
                "    # Make data dict\n",
                "    data['df_train_data'] = df_train_data\n",
                "    data['df_test_data'] = df_test_data\n",
                "    data['df_val_data'] = df_val_data\n",
                "    data['df_labels'] = df_labels\n",
                "    data['Estimator'] = estimator\n",
                "\n",
                "    # Save files\n",
                "    print('='*20)\n",
                "    print('Saving Xy, labels and estimator...')\n",
                "    for file_name, file_ in data.items():\n",
                "        if not isinstance(file_, pd.DataFrame) and file_name == 'Estimator' and 'df_' not in file_name:\n",
                "            # Save as .model\n",
                "            file_.save_model(f'{results_save_path}{method} {file_name}{path_suffix.split(\".pkl\")[0]}.model')\n",
                "            # Save as .pkl\n",
                "            with open(\n",
                "                f'{results_save_path}{method} {file_name}{path_suffix}.model', 'wb'\n",
                "            ) as f:\n",
                "                joblib.dump(file_, f, compress=compression, protocol=protocol)\n",
                "        elif isinstance(file_, pd.DataFrame) and file_name != 'Estimator' and 'df_' in file_name:\n",
                "            file_.to_pickle(\n",
                "                f'{xy_save_path}{method} {file_name}{path_suffix}', protocol=protocol\n",
                "            )\n",
                "    print(f'Done saving Xy, labels and estimator!\\n{list(data.keys())}')\n",
                "    print('='*20)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 184,
            "id": "4b48de3a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save Model\n",
                "def save_table(\n",
                "    df_metrics,\n",
                "    col, vectorizer_name, classifier_name,\n",
                "    results_save_path=results_save_path,\n",
                "    table_save_path=table_save_path,\n",
                "    method=method, save_name=None,\n",
                "    compression=None, protocol=None,\n",
                "):\n",
                "    if save_name is None:\n",
                "        save_name = 'Estimators Table'\n",
                "    if compression is None:\n",
                "        compression = False\n",
                "    if protocol is None:\n",
                "        protocol = pickle.HIGHEST_PROTOCOL\n",
                "\n",
                "    # Save metrics df\n",
                "    print(f'Saving fitted estimator and table for {vectorizer_name} + {classifier_name}.')\n",
                "    df_metrics.to_csv(f'{table_save_path}{save_name}.csv')\n",
                "    df_metrics.to_pickle(f'{table_save_path}{save_name}.pkl')\n",
                "    df_metrics.to_excel(f'{table_save_path}{save_name}.xlsx')\n",
                "    df_metrics.to_latex(f'{table_save_path}{save_name}.tex')\n",
                "    df_metrics.to_markdown(f'{table_save_path}{save_name}.md')\n",
                "    df_metrics.to_html(f'{table_save_path}{save_name}.html')\n",
                "\n",
                "    print('Done saving fitted estimator and table!')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 185,
            "id": "29efbbd2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save Model\n",
                "def get_completed_estimators(results_save_path=results_save_path, method=method):\n",
                "\n",
                "    estimators_list = []\n",
                "\n",
                "    for estimator_path in glob.glob(f'{results_save_path}{method} Estimator - *.model'):\n",
                "        with open(estimator_path, 'rb') as f:\n",
                "            estimators_list.append(joblib.load(f))\n",
                "\n",
                "    return estimators_list\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 186,
            "id": "34e44624",
            "metadata": {},
            "outputs": [],
            "source": [
                "def comparison_plots(\n",
                "    estimators_list, X_test, y_test, col,\n",
                "    curves_dict=None, cmap=plt.cm.Blues\n",
                "):\n",
                "\n",
                "    curves_dict = {\n",
                "        'ROC Curve': metrics.RocCurveDisplay,\n",
                "        'Precision Recall Curve': metrics.PrecisionRecallDisplay,\n",
                "        'Calibration Curve': metrics.CalibrationDisplay,\n",
                "    }\n",
                "\n",
                "    assert len(estimators_list) != 0\n",
                "\n",
                "    for curve_name, curve_package in curves_dict.items():\n",
                "        print('-' * 20)\n",
                "        print(f'{str(curve_name)}: {str(col)}')\n",
                "        fig, ax = plt.subplots()\n",
                "        ax.set_title(f'{str(curve_name)}: {str(col)}')\n",
                "        for estimator in estimators_list:\n",
                "            curve = curve_package.from_estimator(\n",
                "                estimator, X_test, y_test, pos_label=1, ax=ax,\n",
                "                name=f'{estimator.steps[0][0]} + {estimator.steps[1][0]} + {estimator.steps[-1][0]}'\n",
                "            )\n",
                "        show_and_close_plots()\n",
                "\n",
                "        # Save Plots\n",
                "        print('Saving plots.')\n",
                "        for image_save_format in ['eps', 'png', 'svg']:\n",
                "            curve.figure_.savefig(\n",
                "                f'{plot_save_path}{method} {str(col)} - All {str(curve_name)}s.{image_save_format}',\n",
                "                format=image_save_format,\n",
                "                dpi=3000, bbox_inches='tight'\n",
                "            )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "10f64ab3",
            "metadata": {},
            "source": [
                "# Training"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "52fe8e7a",
            "metadata": {},
            "source": [
                "### READ DATA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 187,
            "id": "f7fbe29f",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_trainning.pkl').reset_index(drop=True)\n",
                "# HACK REMOVE THIS!!!!!!\n",
                "df_manual = df_manual.groupby(analysis_columns).sample(n=200).reset_index(drop = True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 192,
            "id": "689d84dd",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "########################################\n",
                        "Starting!\n",
                        "########################################\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/2 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--------------------\n",
                        "============================== TRAINING DATASET OF LENGTH 800 ON WARMTH ==============================\n",
                        "--------------------\n",
                        "====================\n",
                        "Splitting data into training, testing, and validation sets:\n",
                        "Ratios: train_size = 0.75, test size = 0.1, validation size = 0.15\n",
                        "Done splitting data into training, testing, and validation sets.\n",
                        "====================\n",
                        "Encoding training, testing, and validation sets with BertTokenizerFast.from_pretrained using bert-base-uncased.\n",
                        "Done encoding training, testing, and validation sets.\n",
                        "====================\n",
                        "Training set shape: (600,)\n",
                        "----------\n",
                        "Training set example:\n",
                        "Automate) who will be responsible for preparation and execution of improvements working with the RPA and Microsoft Power\n",
                        "----------\n",
                        "Training set BERT encodings example:\n",
                        "[CLS] auto ##mate ) who will be responsible for preparation and execution of improvements working with the r ##pa and microsoft power [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
                        "----------\n",
                        "Training labels after BERT encoding: {0, 1}\n",
                        "~~~~~~~~~~\n",
                        "Testing set shape: (80,)\n",
                        "----------\n",
                        "Testing set example:\n",
                        "self-motivation and a clear dedication to your profession.\n",
                        "----------\n",
                        "Testing set BERT encodings example:\n",
                        "[CLS] self - motivation and a clear dedication to your profession . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
                        "----------\n",
                        "Testing labels after BERT encoding: {0, 1}\n",
                        "~~~~~~~~~~\n",
                        "Validation set shape: (120,)\n",
                        "----------\n",
                        "Validation set example:\n",
                        "Create your own nutrition formula with a discount on our products!\n",
                        "----------\n",
                        "Validation set BERT encodings example:\n",
                        "[CLS] create your own nutrition formula with a discount on our products ! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
                        "----------\n",
                        "Validation labels after BERT encoding: {0, 1}\n",
                        "~~~~~~~~~~\n",
                        "Training data class weights:\n",
                        "Ratio = 0.99 (0 = 0.99, 1 = 1.01)\n",
                        "----------\n",
                        "Testing data class weights:\n",
                        "Ratio = 0.78 (0 = 0.89, 1 = 1.14)\n",
                        "====================\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
                        "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
                        "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
                        "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
                        "The speedups for torchdynamo mostly come wih GPU Ampere or higher and which is not detected here.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "==============================\n",
                        "Initializing BERT Trainer using BertTokenizerFast + BertForSequenceClassification for Warmth\n",
                        "--------------------\n",
                        "Passing arguments to estimator.\n",
                        "--------------------\n",
                        "Starting training for Warmth.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "08c6a398f2c544d7bcbc8880b72e3b8d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/114 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/1230619439.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  item = {key: torch.tensor(val[idx], device=device) for key, val in self.encodings.items()}\n",
                        "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
                        "/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/1230619439.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  item = {key: torch.tensor(val[idx], device=device) for key, val in self.encodings.items()}\n",
                        "/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/1230619439.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  item = {key: torch.tensor(val[idx], device=device) for key, val in self.encodings.items()}\n",
                        "  0%|          | 0/2 [02:03<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'loss': 0.5578, 'learning_rate': 5e-05, 'epoch': 2.63}\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "287cdcace8404150b69d6acbe5d8cf7c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/6 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/1230619439.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  item = {key: torch.tensor(val[idx], device=device) for key, val in self.encodings.items()}\n",
                        "  0%|          | 0/2 [02:13<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting prediction results for Warmth.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/IPython/cor</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">e/magics/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">execution.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1319</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">time</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1316 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1317 │   │   │   </span>st = clock2()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1318 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1319 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>exec(code, glob, local_ns)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1320 │   │   │   │   </span>out=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1321 │   │   │   │   # multi-line %%time case</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1322 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> expr_val <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;timed exec&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">86</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1633</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1630 │   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1631 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1632 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1633 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1634 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1635 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1636 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1979</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1976 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.epoch = epoch + (step + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> + steps_skipped) / steps_in_epo  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1977 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_step_end(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">s</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1978 │   │   │   │   │   </span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1979 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_k  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1980 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1981 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_substep_end(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1982 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2236</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_maybe_log_save_evaluate</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2233 │   │   │   │   │   │   </span>metric_key_prefix=<span style=\"color: #808000; text-decoration-color: #808000\">f\"eval_{</span>eval_dataset_name<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>,                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2234 │   │   │   │   │   </span>)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2235 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2236 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>metrics = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.evaluate(ignore_keys=ignore_keys_for_eval)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2237 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._report_to_hp_search(trial, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.global_step, metrics)             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2238 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2239 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control.should_save:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2932</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluate</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2929 │   │   </span>start_time = time.time()                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2930 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2931 │   │   </span>eval_loop = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.use_legacy_prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">se</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2932 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = eval_loop(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2933 │   │   │   </span>eval_dataloader,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2934 │   │   │   </span>description=<span style=\"color: #808000; text-decoration-color: #808000\">\"Evaluation\"</span>,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2935 │   │   │   # No point gathering the predictions if there are no metrics, otherwise we d</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3220</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluation_loop</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3217 │   │   │   │   │   </span>EvalPrediction(predictions=all_preds, label_ids=all_labels, inputs=a  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3218 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3219 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3220 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>metrics = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_metrics(EvalPrediction(predictions=all_preds, lab  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3221 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3222 │   │   │   </span>metrics = {}                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3223 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3933834647.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">13</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_metrics</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/3933834647.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
                            "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>not enough values to unpack <span style=\"font-weight: bold\">(</span>expected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/IPython/cor\u001b[0m \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33me/magics/\u001b[0m\u001b[1;33mexecution.py\u001b[0m:\u001b[94m1319\u001b[0m in \u001b[92mtime\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1316 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1317 \u001b[0m\u001b[2m│   │   │   \u001b[0mst = clock2()                                                                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1318 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1319 \u001b[2m│   │   │   │   \u001b[0mexec(code, glob, local_ns)                                                \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1320 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mout=\u001b[94mNone\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1321 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# multi-line %%time case\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1322 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m expr_val \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[33m<timed exec>\u001b[0m:\u001b[94m86\u001b[0m in \u001b[92m<module>\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1633\u001b[0m in \u001b[92mtrain\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1630 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1631 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1632 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1633 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1634 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1635 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1636 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1979\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1976 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.state.epoch = epoch + (step + \u001b[94m1\u001b[0m + steps_skipped) / steps_in_epo  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1977 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_step_end(args, \u001b[96mself\u001b[0m.state, \u001b[96ms\u001b[0m  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1978 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1979 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_k  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1980 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1981 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_substep_end(args, \u001b[96mself\u001b[0m.state  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m1982 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2236\u001b[0m in \u001b[92m_maybe_log_save_evaluate\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2233 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mmetric_key_prefix=\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33meval_\u001b[0m\u001b[33m{\u001b[0meval_dataset_name\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m,                    \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2234 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m)                                                                     \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2235 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2236 \u001b[2m│   │   │   │   \u001b[0mmetrics = \u001b[96mself\u001b[0m.evaluate(ignore_keys=ignore_keys_for_eval)                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2237 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._report_to_hp_search(trial, \u001b[96mself\u001b[0m.state.global_step, metrics)             \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2238 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2239 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.control.should_save:                                                      \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2932\u001b[0m in \u001b[92mevaluate\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2929 \u001b[0m\u001b[2m│   │   \u001b[0mstart_time = time.time()                                                          \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2930 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2931 \u001b[0m\u001b[2m│   │   \u001b[0meval_loop = \u001b[96mself\u001b[0m.prediction_loop \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.use_legacy_prediction_loop \u001b[94melse\u001b[0m \u001b[96mse\u001b[0m  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2932 \u001b[2m│   │   \u001b[0moutput = eval_loop(                                                               \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2933 \u001b[0m\u001b[2m│   │   │   \u001b[0meval_dataloader,                                                              \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2934 \u001b[0m\u001b[2m│   │   │   \u001b[0mdescription=\u001b[33m\"\u001b[0m\u001b[33mEvaluation\u001b[0m\u001b[33m\"\u001b[0m,                                                     \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2935 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# No point gathering the predictions if there are no metrics, otherwise we d\u001b[0m  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m3220\u001b[0m in \u001b[92mevaluation_loop\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3217 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mEvalPrediction(predictions=all_preds, label_ids=all_labels, inputs=a  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3218 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3219 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3220 \u001b[2m│   │   │   │   \u001b[0mmetrics = \u001b[96mself\u001b[0m.compute_metrics(EvalPrediction(predictions=all_preds, lab  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3221 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3222 \u001b[0m\u001b[2m│   │   │   \u001b[0mmetrics = {}                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3223 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/\u001b[0m\u001b[1;33m3933834647.py\u001b[0m:\u001b[94m13\u001b[0m in             \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[92mcompute_metrics\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/3933834647.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
                            "\u001b[1;91mValueError: \u001b[0mnot enough values to unpack \u001b[1m(\u001b[0mexpected \u001b[1;36m3\u001b[0m, got \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "%%time\n",
                "print('#'*40)\n",
                "print('Starting!')\n",
                "print('#'*40)\n",
                "\n",
                "analysis_columns = ['Warmth', 'Competence']\n",
                "text_col = 'Job Description spacy_sentencized'\n",
                "\n",
                "# Load Table DF\n",
                "# df_metrics = pd.read_pickle(f'{table_save_path}Classifiers Table.pkl')\n",
                "\n",
                "for col in tqdm.tqdm(analysis_columns):\n",
                "\n",
                "    assert len(df_manual[df_manual[str(col)].map(df_manual[str(col)].value_counts() > 1)]) != 0, f'Dataframe has no {col} values!'\n",
                "    print('-'*20)\n",
                "    print(f'{\"=\"*30} TRAINING DATASET OF LENGTH {len(df_manual)} ON {col.upper()} {\"=\"*30}')\n",
                "    print('-'*20)\n",
                "\n",
                "    # Split\n",
                "    (\n",
                "        train, X_train, X_train_bert_encodings, y_train, y_train_bert_encoded, bert_train_dataset,\n",
                "        test, X_test, X_test_bert_encodings, y_test, y_test_bert_encoded, bert_test_dataset,\n",
                "        val, X_val, X_val_bert_encodings, y_val, y_val_bert_encoded, bert_val_dataset,\n",
                "        bert_label2id, bert_id2label,\n",
                "        train_class_weights, train_class_weights_ratio, train_class_weights_dict,\n",
                "        test_class_weights_dict, test_class_weights_ratio, test_class_weights_dict\n",
                "    ) = encode_data(\n",
                "        df=df_manual, col=col, analysis_columns=analysis_columns, text_col=text_col\n",
                "    )\n",
                "\n",
                "    # Load pre-trained BERT model\n",
                "    bert_model = BertForSequenceClassification.from_pretrained(\n",
                "        bert_model_name, num_labels=len(bert_id2label)\n",
                "    ).to(device)\n",
                "\n",
                "    # Accelerate model\n",
                "    (\n",
                "        bert_model, bert_train_dataset, bert_test_dataset, bert_val_dataset\n",
                "    ) = accelerator.prepare(\n",
                "        bert_model, bert_train_dataset, bert_test_dataset, bert_val_dataset\n",
                "    )\n",
                "    # bert_model.eval()\n",
                "\n",
                "    # Initialize BERT Trainer\n",
                "    print('='*30)\n",
                "    tokenizer_name = bert_tokenizer.__class__.__name__\n",
                "    classifier_name = bert_model.__class__.__name__\n",
                "    print(f'Initializing BERT Trainer using {tokenizer_name} + {classifier_name} for {col}')\n",
                "\n",
                "    # Set BERT fine-tuning parameters\n",
                "    bert_training_args = TrainingArguments(\n",
                "        output_dir=f'{results_save_path}{method} Results',\n",
                "        logging_dir=f'{results_save_path}{method} Logs',\n",
                "        seed=random_state,\n",
                "        torch_compile=True,\n",
                "        use_mps_device=True if device_name == 'mps' else False,\n",
                "        optim='adamw_torch',\n",
                "        num_train_epochs=3,\n",
                "        per_device_train_batch_size=16,\n",
                "        per_device_eval_batch_size=20,\n",
                "        learning_rate=5e-5,\n",
                "        warmup_steps=100,\n",
                "        weight_decay=0.01,\n",
                "        logging_steps=100,\n",
                "        evaluation_strategy='steps',\n",
                "    )\n",
                "\n",
                "    # Pass data to trainer \n",
                "    print('-'*20)\n",
                "    print('Passing arguments to estimator.')\n",
                "    with joblib.parallel_backend(backend='loky', n_jobs=n_jobs):\n",
                "        bert_model, bert_train_dataset, bert_test_dataset, bert_val_dataset = accelerator.prepare(bert_model, bert_train_dataset, bert_test_dataset, bert_val_dataset)\n",
                "        estimator = Trainer(\n",
                "            model=bert_model,\n",
                "            tokenizer=bert_tokenizer,\n",
                "            args=bert_training_args,\n",
                "            train_dataset=bert_train_dataset,\n",
                "            eval_dataset=bert_val_dataset,\n",
                "            compute_metrics=compute_metrics,\n",
                "        )\n",
                "        if estimator.place_model_on_device:\n",
                "            estimator.model.to(device)\n",
                "\n",
                "        # Train trainer\n",
                "        print('-'*20)\n",
                "        print(f'Starting training for {col}.')\n",
                "        estimator.train()\n",
                "        print('Done training!')\n",
                "        print('-'*20)\n",
                "\n",
                "        # Save model\n",
                "        print('-'*20)\n",
                "        print(f'Saving model for {col}.')\n",
                "        save_Xy_estimator(\n",
                "            X_train, y_train, X_train_bert_encodings, y_train_bert_encoded, bert_train_dataset,\n",
                "            X_test, y_test, X_test_bert_encodings, y_test_bert_encoded, bert_test_dataset,\n",
                "            X_val, y_val, X_val_bert_encodings, y_val_bert_encoded, bert_val_dataset,\n",
                "            bert_label2id, bert_id2label,\n",
                "            estimator,\n",
                "            col, vectorizer_name, classifier_name,\n",
                "        )\n",
                "        # estimator.save_model(f'{results_save_path}{method} Estimator {str(col)} - {tokenizer_name} + {classifier_name}.model')\n",
                "        print('Done training!')\n",
                "        print('-'*20)\n",
                "\n",
                "        # Evaluate\n",
                "        print('-'*20)\n",
                "        print(f'Evaluating estimator for {col}.')\n",
                "        estimator.evaluate()\n",
                "        print('Done evaluating!')\n",
                "\n",
                "        # Get predictions\n",
                "        print(f'Getting prediction results for {col}.')\n",
                "        y_test_pred_prob, y_test_pred, metrics_dict, = estimator.predict(bert_test_dataset)\n",
                "        for metric_name, metric_value in metrics_dict.items():\n",
                "            if 'loss' not in metric_name:\n",
                "                metrics_dict[f'{metric_name.split(\"test_\")[1]}'] = metrics_dict.pop(metric_name)\n",
                "            else:\n",
                "                metrics_dict['Log Loss/Cross Entropy'] = metrics_dict.pop(metric_name)\n",
                "        print(f'Predictions shape for {col}: {y_test_pred.shape}')\n",
                "        print('-'*20)\n",
                "\n",
                "        # Get y_test_pred\n",
                "        print('-'*20)\n",
                "        print(f'Find argmax and flattening y_test_pred for {col}')\n",
                "        y_test_pred = [bert_label2id[l] for l in torch.tensor(y_test_pred, device=device).argmax(axis=-1).clone().detach().flatten().tolist()]\n",
                "        print(f'Length of y_test_pred: {len(y_test_pred)}')\n",
                "        print('-'*20)\n",
                "\n",
                "        # Get y_test_pred_prob\n",
                "        print('-'*20)\n",
                "        print(f'Find softmax and flattening y_test_pred for {col}')\n",
                "        try:\n",
                "            y_test_pred_prob = torch.nn.functional.softmax(torch.tensor(y_test_pred_prob[:, 1], device=device), dim=-1).clone().detach()\n",
                "            print('Using torch.nn.functional.softmax')\n",
                "        except Exception:\n",
                "            y_test_pred_prob = scipy.special.softmax(y_test_pred_prob[:, 1], axis=-1)\n",
                "            print('Using scipy.special.softmax')\n",
                "        finally:\n",
                "            y_test_pred_prob = y_test_pred_prob.flatten().tolist()\n",
                "        print(f'Length of y_test_pred_prob: {len(y_test_pred_prob)}')\n",
                "        print('-'*20)\n",
                "    \n",
                "    # # Examine predictions\n",
                "    # print('-'*20)\n",
                "    # print(f'Examining predictions for {col}')\n",
                "    # print('Incorrectly Classified Reviews:')\n",
                "    # for _y_test, _y_test_pred, _X_test in random.sample(list(zip(y_test, y_test_pred, X_test)), 20):\n",
                "    #     if _y_test != _y_test_pred:\n",
                "    #         print(f'TRUE LABEL: {_y_test}')\n",
                "    #         print(f'PREDICTED LABEL: {_y_test_pred}')\n",
                "    #         print(f'REVIEW TEXT: {_X_test[:100]}...')\n",
                "\n",
                "    # # Evluate estimator\n",
                "    # print('-'*20)\n",
                "    # print(f'Probs evaluation and ploting metrics for {col}')\n",
                "    # df_metrics = evaluation(predicted_results, df_metrics, col, tokenizer_name, classifier_name)\n",
                "    # print()\n",
                "\n",
                "    # # Save BERT Model\n",
                "    # print('-'*20)\n",
                "    # print(f'Saving estimator and metrics table for {col}')\n",
                "    # save_table(df_metrics, estimator, col, tokenizer_name, classifier_name)\n",
                "    # print()\n",
                "\n",
                "    # # Compare Estimators\n",
                "    # print('='*20)\n",
                "    # print(f'Comparing estimators for {col}')\n",
                "    # comparison_plots(get_completed_estimators().append(estimator), X_test, y_test, col)\n",
                "    # print('='*20)\n",
                "    # print()\n",
                "\n",
                "print('#'*40)\n",
                "print('DONE!')\n",
                "print('#'*40)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 193,
            "id": "26af9a3c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--------------------\n",
                        "Getting y_test_pred_prob for Warmth\n",
                        "Using torch.nn.functional.softmax\n",
                        "Length of y_test_pred_prob: 240\n"
                    ]
                }
            ],
            "source": [
                "# Get y_test_pred_prob\n",
                "print('-'*20)\n",
                "print(f'Getting y_test_pred_prob for {col}')\n",
                "try:\n",
                "    y_test_pred_prob = torch.nn.functional.softmax(torch.tensor(predicted_results.predictions, device=device), dim=-1)\n",
                "    print('Using torch.nn.functional.softmax')\n",
                "except Exception:\n",
                "    y_test_pred_prob = scipy.special.softmax(predicted_results.predictions, axis=1)\n",
                "    print('Using scipy.special.softmax')\n",
                "except Exception:\n",
                "    y_test_pred_prob = predicted_results.predictions[:, 1]\n",
                "    print('Using predicted_results.predictions[:, 1]')\n",
                "finally:\n",
                "    y_test_pred_prob = y_test_pred_prob.flatten().tolist()\n",
                "print(f'Length of y_test_pred_prob: {len(y_test_pred_prob)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 194,
            "id": "b5a9162b",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "numpy.ndarray"
                        ]
                    },
                    "execution_count": 194,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "type(y_test)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 195,
            "id": "01fa6221",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--------------------\n",
                        "Examining predictions for Warmth\n",
                        "Correctly Classified Reviews:\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3618849491.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/3618849491.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">random.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">482</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sample</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">479 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> [population[bisect(cum_counts, s)] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> s <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> selections]                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">480 │   │   </span>randbelow = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._randbelow                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> &lt;= k &lt;= n:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>482 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Sample larger than population or is negative\"</span>)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">483 │   │   </span>result = [<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>] * k                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">484 │   │   </span>setsize = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">21</span>        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># size of a small set minus size of an empty list</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">485 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> k &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
                            "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Sample larger than population or is negative\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/\u001b[0m\u001b[1;33m3618849491.py\u001b[0m:\u001b[94m5\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/3618849491.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/\u001b[0m\u001b[1;33mrandom.py\u001b[0m:\u001b[94m482\u001b[0m in \u001b[92msample\u001b[0m   \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m479 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m [population[bisect(cum_counts, s)] \u001b[94mfor\u001b[0m s \u001b[95min\u001b[0m selections]                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m480 \u001b[0m\u001b[2m│   │   \u001b[0mrandbelow = \u001b[96mself\u001b[0m._randbelow                                                        \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m481 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[94m0\u001b[0m <= k <= n:                                                                \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m482 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mSample larger than population or is negative\u001b[0m\u001b[33m\"\u001b[0m)               \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m483 \u001b[0m\u001b[2m│   │   \u001b[0mresult = [\u001b[94mNone\u001b[0m] * k                                                                \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m484 \u001b[0m\u001b[2m│   │   \u001b[0msetsize = \u001b[94m21\u001b[0m        \u001b[2m# size of a small set minus size of an empty list\u001b[0m              \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m485 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m k > \u001b[94m5\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
                            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
                            "\u001b[1;91mValueError: \u001b[0mSample larger than population or is negative\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Examine predictions\n",
                "print('-'*20)\n",
                "print(f'Examining predictions for {col}')\n",
                "print('Correctly Classified Reviews:')\n",
                "for y_test, _y_test_pred, _X_test in random.sample(list(zip(y_test, y_test_pred, X_test)), 20):\n",
                "    if y_test == y_test_pred:\n",
                "        print(f'LABEL: {y_test}')\n",
                "        print(f'REVIEW TEXT: {_X_test[:100]}...')\n",
                "        print('-'*20)\n",
                "        print()\n",
                "\n",
                "# print('Incorrectly Classified Reviews:')\n",
                "# for y_test, y_test_pred, _X_test in random.sample(list(zip(y_test, y_test_pred, X_test)), 20):\n",
                "#     if y_test != y_test_pred:\n",
                "#         print(f'TRUE LABEL: {y_test}')\n",
                "#         print(f'PREDICTED LABEL: {y_test_pred}')\n",
                "#         print(f'REVIEW TEXT: {_X_test[:100]}...')\n",
                "#         print()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 196,
            "id": "6961e8f7",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'Log Loss/Cross Entropy': 0.4136017858982086,\n",
                            " 'Explained Variance': 0.21333333333333315,\n",
                            " 'Accuracy': 0.7875,\n",
                            " 'Balanced Accuracy': 0.8015873015873016,\n",
                            " 'Precision': 0.6956521739130435,\n",
                            " 'Recall': 0.9142857142857143,\n",
                            " 'F1-score': 0.7901234567901234,\n",
                            " 'Matthews Correlation Coefficient': 0.6052920249203222,\n",
                            " 'Fowlkes–Mallows Index': 0.6633173894335515,\n",
                            " 'Cohen’s Kappa': 0.5828220858895705,\n",
                            " 'Geometric Mean': 0.6298412698412699,\n",
                            " 'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.91      0.69      0.78        45\\n           1       0.70      0.91      0.79        35\\n\\n    accuracy                           0.79        80\\n   macro avg       0.80      0.80      0.79        80\\nweighted avg       0.82      0.79      0.79        80\\n',\n",
                            " 'Imbalanced Classification Report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n          0       0.91      0.69      0.91      0.78      0.79      0.62        45\\n          1       0.70      0.91      0.69      0.79      0.79      0.64        35\\n\\navg / total       0.82      0.79      0.82      0.79      0.79      0.63        80\\n',\n",
                            " 'Confusion Matrix': array([[31, 14],\n",
                            "        [ 3, 32]]),\n",
                            " 'Normalized Confusion Matrix': array([[0.68888889, 0.31111111],\n",
                            "        [0.08571429, 0.91428571]]),\n",
                            " 'runtime': 2.2731,\n",
                            " 'samples_per_second': 35.195,\n",
                            " 'steps_per_second': 1.76}"
                        ]
                    },
                    "execution_count": 196,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "metrics_dict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 197,
            "id": "0a155ecb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--------------------\n",
                        "Getting y_test_pred_prob for Warmth\n",
                        "Using torch.nn.functional.softmax\n",
                        "Length of y_test_pred_prob: 240\n"
                    ]
                }
            ],
            "source": [
                "# Get y_test_pred_proba\n",
                "print('-'*20)\n",
                "print(f'Getting y_test_pred_prob for {col}')\n",
                "try:\n",
                "    y_test_pred_prob = torch.nn.functional.softmax(torch.tensor(predicted_results.predictions, device=device), dim=-1)\n",
                "    print('Using torch.nn.functional.softmax')\n",
                "except Exception:\n",
                "    y_test_pred_prob = scipy.special.softmax(predicted_results.predictions, axis=1)\n",
                "    print('Using scipy.special.softmax')\n",
                "except Exception:\n",
                "    y_test_pred_prob = predicted_results.predictions[:, 1]\n",
                "    print('Using predicted_results.predictions[:, 1]')\n",
                "finally:\n",
                "    y_test_pred_prob = y_test_pred_prob.flatten().tolist()\n",
                "print(f'Length of y_test_pred_prob: {len(y_test_pred_prob)}')\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 198,
            "id": "6d27de29",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'test_loss': 0.40211421251296997,\n",
                            " 'test_Explained Variance': 0.32441565756125046,\n",
                            " 'test_Accuracy': 0.825,\n",
                            " 'test_Balanced Accuracy': 0.811743170937764,\n",
                            " 'test_Precision': 0.7948717948717948,\n",
                            " 'test_Recall': 0.9253731343283582,\n",
                            " 'test_F1-score': 0.8551724137931035,\n",
                            " 'test_Matthews Correlation Coefficient': 0.6491279867142219,\n",
                            " 'test_Fowlkes–Mallows Index': 0.7215432668699364,\n",
                            " 'test_Cohen’s Kappa': 0.6373056994818653,\n",
                            " 'test_Geometric Mean': 0.6460152069839482,\n",
                            " 'test_Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.88      0.70      0.78        53\\n           1       0.79      0.93      0.86        67\\n\\n    accuracy                           0.82       120\\n   macro avg       0.84      0.81      0.82       120\\nweighted avg       0.83      0.82      0.82       120\\n',\n",
                            " 'test_Imbalanced Classification Report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n          0       0.88      0.70      0.93      0.78      0.80      0.63        53\\n          1       0.79      0.93      0.70      0.86      0.80      0.66        67\\n\\navg / total       0.83      0.82      0.80      0.82      0.80      0.65       120\\n',\n",
                            " 'test_Confusion Matrix': array([[37, 16],\n",
                            "        [ 5, 62]]),\n",
                            " 'test_Normalized Confusion Matrix': array([[0.69811321, 0.30188679],\n",
                            "        [0.07462687, 0.92537313]]),\n",
                            " 'test_runtime': 4.0984,\n",
                            " 'test_samples_per_second': 29.28,\n",
                            " 'test_steps_per_second': 1.464}"
                        ]
                    },
                    "execution_count": 198,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "predicted_results.metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 199,
            "id": "88c27631",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--------------------\n",
                        "Probs evaluation and ploting metrics for Warmth\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1347204323.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/1347204323.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
                            "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'df_metrics'</span> is not defined\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/\u001b[0m\u001b[1;33m1347204323.py\u001b[0m:\u001b[94m4\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/1347204323.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
                            "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'df_metrics'\u001b[0m is not defined\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Evluate estimator\n",
                "print('-'*20)\n",
                "print(f'Probs evaluation and ploting metrics for {col}')\n",
                "df_metrics = evaluation(predicted_results, df_metrics, col, classifier_name, tokenizer_name)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 200,
            "id": "3b34da0c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "False"
                        ]
                    },
                    "execution_count": 200,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "estimator.is_model_parallel\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 201,
            "id": "d9419be1",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "1"
                        ]
                    },
                    "execution_count": 201,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "estimator.args.n_gpu"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 202,
            "id": "fae6833c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">457744598.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/457744598.py'</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
                            "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'sentence'</span> is not defined\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/\u001b[0m\u001b[1;33m457744598.py\u001b[0m:\u001b[94m3\u001b[0m in \u001b[92m<module>\u001b[0m      \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/457744598.py'\u001b[0m                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
                            "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'sentence'\u001b[0m is not defined\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "df_manual['Bert Preditcions'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "    lambda sentence: estimator.predict(sent)\n",
                "    for sent in sentence\n",
                "    if sent and isinstance(sent, (str, list)) and isinstance(sentence, list)\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 203,
            "id": "80575d70",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/1230619439.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  item = {key: torch.tensor(val[idx], device=device) for key, val in self.encodings.items()}\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting prediction results for Warmth.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2849674287.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/2849674287.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2932</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluate</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2929 │   │   </span>start_time = time.time()                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2930 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2931 │   │   </span>eval_loop = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.use_legacy_prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">se</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2932 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = eval_loop(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2933 │   │   │   </span>eval_dataloader,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2934 │   │   │   </span>description=<span style=\"color: #808000; text-decoration-color: #808000\">\"Evaluation\"</span>,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2935 │   │   │   # No point gathering the predictions if there are no metrics, otherwise we d</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3220</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluation_loop</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3217 │   │   │   │   │   </span>EvalPrediction(predictions=all_preds, label_ids=all_labels, inputs=a  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3218 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3219 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3220 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>metrics = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_metrics(EvalPrediction(predictions=all_preds, lab  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3221 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3222 │   │   │   </span>metrics = {}                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3223 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3933834647.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">13</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_metrics</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/3933834647.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
                            "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>not enough values to unpack <span style=\"font-weight: bold\">(</span>expected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/\u001b[0m\u001b[1;33m2849674287.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m     \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/2849674287.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2932\u001b[0m in \u001b[92mevaluate\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2929 \u001b[0m\u001b[2m│   │   \u001b[0mstart_time = time.time()                                                          \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2930 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2931 \u001b[0m\u001b[2m│   │   \u001b[0meval_loop = \u001b[96mself\u001b[0m.prediction_loop \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.use_legacy_prediction_loop \u001b[94melse\u001b[0m \u001b[96mse\u001b[0m  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2932 \u001b[2m│   │   \u001b[0moutput = eval_loop(                                                               \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2933 \u001b[0m\u001b[2m│   │   │   \u001b[0meval_dataloader,                                                              \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2934 \u001b[0m\u001b[2m│   │   │   \u001b[0mdescription=\u001b[33m\"\u001b[0m\u001b[33mEvaluation\u001b[0m\u001b[33m\"\u001b[0m,                                                     \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m2935 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# No point gathering the predictions if there are no metrics, otherwise we d\u001b[0m  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m3220\u001b[0m in \u001b[92mevaluation_loop\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3217 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mEvalPrediction(predictions=all_preds, label_ids=all_labels, inputs=a  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3218 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3219 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3220 \u001b[2m│   │   │   │   \u001b[0mmetrics = \u001b[96mself\u001b[0m.compute_metrics(EvalPrediction(predictions=all_preds, lab  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3221 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3222 \u001b[0m\u001b[2m│   │   │   \u001b[0mmetrics = {}                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3223 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/\u001b[0m\u001b[1;33m3933834647.py\u001b[0m:\u001b[94m13\u001b[0m in             \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[92mcompute_metrics\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/3933834647.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
                            "\u001b[1;91mValueError: \u001b[0mnot enough values to unpack \u001b[1m(\u001b[0mexpected \u001b[1;36m3\u001b[0m, got \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "metrics_dict = estimator.evaluate()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 204,
            "id": "c00b3367",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'Log Loss/Cross Entropy': 0.4136017858982086,\n",
                            " 'Explained Variance': 0.21333333333333315,\n",
                            " 'Accuracy': 0.7875,\n",
                            " 'Balanced Accuracy': 0.8015873015873016,\n",
                            " 'Precision': 0.6956521739130435,\n",
                            " 'Recall': 0.9142857142857143,\n",
                            " 'F1-score': 0.7901234567901234,\n",
                            " 'Matthews Correlation Coefficient': 0.6052920249203222,\n",
                            " 'Fowlkes–Mallows Index': 0.6633173894335515,\n",
                            " 'Cohen’s Kappa': 0.5828220858895705,\n",
                            " 'Geometric Mean': 0.6298412698412699,\n",
                            " 'Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.91      0.69      0.78        45\\n           1       0.70      0.91      0.79        35\\n\\n    accuracy                           0.79        80\\n   macro avg       0.80      0.80      0.79        80\\nweighted avg       0.82      0.79      0.79        80\\n',\n",
                            " 'Imbalanced Classification Report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n          0       0.91      0.69      0.91      0.78      0.79      0.62        45\\n          1       0.70      0.91      0.69      0.79      0.79      0.64        35\\n\\navg / total       0.82      0.79      0.82      0.79      0.79      0.63        80\\n',\n",
                            " 'Confusion Matrix': array([[31, 14],\n",
                            "        [ 3, 32]]),\n",
                            " 'Normalized Confusion Matrix': array([[0.68888889, 0.31111111],\n",
                            "        [0.08571429, 0.91428571]]),\n",
                            " 'runtime': 2.2731,\n",
                            " 'samples_per_second': 35.195,\n",
                            " 'steps_per_second': 1.76}"
                        ]
                    },
                    "execution_count": 204,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "metrics_dict\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 205,
            "id": "9c06dc23",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/1230619439.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  item = {key: torch.tensor(val[idx], device=device) for key, val in self.encodings.items()}\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting prediction results for Warmth.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">238477192.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/238477192.py'</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3008</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3005 │   │   </span>start_time = time.time()                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3006 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3007 │   │   </span>eval_loop = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.use_legacy_prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">se</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3008 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = eval_loop(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3009 │   │   │   </span>test_dataloader, description=<span style=\"color: #808000; text-decoration-color: #808000\">\"Prediction\"</span>, ignore_keys=ignore_keys, metric_k  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3010 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3011 │   │   </span>total_batch_size = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.eval_batch_size * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.world_size               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">s/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3220</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluation_loop</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3217 │   │   │   │   │   </span>EvalPrediction(predictions=all_preds, label_ids=all_labels, inputs=a  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3218 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3219 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3220 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>metrics = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_metrics(EvalPrediction(predictions=all_preds, lab  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3221 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3222 │   │   │   </span>metrics = {}                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3223 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3933834647.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">13</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_metrics</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/3933834647.py'</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
                            "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
                            "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>not enough values to unpack <span style=\"font-weight: bold\">(</span>expected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/\u001b[0m\u001b[1;33m238477192.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m      \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/238477192.py'\u001b[0m                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m3008\u001b[0m in \u001b[92mpredict\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3005 \u001b[0m\u001b[2m│   │   \u001b[0mstart_time = time.time()                                                          \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3006 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3007 \u001b[0m\u001b[2m│   │   \u001b[0meval_loop = \u001b[96mself\u001b[0m.prediction_loop \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.use_legacy_prediction_loop \u001b[94melse\u001b[0m \u001b[96mse\u001b[0m  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3008 \u001b[2m│   │   \u001b[0moutput = eval_loop(                                                               \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3009 \u001b[0m\u001b[2m│   │   │   \u001b[0mtest_dataloader, description=\u001b[33m\"\u001b[0m\u001b[33mPrediction\u001b[0m\u001b[33m\"\u001b[0m, ignore_keys=ignore_keys, metric_k  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3010 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3011 \u001b[0m\u001b[2m│   │   \u001b[0mtotal_batch_size = \u001b[96mself\u001b[0m.args.eval_batch_size * \u001b[96mself\u001b[0m.args.world_size               \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/opt/homebrew/Caskroom/mambaforge/base/envs/study1_3.10/lib/python3.10/site-packages/transformer\u001b[0m \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33ms/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m3220\u001b[0m in \u001b[92mevaluation_loop\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3217 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mEvalPrediction(predictions=all_preds, label_ids=all_labels, inputs=a  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3218 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3219 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3220 \u001b[2m│   │   │   │   \u001b[0mmetrics = \u001b[96mself\u001b[0m.compute_metrics(EvalPrediction(predictions=all_preds, lab  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3221 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3222 \u001b[0m\u001b[2m│   │   │   \u001b[0mmetrics = {}                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m   \u001b[2m3223 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/\u001b[0m\u001b[1;33m3933834647.py\u001b[0m:\u001b[94m13\u001b[0m in             \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[92mcompute_metrics\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
                            "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_51092/3933834647.py'\u001b[0m                 \u001b[31m│\u001b[0m\n",
                            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
                            "\u001b[1;91mValueError: \u001b[0mnot enough values to unpack \u001b[1m(\u001b[0mexpected \u001b[1;36m3\u001b[0m, got \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "predicted_results = estimator.predict(bert_val_dataset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 206,
            "id": "a378b6c1",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'test_loss': 0.40211421251296997,\n",
                            " 'test_Explained Variance': 0.32441565756125046,\n",
                            " 'test_Accuracy': 0.825,\n",
                            " 'test_Balanced Accuracy': 0.811743170937764,\n",
                            " 'test_Precision': 0.7948717948717948,\n",
                            " 'test_Recall': 0.9253731343283582,\n",
                            " 'test_F1-score': 0.8551724137931035,\n",
                            " 'test_Matthews Correlation Coefficient': 0.6491279867142219,\n",
                            " 'test_Fowlkes–Mallows Index': 0.7215432668699364,\n",
                            " 'test_Cohen’s Kappa': 0.6373056994818653,\n",
                            " 'test_Geometric Mean': 0.6460152069839482,\n",
                            " 'test_Classification Report': '              precision    recall  f1-score   support\\n\\n           0       0.88      0.70      0.78        53\\n           1       0.79      0.93      0.86        67\\n\\n    accuracy                           0.82       120\\n   macro avg       0.84      0.81      0.82       120\\nweighted avg       0.83      0.82      0.82       120\\n',\n",
                            " 'test_Imbalanced Classification Report': '                   pre       rec       spe        f1       geo       iba       sup\\n\\n          0       0.88      0.70      0.93      0.78      0.80      0.63        53\\n          1       0.79      0.93      0.70      0.86      0.80      0.66        67\\n\\navg / total       0.83      0.82      0.80      0.82      0.80      0.65       120\\n',\n",
                            " 'test_Confusion Matrix': array([[37, 16],\n",
                            "        [ 5, 62]]),\n",
                            " 'test_Normalized Confusion Matrix': array([[0.69811321, 0.30188679],\n",
                            "        [0.07462687, 0.92537313]]),\n",
                            " 'test_runtime': 4.0984,\n",
                            " 'test_samples_per_second': 29.28,\n",
                            " 'test_steps_per_second': 1.464}"
                        ]
                    },
                    "execution_count": 206,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "predicted_results.metrics\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "98aa1b57",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.10"
        },
        "varInspector": {
            "cols": {
                "lenName": 16,
                "lenType": 16,
                "lenVar": 40
            },
            "kernels_config": {
                "python": {
                    "delete_cmd_postfix": "",
                    "delete_cmd_prefix": "del ",
                    "library": "var_list.py",
                    "varRefreshCmd": "print(var_dic_list())"
                },
                "r": {
                    "delete_cmd_postfix": ") ",
                    "delete_cmd_prefix": "rm(",
                    "library": "var_list.r",
                    "varRefreshCmd": "cat(var_dic_list()) "
                }
            },
            "types_to_exclude": [
                "module",
                "function",
                "builtin_function_or_method",
                "instance",
                "_Feature"
            ],
            "window_display": false
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
