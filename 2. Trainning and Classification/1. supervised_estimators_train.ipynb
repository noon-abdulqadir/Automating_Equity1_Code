{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d4c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # isort:skip # fmt:skip # noqa # nopep8 \n",
    "import sys # isort:skip # fmt:skip # noqa # nopep8\n",
    "from pathlib import Path # isort:skip # fmt:skip # noqa # nopep8\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "sys.path.append(code_dir)\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef3f604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417ccdef0fd74cc4b755d237f65199f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63343b3aca2943cda3b2b759fae5e7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99debbc19424b4aa6e796b656159724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ae8824e35b4d7ca4a87da5c15d3d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from setup_module.imports import * # isort:skip # fmt:skip # noqa # nopep8\n",
    "from supervised_estimators_get_pipe import * # isort:skip # fmt:skip # noqa # nopep8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ccdfed",
   "metadata": {},
   "source": [
    "### Set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b36fe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89f9258ccef4f3682bf2a664b5949e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb409ec13c5d42f1a16f842dd51efa17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variables\n",
    "# Sklearn variables\n",
    "method = 'Supervised'\n",
    "final_models_save_path = f'{models_save_path}{method} Results/'\n",
    "t = time.time()\n",
    "n_jobs = -1\n",
    "n_splits = 10\n",
    "n_repeats = 3\n",
    "random_state = 42\n",
    "refit = True\n",
    "class_weight = 'balanced'\n",
    "cv = RepeatedStratifiedKFold(\n",
    "    n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
    ")\n",
    "scoring = 'recall'\n",
    "scores = [\n",
    "    'recall', 'accuracy', 'f1', 'roc_auc',\n",
    "    'explained_variance', 'matthews_corrcoef'\n",
    "]\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score),\n",
    "}\n",
    "analysis_columns = ['Warmth', 'Competence']\n",
    "text_col = 'Job Description spacy_sentencized'\n",
    "metrics_dict = {\n",
    "    'Mean Cross Validation Train Score': np.nan,\n",
    "    'Mean Cross Validation Test Score': np.nan,\n",
    "    f'Mean Explained Train Variance - {scoring.title()}': np.nan,\n",
    "    f'Mean Explained Test Variance - {scoring.title()}': np.nan,\n",
    "    'Explained Variance': np.nan,\n",
    "    'Accuracy': np.nan,\n",
    "    'Balanced Accuracy': np.nan,\n",
    "    'Precision': np.nan,\n",
    "    'Recall': np.nan,\n",
    "    'F1-score': np.nan,\n",
    "    'Matthews Correlation Coefficient': np.nan,\n",
    "    'Fowlkes–Mallows Index': np.nan,\n",
    "    'ROC': np.nan,\n",
    "    'AUC': np.nan,\n",
    "    f'{scoring.title()} Best Threshold': np.nan,\n",
    "    f'{scoring.title()} Best Score': np.nan,\n",
    "    'Log Loss/Cross Entropy': np.nan,\n",
    "    'Cohen’s Kappa': np.nan,\n",
    "    'Geometric Mean': np.nan,\n",
    "    'Classification Report': np.nan,\n",
    "    'Confusion Matrix': np.nan,\n",
    "    'Normalized Confusion Matrix': np.nan\n",
    "}\n",
    "\n",
    "# Transformer variables\n",
    "max_length = 512\n",
    "returned_tensor = 'pt'\n",
    "cpu_counts = torch.multiprocessing.cpu_count()\n",
    "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available(\n",
    ") else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device_name = str(device.type)\n",
    "print(f'Using {device_name.upper()}')\n",
    "# Set random seed\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "DetectorFactory.seed = random_state\n",
    "cores = multiprocessing.cpu_count()\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    bert_model_name, strip_accents=True\n",
    ")\n",
    "bert_model = BertForSequenceClassification.from_pretrained(\n",
    "    bert_model_name\n",
    ").to(device)\n",
    "\n",
    "# Plotting variables\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "tqdm.tqdm.pandas(desc='progress-bar')\n",
    "tqdm_auto.tqdm.pandas(desc='progress-bar')\n",
    "tqdm.notebook.tqdm().pandas(desc='progress-bar')\n",
    "tqdm_auto.notebook_tqdm().pandas(desc='progress-bar')\n",
    "# pbar = progressbar.ProgressBar(maxval=10)\n",
    "mpl.use('MacOSX')\n",
    "mpl.style.use(f'{code_dir}/setup_module/apa.mplstyle-main/apa.mplstyle')\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "font = {'family': 'arial', 'weight': 'normal', 'size': 10}\n",
    "mpl.rc('font', **font)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "plt.set_cmap('Blues')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c5be4",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a26e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_and_close_plots():\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675cf660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_plots():\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f3840ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, col, text_col=None, analysis_columns=None):\n",
    "\n",
    "    if text_col is None:\n",
    "        text_col = 'Job Description spacy_sentencized'\n",
    "    if analysis_columns is None:\n",
    "        analysis_columns = ['Warmth', 'Competence']\n",
    "\n",
    "    train_ratio = 0.75\n",
    "    test_ratio = 0.10\n",
    "    validation_ratio = 0.15\n",
    "    test_split = test_size = 1 - train_ratio\n",
    "    validation_split = test_ratio / (test_ratio + validation_ratio)\n",
    "\n",
    "    # Split\n",
    "    print('='*20)\n",
    "    print('Splitting data into training, testing, and validation sets:')\n",
    "    print(f'Ratios: train_size = {train_ratio}, test size = {test_ratio}, validation size = {validation_ratio}')\n",
    "\n",
    "    df = df.dropna(subset=analysis_columns, how='any')\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    train, test = train_test_split(\n",
    "        df, train_size = 1-test_split, test_size = test_split, random_state=random_state\n",
    "    )\n",
    "\n",
    "    val, test = train_test_split(\n",
    "        test, test_size=validation_split, random_state=random_state\n",
    "    )\n",
    "\n",
    "    X_train = np.array(list(train[text_col].astype('str').values))\n",
    "    y_train = column_or_1d(train[col].astype('int64').values.tolist(), warn=True)\n",
    "\n",
    "    X_test = np.array(list(test[text_col].astype('str').values))\n",
    "    y_test = column_or_1d(test[col].astype('int64').values.tolist(), warn=True)\n",
    "\n",
    "    X_val = np.array(list(val[text_col].astype('str').values))\n",
    "    y_val = column_or_1d(val[col].astype('int64').values.tolist(), warn=True)\n",
    "\n",
    "    train_class_weights = compute_class_weight(class_weight = class_weight, classes = [0,1], y = y_train)\n",
    "    train_class_weights_ratio = train_class_weights[0]/train_class_weights[1]\n",
    "    train_class_weights_dict = dict(zip(np.unique(y_train), train_class_weights))\n",
    "    \n",
    "    test_class_weights = compute_class_weight(class_weight = class_weight, classes = [0,1], y = y_test)\n",
    "    test_class_weights_ratio = test_class_weights[0]/test_class_weights[1]\n",
    "    test_class_weights_dict = dict(zip(np.unique(y_test), test_class_weights))\n",
    "\n",
    "    print('Done splitting data into training, testing, and validation sets.')\n",
    "    print('='*20)\n",
    "    print(f'Training set shape: {y_train.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Training set example:\\n{X_train[0]}')\n",
    "    print('~'*10)\n",
    "    print(f'Testing set shape: {y_test.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Testing set example:\\n{X_test[0]}')\n",
    "    print('~'*10)\n",
    "    print(f'Validation set shape: {y_val.shape}')\n",
    "    print('-'*10)\n",
    "    print(f'Validation set example:\\n{X_val[0]}')\n",
    "    print('~'*10)\n",
    "    print(f'Training data class weights:\\nRatio = {train_class_weights_ratio:.2f} (0 = {train_class_weights[0]:.2f}, 1 = {train_class_weights[1]:.2f})')\n",
    "    print('-'*10)\n",
    "    print(f'Testing data class weights:\\nRatio = {test_class_weights_ratio:.2f} (0 = {test_class_weights[0]:.2f}, 1 = {test_class_weights[1]:.2f})')\n",
    "    print('='*20)\n",
    "\n",
    "    return (\n",
    "        train, X_train, y_train,\n",
    "        test, X_test, y_test,\n",
    "        val, X_val, y_val,\n",
    "        train_class_weights,\n",
    "        train_class_weights_ratio,\n",
    "        train_class_weights_dict,\n",
    "        test_class_weights,\n",
    "        test_class_weights_ratio,\n",
    "        test_class_weights_dict,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e46bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to place Xy and CV data in df and save\n",
    "def save_Xy_search_cv_estimator(\n",
    "    grid_search, searchcv,\n",
    "    X_train, y_train, y_train_pred,\n",
    "    X_test, y_test, y_test_pred, y_test_pred_prob,\n",
    "    X_val, y_val,\n",
    "    df_feature_importances, estimator,\n",
    "    col, vectorizer_name, classifier_name,\n",
    "    compression=None, save_path=None\n",
    "):\n",
    "\n",
    "    if compression is None:\n",
    "        compression = False\n",
    "    if save_path is None:\n",
    "        save_path = f'{final_models_save_path}SearchCV/'\n",
    "\n",
    "    # Save search\n",
    "    ## Save grid_search\n",
    "    with open(\n",
    "        f'{save_path}{method} Grid Search {str(col)} - {vectorizer_name} + {classifier_name}.pkl', 'wb'\n",
    "    ) as f:\n",
    "        joblib.dump(grid_search, f, compress=compression)\n",
    "\n",
    "    ## Save searchcv\n",
    "    with open(\n",
    "        f'{save_path}{method} SearchCV {str(col)} - {vectorizer_name} + {classifier_name}.pkl', 'wb'\n",
    "    ) as f:\n",
    "        joblib.dump(searchcv, f, compress=compression)\n",
    "\n",
    "    ## Save searchcv data\n",
    "    df_cv_results = pd.DataFrame(searchcv.cv_results_)\n",
    "    df_cv_results.to_pickle(\n",
    "        f'{save_path}{method} df_searchcv_results - {col}_{vectorizer_name}_{classifier_name}.pkl'\n",
    "    )\n",
    "\n",
    "    # Save Xy data\n",
    "    ## Save train data\n",
    "    df_train_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "            'y_train_pred': y_train_pred,\n",
    "        },\n",
    "    )\n",
    "    df_train_data.to_pickle(\n",
    "        f'{save_path}{method} df_train_data - {col}_{vectorizer_name}_{classifier_name}.pkl'\n",
    "    )\n",
    "\n",
    "    ## Save test data\n",
    "    df_test_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'y_test_pred': y_test_pred,\n",
    "            'y_test_pred_prob': y_test_pred_prob,\n",
    "        },\n",
    "    )\n",
    "    df_test_data.to_pickle(\n",
    "        f'{save_path}{method} df_test_data - {col}_{vectorizer_name}_{classifier_name}.pkl'\n",
    "    )\n",
    "\n",
    "    ## Save val data\n",
    "    df_val_data = pd.DataFrame(\n",
    "        {\n",
    "            'X_val': X_val,\n",
    "            'y_val': y_val,\n",
    "        },\n",
    "    )\n",
    "    df_val_data.to_pickle(\n",
    "        f'{save_path}{method} df_val_data - {col}_{vectorizer_name}_{classifier_name}.pkl'\n",
    "    )\n",
    "\n",
    "    # Save feature importance\n",
    "    if df_feature_importances is not None:\n",
    "        df_feature_importances.to_pickle(\n",
    "            f'{save_path}{method} df_feature_importances - {col}_{vectorizer_name}_{classifier_name}.pkl'\n",
    "        )\n",
    "\n",
    "    # Save estimator\n",
    "    with open(\n",
    "        f'{final_models_save_path}{method} Estimator {str(col)} - {vectorizer_name} + {classifier_name}.pkl', 'wb'\n",
    "    ) as f:\n",
    "        joblib.dump(estimator, f, compress=compression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036fcf10",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fe8e7a",
   "metadata": {},
   "source": [
    "### READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7fbe29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_for_trainning.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0212dc9",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################################\n",
      "Starting!\n",
      "########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                 | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "============================== TRAINING WARMTH ==============================\n",
      "--------------------\n",
      "Vectorizers to be used (3):\n",
      "['CountVectorizer', 'TfidfVectorizer', 'FeatureUnion']\n",
      "Total number of vectorizer parameters = 22\n",
      "Selectors to be used (1):\n",
      "['SelectKBest']\n",
      "Total number of selector parameters = 2\n",
      "Resamplers to be used (1):\n",
      "['SMOTETomek']\n",
      "Total number of resamplers parameters = 2\n",
      "Classifers to be used (14):\n",
      "['DummyClassifier', 'MultinomialNB', 'KNeighborsClassifier', 'LogisticRegression', 'PassiveAggressiveClassifier', 'Perceptron', 'LinearSVC', 'DecisionTreeClassifier', 'RandomForestClassifier', 'AdaBoostClassifier', 'XGBClassifier', 'MLPClassifier', 'VotingClassifier', 'StackingClassifier']\n",
      "Total number of classifers parameters = 57\n",
      "====================\n",
      "Splitting data into training, testing, and validation sets:\n",
      "Ratios: train_size = 0.75, test size = 0.1, validation size = 0.15\n",
      "Done splitting data into training, testing, and validation sets.\n",
      "====================\n",
      "Training set shape: (4483,)\n",
      "----------\n",
      "Training set example:\n",
      "Factors)\n",
      "~~~~~~~~~~\n",
      "Testing set shape: (598,)\n",
      "----------\n",
      "Testing set example:\n",
      "You’ll be part of an international consulting firm where people are lead by its values and inspired by our purpose;\n",
      "~~~~~~~~~~\n",
      "Validation set shape: (897,)\n",
      "----------\n",
      "Validation set example:\n",
      "Also my client is HQ’d in Europe meaning you will have better visibility and find it easier to engage and collaborate with your peers and the senior stakeholders (no late night calls to the USA).\n",
      "~~~~~~~~~~\n",
      "Training data class weights:\n",
      "Ratio = 0.33 (0 = 0.67, 1 = 2.00)\n",
      "----------\n",
      "Testing data class weights:\n",
      "Ratio = 0.34 (0 = 0.67, 1 = 1.97)\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c382bbc54a424af29400a790b8c515b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "============================== Using GridSearchCV ==============================\n",
      "--------------------\n",
      "GridSearchCV with:\n",
      "Pipe:\n",
      "Pipeline(steps=[('CountVectorizer', CountVectorizer()),\n",
      "                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),\n",
      "                ('DummyClassifier', DummyClassifier())])\n",
      "Params:\n",
      "{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x179cebe20>, <function chi2 at 0x179cebf40>, <function mutual_info_classif at 0x179d0a7a0>, <function f_regression at 0x179d080d0>, <function mutual_info_regression at 0x179d0a710>], 'SelectKBest__k': ['all'], 'DummyClassifier__strategy': ['stratified', 'most_frequent', 'prior', 'uniform'], 'DummyClassifier__random_state': [42]}\n",
      "++++++++++++++++++++++++++++++\n",
      "n_iterations: 4\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 120\n",
      "max_resources_: 4483\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1000\n",
      "n_resources: 120\n",
      "Fitting 30 folds for each of 1000 candidates, totalling 30000 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 334\n",
      "n_resources: 360\n",
      "Fitting 30 folds for each of 334 candidates, totalling 10020 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 112\n",
      "n_resources: 1080\n",
      "Fitting 30 folds for each of 112 candidates, totalling 3360 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 38\n",
      "n_resources: 3240\n",
      "Fitting 30 folds for each of 38 candidates, totalling 1140 fits\n",
      "====================\n",
      "GridSearch - Best mean train score: M = 0.50, SD = 0.00\n",
      "\n",
      "GridSearch - Best mean test score: M = 0.49, SD = 0.00\n",
      "\n",
      "Number of splits: 30\n",
      "\n",
      "Best estimator and parameters:\n",
      "Pipeline(steps=[('CountVectorizer',\n",
      "                 CountVectorizer(max_df=0.9, min_df=0.2, ngram_range=(1, 3))),\n",
      "                ('SelectKBest',\n",
      "                 SelectKBest(k='all',\n",
      "                             score_func=<function mutual_info_classif at 0x179d0a7a0>)),\n",
      "                ('SMOTETomek', SMOTETomek()),\n",
      "                ('DummyClassifier',\n",
      "                 DummyClassifier(random_state=42, strategy='uniform'))])\n",
      "\n",
      "Best parameters:\n",
      "{'CountVectorizer__analyzer': 'word', 'CountVectorizer__lowercase': True, 'CountVectorizer__max_df': 0.9, 'CountVectorizer__min_df': 0.2, 'CountVectorizer__ngram_range': (1, 3), 'DummyClassifier__random_state': 42, 'DummyClassifier__strategy': 'uniform', 'SelectKBest__k': 'all', 'SelectKBest__score_func': <function mutual_info_classif at 0x179d0a7a0>}\n",
      "\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.49      0.59      3365\n",
      "           1       0.24      0.48      0.32      1118\n",
      "\n",
      "    accuracy                           0.49      4483\n",
      "   macro avg       0.49      0.48      0.45      4483\n",
      "weighted avg       0.61      0.49      0.52      4483\n",
      "\n",
      "\n",
      "--------------------\n",
      "Best train score: 0.49\n",
      "\n",
      "Best test score: 0.51\n",
      "\n",
      "====================\n",
      "--------------------\n",
      "============================== Using GridSearchCV ==============================\n",
      "--------------------\n",
      "GridSearchCV with:\n",
      "Pipe:\n",
      "Pipeline(steps=[('CountVectorizer', CountVectorizer()),\n",
      "                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),\n",
      "                ('MultinomialNB', MultinomialNB())])\n",
      "Params:\n",
      "{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x179cebe20>, <function chi2 at 0x179cebf40>, <function mutual_info_classif at 0x179d0a7a0>, <function f_regression at 0x179d080d0>, <function mutual_info_regression at 0x179d0a710>], 'SelectKBest__k': ['all'], 'MultinomialNB__fit_prior': [True, False]}\n",
      "++++++++++++++++++++++++++++++\n",
      "n_iterations: 4\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 120\n",
      "max_resources_: 4483\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 500\n",
      "n_resources: 120\n",
      "Fitting 30 folds for each of 500 candidates, totalling 15000 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 167\n",
      "n_resources: 360\n",
      "Fitting 30 folds for each of 167 candidates, totalling 5010 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 56\n",
      "n_resources: 1080\n",
      "Fitting 30 folds for each of 56 candidates, totalling 1680 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 19\n",
      "n_resources: 3240\n",
      "Fitting 30 folds for each of 19 candidates, totalling 570 fits\n",
      "====================\n",
      "GridSearch - Best mean train score: M = 0.56, SD = 0.00\n",
      "\n",
      "GridSearch - Best mean test score: M = 0.55, SD = 0.00\n",
      "\n",
      "Number of splits: 30\n",
      "\n",
      "Best estimator and parameters:\n",
      "Pipeline(steps=[('CountVectorizer',\n",
      "                 CountVectorizer(lowercase=False, max_df=0.75, min_df=0.15,\n",
      "                                 ngram_range=(1, 3))),\n",
      "                ('SelectKBest', SelectKBest(k='all')),\n",
      "                ('SMOTETomek', SMOTETomek()),\n",
      "                ('MultinomialNB', MultinomialNB(fit_prior=False))])\n",
      "\n",
      "Best parameters:\n",
      "{'CountVectorizer__analyzer': 'word', 'CountVectorizer__lowercase': False, 'CountVectorizer__max_df': 0.75, 'CountVectorizer__min_df': 0.15, 'CountVectorizer__ngram_range': (1, 3), 'MultinomialNB__fit_prior': False, 'SelectKBest__k': 'all', 'SelectKBest__score_func': <function f_classif at 0x179cebe20>}\n",
      "\n",
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75      3365\n",
      "           1       0.38      0.56      0.45      1118\n",
      "\n",
      "    accuracy                           0.66      4483\n",
      "   macro avg       0.60      0.63      0.60      4483\n",
      "weighted avg       0.71      0.66      0.68      4483\n",
      "\n",
      "\n",
      "--------------------\n",
      "Best train score: 0.55\n",
      "\n",
      "Best test score: 0.63\n",
      "\n",
      "====================\n",
      "--------------------\n",
      "============================== Using GridSearchCV ==============================\n",
      "--------------------\n",
      "GridSearchCV with:\n",
      "Pipe:\n",
      "Pipeline(steps=[('CountVectorizer', CountVectorizer()),\n",
      "                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),\n",
      "                ('KNeighborsClassifier', KNeighborsClassifier())])\n",
      "Params:\n",
      "{'CountVectorizer__analyzer': ['word'], 'CountVectorizer__ngram_range': [(1, 3)], 'CountVectorizer__lowercase': [True, False], 'CountVectorizer__max_df': [0.9, 0.85, 0.8, 0.75, 0.7], 'CountVectorizer__min_df': [0.1, 0.15, 0.2, 0.25, 0.3], 'SelectKBest__score_func': [<function f_classif at 0x179cebe20>, <function chi2 at 0x179cebf40>, <function mutual_info_classif at 0x179d0a7a0>, <function f_regression at 0x179d080d0>, <function mutual_info_regression at 0x179d0a710>], 'SelectKBest__k': ['all'], 'KNeighborsClassifier__weights': ['uniform', 'distance'], 'KNeighborsClassifier__n_neighbors': [2, 5, 15], 'KNeighborsClassifier__algorithm': ['auto']}\n",
      "++++++++++++++++++++++++++++++\n",
      "n_iterations: 4\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 120\n",
      "max_resources_: 4483\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1500\n",
      "n_resources: 120\n",
      "Fitting 30 folds for each of 1500 candidates, totalling 45000 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('#'*40)\n",
    "print('Starting!')\n",
    "print('#'*40)\n",
    "\n",
    "analysis_columns = ['Warmth', 'Competence']\n",
    "text_col = 'Job Description spacy_sentencized'\n",
    "\n",
    "for col in tqdm.tqdm(analysis_columns):\n",
    "\n",
    "    print('-'*20)\n",
    "    print(f'{\"=\"*30} TRAINING {col.upper()} {\"=\"*30}')\n",
    "    print('-'*20)\n",
    "    print(f'Vectorizers to be used ({len(list(vectorizers_pipe.values()))}):\\n{list(vectorizers_pipe.keys())}')\n",
    "    print(f'Total number of vectorizer parameters = {sum([len(list(vectorizers_pipe.values())[i][1]) for i in range(len(vectorizers_pipe))])}')\n",
    "    print(f'Selectors to be used ({len(list(selectors_pipe.values()))}):\\n{list(selectors_pipe.keys())}')\n",
    "    print(f'Total number of selector parameters = {sum([len(list(selectors_pipe.values())[i][1]) for i in range(len(selectors_pipe))])}')\n",
    "    print(f'Resamplers to be used ({len(list(resamplers_pipe.keys()))}):\\n{list(resamplers_pipe.keys())}')\n",
    "    print(f'Total number of resamplers parameters = {sum([len(list(resamplers_pipe.values())[i][1]) for i in range(len(resamplers_pipe))])}')\n",
    "    print(f'Classifers to be used ({len(list(classifiers_pipe.keys()))}):\\n{list(classifiers_pipe.keys())}')\n",
    "    print(f'Total number of classifers parameters = {sum([len(list(classifiers_pipe.values())[i][1]) for i in range(len(classifiers_pipe))])}')\n",
    "    \n",
    "\n",
    "    assert len(df_manual[df_manual[str(col)].map(df_manual[str(col)].value_counts() > 1)]) != 0\n",
    "\n",
    "    # Split\n",
    "    (\n",
    "        train, X_train, y_train,\n",
    "        test, X_test, y_test,\n",
    "        val, X_val, y_val,\n",
    "        train_class_weights,\n",
    "        train_class_weights_ratio,\n",
    "        train_class_weights_dict,\n",
    "        test_class_weights,\n",
    "        test_class_weights_ratio,\n",
    "        test_class_weights_dict\n",
    "    ) = split_data(\n",
    "        df_manual, col, text_col, analysis_columns,\n",
    "    )\n",
    "\n",
    "    for (\n",
    "        vectorizer_name, vectorizer_and_params\n",
    "    ), (\n",
    "        selector_name, selector_and_params\n",
    "    ), (\n",
    "        resampler_name, resampler_and_params\n",
    "    ), (\n",
    "        classifier_name, classifier_and_params\n",
    "    ) in tqdm_product(\n",
    "        vectorizers_pipe.items(), selectors_pipe.items(), resamplers_pipe.items(), classifiers_pipe.items()\n",
    "    ):\n",
    "\n",
    "        # Identify names and params\n",
    "        vectorizer = vectorizer_and_params[0]\n",
    "        vectorizer_params = vectorizer_and_params[1]\n",
    "\n",
    "        selector = selector_and_params[0]\n",
    "        selector_params = selector_and_params[1]\n",
    "\n",
    "        resampler = resampler_and_params[0]\n",
    "        resampler_params = resampler_and_params[1]\n",
    "\n",
    "        classifier = classifier_and_params[0]\n",
    "        classifier_params = classifier_and_params[1]\n",
    "\n",
    "        # Pipeline\n",
    "        ## Steps\n",
    "        if col == 'Warmth':\n",
    "            steps = [\n",
    "                (vectorizer_name, vectorizer),\n",
    "                (selector_name, selector),\n",
    "                (resampler_name, resampler),\n",
    "                (classifier_name, classifier)\n",
    "            ]\n",
    "        else:\n",
    "            steps = [\n",
    "                (vectorizer_name, vectorizer),\n",
    "                (selector_name, selector),\n",
    "                (classifier_name, classifier)\n",
    "            ]\n",
    "\n",
    "        ## Params\n",
    "        param_grid = {\n",
    "            **vectorizer_params,\n",
    "            **selector_params,\n",
    "            **classifier_params,\n",
    "        }\n",
    "\n",
    "        ## Pipeline\n",
    "        pipe = imblearn.pipeline.Pipeline(steps=steps)\n",
    "\n",
    "        # Search\n",
    "        print('-'*20)\n",
    "        print(f'{\"=\"*30} Using GridSearchCV {\"=\"*30}')\n",
    "        print('-'*20)\n",
    "        print(f'GridSearchCV with:\\nPipe:\\n{pipe}\\nParams:\\n{param_grid}')\n",
    "        print('+'*30)\n",
    "\n",
    "        grid_search = HalvingGridSearchCV(\n",
    "            estimator=pipe,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            n_jobs=n_jobs,\n",
    "            return_train_score=True,\n",
    "            verbose=1,\n",
    "            scoring=scoring,\n",
    "            error_score='raise',\n",
    "            random_state=random_state,\n",
    "            refit=refit,\n",
    "        )\n",
    "        ## Normalize unusual classifiers before fitting\n",
    "        if classifier_name == 'GaussianNB':\n",
    "            X_train = X_train.todense()\n",
    "            X_test = X_test.todense()\n",
    "            X_val = X_val.todense()\n",
    "\n",
    "        # Fit SearchCV\n",
    "        with joblib.parallel_backend(backend='multiprocessing', n_jobs=n_jobs):\n",
    "            searchcv = grid_search.fit(X_train, y_train)\n",
    "\n",
    "            # Reidentify and name best estimator and params\n",
    "            estimator = searchcv.best_estimator_\n",
    "            vectorizer = estimator[0]\n",
    "            vectorizer_params = vectorizer.get_params()\n",
    "            vectorizer_name = vectorizer.__class__.__name__\n",
    "            selector = estimator[1]\n",
    "            selector_params = selector.get_params()\n",
    "            selector_name = selector.__class__.__name__\n",
    "            classifier = estimator[-1]\n",
    "            classifier_params = classifier.get_params()\n",
    "            classifier_name = classifier.__class__.__name__\n",
    "            if col == 'Warmth':\n",
    "                resampler = estimator[-2]\n",
    "                resampler_params = resampler.get_params()\n",
    "                resampler_name = resampler.__class__.__name__\n",
    "\n",
    "            # Normalize unusual classifiers after fitting\n",
    "            ## Get feature importance if classifier provides them and use as X\n",
    "            if any(hasattr(estimator, feature_attr) for feature_attr in ['feature_importances_', 'coef_']):\n",
    "                feature_selector = SelectFromModel(estimator, prefit=True)\n",
    "                X_train = feature_selector.transform(X_train)\n",
    "                X_test = X_test[:, feature_selector.get_support()]\n",
    "                df_feature_importances = pd.DataFrame(\n",
    "                    {\n",
    "                        'features': X_test.values,\n",
    "                        'feature_importances': estimator.feature_importances_\n",
    "                    }\n",
    "                )\n",
    "                df_feature_importances = df_feature_importances.sort_values('feature_importances', ascending=False)\n",
    "                print(df_feature_importances.head(20))\n",
    "                print(f'Best estimator has feature_importances of shape:\\n{estimator}')\n",
    "            else:\n",
    "                df_feature_importances = None\n",
    "            ## For perceptron: calibrate classifier to get prediction probabilities\n",
    "            if hasattr(searchcv, 'decision_function') and not all(hasattr(searchcv, pred_attr) for pred_attr in ['predict_proba', '_predict_proba_lr']):\n",
    "                searchcv = CalibratedClassifierCV(\n",
    "                    searchcv, cv=cv, method='sigmoid'\n",
    "                ).fit(X_train, y_train)\n",
    "            ## For Sequential classifier: compile for binary classification, optimize with adam and score on recall\n",
    "            if classifier_name == 'Sequential':\n",
    "                searchcv.compile(\n",
    "                    loss='binary_crossentropy', optimizer='adam', metrics=list(scoring)\n",
    "                ).fit(X_train, y_train)\n",
    "\n",
    "            ## Set prediction probability attribute\n",
    "            if hasattr(searchcv, 'predict_proba'):\n",
    "                searchcv_predict_attr = searchcv.predict_proba\n",
    "            elif hasattr(searchcv, '_predict_proba_lr'):\n",
    "                searchcv_predict_attr = searchcv._predict_proba_lr\n",
    "\n",
    "            # Get predictions and probabilities\n",
    "            y_train_pred = estimator.predict(X_train)\n",
    "            y_test_pred = searchcv.predict(X_test)\n",
    "            y_test_pred_prob = searchcv_predict_attr(X_test)[:, 1]\n",
    "\n",
    "            # Save Xy and CV data\n",
    "            save_Xy_search_cv_estimator(\n",
    "                grid_search, searchcv,\n",
    "                X_train, y_train, y_train_pred,\n",
    "                X_test, y_test, y_test_pred, y_test_pred_prob,\n",
    "                X_val, y_val,\n",
    "                df_feature_importances, estimator,\n",
    "                col, vectorizer_name, classifier_name,\n",
    "            )\n",
    "\n",
    "            # Print results\n",
    "            print('='*20)\n",
    "            print(\n",
    "                f'GridSearch - Best mean train score: M = {float(best_mean_train_score:=searchcv.cv_results_[\"mean_train_score\"][best_index:=searchcv.best_index_]):.2f}, SD = {int(best_std_train_score:=searchcv.cv_results_[\"std_train_score\"][best_index]):.2f}\\n'\n",
    "            )\n",
    "            print(\n",
    "                f'GridSearch - Best mean test score: M = {float(best_mean_test_score:=searchcv.cv_results_[\"mean_test_score\"][best_index]):.2f}, SD = {int(best_std_test_score:=searchcv.cv_results_[\"std_test_score\"][best_index]):.2f}\\n'\n",
    "            )\n",
    "            print(\n",
    "                f'Number of splits: {int(n_splits:=searchcv.n_splits_)}\\n'\n",
    "            )\n",
    "            print(\n",
    "                f'Best estimator and parameters:\\n{estimator}\\n')\n",
    "            print(\n",
    "                f'Best parameters:\\n{(best_params:=searchcv.best_params_)}\\n'\n",
    "            )\n",
    "            print(\n",
    "                f'Training Classification Report:\\n{(train_report:=classification_report(y_train, y_train_pred))}\\n'\n",
    "            )\n",
    "            print('-'*20)\n",
    "            print(\n",
    "                f'Best train score: {float(best_train_score:=searchcv.best_score_):.2f}\\n'\n",
    "            )\n",
    "            print(\n",
    "                f'Best test score: {float(best_test_score:=searchcv.score(X_test, y_test)):.2f}\\n'\n",
    "            )\n",
    "            print('='*20)\n",
    "\n",
    "print('#'*40)\n",
    "print('DONE!')\n",
    "print('#'*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2642e18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "study1_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
