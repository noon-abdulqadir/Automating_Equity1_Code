Using MPS
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using MPS
0it [00:00, ?it/s]0it [00:00, ?it/s]
Using MPS
0it [00:00, ?it/s]0it [00:00, ?it/s]
Dataframe loaded with shape: (5978, 58)
########################################
Starting!
########################################
Searching for existing estimators in directory:
/Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/Supervised Results/
  0%|          | 0/49 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:00<00:00, 441031.97it/s]
  0%|          | 0/2 [00:00<?, ?it/s]--------------------
============================== TRAINING DATASET OF LENGTH 5978 ON WARMTH ==============================
--------------------
Vectorizers to be used (3):
['CountVectorizer', 'TfidfVectorizer', 'FeatureUnion']
Total number of vectorizer parameters = 6
Selectors to be used (1):
['SelectKBest']
Total number of selector parameters = 2
Resamplers to be used (1):
['SMOTETomek']
Total number of resamplers parameters = 2
classifiers to be used (4):
['VotingClassifier', 'StackingClassifier', 'AdaBoostClassifier', 'BaggingClassifier']
Total number of classifiers parameters = 11
Loading previous Xy.
++++++++++++++++++++++++++++++
========== Loading Xy from previous for Warmth ==========
++++++++++++++++++++++++++++++
Loading df_train_data from /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_train_data - Warmth - (Save_protocol=5).pkl
Loading df_test_data from /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_test_data - Warmth - (Save_protocol=5).pkl
Loading df_val_data from /Users/nyxinsane/Documents/Work - UvA/Automating Equity/Study 1/Study1_Code/data/classification models/df_val_data - Warmth - (Save_protocol=5).pkl
Done loading Xy from previous for Warmth!
Done splitting data into training and testing sets.
====================
Training set shape: (4023,)
----------
Training set example:
Analysis (technical, quantitative and qualitative) of multiple sources of information (commercial Intelligence, OSINT, community, **ISACs sharing) to provide timely, actionable intelligence and reporting.
~~~~~~~~~~
Testing set shape: (537,)
----------
Testing set example:
Experience with agile development practices, particularly owning and running specific agile events such as backlog refinement and sprint reviews Knowledge of multi channel supply chain processes, preferable in a retail context.
~~~~~~~~~~
Validation set shape: (805,)
----------
Validation set example:
Duties and responsibilities: Handling incoming phone calls and emails from the website users;Acting as an intermediary between the customers and accommodations;Managing reservations, special requests, and complaints and finding solutions to website users inquiries.
~~~~~~~~~~
Training data class weights:
Ratio = 0.33 (0 = 0.67, 1 = 2.00)
----------
Testing data class weights:
Ratio = 0.40 (0 = 0.70, 1 = 1.74)
----------
Validation data class weights:
Ratio = 0.30 (0 = 0.65, 1 = 2.14)
====================
Done loading Xy from previous for Warmth!

  0%|          | 0/12 [00:00<?, ?it/s][A--------------------
Already trained Warmth - CountVectorizer + VotingClassifier
--------------------
--------------------
Already trained Warmth - CountVectorizer + StackingClassifier
--------------------
--------------------
Already trained Warmth - CountVectorizer + AdaBoostClassifier
--------------------
--------------------
Already trained Warmth - CountVectorizer + BaggingClassifier
--------------------
--------------------
Already trained Warmth - TfidfVectorizer + VotingClassifier
--------------------
--------------------
Already trained Warmth - TfidfVectorizer + StackingClassifier
--------------------
--------------------
Already trained Warmth - TfidfVectorizer + AdaBoostClassifier
--------------------
--------------------
Already trained Warmth - TfidfVectorizer + BaggingClassifier
--------------------
--------------------
Already trained Warmth - FeatureUnion + VotingClassifier
--------------------
--------------------
Already trained Warmth - FeatureUnion + StackingClassifier
--------------------
--------------------
============================== Using GridSearchCV ==============================
--------------------
GridSearchCV with:
Pipe:
Pipeline(steps=[('FeatureUnion',
                 FeatureUnion(transformer_list=[('CountVectorizer',
                                                 CountVectorizer(max_df=0.85,
                                                                 min_df=0.15,
                                                                 ngram_range=(1,
                                                                              3))),
                                                ('TfidfVectorizer',
                                                 TfidfVectorizer(max_df=0.85,
                                                                 min_df=0.15,
                                                                 ngram_range=(1,
                                                                              3)))])),
                ('SelectKBest', SelectKBest()), ('SMOTETomek', SMOTETomek()),
                ('AdaBoostClassifier',
                 AdaBoostClassifier(estimator=VotingClassifier(...
                                                                                               random_state=42,
                                                                                               solver='liblinear')),
                                                                           ('DecisionTreeClassifier',
                                                                            DecisionTreeClassifier(class_weight='balanced',
                                                                                                   max_depth=2,
                                                                                                   random_state=42)),
                                                                           ('RandomForestClassifier',
                                                                            RandomForestClassifier(class_weight='balanced',
                                                                                                   max_depth=2,
                                                                                                   n_estimators=50,
                                                                                                   random_state=42)),
                                                                           ('GradientBoostingClassifier',
                                                                            GradientBoostingClassifier(random_state=42))],
                                                               voting='soft')))])
Params:
{'FeatureUnion__CountVectorizer__analyzer': ['word'], 'FeatureUnion__CountVectorizer__ngram_range': [(1, 3)], 'FeatureUnion__CountVectorizer__lowercase': [True, False], 'FeatureUnion__CountVectorizer__max_df': [0.85, 0.8, 0.75], 'FeatureUnion__CountVectorizer__min_df': [0.15, 0.2, 0.25], 'FeatureUnion__TfidfVectorizer__analyzer': ['word'], 'FeatureUnion__TfidfVectorizer__ngram_range': [(1, 3)], 'FeatureUnion__TfidfVectorizer__lowercase': [True, False], 'FeatureUnion__TfidfVectorizer__use_idf': [True, False], 'FeatureUnion__TfidfVectorizer__max_df': [0.85, 0.8, 0.75], 'FeatureUnion__TfidfVectorizer__min_df': [0.15, 0.2, 0.25], 'SelectKBest__score_func': [<function f_classif at 0x288df1900>, <function chi2 at 0x288df1a20>, <function f_regression at 0x288df1b40>], 'SelectKBest__k': ['all'], 'AdaBoostClassifier__random_state': [42], 'AdaBoostClassifier__n_estimators': [50, 100, 150], 'AdaBoostClassifier__learning_rate': [0.01, 0.1, 0.5, 1], 'AdaBoostClassifier__algorithm': ['SAMME', 'SAMME.R']}
++++++++++++++++++++++++++++++
Fitting GridSearchCV
n_iterations: 4
n_required_iterations: 10
n_possible_iterations: 4
min_resources_: 120
max_resources_: 4828
aggressive_elimination: False
factor: 3
----------
iter: 0
n_candidates: 46656
n_resources: 120
Fitting 30 folds for each of 46656 candidates, totalling 1399680 fits
