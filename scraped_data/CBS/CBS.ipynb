{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "sys.path.append(code_dir)\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_module.imports import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stopwords\n",
    "def remove_code(keywords_lst: list, keyword_clean_lst=None) -> list:\n",
    "\n",
    "    if keyword_clean_lst is None:\n",
    "        keyword_clean_lst = []\n",
    "\n",
    "    for s in keywords_lst:\n",
    "        lst = s.split()\n",
    "        for i in lst:\n",
    "            if len(i) <= 2:\n",
    "                lst.remove(i)\n",
    "            keyword_clean_lst.append(' '.join(lst))\n",
    "\n",
    "    # map(lambda n: n * 2, [1, 2, 3, 4, 5])\n",
    "    return [x for x in keyword_clean_lst if x != '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to to check file exists and not empty\n",
    "def is_non_zero_file(fpath):\n",
    "\n",
    "    return (os.path.isfile(fpath) and os.path.getsize(fpath) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to validate path or file\n",
    "def validate_path(file: str) -> str:\n",
    "\n",
    "    if not os.path.isdir(file) and is_non_zero_file(file) is False:\n",
    "        # file = input(f'No file found at {file}.\\nPlease enter correct path.')\n",
    "        try:\n",
    "            print(f'File {file} not found.')\n",
    "        except Exception as e:\n",
    "            print(e.json())\n",
    "    return file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean keyword list\n",
    "def clean_and_translate_keyword_list(\n",
    "    keywords_lst: list,\n",
    "    translate_enabled = None\n",
    ") -> list:\n",
    "\n",
    "    if translate_enabled is None:\n",
    "        translate_enabled = False\n",
    "    elif translate_enabled is True:\n",
    "        translator = Translator()\n",
    "\n",
    "    assert all(isinstance(i, str) for i in keywords_lst), 'Keywords must be strings.'\n",
    "\n",
    "    # Collect all and and comma containing keywords\n",
    "    and_comma = [i for i in keywords_lst if (',' in i) or ('and' in i)]\n",
    "\n",
    "    # Remove ands and commas and append to keywords\n",
    "    if len(and_comma) > 0:\n",
    "        for i in and_comma:\n",
    "            for x in re.split('and|,', i.strip().lower()):\n",
    "                keywords_lst.append(x.strip().lower())\n",
    "\n",
    "        # Remove duplicates\n",
    "        keywords_lst = list(set(keywords_lst) ^ set(and_comma))\n",
    "\n",
    "    else:\n",
    "        keywords_lst = list(set(keywords_lst))\n",
    "\n",
    "    # # Remove codes\n",
    "    keywords_lst = remove_code(keywords_lst)\n",
    "\n",
    "    # Singularize and remove duplicates\n",
    "    keywords_list = list(\n",
    "        set(\n",
    "            list(\n",
    "                map(\n",
    "                    lambda line: (Word(line.lower()).singularize()).lower(),\n",
    "                    keywords_lst,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Remove all non-specific keywords\n",
    "    for i in keywords_list:\n",
    "        if 'other ' in i.lower() and i.lower() not in ['other business support', 'other service activities']:\n",
    "            keywords_list.append(i.lower().split('other')[1])\n",
    "            keywords_list.remove(i)\n",
    "        if ' (excl.' in i.lower():\n",
    "            keywords_list.append(i.lower().split(' (excl.')[0].lower())\n",
    "            keywords_list.remove(i)\n",
    "        if '_(excl' in i.lower():\n",
    "            keywords_list.append(i.lower().split('_(excl')[0].lower())\n",
    "            keywords_list.remove(i)\n",
    "    for i in keywords_list:\n",
    "        if ' (' in i.lower():\n",
    "            keywords_list.append(i.lower().split(' (')[0].lower())\n",
    "            keywords_list.remove(i)\n",
    "        if \"-Noon's\" in i.lower():\n",
    "            keywords_list.append(i.lower().split('-Noon')[0].lower())\n",
    "            keywords_list.remove(i)\n",
    "        if len(i) <= 2:\n",
    "            keywords_list.remove(i)\n",
    "    for i in keywords_list:\n",
    "        for w_keyword, r_keyword in keyword_trans_dict.items():\n",
    "            if str(i.lower()) == w_keyword.lower():\n",
    "                keywords_list.remove(i)\n",
    "                keywords_list.append(r_keyword)\n",
    "\n",
    "    # Remove duplicates\n",
    "    keywords_list = list(filter(None, list(set(keywords_list))))\n",
    "\n",
    "    # Translate to Dutch\n",
    "    if translate_enabled is True:\n",
    "        for english_keyword in keywords_list:\n",
    "            while True:\n",
    "                try:\n",
    "                    dutch_keyword = translator.translate(english_keyword).text\n",
    "                except Exception as e:\n",
    "                    time.sleep(0.3)\n",
    "                    continue\n",
    "                break\n",
    "            keywords_list.append(dutch_keyword.lower())\n",
    "\n",
    "        # Remove duplicates\n",
    "        keywords_list = list(filter(None, list(set(keywords_list))))\n",
    "\n",
    "    return list(\n",
    "        filter(None, list(set([i.lower().strip() for i in keywords_list if i])))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% CBS Data request\n",
    "def get_cbs_odata(\n",
    "    sectors_file_path = None,\n",
    "    table_url: str = None,\n",
    "    table_id: str = None,\n",
    "    addition_url: str = None,\n",
    "    select: list=None,\n",
    "):\n",
    "    if sectors_file_path is None:\n",
    "        sectors_file_path: str = validate_path(f'{code_dir}/scraped_data/CBS/Found Data/')\n",
    "    if table_url is None:\n",
    "        table_url='https://opendata.cbs.nl/ODataAPI/OData/'\n",
    "    if table_id is None:\n",
    "        table_id='81434ENG'\n",
    "    if addition_url is None:\n",
    "        addition_url='/UntypedDataSet'\n",
    "    if select is None:\n",
    "        select=['SexOfEmployee', 'TypeOfEmploymentContract', 'OtherCharacteristicsEmployee', 'IndustryClassBranchSIC2008', 'Periods', 'Jobs_1']\n",
    "    # data: https://opendata.cbs.nl/#/CBS/en/dataset/81434ENG/table?ts=1663627369191\n",
    "    # instruction: https://data.overheid.nl/dataset/410-bevolking-op-eerste-van-de-maand--geslacht--leeftijd--migratieachtergrond\n",
    "    # github: https://github.com/statistiekcbs/CBS-Open-Data-v4\n",
    "\n",
    "    tables = cbsodata.get_table_list()\n",
    "    for table in tables:\n",
    "        if table['Identifier'] == table_id:\n",
    "            data_info = table\n",
    "    info = cbsodata.get_info(table_id)\n",
    "    diffs = list(set(info.keys()) - set(data_info.keys()))\n",
    "    for i in diffs:\n",
    "        data_info[i] = info[i]\n",
    "\n",
    "    with open(f'{sectors_file_path}cbs_data_info.json', 'w', encoding='utf8') as f:\n",
    "        json.dump(data_info, f)\n",
    "\n",
    "    dimensions = defaultdict(dict)\n",
    "    for sel in select:\n",
    "        if sel != 'Jobs_1':\n",
    "            meta_data = pd.DataFrame(cbsodata.get_meta('81434ENG', sel))\n",
    "        if sel == 'TypeOfEmploymentContract':\n",
    "            meta_data = meta_data.loc[~meta_data['Title'].str.contains('Type of employment contract:')]\n",
    "        if sel == 'OtherCharacteristicsEmployee':\n",
    "            meta_data = meta_data.loc[~meta_data['Key'].str.contains('NAT')]\n",
    "        if sel == 'Periods':\n",
    "            meta_data = meta_data.loc[meta_data['Title'].astype(str) == '2020']\n",
    "\n",
    "        for title, key in zip(meta_data['Title'].tolist(), meta_data['Key'].tolist()):\n",
    "            if sel != 'Jobs_1':\n",
    "                dimensions[sel][title] = key\n",
    "    with open(f'{sectors_file_path}cbs_data_dimensions.json', 'w', encoding='utf8') as f:\n",
    "        json.dump(dimensions, f)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            data = pd.DataFrame(cbsodata.get_data(table_id, select=select))\n",
    "            break\n",
    "        except ConnectionError:\n",
    "            time.sleep(5)\n",
    "\n",
    "    data = data.loc[~data['TypeOfEmploymentContract'].str.contains('Type of employment contract:') & ~data['OtherCharacteristicsEmployee'].str.contains('Nationality:') & data['Periods'].str.contains('2020')]\n",
    "\n",
    "    data.to_csv(f'{sectors_file_path}Sectors Tables/FINAL/Gender x Age_CBS_DATA_from_code.csv')\n",
    "\n",
    "    # target_url = table_url + table_id + addition_url\n",
    "\n",
    "    # data = pd.DataFrame()\n",
    "    # while target_url:\n",
    "    #     r = requests.get(target_url).json()\n",
    "    #     data = data.append(pd.DataFrame(r['value']))\n",
    "\n",
    "    #     if '@odata.nextLink' in r:\n",
    "    #         target_url = r['@odata.nextLink']\n",
    "    #     else:\n",
    "    #         target_url = None\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Function to get sbi_sectors_dict\n",
    "def get_sbi_sectors_list(\n",
    "    save_enabled=None,\n",
    "    parent_dir=None,\n",
    "    ):\n",
    "\n",
    "    if save_enabled is None:\n",
    "        save_enabled=True\n",
    "    if parent_dir is None:\n",
    "        parent_dir=validate_path(f'{code_dir}/scraped_data/CBS/')\n",
    "\n",
    "    sib_5_loc = validate_path(f'{parent_dir}Found Data/SBI_ALL_NACE_REV2.csv')\n",
    "    data_save_dir = validate_path(f'{parent_dir}Data/')\n",
    "\n",
    "    df_sbi_sectors = pd.read_csv(sib_5_loc, delimiter=',')\n",
    "    df_sbi_sectors.columns = df_sbi_sectors.columns.str.strip()\n",
    "    df_sbi_sectors = df_sbi_sectors.rename(columns = {'Description': 'Old_Sector_Name'})\n",
    "    df_sbi_sectors = df_sbi_sectors.dropna(subset=['Old_Sector_Name', 'Code'])\n",
    "    df_sbi_sectors['Old_Sector_Name'] = df_sbi_sectors['Old_Sector_Name'].progress_apply(lambda x: x.lower().strip())\n",
    "    df_sbi_sectors = df_sbi_sectors.loc[df_sbi_sectors['Level'] == 1]\n",
    "    df_sbi_sectors = df_sbi_sectors.drop(columns=['Level', 'Parent', 'This item includes', 'This item also includes', 'Rulings', 'This item excludes', 'Reference to ISIC Rev. 4'])\n",
    "\n",
    "    df_sectors_all = pd.read_pickle(f'{data_save_dir}Sectors Output from script.pkl')[[('SBI Sector Titles'), ('Gender'), ('Age')]].droplevel('Categories', axis='columns')[[('SBI Sector Titles', 'Code'), ('SBI Sector Titles', 'Sector Name'), ('SBI Sector Titles', 'Keywords'), ('Gender', 'Dominant Category'), ('Age', 'Dominant Category')]].droplevel('Variables', axis='columns')\n",
    "    df_sectors_all.columns = ['Code', 'Sector Name', 'Keywords', 'Gender Dominant Category', 'Age Dominant Category']\n",
    "    df_sbi_sectors = df_sbi_sectors.merge(df_sectors_all, how='inner', on='Code')\n",
    "    df_sbi_sectors = df_sbi_sectors.rename(columns = {'Sector Name': 'Sector_Name', 'Keywords': 'Used_Sector_Keywords', 'Gender Dominant Category': 'Gender_Dominant_Category', 'Age Dominant Category': 'Age_Dominant_Category'})\n",
    "    df_sbi_sectors['Sector_Name'] = df_sbi_sectors['Sector_Name'].progress_apply(lambda x: x.strip().lower() if isinstance(x, str) else np.nan)\n",
    "    df_sbi_sectors['Used_Sector_Keywords'] = df_sbi_sectors['Used_Sector_Keywords'].progress_apply(lambda x: clean_and_translate_keyword_list(x) if isinstance(x, list) else np.nan)\n",
    "    df_sbi_sectors = df_sbi_sectors.set_index(df_sbi_sectors['Code'])\n",
    "\n",
    "    df_sbi_sectors.to_csv(f'{data_save_dir}SBI-5_Sectors.csv', index=True)\n",
    "    df_sbi_sectors.to_excel(f'{data_save_dir}SBI-5_Sectors.xlsx', index=True)\n",
    "    df_sbi_sectors.to_pickle(f'{data_save_dir}SBI-5_Sectors.pkl')\n",
    "\n",
    "    sbi_english_keyword_list = [i for index, row in df_sbi_sectors['Used_Sector_Keywords'].items() if isinstance(row, list) for i in row]\n",
    "    sbi_english_keyword_list = clean_and_translate_keyword_list(sbi_english_keyword_list)\n",
    "\n",
    "    sbi_english_keyword_dict = df_sbi_sectors['Used_Sector_Keywords'].to_dict()\n",
    "    sbi_sectors_dict = df_sbi_sectors.to_dict('index')\n",
    "    sbi_sectors_dict_full = {}\n",
    "    sbi_sectors_dom_gen = {}\n",
    "    sbi_sectors_dom_age = {}\n",
    "    sbi_sectors_keywords_gen_dom = defaultdict(list)\n",
    "    sbi_sectors_keywords_age_dom = defaultdict(list)\n",
    "    sbi_sectors_keywords_full_dom = defaultdict(list)\n",
    "    for index, row in df_sbi_sectors.iterrows():\n",
    "        sbi_sectors_dict_full[row['Sector_Name']] = row['Used_Sector_Keywords']\n",
    "        sbi_sectors_dom_gen[row['Sector_Name']] = row['Gender_Dominant_Category']\n",
    "        sbi_sectors_dom_age[row['Sector_Name']] = row['Age_Dominant_Category']\n",
    "    for cat_keywords in df_sbi_sectors[['Gender_Dominant_Category', 'Used_Sector_Keywords']].to_dict(orient='split')['data']:\n",
    "        sbi_sectors_keywords_gen_dom[cat_keywords[0]].extend(cat_keywords[1])\n",
    "    for cat_keywords in df_sbi_sectors[['Age_Dominant_Category', 'Used_Sector_Keywords']].to_dict(orient='split')['data']:\n",
    "        sbi_sectors_keywords_age_dom[cat_keywords[0]].extend(cat_keywords[1])\n",
    "    for d in (sbi_sectors_keywords_gen_dom, sbi_sectors_keywords_age_dom):\n",
    "        sbi_sectors_keywords_full_dom |= d\n",
    "\n",
    "    if save_enabled is True:\n",
    "        with open(f'{data_save_dir}sbi_english_keyword_list.txt', 'w', encoding='utf8') as f:\n",
    "            for i in sbi_english_keyword_list:\n",
    "                f.write(f'{i.lower()}\\n')\n",
    "        with open(f'{data_save_dir}sbi_english_keyword_dict.json', 'w', encoding='utf8') as f:\n",
    "            json.dump(sbi_english_keyword_dict, f)\n",
    "        with open(f'{data_save_dir}sbi_sectors_dict.json', 'w', encoding='utf8') as f:\n",
    "            json.dump(sbi_sectors_dict, f)\n",
    "\n",
    "        with open(f'{data_save_dir}sbi_sectors_keywords_gen_dom.json', 'w', encoding='utf8') as f:\n",
    "            json.dump(sbi_sectors_keywords_gen_dom, f)\n",
    "        with open(f'{data_save_dir}sbi_sectors_keywords_age_dom.json', 'w', encoding='utf8') as f:\n",
    "            json.dump(sbi_sectors_keywords_age_dom, f)\n",
    "        with open(f'{data_save_dir}sbi_sectors_keywords_full_dom.json.json', 'w', encoding='utf8') as f:\n",
    "            json.dump(sbi_sectors_keywords_full_dom, f)\n",
    "\n",
    "    return (\n",
    "        sbi_english_keyword_list,\n",
    "        sbi_english_keyword_dict,\n",
    "        sbi_sectors_dict,\n",
    "        sbi_sectors_dict_full,\n",
    "        sbi_sectors_dom_gen,\n",
    "        sbi_sectors_dom_age,\n",
    "        sbi_sectors_keywords_gen_dom,\n",
    "        sbi_sectors_keywords_age_dom,\n",
    "        sbi_sectors_keywords_full_dom\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rearrgane gender and age columns\n",
    "def get_only_df(df_sectors, col_name, opp_col_name):\n",
    "    df_only = df_sectors.pivot_table(values='n', index=['Code', 'Sector Name', opp_col_name], columns=[col_name], aggfunc='sum')\n",
    "    df_only = df_only.reset_index()\n",
    "    df_only = df_only.loc[df_only[opp_col_name] == 'Total']\n",
    "    df_only = df_only.drop(columns=[opp_col_name, 'Total'])\n",
    "    df_only.name = col_name\n",
    "\n",
    "    return df_only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sector_excel(\n",
    "    df_sectors_all,\n",
    "    tables_file_path,\n",
    "    sheet_name=None,\n",
    "    excel_file_name=None,\n",
    "    age_limit: int=None,\n",
    "    age_ratio: int=None,\n",
    "    gender_ratio: int=None,\n",
    "):\n",
    "    if sheet_name is None:\n",
    "        sheet_name = 'All'\n",
    "    if excel_file_name is None:\n",
    "        excel_file_name = 'Sectors Output from script.xlsx'\n",
    "    if age_limit is None:\n",
    "        age_limit = 45\n",
    "    if age_ratio is None:\n",
    "        age_ratio = 10\n",
    "    if gender_ratio is None:\n",
    "        gender_ratio = 20\n",
    "\n",
    "    writer = pd.ExcelWriter(f'{tables_file_path}{excel_file_name}', engine='xlsxwriter')\n",
    "    df_sectors_all.to_excel(writer, sheet_name=sheet_name, merge_cells = True, startrow = 3)\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "    worksheet.set_row(6, None, None, {'hidden': True})\n",
    "    worksheet.set_column(0, 0, None, None, {'hidden': True})\n",
    "    # Title\n",
    "    worksheet.merge_range(0, 0, 0, df_sectors_all.shape[1], 'Table', workbook.add_format({'bold': True, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'left'}))\n",
    "    worksheet.merge_range(1, 0, 1, df_sectors_all.shape[1], 'Sectoral Gender and Age Composition and Segregation, Keywords, Counts, and Percentages', workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'left'}))\n",
    "    worksheet.merge_range(2, 0, 2, df_sectors_all.shape[1], 'Jobs Count per Sector (x 1000)', workbook.add_format({'bold': False, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'top': True, 'bottom': True}))\n",
    "    # Format column headers\n",
    "    for col_num, value in enumerate(df_sectors_all.columns.values):\n",
    "        for i in range(3):\n",
    "            worksheet.write(3 + i, col_num + 1, value[i], workbook.add_format({'bold': False, 'font_name': 'Times New Roman', 'font_size': 12, 'font_color': 'black', 'align': 'center', 'top': True, 'bottom': True}))\n",
    "            if value[i] == 'n':\n",
    "                worksheet.set_column(col_num + 1, col_num + 1, 5.5)\n",
    "            elif value[i] == 'Code':\n",
    "                worksheet.set_column(col_num + 1, col_num + 1, 4.5)\n",
    "            elif value[i] == 'Sector Name':\n",
    "                worksheet.set_column(col_num + 1, col_num + 1, 28.5)\n",
    "            elif value[i] == 'Keywords':\n",
    "                worksheet.set_column(col_num + 1, col_num + 1, 30)\n",
    "            elif value[i] == 'Keywords Count':\n",
    "                worksheet.set_column(col_num + 1, col_num + 1, 13.5)\n",
    "            elif value[i] == '% per Sector':\n",
    "                worksheet.set_column(col_num + 1, col_num + 1, 12)\n",
    "            elif value[i] == '% per Social Category':\n",
    "                worksheet.set_column(col_num + 1, col_num + 1, 19.5)\n",
    "            elif value[i] == '% per Workforce':\n",
    "                worksheet.set_column(col_num + 1, col_num + 1, 15.5)\n",
    "            elif value[i] == 'Dominant Category':\n",
    "                worksheet.set_column(col_num + 1, col_num + 1, 24.5)\n",
    "            elif value[i] == '% Sector per Workforce':\n",
    "                worksheet.set_column(col_num + 1, col_num + 1, 21.5)\n",
    "\n",
    "    # Borders\n",
    "    perc = [col_num for col_num, value in enumerate(df_sectors_all.columns.values) if '%' in value[-1]]\n",
    "    num = [col_num for col_num, value in enumerate(df_sectors_all.columns.values) if 'n' in value[-1]]\n",
    "    word = [col_num for col_num, value in enumerate(df_sectors_all.columns.values) if value[-1] in ['Code', 'Sector Name', 'Dominant Category']]\n",
    "    keyword = [col_num for col_num, value in enumerate(df_sectors_all.columns.values) if 'Keywords' in value[-1]]\n",
    "\n",
    "    row_idx, col_idx = df_sectors_all.shape\n",
    "    for c, r in itertools.product(range(col_idx), range(row_idx)):\n",
    "        if c in perc:\n",
    "            formats = {'num_format': '0.00', 'font_name': 'Times New Roman', 'font_size': 12}\n",
    "            if r == row_idx-1:\n",
    "                formats |= {'top': True, 'bottom': True}\n",
    "        elif c in num:\n",
    "            formats = {'num_format': '0', 'font_name': 'Times New Roman', 'font_size': 12}\n",
    "            if r == row_idx-1:\n",
    "                formats |= {'top': True, 'bottom': True}\n",
    "        elif c in word:\n",
    "            formats = {'font_name': 'Times New Roman', 'font_size': 12}\n",
    "            if r == row_idx-1:\n",
    "                formats |= {'top': True, 'bottom': True}\n",
    "        elif c in keyword:\n",
    "            formats = {'font_name': 'Times New Roman', 'font_size': 12, 'align': 'left'}\n",
    "            if r == row_idx-1:\n",
    "                formats |= {'top': True, 'bottom': True}\n",
    "        try:\n",
    "            worksheet.write(r + 7, c + 1, df_sectors_all.iloc[r, c], workbook.add_format(formats))\n",
    "        except TypeError:\n",
    "            value = (\n",
    "                str(df_sectors_all.iloc[r, c])\n",
    "                if isinstance(df_sectors_all.iloc[r, c], list)\n",
    "                else ''\n",
    "            )\n",
    "            worksheet.write(r + 7, c + 1, value, workbook.add_format(formats))\n",
    "\n",
    "    worksheet.merge_range(len(df_sectors_all)+7, 0, len(df_sectors_all)+7, df_sectors_all.shape[1], 'Note.', workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 10, 'font_color': 'black', 'align': 'left'}))\n",
    "    worksheet.merge_range(len(df_sectors_all)+8, 0, len(df_sectors_all)+8, df_sectors_all.shape[1], f'Threshold for gender = {df_sectors_all.loc[df_sectors_all.index[-1], (\"Gender\", \"Female\", \"% per Workforce\")]:.2f}% ± 20%', workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 10, 'font_color': 'black', 'align': 'left'}))\n",
    "    worksheet.merge_range(len(df_sectors_all)+9, 0, len(df_sectors_all)+9, df_sectors_all.shape[1], f'Threshold for age = {df_sectors_all.loc[df_sectors_all.index[-1], (\"Age\", f\"Older (>= {age_limit} years)\", \"% per Workforce\")]:.2f}% ± 10%', workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 10, 'font_color': 'black', 'align': 'left'}))\n",
    "    worksheet.merge_range(len(df_sectors_all)+10, 0, len(df_sectors_all)+10, df_sectors_all.shape[1], 'Source: Centraal Bureau voor de Statistiek (CBS)', workbook.add_format({'italic': True, 'font_name': 'Times New Roman', 'font_size': 8, 'font_color': 'black', 'align': 'left'}))\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sector df from cbs\n",
    "def get_sector_df_from_cbs(\n",
    "    save_enabled: bool = True,\n",
    "    parent_dir=validate_path(f'{code_dir}/scraped_data/CBS/'),\n",
    "    cols = ['Industry class / branch (SIC2008)', 'Sex of employee', 'Other characteristics employee', 'Employment/Jobs (x 1 000)'],\n",
    "    get_cbs_odata_enabled=False,\n",
    "    age_limit: int = 45,\n",
    "    age_ratio: int = 10,\n",
    "    gender_ratio: int = 20,\n",
    "):\n",
    "\n",
    "    sectors_file_path: str = validate_path(f'{parent_dir}Found Data/')\n",
    "    data_save_dir1: str = validate_path(f'{parent_dir}Data/')\n",
    "    data_save_dir2: str = validate_path(f'{code_dir}/data/output tables/')\n",
    "\n",
    "    # with open(f'{code_dir}/data/content analysis + ids + sectors/sbi_sectors_dict.json', 'r', encoding='utf8') as f:\n",
    "    #     sbi_sectors_dict = json.load(f)\n",
    "    sbi_english_keyword_list, sbi_english_keyword_dict, sbi_sectors_dict, sbi_sectors_dict_full, sbi_sectors_dom_gen, sbi_sectors_dom_age, sbi_sectors_keywords_gen_dom, sbi_sectors_keywords_age_dom, sbi_sectors_keywords_full_dom = get_sbi_sectors_list()\n",
    "\n",
    "    if get_cbs_odata_enabled is True:\n",
    "        select = ['SexOfEmployee', 'TypeOfEmploymentContract', 'OtherCharacteristicsEmployee', 'IndustryClassBranchSIC2008', 'Periods', 'Jobs_1']\n",
    "        odata_colnames_normalized = {'IndustryClassBranchSIC2008': 'Industry class / branch (SIC2008)', 'SexOfEmployee': 'Sex of employee', 'OtherCharacteristicsEmployee': 'Other characteristics employee', 'Jobs_1': 'Employment/Jobs (x 1 000)'}\n",
    "        df_sectors = get_cbs_odata()\n",
    "        df_sectors = df_sectors.rename(columns=odata_colnames_normalized)\n",
    "    elif get_cbs_odata_enabled is False:\n",
    "        # print(f'Error getting data from CBS Statline OData. Using the following file:\\n{sectors_file_path}Sectors Tables/FINAL/Gender x Age_CBS_DATA.csv')\n",
    "        # Read, clean, create code variable\n",
    "        try:\n",
    "            df_sectors = pd.read_csv(f'{sectors_file_path}Sectors Tables/FINAL/Gender x Age_CBS_DATA.csv', delimiter=';')\n",
    "        except Exception:\n",
    "            df_sectors = pd.read_csv(f'{sectors_file_path}Sectors Tables/FINAL/Gender x Age_CBS_DATA_from_code.csv', delimiter=';')\n",
    "\n",
    "\n",
    "    df_sectors = df_sectors[cols]\n",
    "    df_sectors = df_sectors.rename({'Sex of employee': 'Gender', 'Other characteristics employee': 'Age Range (in years)', 'Industry class / branch (SIC2008)': 'Sector Name', 'Employment/Jobs (x 1 000)': 'n'}, axis = 1)\n",
    "    df_sectors.insert(0, 'Code', df_sectors['Sector Name'].progress_apply(lambda row: row[0]))\n",
    "    df_sectors['Sector Name'] = df_sectors['Sector Name'].progress_apply(lambda row: row[2:].strip() if '-' not in row else row[3:].strip())\n",
    "\n",
    "    # Categorize by age label\n",
    "    all_age = df_sectors['Age Range (in years)'].unique().tolist()[1:]\n",
    "    for i, word in enumerate(all_age):\n",
    "        if word.startswith(str(age_limit)):\n",
    "            young = all_age[:i]\n",
    "            old = all_age[i:]\n",
    "    conditions = [\n",
    "        (df_sectors['Age Range (in years)'].isin(old)),\n",
    "        (df_sectors['Age Range (in years)'].isin(young))\n",
    "    ]\n",
    "    choices = [f'Older (>= {age_limit} years)', f'Younger (< {age_limit} years)']\n",
    "    age_cat = np.select(conditions, choices, default='Total')\n",
    "    df_sectors.insert(3, 'Age', age_cat)\n",
    "    choices.append('Total')\n",
    "\n",
    "    # Change gender label\n",
    "    df_sectors['Gender'] = df_sectors['Gender'].replace({'Sex: Female': 'Female', 'Sex: Male': 'Male'})\n",
    "\n",
    "    # Rearrgane columns\n",
    "    # Gender\n",
    "    df_gender_only = get_only_df(df_sectors, 'Gender', 'Age')\n",
    "\n",
    "    # Age\n",
    "    df_age_only = get_only_df(df_sectors, 'Age', 'Gender')\n",
    "\n",
    "    # Total\n",
    "    df_total_only = df_sectors.pivot_table(values='n', index=['Code', 'Sector Name', 'Gender', 'Age'], aggfunc='sum')\n",
    "    df_total_only = df_total_only.reset_index()\n",
    "    df_total_only = df_total_only.loc[(df_total_only['Gender'] == 'Total') & (df_total_only['Age'] == 'Total')]\n",
    "    df_total_only = df_total_only.drop(columns=['Gender', 'Age'])\n",
    "    df_total_only = df_total_only.rename(columns={'n': 'Total Workforce'})\n",
    "    df_total_only.name = 'Total'\n",
    "\n",
    "    # Merge all\n",
    "    df_sectors_all = pd.merge(pd.merge(df_gender_only, df_age_only, how='outer'), df_total_only, how='outer')\n",
    "\n",
    "    # Take out \"All economic activities\" row\n",
    "    au = df_sectors_all.loc[df_sectors_all['Sector Name'] == 'All economic activities']\n",
    "    au.loc[au['Code'] != 'A-U', 'Code'] = 'A-U'\n",
    "    df_sectors_all = df_sectors_all[df_sectors_all['Sector Name'] != 'All economic activities']\n",
    "    df_sectors_all = df_sectors_all.groupby(['Code'], as_index=True).agg({'Sector Name': 'first', **dict.fromkeys(df_sectors_all.loc[:, ~df_sectors_all.columns.isin(['Code', 'Sector Name'])].columns.to_list(), 'sum')})\n",
    "    df_sectors_all = df_sectors_all.reset_index()\n",
    "\n",
    "    # Add keywords\n",
    "    df_sectors_all.insert(2, 'Keywords', df_sectors_all['Code'].progress_apply(lambda row: sbi_sectors_dict[row]['Used_Sector_Keywords'] if row in sbi_sectors_dict and isinstance(row, str) else np.nan))\n",
    "    df_sectors_all['Keywords'] = df_sectors_all['Keywords'].progress_apply(lambda row: clean_and_translate_keyword_list(row) if isinstance(row, list) else np.nan)\n",
    "    df_sectors_all.insert(\n",
    "        3,\n",
    "        'Keywords Count',\n",
    "        df_sectors_all['Keywords'].progress_apply(\n",
    "            lambda row: len(row) if isinstance(row, list) else np.nan\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Add totals in bottom row\n",
    "    df_sectors_all.loc[df_sectors_all[df_sectors_all['Sector Name'] == 'Other service activities'].index.values.astype(int)[0]+1, 'Sector Name'] = 'Total (excluding A-U)'\n",
    "    df_sectors_all.iloc[df_sectors_all[df_sectors_all['Sector Name'] == 'Total (excluding A-U)'].index.values.astype(int)[0], ~df_sectors_all.columns.isin(['Code', 'Sector Name', 'Keywords'])] = df_sectors_all.sum(numeric_only=True)\n",
    "    df_sectors_all.columns = pd.MultiIndex.from_tuples([('Industry class / branch (SIC2008)', 'Code'), ('Industry class / branch (SIC2008)', 'Sector Name'), ('Industry class / branch (SIC2008)', 'Keywords'), ('Industry class / branch (SIC2008)', 'Keywords Count'), ('Female', 'n'), ('Male', 'n'), (f'Older (>= {age_limit} years)', 'n'), (f'Younger (< {age_limit} years)', 'n'), ('Total Workforce', 'n')], names = ['Social category', 'Counts'])\n",
    "\n",
    "    # Make percentages\n",
    "    for index, row in df_sectors_all.items():\n",
    "        if ('Total' not in index[0]) and ('%' not in index[1]) and ('n' in index[1]) and (not isinstance(row[0], str)) and (not math.isnan(row[0])):\n",
    "            df_sectors_all[(index[0], '% per Sector')] = row/df_sectors_all[('Total Workforce', 'n')]*100\n",
    "            df_sectors_all[(index[0], '% per Social Category')] = row/df_sectors_all.loc[df_sectors_all[df_sectors_all[('Industry class / branch (SIC2008)', 'Sector Name')] == 'Total (excluding A-U)'].index.values.astype(int)[0], index]*100\n",
    "            df_sectors_all[(index[0], '% per Workforce')] = row/df_sectors_all.loc[df_sectors_all[df_sectors_all[('Industry class / branch (SIC2008)', 'Sector Name')] == 'Total (excluding A-U)'].index.values.astype(int)[0], ('Total Workforce', 'n')]*100\n",
    "        if ('Total' in index[0]):\n",
    "            df_sectors_all[(index[0], '% Sector per Workforce')] = row/df_sectors_all.loc[df_sectors_all[df_sectors_all[('Industry class / branch (SIC2008)', 'Sector Name')] == 'Total (excluding A-U)'].index.values.astype(int)[0], ('Total Workforce', 'n')]*100\n",
    "\n",
    "    # Set cut-off\n",
    "    # Gender\n",
    "    total_female = df_sectors_all.loc[df_sectors_all[df_sectors_all[('Industry class / branch (SIC2008)', 'Sector Name')] == 'Total (excluding A-U)'].index.values.astype(int)[0], ('Female', '% per Workforce')]\n",
    "    female_dominated = total_female + (gender_ratio / 100)\n",
    "    df_sectors_all.loc[df_sectors_all[('Female', '% per Sector')] >= female_dominated, ('Sectoral Gender Segregation', 'Dominant Category')] = 'Female'\n",
    "    male_dominated = total_female - (gender_ratio / 100)\n",
    "    df_sectors_all.loc[df_sectors_all[('Female', '% per Sector')] <= male_dominated, ('Sectoral Gender Segregation', 'Dominant Category')] = 'Male'\n",
    "    df_sectors_all.loc[(df_sectors_all[('Female', '% per Sector')] > male_dominated) & (df_sectors_all[('Female', '% per Sector')] < female_dominated) & (df_sectors_all[('Industry class / branch (SIC2008)', 'Sector Name')].astype(str) != 'Total (excluding A-U)'), ('Sectoral Gender Segregation', 'Dominant Category')] = 'Mixed Gender'\n",
    "    # Age\n",
    "    total_old = df_sectors_all.loc[df_sectors_all[df_sectors_all[('Industry class / branch (SIC2008)', 'Sector Name')] == 'Total (excluding A-U)'].index.values.astype(int)[0], (f'Older (>= {age_limit} years)', '% per Workforce')]\n",
    "    old_dominated = total_old + age_ratio / 100\n",
    "    df_sectors_all.loc[df_sectors_all[(f'Older (>= {age_limit} years)', '% per Sector')] >= old_dominated, ('Sectoral Age Segregation', 'Dominant Category')] = 'Older'\n",
    "    young_dominated = total_old - age_ratio / 100\n",
    "    df_sectors_all.loc[df_sectors_all[(f'Older (>= {age_limit} years)', '% per Sector')] <= young_dominated, ('Sectoral Age Segregation', 'Dominant Category')] = 'Younger'\n",
    "    df_sectors_all.loc[(df_sectors_all[(f'Older (>= {age_limit} years)', '% per Sector')] < old_dominated) & (df_sectors_all[(f'Older (>= {age_limit} years)', '% per Sector')] > young_dominated) & (df_sectors_all[('Industry class / branch (SIC2008)', 'Sector Name')].astype(str) != 'Total (excluding A-U)'), ('Sectoral Age Segregation', 'Dominant Category')] = 'Mixed Age'\n",
    "\n",
    "    # Add AU and other rows\n",
    "    au.insert(2, 'Keywords', np.nan)\n",
    "    au.insert(3, 'Keywords Count', np.nan)\n",
    "    au[['Sectoral Gender Segregation', 'Sectoral Age Segregation']] = np.nan\n",
    "    au.columns = pd.MultiIndex.from_tuples([col for col in df_sectors_all.columns if '%' not in col[1]])\n",
    "    df_sectors_all = pd.concat([au, df_sectors_all], ignore_index=True)\n",
    "\n",
    "    # Arrange columns\n",
    "    df_sectors_all = df_sectors_all.reindex(columns=df_sectors_all.columns.reindex(['Industry class / branch (SIC2008)', 'Female', 'Male', 'Sectoral Gender Segregation', f'Older (>= {age_limit} years)', f'Younger (< {age_limit} years)', 'Sectoral Age Segregation', 'Total Workforce'], level=0)[0])\n",
    "    df_sectors_all = df_sectors_all.reindex(columns=df_sectors_all.columns.reindex(['Code', 'Sector Name', 'Keywords', 'Keywords Count', 'n', '% per Sector', '% per Social Category', '% per Workforce', '% Sector per Workforce', 'Dominant Category'], level=1)[0])\n",
    "\n",
    "    level1_cols_tuple = []\n",
    "    for col in df_sectors_all.columns:\n",
    "        if ('SIC2008' in col[0]):\n",
    "            level1_cols_tuple.append(('SBI Sector Titles', *col))\n",
    "        elif (re.search(r'[Mm]ale', col[0])) or ('Gender' in col[0]):\n",
    "            level1_cols_tuple.append(('Gender', *col))\n",
    "        elif ('45' in col[0]) or ('Age' in col[0]):\n",
    "            level1_cols_tuple.append(('Age', *col))\n",
    "        elif ('Total' in col[0]):\n",
    "            level1_cols_tuple.append(('Total Workforce', *col))\n",
    "\n",
    "    df_sectors_all.columns = pd.MultiIndex.from_tuples(level1_cols_tuple, names=['Variables', 'Categories', 'Counts'])\n",
    "\n",
    "    if save_enabled:\n",
    "        for data_save_dir in [data_save_dir1, data_save_dir2]:\n",
    "            df_sectors_all.to_csv(f'{data_save_dir}Sectors Output from script.csv', index=False)\n",
    "            df_sectors_all.to_pickle(f'{data_save_dir}Sectors Output from script.pkl')\n",
    "            with pd.option_context('max_colwidth', 10000000000):\n",
    "                df_sectors_all.to_latex(f'{data_save_dir}Sectors Output from script.tex', index=False, longtable=True, escape=True, multicolumn=True, multicolumn_format='c', position='H', caption='Sectoral Gender and Age Composition and Segregation, Keywords, Counts, and Percentages', label='Jobs Count per Sector (x 1000)')\n",
    "            df_sectors_all.to_markdown(f'{data_save_dir}Sectors Output from script.md', index=True)\n",
    "            save_sector_excel(df_sectors_all, data_save_dir)\n",
    "\n",
    "    return df_sectors_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of keywords for the SBI sectors\n",
    "(\n",
    "    sbi_english_keyword_list,\n",
    "    sbi_english_keyword_dict,\n",
    "    sbi_sectors_dict,\n",
    "    sbi_sectors_dict_full,\n",
    "    sbi_sectors_dom_gen,\n",
    "    sbi_sectors_dom_age,\n",
    "    sbi_sectors_keywords_gen_dom,\n",
    "    sbi_sectors_keywords_age_dom,\n",
    "    sbi_sectors_keywords_full_dom\n",
    ") = get_sbi_sectors_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbi_sectors_dict['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table for Sector Composition + used keyowrds + classification of dominant caterory\n",
    "df_sectors_all = get_sector_df_from_cbs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors_all[('Total Workforce', 'Total Workforce', '% Sector per Workforce')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e64b55c31e662d3b8ca165241f15a246a93354fe580fc7a1249b2f351dbc5a06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
