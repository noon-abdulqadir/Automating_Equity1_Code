{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7d3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189dea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "# columns\n",
    "cols=['Sector', \n",
    "      'Sector Code', \n",
    "      'Gender', \n",
    "      'Age', \n",
    "      'Language', \n",
    "      'Dutch Requirement', \n",
    "      'English Requirement', \n",
    "      'Gender_Female', \n",
    "      'Gender_Mixed', \n",
    "      'Gender_Male', \n",
    "      'Age_Older', \n",
    "      'Age_Mixed', \n",
    "      'Age_Younger', \n",
    "      'Gender_Num', \n",
    "      'Age_Num', \n",
    "      '% Female', \n",
    "      '% Male', \n",
    "      '% Older', \n",
    "      '% Younger']\n",
    "\n",
    "int_variable: str = 'Job ID'\n",
    "str_variable: str = 'Job Description'\n",
    "gender: str = 'Gender'\n",
    "age: str = 'Age'\n",
    "language: str = 'en'\n",
    "str_cols = ['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name', 'Location', 'Job Description', 'Company URL', 'Job URL', 'Tracking ID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21414866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import googletrans\n",
    "from pathlib import Path\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from spacy.pipeline import Sentencizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c22dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw_dropped.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1039d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = df_jobs.sample(n=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b23278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw_glob_paths_10.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c9ce03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 15019 to 20563\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Search Keyword     100 non-null    object \n",
      " 1   Platform           100 non-null    object \n",
      " 2   Job ID             100 non-null    object \n",
      " 3   Job Title          100 non-null    object \n",
      " 4   Company Name       100 non-null    object \n",
      " 5   Location           100 non-null    object \n",
      " 6   Job Description    100 non-null    object \n",
      " 7   Rating             5 non-null      float64\n",
      " 8   Employment Type    99 non-null     object \n",
      " 9   Company URL        96 non-null     object \n",
      " 10  Job URL            100 non-null    object \n",
      " 11  Job Age            100 non-null    object \n",
      " 12  Job Age Number     100 non-null    object \n",
      " 13  Collection Date    100 non-null    object \n",
      " 14  Data Row           95 non-null     float64\n",
      " 15  Tracking ID        95 non-null     object \n",
      " 16  Industry           96 non-null     object \n",
      " 17  Job Date           95 non-null     object \n",
      " 18  Type of ownership  1 non-null      object \n",
      "dtypes: float64(2), object(17)\n",
      "memory usage: 15.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fee089f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name',\n",
       "       'Location', 'Job Description', 'Rating', 'Employment Type',\n",
       "       'Company URL', 'Job URL', 'Job Age', 'Job Age Number',\n",
       "       'Collection Date', 'Data Row', 'Tracking ID', 'Industry', 'Job Date',\n",
       "       'Type of ownership'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e556d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descriptions = list(set(df_jobs['Job Description'].to_list()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de4de75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaf53549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load NLK\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk_path = f'{llm_path}/nltk'\n",
    "nltk.data.path.append(nltk_path)\n",
    "\n",
    "nltk.download('words', download_dir = nltk_path)\n",
    "nltk.download('punkt', download_dir = nltk_path)\n",
    "nltk.download('stopwords', download_dir = nltk_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "513f203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentencizer = []\n",
    "\n",
    "for job_description in job_descriptions:\n",
    "    doc = sent_tokenize(job_description)\n",
    "    nltk_sentencizer.extend(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "886e918d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_sentencizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47c2a40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At Uber, we ignite opportunity by setting the world in motion We take on big problems to help drivers, riders, delivery partners, and eaters get moving in more than 10,000 cities around the world, , We welcome people from all backgrounds who seek the opportunity to help build a future where everyone and everything can move independently If you have the curiosity, passion, and collaborative spirit, work with us, and lets move the world forward, together, , , , As a member of the team, you will work alongside Community Operations Managers to improve our customers support experience You will support strategic decisionmaking and process improvement through datadriven problem solving and collaboration across key Community Operations functions eg Agent Enablement, Analytics  Insights, Program Management, Strategy  Planning, , For this role you should have high attention to detail, strong verbal and written communication skills, excellent organization and time management, and a bias towards data and quantitative analysis, , , , , , , Competencies, , , , , , , , For Bonus Points, , , , Perks  Benefits We offer an aboveaverage monthly internship allowance and Uber credits, , You have the rare chance to create a global impact were moving real people and assets and reinventing transportation and logistics We offer expansive mentorship from Uber employees to guide you through your internship experience and for you to build personal networks and friendships with hardworking people who share your passion for technology'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_sentencizer[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c845236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Spacy\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "try:\n",
    "    nlp = English()\n",
    "except:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "custom_punct_chars = ['\\n', '\\n\\n', '\\n\\n\\n', ',,', ', ,', ', , ', ',,,', ', , ,', ', , , ', ',,,,', ', , , ,', ', , , , ', ',,,,,', ', , , , ,', ', , , , , ', ':', '|']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd2f4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencizer = nlp.add_pipe('sentencizer')\n",
    "sentencizer.punct_chars.update(custom_punct_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37292ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    with open(f'{data_dir}punctuations.txt', 'wb') as f:\n",
    "        pickle.dump(sentencizer.punct_chars, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08e8ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}punctuations.txt', 'rb') as f:\n",
    "    new_punct_chars = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c760575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_sentencizer = []\n",
    "\n",
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    for job_description in job_descriptions:\n",
    "        doc = nlp(job_description)\n",
    "        spacy_sentencizer.extend([sent.text for sent in doc.sents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50402404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacy_sentencizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dcf1dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At Uber, we ignite opportunity by setting the world in motion We take on big problems to help drivers, riders, delivery partners, and eaters get moving in more than 10,000 cities around the world, , We welcome people from all backgrounds who seek the opportunity to help build a future where everyone and everything can move independently If you have the curiosity, passion, and collaborative spirit, work with us, and lets move the world forward, together, , , , As a member of the team, you will work alongside Community Operations Managers to improve our customers support experience You will support strategic decisionmaking and process improvement through datadriven problem solving and collaboration across key Community Operations functions eg Agent Enablement, Analytics  Insights, Program Management, Strategy  Planning, , For this role you should have high attention to detail, strong verbal and written communication skills, excellent organization and time management, and a bias towards data and quantitative analysis, , , , , , , Competencies, , , , , , , , For Bonus Points, , , , Perks  Benefits We offer an aboveaverage monthly internship allowance and Uber credits, , You have the rare chance to create a global impact were moving real people and assets and reinventing transportation and logistics We offer expansive mentorship from Uber employees to guide you through your internship experience and for you to build personal networks and friendships with hardworking people who share your passion for technology'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_sentencizer[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nlp.tokenizer\n",
    "\n",
    "spacy_tokenizer = []\n",
    "\n",
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    for job_description in job_descriptions:\n",
    "        doc = tokenizer(job_description)\n",
    "        spacy_tokenizer.extend([token.text for token in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenizer[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e73cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6595ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in spacy_sentencizer:\n",
    "    print(model.encode(sentence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.electra.modeling_tf_electra import TFElectraMainLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pavanchhatpar/electra-base-sentence-splitter\")\n",
    "\n",
    "model = AutoModelForPreTraining.from_pretrained(\"pavanchhatpar/electra-base-sentence-splitter\", from_tf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ee3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline('sentence-splitter', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8d4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "study1_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
