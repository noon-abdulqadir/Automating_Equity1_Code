{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7d3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189dea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "# columns\n",
    "cols=['Sector', \n",
    "      'Sector Code', \n",
    "      'Gender', \n",
    "      'Age', \n",
    "      'Language', \n",
    "      'Dutch Requirement', \n",
    "      'English Requirement', \n",
    "      'Gender_Female', \n",
    "      'Gender_Mixed', \n",
    "      'Gender_Male', \n",
    "      'Age_Older', \n",
    "      'Age_Mixed', \n",
    "      'Age_Younger', \n",
    "      'Gender_Num', \n",
    "      'Age_Num', \n",
    "      '% Female', \n",
    "      '% Male', \n",
    "      '% Older', \n",
    "      '% Younger']\n",
    "\n",
    "int_variable: str = 'Job ID'\n",
    "str_variable: str = 'Job Description'\n",
    "gender: str = 'Gender'\n",
    "age: str = 'Age'\n",
    "language: str = 'en'\n",
    "str_cols = ['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name', 'Location', 'Job Description', 'Company URL', 'Job URL', 'Tracking ID']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21414866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import googletrans\n",
    "from pathlib import Path\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from spacy.pipeline import Sentencizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8c22dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw_dropped.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f9087aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description'] = df_jobs['Job Description'].apply(lambda job_sentence: ' '.join(job_sentence.split('/')) if '/' in job_sentence else job_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d45507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = df_jobs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = df_jobs.sample(n=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b23278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw_glob_paths_10.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c9c9ce03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64684 entries, 0 to 64683\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Search Keyword     64684 non-null  object \n",
      " 1   Platform           64684 non-null  object \n",
      " 2   Job ID             64684 non-null  object \n",
      " 3   Job Title          64684 non-null  object \n",
      " 4   Company Name       64679 non-null  object \n",
      " 5   Location           64684 non-null  object \n",
      " 6   Job Description    64684 non-null  object \n",
      " 7   Rating             4130 non-null   float64\n",
      " 8   Employment Type    63959 non-null  object \n",
      " 9   Company URL        61360 non-null  object \n",
      " 10  Job URL            64684 non-null  object \n",
      " 11  Job Age            64684 non-null  object \n",
      " 12  Job Age Number     64684 non-null  object \n",
      " 13  Collection Date    64684 non-null  object \n",
      " 14  Data Row           60551 non-null  float64\n",
      " 15  Tracking ID        60551 non-null  object \n",
      " 16  Industry           61279 non-null  object \n",
      " 17  Job Date           60554 non-null  object \n",
      " 18  Type of ownership  725 non-null    object \n",
      "dtypes: float64(2), object(17)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fee089f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name',\n",
       "       'Location', 'Job Description', 'Rating', 'Employment Type',\n",
       "       'Company URL', 'Job URL', 'Job Age', 'Job Age Number',\n",
       "       'Collection Date', 'Data Row', 'Tracking ID', 'Industry', 'Job Date',\n",
       "       'Type of ownership'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a22cc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_fix_incl = 'Apply appropriate and effective communication methods to senior management and important stakeholders \\(incl.'\n",
    "str_fix_eg = 'Partner with Procurement in order to manage suppliers for the projects & programs in scope, e.g.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9884dfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_jobs.loc[(df_jobs['Job Description'].str.contains(str_fix_incl)) | (df_jobs['Job Description'].str.contains(str_fix_eg))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e556d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_descriptions = list(set(df_jobs['Job Description'].to_list()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da09d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descriptions = list(\n",
    "    set(\n",
    "        df_jobs['Job Description'].loc[\n",
    "            (df_jobs['Job Description'].str.contains(str_fix_incl)) |\n",
    "            (df_jobs['Job Description'].str.contains(str_fix_eg))\n",
    "        ].to_list()\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0de4de75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7901bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descriptions = list(map(lambda job_sentence: ' '.join(job_sentence.split('/')) if '/' in job_sentence else job_sentence, job_descriptions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eaf53549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load NLK\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk_path = f'{llm_path}/nltk'\n",
    "nltk.data.path.append(nltk_path)\n",
    "\n",
    "nltk.download('words', download_dir = nltk_path)\n",
    "nltk.download('stopwords', download_dir = nltk_path)\n",
    "nltk.download('punkt', download_dir = nltk_path)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "87f15f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'suppliers for the projects & programs in scope, e.g. interviews, staffing, supplier costs.\\n\\nCommunication   stakeholder management\\nAct as the key contact person for strategic stakeholders.\\nApply appropriate and effective communication methods to senior management and important stakeholders (incl. vendor) throughout the project lifecycle.\\nAs conflicts and escalations arise within projects, identify solutions and manage the resolution in a timely and appropriate manner.\\nDrive change management act'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_descriptions[0][1500:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7771bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = r'[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?<=[a-z])(?=[A-Z])'\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "483e577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk_sentencizer = []\n",
    "\n",
    "# for job_description in job_descriptions:\n",
    "#     for sentence in sent_tokenize(job_description):\n",
    "#         for sent in re.split(pattern, sentence):\n",
    "#             nltk_sentencizer.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3defa20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentencizer = [\n",
    "    sent \n",
    "    for job_description in job_descriptions \n",
    "    for sentence in sent_tokenize(job_description) \n",
    "    for sent in re.split(pattern, sentence)\n",
    "    if len(sent) != 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2309d916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_sentencizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0bde1c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(nltk_sentencizer):\n",
    "    if str_fix_eg in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1548e80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(idx for idx, sent in enumerate(nltk_sentencizer) if str_fix_eg in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8fdc134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "# str_fix = 'Apply appropriate and effective communication methods to senior management and important stakeholders \\(incl.'\n",
    "\n",
    "for idx, sent in enumerate(nltk_sentencizer):\n",
    "    if str_fix_incl.split('\\(')[0] in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c1476b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Partner with Procurement in order to manage suppliers for the projects & programs in scope, e.g.',\n",
       " 'interviews, staffing, supplier costs.',\n",
       " 'Communication   stakeholder management',\n",
       " 'Act as the key contact person for strategic stakeholders.',\n",
       " 'Apply appropriate and effective communication methods to senior management and important stakeholders (incl.',\n",
       " 'vendor) throughout the project lifecycle.']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentences split on e.g. and incl.\n",
    "nltk_sentencizer[next(idx for idx, sent in enumerate(nltk_sentencizer) if str_fix_eg in sent):next(idx for idx, sent in enumerate(nltk_sentencizer) if str_fix_incl.split('\\(')[0] in sent)+2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4da72e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(nltk_sentencizer):\n",
    "    if 'Power' in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3013d2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(idx for idx, sent in enumerate(nltk_sentencizer) if 'Power' in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6ece8b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Strong MS-Office skills (Word, Excel, PowerPoint)'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_sentencizer[next(idx for idx, sent in enumerate(nltk_sentencizer) if 'Power' in sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "47c2a40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Partner with Procurement in order to manage suppliers for the projects & programs in scope, e.g.\n",
      "\n",
      "Sentence 2: interviews, staffing, supplier costs.\n",
      "\n",
      "Sentence 3: Communication   stakeholder management\n",
      "\n",
      "Sentence 4: Act as the key contact person for strategic stakeholders.\n",
      "\n",
      "Sentence 5: Apply appropriate and effective communication methods to senior management and important stakeholders (incl.\n",
      "\n",
      "Sentence 6: vendor) throughout the project lifecycle.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(nltk_sentencizer[18:24]):\n",
    "    print(f'Sentence {idx+1}: {sentence}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd65f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tokenizer = []\n",
    "\n",
    "for job_sentence in nltk_sentencizer:\n",
    "    for token in word_tokenize(job_sentence):\n",
    "        if len(token) != 0 and token != '...' and token.lower() not in set(stopwords.words('english')) and token.lower() not in list(string.punctuation):\n",
    "            nltk_tokenizer.append(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c29456f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tokenizer = [\n",
    "    token \n",
    "    for job_sentence in nltk_sentencizer \n",
    "    for token in word_tokenize(job_sentence) \n",
    "    if len(token) != 0 \n",
    "    and token != '...' \n",
    "    and not token.lower() in set(stopwords.words('english')) \n",
    "    and not token.lower() in list(string.punctuation) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b7159883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8d5e14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a list of punctuations that determine sentence boundry, i.e., split characters\n",
    "def make_custom_punct_chars(main_punct_chars = [':', '|'], repeated_punct_chars = ['\\n', ',']):\n",
    "    custom_punct_chars = []\n",
    "    temp_multi = []\n",
    "    temp_spaced = []\n",
    "\n",
    "    for punct_char in main_punct_chars:\n",
    "        custom_punct_chars+= f'{punct_char}', f'{punct_char} '\n",
    "\n",
    "    for idx in range(4):\n",
    "        for punct_char in repeated_punct_chars:\n",
    "            temp_multi.append(f'{punct_char}'*int(idx+1))\n",
    "            temp_spaced.append(f'{punct_char} '*int(idx+1))\n",
    "\n",
    "    for multi, spaced in zip(temp_multi, temp_spaced):\n",
    "        custom_punct_chars+= multi, spaced\n",
    "\n",
    "    custom_punct_chars.remove(',')\n",
    "    custom_punct_chars.remove(', ')\n",
    "\n",
    "    return custom_punct_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0c7f61ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_punct_chars = make_custom_punct_chars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "183846a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':',\n",
       " ': ',\n",
       " '|',\n",
       " '| ',\n",
       " '\\n',\n",
       " '\\n ',\n",
       " '\\n\\n',\n",
       " '\\n \\n ',\n",
       " ',,',\n",
       " ', , ',\n",
       " '\\n\\n\\n',\n",
       " '\\n \\n \\n ',\n",
       " ',,,',\n",
       " ', , , ',\n",
       " '\\n\\n\\n\\n',\n",
       " '\\n \\n \\n \\n ',\n",
       " ',,,,',\n",
       " ', , , , ']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_punct_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5c845236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Spacy\n",
    "import spacy\n",
    "from spacy.symbols import ORTH, LEMMA\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cd2f4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencizer = nlp.add_pipe('sentencizer')\n",
    "sentencizer.punct_chars.update(custom_punct_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37292ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    with open(f'{data_dir}punctuations.txt', 'wb') as f:\n",
    "        pickle.dump(sentencizer.punct_chars, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08e8ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}punctuations.txt', 'rb') as f:\n",
    "    custom_punct_char = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52198bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_cases = {\":)\": [{\"ORTH\": \":)\"}]}\n",
    "# prefix_re = re.compile(r'''^[\\\\[\\\\(\"']''')\n",
    "# suffix_re = re.compile(r'''[\\\\]\\\\)\"']$''')\n",
    "# infix_re = re.compile(r'''[-~]''')\n",
    "# simple_url_re = re.compile(r'''^https?://''')\n",
    "\n",
    "# def custom_tokenizer(nlp):\n",
    "#     return Tokenizer(nlp.vocab, rules=special_cases,\n",
    "#                                 prefix_search=prefix_re.search,\n",
    "#                                 suffix_search=suffix_re.search,\n",
    "#                                 infix_finditer=infix_re.finditer,\n",
    "#                                 url_match=simple_url_re.match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65795c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_sm')\n",
    "# nlp.tokenizer.add_special_case('incl.', [{ORTH: 'incl', LEMMA: 'including'}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6425cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.symbols import ORTH, LEMMA\n",
    "\n",
    "special_cases_dict = {\n",
    "    'incl.': [{65: 'incl', 67: 'including'}],\n",
    "    'incl. ': [{65: 'incl', 67: 'including'}],\n",
    "    '(incl.': [{65: 'incl', 67: 'including'}],\n",
    "    'etc.': [{65: 'etc', 67: 'et cetera'}],\n",
    "    'etc. ': [{65: 'etc', 67: 'et cetera'}],\n",
    "    'e.g.': [{65: 'e.g', 67: 'for example'}],\n",
    "    'e.g. ': [{65: 'e.g', 67: 'for example'}],\n",
    "}\n",
    "\n",
    "nlp.tokenizer.rules.update(special_cases_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4987aa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{65: 'e.g', 67: 'for example'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tokenizer.rules['e.g.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c760575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy sentencizer\n",
    "# spacy_sentencizer = []\n",
    "\n",
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     for job_description in job_descriptions:\n",
    "#         for sentence in nlp(job_description).sents:\n",
    "#             for sent in re.split(pattern, sentence.text):\n",
    "#                 if len(sent) != 0:\n",
    "#                     spacy_sentencizer.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9faaa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy sentencizer\n",
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    spacy_sentencizer = [\n",
    "        sent \n",
    "        for job_description in job_descriptions \n",
    "        for sentence in nlp(job_description).sents \n",
    "        for sent in re.split(pattern, sentence.text) \n",
    "        if len(sent) != 0 \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa78330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy tokenizer\n",
    "# spacy_tokenizer = []\n",
    "\n",
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     for job_sentence in spacy_sentencizer:\n",
    "#         for token in nlp.tokenizer(job_sentence):\n",
    "#             if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars:\n",
    "#                 spacy_tokenizer.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78f574e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spacy_sentencizer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b715ec90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacy_sentencizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d84b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy tokenizer\n",
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    spacy_tokenizer = [\n",
    "        token.text \n",
    "        for job_sentence in spacy_sentencizer \n",
    "        for token in nlp.tokenizer(job_sentence) \n",
    "        if len(token) != 0 \n",
    "        and not token.is_stop \n",
    "        and not token.is_punct \n",
    "        and not token.text in custom_punct_chars\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab9cc643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spacy_tokenizer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2e36b544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "90503a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(spacy_sentencizer):\n",
    "    if str_fix_eg in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c222370e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(idx for idx, sent in enumerate(spacy_sentencizer) if str_fix_eg in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a454eeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "# str_fix = 'Apply appropriate and effective communication methods to senior management and important stakeholders \\(incl.'\n",
    "\n",
    "\n",
    "for idx, sent in enumerate(spacy_sentencizer):\n",
    "    if str_fix_incl.split('\\(')[0] in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd2a7d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(idx for idx, sent in enumerate(spacy_sentencizer) if str_fix_incl.split('\\(')[0] in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3c515eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Partner with Procurement in order to manage suppliers for the projects & programs in scope, e.g. interviews, staffing, supplier costs.',\n",
       " 'Communication / stakeholder management',\n",
       " 'Act as the key contact person for strategic stakeholders.',\n",
       " 'Apply appropriate and effective communication methods to senior management and important stakeholders (incl.',\n",
       " 'vendor) throughout the project lifecycle.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_sentencizer[19:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d97282ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(spacy_sentencizer):\n",
    "    if 'Power' in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b2147d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(idx for idx, sent in enumerate(spacy_sentencizer) if 'Power' in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b314b701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Strong MS-Office skills (Word, Excel, PowerPoint)'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_sentencizer[66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5dcf1dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Partner with Procurement in order to manage suppliers for the projects & programs in scope, e.g. interviews, staffing, supplier costs.\n",
      "\n",
      "Sentence 2: Communication / stakeholder management\n",
      "\n",
      "Sentence 3: Act as the key contact person for strategic stakeholders.\n",
      "\n",
      "Sentence 4: Apply appropriate and effective communication methods to senior management and important stakeholders (incl.\n",
      "\n",
      "Sentence 5: vendor) throughout the project lifecycle.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(spacy_sentencizer[19:24]):\n",
    "    print(f'Sentence {idx+1}: {sentence}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy tokenizer\n",
    "# spacy_tokenizer = []\n",
    "\n",
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     for job_sentence in spacy_sentencizer:\n",
    "# #         doc = nlp.tokenizer(job_sentence)\n",
    "#         spacy_tokenizer.extend(\n",
    "#             [\n",
    "#                 token.text for token in nlp.tokenizer(job_sentence) \n",
    "#                 if token.text not in custom_punct_chars\n",
    "#                 and not token.is_stop \n",
    "                \n",
    "#             ]\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenizer[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.lang.en import English\n",
    "# nlp = English()\n",
    "# nlp.add_pipe('sentencizer')\n",
    "doc = nlp('Operating income incl. JV was SEK 2.1 b. with an operating margin of 4.0%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526da0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "bigram_rules = [\n",
    "    ['VERB', 'ADJ', 'NOUN'],\n",
    "    ['NOUN', 'VERB', 'ADV'],\n",
    "    ['NOUN', 'ADP', 'NOUN'],\n",
    "    # more rules here...\n",
    "]\n",
    "\n",
    "rules = [\n",
    "    ['VERB', 'ADJ', 'NOUN'],\n",
    "    ['NOUN', 'VERB', 'ADV'],\n",
    "    ['NOUN', 'ADP', 'NOUN'],\n",
    "    # more rules here...\n",
    "]\n",
    "\n",
    "trigram_patterns = [[{\"POS\": i} for i in j] for j in rules]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2de96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "    'noun_verb': [{'POS': 'NOUN'}, {'POS': 'VERB'}],\n",
    "    'verb_noun': [{'POS': 'VERB'}, {'POS': 'NOUN'}],\n",
    "    'adj_noun': [{'POS': 'ADJ'}, {'POS': 'NOUN'}],\n",
    "    'adj_propn': [{'POS': 'ADJ'}, {'POS': 'PROPN'}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern_name, pattern in patterns.items():\n",
    "    matcher.add(pattern_name, [pattern])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e002bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_description in job_descriptions:\n",
    "    doc = nlp(job_description)\n",
    "    matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_id, start, end in matches:\n",
    "    \n",
    "    # Get string representation\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "\n",
    "    # The matched span\n",
    "    span = doc[start:end]\n",
    "    \n",
    "    print(repr(span.text))\n",
    "    print(match_id, string_id, start, end)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e73cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6595ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence in spacy_sentencizer:\n",
    "#     print(model.encode(sentence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.electra.modeling_tf_electra import TFElectraMainLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pavanchhatpar/electra-base-sentence-splitter\")\n",
    "\n",
    "model = AutoModelForPreTraining.from_pretrained(\"pavanchhatpar/electra-base-sentence-splitter\", from_tf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ee3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline('sentence-splitter', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8d4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "study1_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
