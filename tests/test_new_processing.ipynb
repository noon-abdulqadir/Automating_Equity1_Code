{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7d3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189dea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "# columns\n",
    "cols=['Sector', \n",
    "      'Sector Code', \n",
    "      'Gender', \n",
    "      'Age', \n",
    "      'Language', \n",
    "      'Dutch Requirement', \n",
    "      'English Requirement', \n",
    "      'Gender_Female', \n",
    "      'Gender_Mixed', \n",
    "      'Gender_Male', \n",
    "      'Age_Older', \n",
    "      'Age_Mixed', \n",
    "      'Age_Younger', \n",
    "      'Gender_Num', \n",
    "      'Age_Num', \n",
    "      '% Female', \n",
    "      '% Male', \n",
    "      '% Older', \n",
    "      '% Younger']\n",
    "\n",
    "int_variable: str = 'Job ID'\n",
    "str_variable: str = 'Job Description'\n",
    "gender: str = 'Gender'\n",
    "age: str = 'Age'\n",
    "language: str = 'en'\n",
    "str_cols = ['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name', 'Location', 'Job Description', 'Company URL', 'Job URL', 'Tracking ID']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n",
    "pattern_numbers = r'[^a-zA-Z0-9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21414866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pygwalker as pyg\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tag import pos_tag, pos_tag_sents\n",
    "from spacy.pipeline import Sentencizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c22dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw_dropped.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8818717b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62577"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "523b4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].apply(\n",
    "    lambda job_description: ' '.join(job_description.split('/')) if '/' in job_description else job_description\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3727334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abb_dict = {\n",
    "    r'incl\\.': 'including', \n",
    "    r'e\\.g\\.': 'for example', \n",
    "    r'e\\.g': 'for example', \n",
    "    r'etc\\.': 'et cetera', \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a22cc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_fix_incl = 'Apply appropriate and effective communication methods to senior management and important stakeholders'\n",
    "str_fix_eg = 'Partner with Procurement in order to manage suppliers for the projects & programs in scope'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2fd4414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description'] = df_jobs['Job Description'].replace(abb_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description'][df_jobs['Job Description'].str.contains(str_fix_incl)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(str_fix_eg, df_jobs['Job Description'][35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952299c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(re.finditer(str_fix_eg, df_jobs['Job Description'][35]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35af326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description'][35][1461:1580]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd40a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].apply(\n",
    "#     lambda job_description: job_description.replace('incl.', 'including')\n",
    "# )\n",
    "\n",
    "# df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].apply(\n",
    "#     lambda job_description: job_description.replace('e.g.', 'e.g')\n",
    "# )\n",
    "\n",
    "# df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].apply(\n",
    "#     lambda job_description: job_description.replace('e.g', 'for example')\n",
    "# )\n",
    "\n",
    "# df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].apply(\n",
    "#     lambda job_description: job_description.replace('etc.', 'et cetera')\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d45507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = df_jobs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = df_jobs.sample(n=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b23278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw_glob_paths_10.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d53f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_requirement_pattern = r'[Ll]anguage: [Dd]utch|[Dd]utch [Pp]referred|[Dd]utch [Re]quired|[Dd]utch [Ll]anguage|[Pp]roficient in [Dd]utch|[Ss]peak [Dd]utch|[Kk]now [Dd]utch'\n",
    "english_requirement_pattern = r'[Ll]anguage: [Ee]nglish|[Ee]nglish [Pp]referred|[Ee]nglish [Re]quired|[Ee]nglish [Ll]anguage|[Pp]roficient in [Ee]nglish|[Ss]peak [Ee]nglish|[Kk]now [Ee]nglish'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee66305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language requirements\n",
    "# Dutch\n",
    "if 'Dutch Requirement' in df_jobs.columns:\n",
    "    df_jobs.drop(columns=['Dutch Requirement'], inplace=True)\n",
    "df_jobs['Dutch Requirement'] = np.where(\n",
    "    df_jobs['Job Description'].str.contains(dutch_requirement_pattern),\n",
    "    'Yes',\n",
    "    'No',\n",
    ")\n",
    "\n",
    "# English\n",
    "if 'English Requirement' in df_jobs.columns:\n",
    "    df_jobs.drop(columns=['English Requirement'], inplace=True)\n",
    "df_jobs['English Requirement'] = np.where(\n",
    "    df_jobs['Job Description'].str.contains(english_requirement_pattern),\n",
    "    'Yes',\n",
    "    'No',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Dutch Requirement'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f6344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors = pd.read_pickle(f'{scraped_data}CBS/Data/Sectors Output from script.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors.columns = [\n",
    "    '_'.join(col) \n",
    "    if 'SBI Sector Titles' not in col \n",
    "    and 'Total Workforce' not in col \n",
    "    else col[-1] \n",
    "    for col in df_sectors.columns\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e87cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors.rename(\n",
    "    columns={\n",
    "        'Keywords': 'Search Keyword', \n",
    "        'Code': 'Sector Code', \n",
    "        'Sector Name': 'Sector', \n",
    "        'Gender_Female_n': 'Female Count (x 1000)', \n",
    "        'Gender_Male_n': 'Male Count (x 1000)', \n",
    "        'Gender_Sectoral Gender Segregation_Dominant Category': 'Gender', \n",
    "        'Age_Sectoral Age Segregation_Dominant Category': 'Age', \n",
    "        'n': 'Sector Count (x 1000)', \n",
    "    },\n",
    "    inplace=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_sectors['Search Keyword'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ded22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sectors = df_sectors.explode(\n",
    "    'Search Keyword', ignore_index=True\n",
    ").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7518a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_jobs = df_jobs.merge(df_sectors, on='Search Keyword', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4188c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ce97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f40d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_jobs['Search Keyword'].loc[df_jobs['Sector'].isna().sum()] != 0:\n",
    "    print('Some search keywords did not match a sector. Fixing')\n",
    "    print(set(df_jobs['Search Keyword'].loc[df_jobs['Sector'].isna()].to_list()))\n",
    "    print(len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n",
    "    df_jobs = fix_keywords(df_jobs)\n",
    "    print(set(df_jobs['Search Keyword'].loc[df_jobs['Sector'].isna()].to_list()))\n",
    "    print(len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9884dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_jobs.loc[(df_jobs['Job Description'].str.contains(str_fix_incl)) | (df_jobs['Job Description'].str.contains(str_fix_eg))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e556d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_descriptions = list(set(df_jobs['Job Description'].to_list()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9da09d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descriptions = list(\n",
    "    set(\n",
    "        df_jobs['Job Description'].loc[\n",
    "            (df_jobs['Job Description'].str.contains(str_fix_incl)) |\n",
    "            (df_jobs['Job Description'].str.contains(str_fix_eg))\n",
    "        ].to_list()\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0de4de75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87f15f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and important stakeholders throughout the project lifecycle.\\nAs conflicts and escalations arise within projects, identify solutions and drive their resolution in a timely and appropriate manner.\\nManage change within projects and ensure changes are smoothly and successfully implemented to achieve lasting benefits.\\nProject Controlling\\nManage project controlling as an independent element to ensure that actual project costs are in line the committed budget.\\nConduct engagement reviews. Verify complia'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_descriptions[0][1500:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5aaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = df_jobs.loc[\n",
    "    (df_jobs['Job Description'].str.contains(str_fix_incl)) | \n",
    "    (df_jobs['Job Description'].str.contains(str_fix_eg))\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ab475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d5e14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a list of punctuations that determine sentence boundry, i.e., split characters\n",
    "def make_custom_punct_chars(main_punct_chars = [':', '|'], repeated_punct_chars = ['\\n', ',']):\n",
    "    custom_punct_chars = []\n",
    "    temp_multi = []\n",
    "    temp_spaced = []\n",
    "\n",
    "    for punct_char in main_punct_chars:\n",
    "        custom_punct_chars+= f'{punct_char}', f'{punct_char} '\n",
    "\n",
    "    for idx in range(4):\n",
    "        for punct_char in repeated_punct_chars:\n",
    "            temp_multi.append(f'{punct_char}'*int(idx+1))\n",
    "            temp_spaced.append(f'{punct_char} '*int(idx+1))\n",
    "\n",
    "    for multi, spaced in zip(temp_multi, temp_spaced):\n",
    "        custom_punct_chars+= multi, spaced\n",
    "\n",
    "    custom_punct_chars.remove(',')\n",
    "    custom_punct_chars.remove(', ')\n",
    "\n",
    "    return custom_punct_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c7f61ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_punct_chars = make_custom_punct_chars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "183846a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':',\n",
       " ': ',\n",
       " '|',\n",
       " '| ',\n",
       " '\\n',\n",
       " '\\n ',\n",
       " '\\n\\n',\n",
       " '\\n \\n ',\n",
       " ',,',\n",
       " ', , ',\n",
       " '\\n\\n\\n',\n",
       " '\\n \\n \\n ',\n",
       " ',,,',\n",
       " ', , , ',\n",
       " '\\n\\n\\n\\n',\n",
       " '\\n \\n \\n \\n ',\n",
       " ',,,,',\n",
       " ', , , , ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_punct_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c845236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Spacy\n",
    "import spacy\n",
    "from spacy.symbols import NORM, ORTH, LEMMA, POS\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd2f4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sentencizer to nlp pip and set custom punctuations\n",
    "sentencizer = nlp.add_pipe('sentencizer')\n",
    "sentencizer.punct_chars.update(custom_punct_chars)\n",
    "\n",
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     with open(f'{data_dir}punctuations.txt', 'wb') as f:\n",
    "#         pickle.dump(sentencizer.punct_chars, f)\n",
    "\n",
    "# with open(f'{data_dir}punctuations.txt', 'rb') as f:\n",
    "#     custom_punct_chars = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37292ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     with open(f'{data_dir}punctuations.txt', 'wb') as f:\n",
    "#         pickle.dump(sentencizer.punct_chars, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e8ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'{data_dir}punctuations.txt', 'rb') as f:\n",
    "#     custom_punct_char = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6425cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import NORM, ORTH, LEMMA\n",
    "\n",
    "special_cases_dict = {\n",
    "    'incl.': [{65: 'incl', 67: 'including'}],\n",
    "    'incl. ': [{65: 'incl', 67: 'including'}],\n",
    "    '(incl.': [{65: 'incl', 67: 'including'}],\n",
    "    'etc.': [{65: 'etc', 67: 'et cetera'}],\n",
    "    'etc. ': [{65: 'etc', 67: 'et cetera'}],\n",
    "    'e.g.': [{65: 'e.g', 67: 'for example'}],\n",
    "    'e.g. ': [{65: 'e.g', 67: 'for example'}],\n",
    "}\n",
    "\n",
    "nlp.tokenizer.rules.update(special_cases_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer.rules['e.g.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    df_jobs['Job Description spacy_sentencized'] = df_jobs['Job Description'].apply(\n",
    "        lambda job_description: [\n",
    "            sent \n",
    "            for sentence in nlp(job_description).sents \n",
    "            for sent in re.split(pattern, sentence.text) \n",
    "            if len(sent) != 0 \n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description spacy_sentencized']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bc9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = df_jobs.explode('Job Description spacy_sentencized', ignore_index=True).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d1cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description spacy_sentencized_lower'] = df_jobs['Job Description spacy_sentencized'].apply(\n",
    "    lambda job_sentence: job_sentence.strip().lower()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c817bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9369d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy tokenize\n",
    "df_jobs['Job Description spacy_tokenized'] = df_jobs['Job Description spacy_sentencized'].apply(\n",
    "    lambda job_sentence: [\n",
    "        str(token.text.strip().lower()) \n",
    "        for token in nlp.tokenizer(job_sentence) \n",
    "        if len(token) != 0 \n",
    "        and not token.is_stop \n",
    "        and not token.is_punct \n",
    "        and not token.text in custom_punct_chars\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a4126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description spacy_tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaf53549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Load NLK\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer, PorterStemmer, LancasterStemmer\n",
    "\n",
    "nltk_path = f'{llm_path}/nltk'\n",
    "nltk.data.path.append(nltk_path)\n",
    "\n",
    "nltk.download('words', download_dir = nltk_path)\n",
    "nltk.download('stopwords', download_dir = nltk_path)\n",
    "nltk.download('punkt', download_dir = nltk_path)\n",
    "nltk.download('averaged_perceptron_tagger', download_dir = nltk_path)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7771bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = r'[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?<=[a-z])(?=[A-Z])'\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n",
    "\n",
    "pattern_numbers = r'[^a-zA-Z0-9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk_sentencized = []\n",
    "\n",
    "# for job_description in job_descriptions:\n",
    "#     for sentence in sent_tokenize(job_description):\n",
    "#         for sent in re.split(pattern, sentence):\n",
    "#             nltk_sentencized.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3defa20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentencized = [\n",
    "    sent \n",
    "    for job_description in job_descriptions \n",
    "    for sentence in sent_tokenize(job_description) \n",
    "    for sent in re.split(pattern, sentence)\n",
    "    if len(sent) != 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6151cea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_sentencized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b85716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs['Job Description nltk_sentencized'] = df_jobs['Job Description'].apply(\n",
    "#     lambda job_description: [\n",
    "#         sent \n",
    "#         for sentence in sent_tokenize(job_description) \n",
    "#         for sent in re.split(pattern, sentence)\n",
    "#         if len(sent) != 0\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs['Job Description nltk_sentencized'] = df_jobs['Job Description'].apply(\n",
    "#     lambda job_description: [\n",
    "#         re.split(pattern, sentence)\n",
    "#         for sentence in sent_tokenize(job_description)\n",
    "#         if len(sentence) != 0\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3808eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs['Job Description nltk_sentencized'][0][-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_jobs['Job Description nltk_sentencized'][0]) + len(df_jobs['Job Description nltk_sentencized'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af60e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = df_jobs.explode('Job Description nltk_sentencized', ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e9b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs['Job Description nltk_sentencized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1126453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentencized_lower = [\n",
    "    str(sent.strip().lower()) \n",
    "    for sent in nltk_sentencized\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d00571",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nltk_sentencized_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2042a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs['Job Description nltk_sentencized_lower'] = df_jobs['Job Description nltk_sentencized'].apply(\n",
    "#     lambda job_sentence: job_sentence.strip().lower()\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246ff470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs['Job Description nltk_sentencized_lower']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sentence in df_jobs['Job Description spacy_sentencized'].items():\n",
    "    if str_fix_eg in sentence:\n",
    "        print(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description spacy_sentencized'][17:25].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d85ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sentence in df_jobs['Job Description spacy_sentencized'].items():\n",
    "    if 'Power' in sentence:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d27dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description spacy_sentencized'][60:70].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sent in enumerate(nltk_sentencized):\n",
    "    if str_fix_eg in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1548e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(idx for idx, sent in enumerate(nltk_sentencized) if str_fix_eg in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_fix = 'Apply appropriate and effective communication methods to senior management and important stakeholders \\(incl.'\n",
    "\n",
    "for idx, sent in enumerate(nltk_sentencized):\n",
    "    if str_fix_incl.split('\\(')[0] in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentencized[84:95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1476b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences split on e.g. and incl.\n",
    "nltk_sentencized[\n",
    "    next(idx for idx, sent in enumerate(nltk_sentencized) if str_fix_eg in sent):next(idx for idx, sent in enumerate(nltk_sentencized) if str_fix_incl.split('\\(')[0] in sent)+2\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da72e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sent in enumerate(nltk_sentencized):\n",
    "    if 'Power' in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013d2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(idx for idx, sent in enumerate(nltk_sentencized) if 'Power' in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentencized[next(idx for idx, sent in enumerate(nltk_sentencized) if 'Power' in sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sentence in enumerate(nltk_sentencized[84:95]):\n",
    "    print(f'Sentence {idx+1}: {sentence}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk_tokenized = []\n",
    "\n",
    "# for job_sentence in nltk_sentencized:\n",
    "#     for token in word_tokenize(job_sentence):\n",
    "#         if len(token) != 0 and token != '...' and token.lower() not in set(stopwords.words('english')) and token.lower() not in list(string.punctuation):\n",
    "#             nltk_tokenized.append(str(token.strip().lower())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tokenized = [\n",
    "    str(token.strip().lower()) \n",
    "    for job_sentence in nltk_sentencized \n",
    "    for token in word_tokenize(job_sentence) \n",
    "    if len(token) != 0 \n",
    "    and token != '...' \n",
    "    and not token.lower() in set(stopwords.words('english')) \n",
    "    and not token.lower() in list(string.punctuation) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad77469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nltk_tokenized'] = df_jobs['Job Description spacy_sentencized'].apply(\n",
    "    lambda job_sentence: [\n",
    "        str(token.strip().lower()) \n",
    "        for token in word_tokenize(job_sentence) \n",
    "        if len(token) != 0 \n",
    "        and token != '...' \n",
    "        and not token.lower() in set(stopwords.words('english')) \n",
    "        and not token.lower() in list(string.punctuation) \n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1365b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nltk_tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d604e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'...' in nltk_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90fd54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nltk_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c008f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import save_as_line_sentence, simple_preprocess\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string, preprocess_documents\n",
    "\n",
    "gensim_tokenized = []\n",
    "\n",
    "for job_sentence in nltk_sentencized:\n",
    "    gensim_tokenized.append(preprocess_string(re.sub(pattern_numbers, ' ', job_sentence.strip().lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df785608",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description gensim_tokenized'] = df_jobs['Job Description spacy_sentencized'].apply(\n",
    "    lambda job_sentence: preprocess_string(re.sub(pattern_numbers, ' ', job_sentence.strip().lower()))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea685cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description gensim_tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b222c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_token_tags = pos_tag(nltk_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b74e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_token_tags[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nltk_token_tags'] = df_jobs['Job Description nltk_tokenized'].apply(\n",
    "    lambda token: pos_tag(token)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135b1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nltk_token_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.machinelearningplus.com/nlp/lemmatization-examples-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db3011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([token])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda77df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "nltk_lemmas = []\n",
    "nltk_stems = []\n",
    "\n",
    "for token in nltk_tokenized:\n",
    "    token = unicodedata.normalize('NFKD', str(token.strip().lower())).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    token_lemma = lemmatizer.lemmatize(token)\n",
    "    token_stem = stemmer.stem(token)\n",
    "    token_pos = get_wordnet_pos(token)\n",
    "    token_pos_lemma = lemmatizer.lemmatize(token, token_pos)\n",
    "    print(f'Token: {token} | Stem: {token_stem} | Lemma: {token_lemma} | POS Lemma: {token_pos_lemma}')\n",
    "    nltk_lemmas.append(token_pos_lemma)\n",
    "    nltk_stems.append(token_stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb7d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "nltk_lemmas = []\n",
    "nltk_stems = []\n",
    "\n",
    "for token in nltk_tokenized:\n",
    "    token = unicodedata.normalize('NFKD', str(token.strip().lower())).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    token_lemma = lemmatizer.lemmatize(token)\n",
    "    token_stem = stemmer.stem(token)\n",
    "    token_pos = get_wordnet_pos(token)\n",
    "    nltk_lemmas.append(lemmatizer.lemmatize(token, get_wordnet_pos(token)))\n",
    "    nltk_stems.append(token_stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_lemmas = [\n",
    "    lemmatizer.lemmatize(\n",
    "        token, get_wordnet_pos(\n",
    "            unicodedata.normalize('NFKD', str(token.strip().lower())).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        )\n",
    "    )\n",
    "    for token in nltk_tokenized\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d82225",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nltk_lemmas'] = df_jobs['Job Description spacy_tokenized'].apply(\n",
    "    lambda tokens: [\n",
    "        lemmatizer.lemmatize(\n",
    "            token, get_wordnet_pos(\n",
    "                unicodedata.normalize('NFKD', str(token.strip().lower())).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "            )\n",
    "        )\n",
    "        for token in tokens\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9723c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nltk_lemmas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8227a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nltk_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "nltk_lemmas = []\n",
    "nltk_stems = []\n",
    "\n",
    "for token in nltk_tokenized:\n",
    "    token = unicodedata.normalize('NFKD', str(token.strip().lower())).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "    nltk_stems.append(stemmer.stem(unicodedata.normalize('NFKD', str(token.strip().lower())).encode('ascii', 'ignore').decode('utf-8', 'ignore')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45564d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stems = [\n",
    "    stemmer.stem(\n",
    "        unicodedata.normalize('NFKD', str(token.strip().lower())).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    )\n",
    "    for token in nltk_tokenized\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47888b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nltk_stems'] = df_jobs['Job Description spacy_tokenized'].apply(\n",
    "    lambda tokens: [\n",
    "        stemmer.stem(\n",
    "            unicodedata.normalize('NFKD', str(token.strip().lower())).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        )\n",
    "        for token in tokens\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nltk_stems']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nltk_stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc52927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52198bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_cases = {\":)\": [{\"ORTH\": \":)\"}]}\n",
    "# prefix_re = re.compile(r'''^[\\\\[\\\\(\"']''')\n",
    "# suffix_re = re.compile(r'''[\\\\]\\\\)\"']$''')\n",
    "# infix_re = re.compile(r'''[-~]''')\n",
    "# simple_url_re = re.compile(r'''^https?://''')\n",
    "\n",
    "# def custom_tokenizer(nlp):\n",
    "#     return Tokenizer(nlp.vocab, rules=special_cases,\n",
    "#                                 prefix_search=prefix_re.search,\n",
    "#                                 suffix_search=suffix_re.search,\n",
    "#                                 infix_finditer=infix_re.finditer,\n",
    "#                                 url_match=simple_url_re.match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65795c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.tokenizer.add_special_case('incl', [{ORTH: u'incl', NORM: u'include', LEMMA: u'include', POS: u'VERB'}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy sentencizer\n",
    "# spacy_sentencized = []\n",
    "\n",
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     for job_description in job_descriptions:\n",
    "#         for sentence in nlp(job_description).sents:\n",
    "#             for sent in re.split(pattern, sentence.text):\n",
    "#                 if len(sent) != 0:\n",
    "#                     spacy_sentencized.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0ea7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy sentencizer\n",
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    spacy_sentencized = [\n",
    "        sent \n",
    "        for job_description in job_descriptions \n",
    "        for sentence in nlp(job_description).sents \n",
    "        for sent in re.split(pattern, sentence.text) \n",
    "        if len(sent) != 0 \n",
    "    ]\n",
    "    \n",
    "    spacy_sentencized_lower = [\n",
    "        str(sent.strip().lower()) \n",
    "        for sent in spacy_sentencized\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy sentencizer\n",
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     spacy_sentencized = [\n",
    "#         re.split(pattern, sentence.text) \n",
    "#         for job_description in job_descriptions \n",
    "#         for sentence in nlp(job_description).sents \n",
    "# #         for sent in re.split(pattern, sentence.text) \n",
    "#         if len(sentence) != 0 \n",
    "#     ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d6eff4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conduct engagement reviews.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_sentencized[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa78330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy tokenizer\n",
    "spacy_tokenized = []\n",
    "\n",
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    for job_sentence in spacy_sentencized:\n",
    "        for token in nlp.tokenizer(job_sentence):\n",
    "            if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars:\n",
    "                spacy_tokenized.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c17a0255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Purpose',\n",
       " 'Manager',\n",
       " 'Digital',\n",
       " 'Strategy',\n",
       " 'Programs',\n",
       " 'adidas',\n",
       " 'market',\n",
       " 'ecom',\n",
       " 'organization',\n",
       " 'task',\n",
       " 'manage',\n",
       " 'deliver',\n",
       " 'small',\n",
       " 'digital',\n",
       " 'projects',\n",
       " 'significant',\n",
       " 'RFCs',\n",
       " 'sub',\n",
       " 'elements',\n",
       " 'mid',\n",
       " 'scale',\n",
       " 'digital',\n",
       " 'projects',\n",
       " 'project',\n",
       " 'scope',\n",
       " 'local',\n",
       " 'market',\n",
       " 'level',\n",
       " 'brands',\n",
       " 'functions',\n",
       " 'objective',\n",
       " 'conduct',\n",
       " 'projects',\n",
       " 'boundaries',\n",
       " 'time',\n",
       " 'cost',\n",
       " 'quality',\n",
       " 'focusing',\n",
       " 'consumers',\n",
       " 'expectations',\n",
       " 'requirements',\n",
       " 'Planning',\n",
       " 'executing',\n",
       " 'tracking',\n",
       " 'projects',\n",
       " 'cooperation',\n",
       " 'respective',\n",
       " 'functions',\n",
       " 'project',\n",
       " 'team',\n",
       " 'members',\n",
       " 'examples',\n",
       " 'expected',\n",
       " 'role',\n",
       " 'Additionally',\n",
       " 'focusing',\n",
       " 'resource',\n",
       " 'management',\n",
       " 'coordination',\n",
       " 'activities',\n",
       " 'acting',\n",
       " 'central',\n",
       " 'interface',\n",
       " 'local',\n",
       " 'stakeholders',\n",
       " 'Key',\n",
       " 'Responsibilities',\n",
       " 'Scope',\n",
       " 'Manage',\n",
       " 'deliver',\n",
       " 'small',\n",
       " 'digital',\n",
       " 'projects',\n",
       " 'local',\n",
       " 'market',\n",
       " 'level',\n",
       " 'Project',\n",
       " ' ',\n",
       " 'Program',\n",
       " 'Delivery',\n",
       " 'Deliver',\n",
       " 'projects',\n",
       " 'end',\n",
       " 'end',\n",
       " 'successfully',\n",
       " 'ideally',\n",
       " 'effective',\n",
       " 'application',\n",
       " 'PMI',\n",
       " 'Agile',\n",
       " 'methodology',\n",
       " 'Develop',\n",
       " 'detailed',\n",
       " 'plans',\n",
       " 'allow',\n",
       " 'providing',\n",
       " 'transparency',\n",
       " 'progress',\n",
       " 'identifying',\n",
       " 'risks',\n",
       " 'time',\n",
       " 'Identify',\n",
       " 'interdependencies',\n",
       " 'projects',\n",
       " 'solve',\n",
       " 'issues',\n",
       " 'proactively',\n",
       " 'Drive',\n",
       " 'continuous',\n",
       " 'improvement',\n",
       " 'products',\n",
       " 'processes',\n",
       " 'systems',\n",
       " 'project',\n",
       " 'scope',\n",
       " 'Resource',\n",
       " 'Planning',\n",
       " 'Lead',\n",
       " 'manage',\n",
       " 'team',\n",
       " 'resources',\n",
       " 'internals',\n",
       " 'externals',\n",
       " 'deliver',\n",
       " 'support',\n",
       " 'projects',\n",
       " 'programs',\n",
       " 'Communication',\n",
       " 'Act',\n",
       " 'key',\n",
       " 'contact',\n",
       " 'person',\n",
       " 'local',\n",
       " 'stakeholders',\n",
       " 'Apply',\n",
       " 'appropriate',\n",
       " 'effective',\n",
       " 'communication',\n",
       " 'methods',\n",
       " 'senior',\n",
       " 'management',\n",
       " 'important',\n",
       " 'stakeholders',\n",
       " 'project',\n",
       " 'lifecycle',\n",
       " 'conflicts',\n",
       " 'escalations',\n",
       " 'arise',\n",
       " 'projects',\n",
       " 'identify',\n",
       " 'solutions',\n",
       " 'drive',\n",
       " 'resolution',\n",
       " 'timely',\n",
       " 'appropriate',\n",
       " 'manner',\n",
       " 'Manage',\n",
       " 'change',\n",
       " 'projects',\n",
       " 'ensure',\n",
       " 'changes',\n",
       " 'smoothly',\n",
       " 'successfully',\n",
       " 'implemented',\n",
       " 'achieve',\n",
       " 'lasting',\n",
       " 'benefits',\n",
       " 'Project',\n",
       " 'Controlling',\n",
       " 'Manage',\n",
       " 'project',\n",
       " 'controlling',\n",
       " 'independent',\n",
       " 'element',\n",
       " 'ensure',\n",
       " 'actual',\n",
       " 'project',\n",
       " 'costs',\n",
       " 'line',\n",
       " 'committed',\n",
       " 'budget',\n",
       " 'Conduct',\n",
       " 'engagement',\n",
       " 'reviews',\n",
       " 'Verify',\n",
       " 'compliance',\n",
       " 'quality',\n",
       " 'assurance',\n",
       " 'procedures',\n",
       " 'Validate',\n",
       " 'project',\n",
       " 'delivering',\n",
       " 'program',\n",
       " 'KPIs',\n",
       " 'Monitor',\n",
       " 'project',\n",
       " 'variables',\n",
       " 'cost',\n",
       " 'effort',\n",
       " 'scope',\n",
       " 'et',\n",
       " 'cetera',\n",
       " 'plan',\n",
       " 'order',\n",
       " 'implement',\n",
       " 'corrective',\n",
       " 'preventive',\n",
       " 'actions',\n",
       " 'required',\n",
       " 'Responsibilities',\n",
       " 'Agile',\n",
       " 'Transformation',\n",
       " 'Drive',\n",
       " 'implementation',\n",
       " 'elements',\n",
       " 'transformation',\n",
       " 'agile',\n",
       " 'working',\n",
       " 'mode',\n",
       " 'facilitate',\n",
       " 'agile',\n",
       " 'adoption',\n",
       " 'Contribute',\n",
       " 'developing',\n",
       " 'orchestrating',\n",
       " 'demand',\n",
       " 'delivery',\n",
       " 'process',\n",
       " 'Global',\n",
       " 'Facilitate',\n",
       " 'initial',\n",
       " 'demand',\n",
       " 'discussions',\n",
       " 'Market',\n",
       " 'Development',\n",
       " 'Create',\n",
       " 'business',\n",
       " 'cases',\n",
       " 'market',\n",
       " 'support',\n",
       " 'local',\n",
       " 'global',\n",
       " 'Analytics',\n",
       " 'team',\n",
       " 'evaluate',\n",
       " 'growth',\n",
       " 'opportunities',\n",
       " 'Implement',\n",
       " 'base',\n",
       " 'platform',\n",
       " 'capabilities',\n",
       " 'build',\n",
       " 'global',\n",
       " 'required',\n",
       " 'fulfill',\n",
       " 'business',\n",
       " 'cases',\n",
       " 'Key',\n",
       " 'Relationships',\n",
       " 'Leading',\n",
       " 'Sr',\n",
       " ' ',\n",
       " 'Project',\n",
       " 'Manager',\n",
       " 'Sr',\n",
       " 'Dir',\n",
       " 'Digital',\n",
       " 'Strategy',\n",
       " 'Programs',\n",
       " 'Project',\n",
       " 'Team',\n",
       " 'Local',\n",
       " 'Project',\n",
       " 'Stakeholders',\n",
       " 'Global',\n",
       " 'Digital',\n",
       " 'Global',\n",
       " 'Digital',\n",
       " 'Sales',\n",
       " 'Solutions',\n",
       " 'Respective',\n",
       " 'business',\n",
       " 'functions',\n",
       " 'Ops',\n",
       " 'Finance',\n",
       " 'HR',\n",
       " 'Brand',\n",
       " 'Marketing',\n",
       " 'Wholesale',\n",
       " 'Retail',\n",
       " 'HR',\n",
       " 'Management',\n",
       " 'Controlling',\n",
       " 'Education',\n",
       " 'Experience',\n",
       " 'University',\n",
       " 'degree',\n",
       " 'focus',\n",
       " 'Business',\n",
       " 'Administration',\n",
       " 'Communication',\n",
       " 'related',\n",
       " 'areas',\n",
       " 'equivalent',\n",
       " 'combination',\n",
       " 'education',\n",
       " 'experience',\n",
       " '5',\n",
       " '+',\n",
       " 'years',\n",
       " 'depth',\n",
       " 'professional',\n",
       " 'experience',\n",
       " 'related',\n",
       " 'project',\n",
       " 'management',\n",
       " 'similar',\n",
       " 'topics',\n",
       " '1',\n",
       " '3',\n",
       " 'years',\n",
       " 'professional',\n",
       " 'experience',\n",
       " 'ecosystem',\n",
       " 'environment',\n",
       " 'project',\n",
       " 'area',\n",
       " 'scope',\n",
       " 'Proven',\n",
       " 'market',\n",
       " 'business',\n",
       " 'acumen',\n",
       " 'Experience',\n",
       " 'ecommerce',\n",
       " 'plus',\n",
       " 'Experience',\n",
       " 'Finance',\n",
       " 'plus',\n",
       " 'Experience',\n",
       " 'working',\n",
       " 'stakeholders',\n",
       " 'seniority',\n",
       " 'levels',\n",
       " 'subject',\n",
       " 'matter',\n",
       " 'experts',\n",
       " 'functions',\n",
       " 'Developers',\n",
       " 'business',\n",
       " 'stakeholders',\n",
       " 'product',\n",
       " 'marketing',\n",
       " 'teams',\n",
       " 'et',\n",
       " 'cetera',\n",
       " 'Knowledge',\n",
       " 'Skills',\n",
       " 'Abilities',\n",
       " 'Soft',\n",
       " 'Skills',\n",
       " 'Good',\n",
       " 'communication',\n",
       " 'skills',\n",
       " 'especially',\n",
       " 'interacting',\n",
       " 'different',\n",
       " 'levels',\n",
       " 'business',\n",
       " 'Ability',\n",
       " 'work',\n",
       " 'fast',\n",
       " 'paced',\n",
       " 'environment',\n",
       " 'different',\n",
       " 'international',\n",
       " 'cultures',\n",
       " 'Solutions',\n",
       " 'oriented',\n",
       " 'approach',\n",
       " 'entrepreneurial',\n",
       " 'mindset',\n",
       " 'Good',\n",
       " 'numerical',\n",
       " 'analytical',\n",
       " 'skills',\n",
       " 'Hard',\n",
       " 'Skills',\n",
       " 'Strong',\n",
       " 'MS',\n",
       " 'Office',\n",
       " 'skills',\n",
       " 'Word',\n",
       " 'Excel',\n",
       " 'PowerPoint',\n",
       " 'Basic',\n",
       " 'Experience',\n",
       " 'broad',\n",
       " 'understanding',\n",
       " 'Working',\n",
       " 'knowledge',\n",
       " 'Agile',\n",
       " 'working',\n",
       " 'methods',\n",
       " 'example',\n",
       " 'Scrum',\n",
       " 'Kanban',\n",
       " 'Working',\n",
       " 'knowledge',\n",
       " 'PMI',\n",
       " 'methods',\n",
       " 'ideally',\n",
       " 'certification',\n",
       " 'Fluent',\n",
       " 'English',\n",
       " 'verbally',\n",
       " 'written',\n",
       " 'Purpose',\n",
       " 'Studio',\n",
       " 'Director',\n",
       " 'Special',\n",
       " 'Projects',\n",
       " 'adidas',\n",
       " 'Digital',\n",
       " 'task',\n",
       " 'manage',\n",
       " 'deliver',\n",
       " 'Studio',\n",
       " 'programs',\n",
       " 'including',\n",
       " 'projects',\n",
       " 'roadmap',\n",
       " 'program',\n",
       " 'scope',\n",
       " 'comprise',\n",
       " 'multiple',\n",
       " 'countries',\n",
       " 'functions',\n",
       " 'objective',\n",
       " 'conduct',\n",
       " 'projects',\n",
       " 'boundaries',\n",
       " 'time',\n",
       " 'cost',\n",
       " 'quality',\n",
       " 'focusing',\n",
       " 'consumers',\n",
       " 'expectations',\n",
       " 'requirements',\n",
       " 'Planning',\n",
       " 'executing',\n",
       " 'tracking',\n",
       " 'projects',\n",
       " 'programs',\n",
       " 'cooperation',\n",
       " 'respective',\n",
       " 'functions',\n",
       " 'project',\n",
       " 'team',\n",
       " 'members',\n",
       " 'examples',\n",
       " 'expected',\n",
       " 'role',\n",
       " 'Additionally',\n",
       " 'focusing',\n",
       " 'resource',\n",
       " 'planning',\n",
       " 'vendor',\n",
       " 'management',\n",
       " 'coordination',\n",
       " 'activities',\n",
       " 'acting',\n",
       " 'central',\n",
       " 'interface',\n",
       " 'key',\n",
       " 'stakeholders',\n",
       " 'Scope',\n",
       " 'Manage',\n",
       " 'deliver',\n",
       " 'Studio',\n",
       " 'programs',\n",
       " 'including',\n",
       " 'projects',\n",
       " 'roadmap',\n",
       " 'Project',\n",
       " ' ',\n",
       " 'Program',\n",
       " 'Delivery',\n",
       " 'Manage',\n",
       " 'set',\n",
       " 'roll',\n",
       " 'Studio',\n",
       " 'hubs',\n",
       " 'Portland',\n",
       " 'Shanghai',\n",
       " 'locations',\n",
       " 'Ensure',\n",
       " 'clear',\n",
       " 'operating',\n",
       " 'interaction',\n",
       " 'models',\n",
       " 'processes',\n",
       " 'reporting',\n",
       " 'frameworks',\n",
       " 'Manage',\n",
       " 'strategic',\n",
       " 'partnership',\n",
       " 'Oliver',\n",
       " 'globally',\n",
       " 'market',\n",
       " 'Set',\n",
       " 'pilots',\n",
       " 'new',\n",
       " 'production',\n",
       " 'topics',\n",
       " 'ie',\n",
       " 'Tier',\n",
       " '1',\n",
       " 'elevated',\n",
       " 'content',\n",
       " 'manage',\n",
       " 'point',\n",
       " 'moved',\n",
       " 'mass',\n",
       " 'production',\n",
       " 'scale',\n",
       " 'Manage',\n",
       " 'creator',\n",
       " 'production',\n",
       " 'requests',\n",
       " 'ie',\n",
       " 'Beyonce',\n",
       " 'Pharrell',\n",
       " 'et',\n",
       " 'ceteraManage',\n",
       " 'supporting',\n",
       " 'system',\n",
       " 'platforms',\n",
       " 'Resource',\n",
       " 'Planning',\n",
       " 'Form',\n",
       " 'lead',\n",
       " 'manage',\n",
       " 'monitor',\n",
       " 'multi',\n",
       " 'functional',\n",
       " 'team',\n",
       " 'resources',\n",
       " 'internals',\n",
       " 'externals',\n",
       " 'deliver',\n",
       " 'support',\n",
       " 'projects',\n",
       " 'programs',\n",
       " 'Partner',\n",
       " 'Procurement',\n",
       " 'order',\n",
       " 'manage',\n",
       " 'suppliers',\n",
       " 'projects',\n",
       " 'programs',\n",
       " 'scope',\n",
       " 'example',\n",
       " 'interviews',\n",
       " 'staffing',\n",
       " 'supplier',\n",
       " 'costs',\n",
       " 'Communication',\n",
       " '  ',\n",
       " 'stakeholder',\n",
       " 'management',\n",
       " 'Act',\n",
       " 'key',\n",
       " 'contact',\n",
       " 'person',\n",
       " 'strategic',\n",
       " 'stakeholders',\n",
       " 'Apply',\n",
       " 'appropriate',\n",
       " 'effective',\n",
       " 'communication',\n",
       " 'methods',\n",
       " 'senior',\n",
       " 'management',\n",
       " 'important',\n",
       " 'stakeholders',\n",
       " 'including',\n",
       " 'vendor',\n",
       " 'project',\n",
       " 'lifecycle',\n",
       " 'conflicts',\n",
       " 'escalations',\n",
       " 'arise',\n",
       " 'projects',\n",
       " 'identify',\n",
       " 'solutions',\n",
       " 'manage',\n",
       " 'resolution',\n",
       " 'timely',\n",
       " 'appropriate',\n",
       " 'manner',\n",
       " 'Drive',\n",
       " 'change',\n",
       " 'management',\n",
       " 'activities',\n",
       " 'respective',\n",
       " 'projects',\n",
       " 'programs',\n",
       " 'ensure',\n",
       " 'changes',\n",
       " 'smoothly',\n",
       " 'successfully',\n",
       " 'implemented',\n",
       " 'achieve',\n",
       " 'lasting',\n",
       " 'benefits',\n",
       " 'Project',\n",
       " 'Controlling',\n",
       " 'Manage',\n",
       " 'project',\n",
       " 'controlling',\n",
       " 'independent',\n",
       " 'element',\n",
       " 'ensure',\n",
       " 'actual',\n",
       " 'project',\n",
       " 'costs',\n",
       " 'line',\n",
       " 'committed',\n",
       " 'budget',\n",
       " 'Lead',\n",
       " 'conduct',\n",
       " 'engagement',\n",
       " 'reviews',\n",
       " 'Verify',\n",
       " 'implementation',\n",
       " 'quality',\n",
       " 'assurance',\n",
       " 'procedures',\n",
       " 'Ensure',\n",
       " 'project',\n",
       " 'program',\n",
       " 'delivery',\n",
       " 'program',\n",
       " 'KPIs',\n",
       " 'Monitor',\n",
       " 'project',\n",
       " 'program',\n",
       " 'variables',\n",
       " 'cost',\n",
       " 'effort',\n",
       " 'scope',\n",
       " 'et',\n",
       " 'cetera',\n",
       " 'plan',\n",
       " 'order',\n",
       " 'implement',\n",
       " 'corrective',\n",
       " 'preventive',\n",
       " 'actions',\n",
       " 'People',\n",
       " 'Management',\n",
       " 'Ensure',\n",
       " 'appropriate',\n",
       " 'leadership',\n",
       " 'skills',\n",
       " 'present',\n",
       " 'level',\n",
       " 'creating',\n",
       " 'motivational',\n",
       " 'supportive',\n",
       " 'work',\n",
       " 'environment',\n",
       " 'employees',\n",
       " 'coached',\n",
       " 'trained',\n",
       " 'provided',\n",
       " 'career',\n",
       " 'opportunities',\n",
       " 'development',\n",
       " 'Continuously',\n",
       " 'monitor',\n",
       " 'evaluate',\n",
       " 'team',\n",
       " 'workload',\n",
       " 'organizational',\n",
       " 'efficiency',\n",
       " 'support',\n",
       " 'systems',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'team',\n",
       " 'feedback',\n",
       " 'appropriate',\n",
       " 'changes',\n",
       " 'order',\n",
       " 'meet',\n",
       " 'business',\n",
       " 'needs',\n",
       " 'Provide',\n",
       " 'team',\n",
       " 'members',\n",
       " 'direct',\n",
       " 'reports',\n",
       " 'clear',\n",
       " 'direction',\n",
       " 'targets',\n",
       " 'aligned',\n",
       " 'business',\n",
       " 'needs',\n",
       " 'Digital',\n",
       " 'objectives',\n",
       " 'Key',\n",
       " 'Relationships',\n",
       " 'Studio',\n",
       " 'Creative',\n",
       " 'Operations',\n",
       " 'Production',\n",
       " 'Content',\n",
       " 'Strategy',\n",
       " 'Digital',\n",
       " 'Teams',\n",
       " 'Planning',\n",
       " 'Experience',\n",
       " 'Design',\n",
       " 'Activation',\n",
       " 'Major',\n",
       " 'Global',\n",
       " 'Stakeholders',\n",
       " 'Global',\n",
       " 'comms',\n",
       " 'teams',\n",
       " 'Global',\n",
       " 'operations',\n",
       " 'Brand',\n",
       " 'Design',\n",
       " 'Major',\n",
       " 'Digital',\n",
       " 'teams',\n",
       " 'Digital',\n",
       " 'Planning',\n",
       " 'Growth',\n",
       " 'Digital',\n",
       " 'Products',\n",
       " 'DTO',\n",
       " 'Respective',\n",
       " 'business',\n",
       " 'function',\n",
       " 'GOPS',\n",
       " 'Finance',\n",
       " 'HR',\n",
       " 'Brand',\n",
       " 'Marketing',\n",
       " 'Wholesale',\n",
       " 'Retail',\n",
       " 'Global',\n",
       " 'External',\n",
       " 'studios',\n",
       " 'agencies',\n",
       " 'Procurement',\n",
       " 'Requirements',\n",
       " 'Education',\n",
       " 'Experience',\n",
       " 'Ideally',\n",
       " 'Master',\n",
       " 'degree',\n",
       " 'focus',\n",
       " 'Business',\n",
       " 'Administration',\n",
       " 'Communication',\n",
       " 'related',\n",
       " 'areas',\n",
       " 'equivalent',\n",
       " 'combination',\n",
       " 'education',\n",
       " 'experience',\n",
       " '10',\n",
       " '+',\n",
       " 'years',\n",
       " 'depth',\n",
       " 'experience',\n",
       " 'related',\n",
       " 'project',\n",
       " 'management',\n",
       " 'similar',\n",
       " 'topics',\n",
       " '6',\n",
       " '8',\n",
       " 'years',\n",
       " 'professional',\n",
       " 'experience',\n",
       " 'digital',\n",
       " 'ecosystem',\n",
       " 'environment',\n",
       " 'Experience',\n",
       " 'house',\n",
       " 'studio',\n",
       " 'roll',\n",
       " 'Understanding',\n",
       " 'eCom',\n",
       " 'image',\n",
       " 'video',\n",
       " 'copy',\n",
       " 'mass',\n",
       " 'production',\n",
       " 'Experience',\n",
       " 'working',\n",
       " 'agencies',\n",
       " 'consultancy',\n",
       " 'plus',\n",
       " 'Experience',\n",
       " 'working',\n",
       " 'stakeholders',\n",
       " 'seniority',\n",
       " 'levels',\n",
       " 'subject',\n",
       " 'matter',\n",
       " 'experts',\n",
       " 'functions',\n",
       " 'Developers',\n",
       " 'business',\n",
       " 'stakeholders',\n",
       " 'product',\n",
       " 'marketing',\n",
       " 'teams',\n",
       " 'et',\n",
       " 'cetera',\n",
       " '3',\n",
       " '+',\n",
       " 'years',\n",
       " 'experience',\n",
       " 'leading',\n",
       " 'team',\n",
       " 'Soft',\n",
       " 'Skills',\n",
       " 'good',\n",
       " 'communication',\n",
       " 'skills',\n",
       " 'especially',\n",
       " 'interacting',\n",
       " 'different',\n",
       " 'levels',\n",
       " 'business',\n",
       " 'Ability',\n",
       " 'work',\n",
       " 'fast',\n",
       " 'paced',\n",
       " 'environment',\n",
       " 'different',\n",
       " 'international',\n",
       " 'cultures',\n",
       " 'Ability',\n",
       " 'handle',\n",
       " 'ambiguity',\n",
       " 'untangle',\n",
       " 'complex',\n",
       " 'situations',\n",
       " 'actionable',\n",
       " 'activities',\n",
       " 'Distinctive',\n",
       " 'strategic',\n",
       " 'mindset',\n",
       " 'ability',\n",
       " 'prioritize',\n",
       " 'delegate',\n",
       " 'high',\n",
       " 'numbers',\n",
       " 'tasks',\n",
       " 'varying',\n",
       " 'workload',\n",
       " 'importance',\n",
       " 'Solutions',\n",
       " 'oriented',\n",
       " 'approach',\n",
       " 'entrepreneurial',\n",
       " 'mindset',\n",
       " 'Good',\n",
       " 'numerical',\n",
       " 'analytical',\n",
       " 'skills',\n",
       " 'Highly',\n",
       " 'developed',\n",
       " 'leadership',\n",
       " 'skills',\n",
       " 'required',\n",
       " 'Hard',\n",
       " 'Skills',\n",
       " 'Knowledge',\n",
       " 'digital',\n",
       " 'technologies',\n",
       " 'communications',\n",
       " 'platforms',\n",
       " 'culture',\n",
       " 'Strong',\n",
       " 'MS',\n",
       " 'Office',\n",
       " 'skills',\n",
       " 'Word',\n",
       " 'Excel',\n",
       " 'PowerPoint',\n",
       " 'Ability',\n",
       " 'travel',\n",
       " 'domestic',\n",
       " 'international',\n",
       " 'required',\n",
       " 'depth',\n",
       " 'understanding',\n",
       " 'Fluent',\n",
       " 'English',\n",
       " 'verbally',\n",
       " 'written']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f574e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spacy_sentencized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b715ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spacy_sentencized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sent in enumerate(spacy_sentencized):\n",
    "    if str_fix_eg in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c222370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(idx for idx, sent in enumerate(spacy_sentencized) if str_fix_eg in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_fix = 'Apply appropriate and effective communication methods to senior management and important stakeholders \\(incl.'\n",
    "\n",
    "\n",
    "for idx, sent in enumerate(spacy_sentencized):\n",
    "    if str_fix_incl.split('\\(')[0] in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a7d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(idx for idx, sent in enumerate(spacy_sentencized) if str_fix_incl.split('\\(')[0] in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c515eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_sentencized[18:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97282ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sent in enumerate(spacy_sentencized):\n",
    "    if 'Power' in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2147d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(idx for idx, sent in enumerate(spacy_sentencized) if 'Power' in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_sentencized[63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf1dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, sentence in enumerate(spacy_sentencized[18:25]):\n",
    "    print(f'Sentence {idx+1}: {sentence}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy tokenizer\n",
    "# spacy_tokenized = []\n",
    "\n",
    "# for job_sentence in spacy_sentencized:\n",
    "# #         doc = nlp.tokenizer(job_sentence)\n",
    "#     spacy_tokenized.extend(\n",
    "#         [\n",
    "#             token.text for token in nlp.tokenizer(job_sentence) \n",
    "#             if token.text not in custom_punct_chars\n",
    "#             and not token.is_stop \n",
    "\n",
    "#         ]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeddf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spacy_sentencized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d95615",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_sentencized[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d84b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy tokenizer\n",
    "\n",
    "spacy_tokenized = [\n",
    "    str(token.text.strip().lower()) \n",
    "    for job_sentence in spacy_sentencized \n",
    "    for token in nlp.tokenizer(job_sentence) \n",
    "    if len(token) != 0 \n",
    "    and not token.is_stop \n",
    "    and not token.is_punct \n",
    "    and not token.text in custom_punct_chars\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spacy_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokenized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6dcfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.get_pipe('attribute_ruler').add([[{\"TEXT\":\"Angeltown\"}]],{\"LEMMA\":\"San Fransisco\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91acafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy pos tagging\n",
    "# nlp_stemmer = LancasterStemmer()\n",
    "nlp_stemmer = PorterStemmer()\n",
    "\n",
    "nlp_token_tags = []\n",
    "nlp_lemmas = []\n",
    "nlp_stems = []\n",
    "\n",
    "for job_description in job_descriptions:\n",
    "    for token in nlp(job_description):\n",
    "        if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars:\n",
    "            nlp_token_tags.append(tuple([token.text, token.tag_]))\n",
    "            nlp_lemmas.append(token.lemma_)\n",
    "            nlp_stems.append(nlp_stemmer.stem(token.text))\n",
    "#         for sentence in doc.sents:\n",
    "#             for sent in re.split(pattern, sentence.text):\n",
    "#                 if len(sent) != 0:\n",
    "#                     spacy_sentencized.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7002207",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_token_tags = [\n",
    "    tuple([token.text.strip().lower(), token.tag_])\n",
    "    for job_description in job_descriptions\n",
    "    for token in nlp(job_description)\n",
    "    if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c2309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nlp_token_tags'] = df_jobs['Job Description spacy_sentencized'].apply(\n",
    "    lambda job_sentence: [\n",
    "        tuple([token.text.strip().lower(), token.tag_])\n",
    "        for token in nlp(job_sentence)\n",
    "        \n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac855d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_lemmas = [\n",
    "    token.lemma_.strip().lower()\n",
    "    for job_description in job_descriptions\n",
    "    for token in nlp(job_description)\n",
    "    if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nlp_lemmas'] = df_jobs['Job Description spacy_sentencized'].apply(\n",
    "    lambda job_sentence: [\n",
    "        token.lemma_.strip().lower()\n",
    "        for token in nlp(job_sentence)\n",
    "        if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab24dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_stems = [\n",
    "    stemmer.stem(token.text.strip().lower())\n",
    "    for job_description in job_descriptions\n",
    "    for token in nlp(job_description)\n",
    "    if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ccde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nlp_stems'] = df_jobs['Job Description spacy_sentencized'].apply(\n",
    "    lambda job_sentence: [\n",
    "        stemmer.stem(token.text.strip().lower())\n",
    "        for token in nlp(job_sentence)\n",
    "        if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9beae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nlp_stems']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b610ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     nlp_token_tags = [\n",
    "#         tuple([token.text, token.tag_]) \n",
    "#         for job_description in job_descriptions \n",
    "#         for token in nlp(job_description) \n",
    "#         if len(token) != 0 \n",
    "#         and not token.is_stop \n",
    "#         and not token.is_punct \n",
    "#         and not token.text in custom_punct_chars\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_num_and_frequency(row, text_col):\n",
    "\n",
    "    row['Job Description num_words'] = len(str(row[f'{text_col}']).split())\n",
    "    row['Job Description num_unique_words'] = len(set(str(row[f'{text_col}']).split()))\n",
    "    row['Job Description num_chars'] = len(str(row[f'{text_col}']))\n",
    "    row['Job Description num_punctuations'] = len([c for c in str(row[f'{text_col}']) if c in string.punctuation])\n",
    "\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e640ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = df_jobs.apply(lambda row: get_word_num_and_frequency(row=row, text_col='Job Description spacy_sentencized'), axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sent in spacy_sentencized:\n",
    "#     num_words = len(sent.split())\n",
    "#     num_unique_words = len(set(sent.split()))\n",
    "#     num_chars = len(sent)\n",
    "#     num_punctuations = len([c for c in sent if c in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a2e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentim_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(df_jobs_to_be_processed, text_col, algo='vader', sentiment_range=(-1,1)):\n",
    "\n",
    "    ## calculate sentiment\n",
    "    if algo == 'vader':\n",
    "        df_jobs_to_be_processed['Sentiment'] = df_jobs_to_be_processed[text_col].apply(lambda x: sentim_analyzer.polarity_scores(x)['compound'] if isinstance(x, str) else np.nan)\n",
    "    elif algo == 'textblob':\n",
    "        df_jobs_to_be_processed['Sentiment'] = df_jobs_to_be_processed[text_col].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    ## rescaled\n",
    "    if sentiment_range != (-1,1):\n",
    "        df_jobs_to_be_processed['Sentiment'] = preprocessing.MinMaxScaler(feature_range=sentiment_range).fit_transform(df_jobs_to_be_processed[['sentiment']])\n",
    "    # print(df_jobs_to_be_processed[['sentiment']].describe().T)\n",
    "\n",
    "    return df_jobs_to_be_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a05fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b22b69a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purpose:\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "As a Manager Digital Strategy and Programs in adidas market ecom organization your task is to manage and deliver small digital projects, significant RFCs or sub-elements of mid-scale digital projects.\n",
      "Sentiment(polarity=0.025, subjectivity=0.255, assessments=[(['digital'], 0.0, 0.0, None), (['small'], -0.25, 0.4, None), (['digital'], 0.0, 0.0, None), (['significant'], 0.375, 0.875, None), (['digital'], 0.0, 0.0, None)])\n",
      "The project scope is on a local (market) level across brands and functions.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['local'], 0.0, 0.0, None)])\n",
      "Your objective is to conduct the projects within the boundaries of time, cost & quality while focusing on consumers' expectations and requirements.\n",
      "Sentiment(polarity=0.0, subjectivity=0.1, assessments=[(['objective'], 0.0, 0.1, None)])\n",
      "Planning, executing and tracking projects in cooperation with the respective functions and project team members are a few examples of what is expected from this role.\n",
      "Sentiment(polarity=-0.10000000000000002, subjectivity=0.20000000000000004, assessments=[(['respective'], 0.0, 0.1, None), (['few'], -0.2, 0.1, None), (['expected'], -0.1, 0.4, None)])\n",
      "Additionally, you will be focusing on resource management and coordination activities, acting as the central interface to local stakeholders.\n",
      "Sentiment(polarity=0.0, subjectivity=0.08333333333333333, assessments=[(['acting'], 0.0, 0.0, None), (['central'], 0.0, 0.25, None), (['local'], 0.0, 0.0, None)])\n",
      "Key Responsibilities\n",
      "Sentiment(polarity=0.0, subjectivity=1.0, assessments=[(['key'], 0.0, 1.0, None)])\n",
      ":Scope:\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Manage and deliver small digital projects on a local (market) level\n",
      "Sentiment(polarity=-0.08333333333333333, subjectivity=0.13333333333333333, assessments=[(['small'], -0.25, 0.4, None), (['digital'], 0.0, 0.0, None), (['local'], 0.0, 0.0, None)])\n",
      "Project  Program Delivery\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Deliver projects end-to-end successfully, ideally through effective application of PMI Agile methodology.\n",
      "Sentiment(polarity=0.6666666666666666, subjectivity=0.85, assessments=[(['successfully', 'ideally'], 0.9, 1.0, None), (['effective'], 0.6, 0.8, None), (['agile'], 0.5, 0.75, None)])\n",
      "Develop detailed plans that allow providing transparency on progress and identifying risks on time.\n",
      "Sentiment(polarity=0.4, subjectivity=0.75, assessments=[(['detailed'], 0.4, 0.75, None)])\n",
      "Identify interdependencies with other projects and solve issues proactively.\n",
      "Sentiment(polarity=-0.125, subjectivity=0.375, assessments=[(['other'], -0.125, 0.375, None)])\n",
      "Drive continuous improvement of products, processes or systems within the project scope.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Resource Planning\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Lead and manage team resources (internals and externals) to deliver and support projects & programs.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Communication\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Act as the key contact person for local stakeholders.\n",
      "Sentiment(polarity=0.0, subjectivity=0.5, assessments=[(['key'], 0.0, 1.0, None), (['local'], 0.0, 0.0, None)])\n",
      "Apply appropriate and effective communication methods to senior management and important stakeholders throughout the project lifecycle.\n",
      "Sentiment(polarity=0.5, subjectivity=0.7666666666666666, assessments=[(['appropriate'], 0.5, 0.5, None), (['effective'], 0.6, 0.8, None), (['important'], 0.4, 1.0, None)])\n",
      "As conflicts and escalations arise within projects, identify solutions and drive their resolution in a timely and appropriate manner.\n",
      "Sentiment(polarity=0.5, subjectivity=0.5, assessments=[(['appropriate'], 0.5, 0.5, None)])\n",
      "Manage change within projects and ensure changes are smoothly and successfully implemented to achieve lasting benefits.\n",
      "Sentiment(polarity=0.3833333333333333, subjectivity=0.48333333333333334, assessments=[(['smoothly'], 0.4, 0.5, None), (['successfully'], 0.75, 0.95, None), (['lasting'], 0.0, 0.0, None)])\n",
      "Project Controlling\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Manage project controlling as an independent element to ensure that actual project costs are in line the committed budget.\n",
      "Sentiment(polarity=0.0, subjectivity=0.1125, assessments=[(['independent'], 0.0, 0.125, None), (['actual'], 0.0, 0.1, None)])\n",
      "Conduct engagement reviews.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Verify compliance with quality assurance procedures.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Validate if project are delivering against program KPIs.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Monitor project variables (cost, effort, scope, et cetera) against plan in order to implement corrective or preventive actions.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "\"If required\" Responsibilities\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Agile Transformation\n",
      "Sentiment(polarity=0.5, subjectivity=0.75, assessments=[(['agile'], 0.5, 0.75, None)])\n",
      "Drive the implementation of elements of the transformation to full agile working mode and facilitate agile adoption.\n",
      "Sentiment(polarity=0.45, subjectivity=0.6833333333333332, assessments=[(['full'], 0.35, 0.55, None), (['agile'], 0.5, 0.75, None), (['agile'], 0.5, 0.75, None)])\n",
      "Contribute to developing and orchestrating the demand & delivery process within Global\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['global'], 0.0, 0.0, None)])\n",
      "Facilitate initial demand discussions.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['initial'], 0.0, 0.0, None)])\n",
      "Market Development\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Create business cases for your market with support from local global Analytics team to evaluate growth opportunities.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['local'], 0.0, 0.0, None), (['global'], 0.0, 0.0, None)])\n",
      "Implement the base platform capabilities, build by global, required to fulfill business cases, together with IT.\n",
      "Sentiment(polarity=-0.4, subjectivity=0.5, assessments=[(['base'], -0.8, 1.0, None), (['global'], 0.0, 0.0, None)])\n",
      "Key Relationships:\n",
      "Sentiment(polarity=0.0, subjectivity=1.0, assessments=[(['key'], 0.0, 1.0, None)])\n",
      "Leading Sr.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      " Project Manager or (Sr.)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Dir.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Digital Strategy & Programs\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['digital'], 0.0, 0.0, None)])\n",
      "Project Team\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Local Project Stakeholders\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['local'], 0.0, 0.0, None)])\n",
      "Global Digital\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['global'], 0.0, 0.0, None), (['digital'], 0.0, 0.0, None)])\n",
      "Global IT\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['global'], 0.0, 0.0, None)])\n",
      "Digital Sales Solutions\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['digital'], 0.0, 0.0, None)])\n",
      "Respective business functions (Ops, Finance, HR, Brand Marketing, Wholesale Retail)\n",
      "Sentiment(polarity=0.0, subjectivity=0.1, assessments=[(['respective'], 0.0, 0.1, None)])\n",
      "HR Management\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Controlling\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Education & Experience\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "University degree with focus on Business Administration, Communication or IT or related areas, or equivalent combination of education and experience\n",
      "Sentiment(polarity=0.0, subjectivity=0.4, assessments=[(['related'], 0.0, 0.4, None)])\n",
      "5+ years of in-depth professional experience related to project management or similar topics\n",
      "Sentiment(polarity=0.03333333333333333, subjectivity=0.3, assessments=[(['professional'], 0.1, 0.1, None), (['related'], 0.0, 0.4, None), (['similar'], 0.0, 0.4, None)])\n",
      "1-3 years of professional experience in the ecosystem environment of the project area in scope\n",
      "Sentiment(polarity=0.1, subjectivity=0.1, assessments=[(['professional'], 0.1, 0.1, None)])\n",
      "Proven market business acumen\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Experience in ecommerce is a plus\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Experience in Finance is a plus\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Experience working with stakeholders at various seniority levels as well as subject matter experts across various functions (Developers, business stakeholders, product and marketing teams, et cetera)\n",
      "Sentiment(polarity=-0.05555555555555555, subjectivity=0.4444444444444444, assessments=[(['various'], 0.0, 0.5, None), (['subject'], -0.16666666666666666, 0.3333333333333333, None), (['various'], 0.0, 0.5, None)])\n",
      "Knowledge Skills and Abilities\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Soft-Skills\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Good communication skills, especially when interacting with different levels of business\n",
      "Sentiment(polarity=0.2333333333333333, subjectivity=0.7333333333333334, assessments=[(['good'], 0.7, 0.6000000000000001, None), (['especially'], 0.0, 1.0, None), (['different'], 0.0, 0.6, None)])\n",
      "Ability to work in a fast-paced environment with different international cultures\n",
      "Sentiment(polarity=0.0, subjectivity=0.3, assessments=[(['different'], 0.0, 0.6, None), (['international'], 0.0, 0.0, None)])\n",
      "Solutions-oriented approach and entrepreneurial mindset\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Good numerical and analytical skills\n",
      "Sentiment(polarity=0.7, subjectivity=0.6000000000000001, assessments=[(['good'], 0.7, 0.6000000000000001, None)])\n",
      "Hard-Skills\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Strong MS-Office skills (Word, Excel, PowerPoint)\n",
      "Sentiment(polarity=0.4333333333333333, subjectivity=0.7333333333333333, assessments=[(['strong'], 0.4333333333333333, 0.7333333333333333, None)])\n",
      "Basic Experience and a broad understanding of IT\n",
      "Sentiment(polarity=0.03125, subjectivity=0.21875, assessments=[(['basic'], 0.0, 0.125, None), (['broad'], 0.0625, 0.3125, None)])\n",
      "Working knowledge of Agile working methods for example Scrum Kanban\n",
      "Sentiment(polarity=0.5, subjectivity=0.75, assessments=[(['agile'], 0.5, 0.75, None)])\n",
      "Working knowledge of PMI methods ideally with certification\n",
      "Sentiment(polarity=0.9, subjectivity=1.0, assessments=[(['ideally'], 0.9, 1.0, None)])\n",
      "Fluent English both verbally and written\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['english'], 0.0, 0.0, None)])\n",
      "Purpose\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "As a Studio A Director\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Special Projects\n",
      "Sentiment(polarity=0.35714285714285715, subjectivity=0.5714285714285714, assessments=[(['special'], 0.35714285714285715, 0.5714285714285714, None)])\n",
      "in adidas Digital your task is to manage and deliver Studio A programs including full projects roadmap.\n",
      "Sentiment(polarity=0.175, subjectivity=0.275, assessments=[(['digital'], 0.0, 0.0, None), (['full'], 0.35, 0.55, None)])\n",
      "The program scope may comprise multiple countries and functions.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['multiple'], 0.0, 0.0, None)])\n",
      "Your objective is to conduct the projects within the boundaries of time, cost & quality while focusing on consumers' expectations and requirements.\n",
      "Sentiment(polarity=0.0, subjectivity=0.1, assessments=[(['objective'], 0.0, 0.1, None)])\n",
      "Planning, executing and tracking projects & programs in cooperation with the respective functions and project team members are a few examples of what is expected from this role.\n",
      "Sentiment(polarity=-0.10000000000000002, subjectivity=0.20000000000000004, assessments=[(['respective'], 0.0, 0.1, None), (['few'], -0.2, 0.1, None), (['expected'], -0.1, 0.4, None)])\n",
      "Additionally, you will be focusing on resource planning, vendor management and coordination activities, acting as the central interface to key stakeholders.\n",
      "Sentiment(polarity=0.0, subjectivity=0.4166666666666667, assessments=[(['acting'], 0.0, 0.0, None), (['central'], 0.0, 0.25, None), (['key'], 0.0, 1.0, None)])\n",
      "Scope: Manage and deliver Studio\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "A programs including full projects roadmap.\n",
      "Sentiment(polarity=0.35, subjectivity=0.55, assessments=[(['full'], 0.35, 0.55, None)])\n",
      "Project  Program Delivery\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Manage the set up and roll out of the Studio A hubs (Portland, Shanghai, further locations).\n",
      "Sentiment(polarity=0.0, subjectivity=0.5, assessments=[(['further'], 0.0, 0.5, None)])\n",
      "Ensure clear operating and interaction models, processes and reporting frameworks\n",
      "Sentiment(polarity=0.10000000000000002, subjectivity=0.3833333333333333, assessments=[(['clear'], 0.10000000000000002, 0.3833333333333333, None)])\n",
      "Manage the strategic partnership with Oliver globally and in market\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['globally'], 0.0, 0.0, None)])\n",
      "Set up pilots for all new production topics ie Tier 1 elevated content and manage up until the point they can be moved into mass production at scale\n",
      "Sentiment(polarity=0.13636363636363635, subjectivity=0.45454545454545453, assessments=[(['new'], 0.13636363636363635, 0.45454545454545453, None)])\n",
      "Manage all top creator production requests ie Beyonce, Pharrell, et ceteraManage supporting system platforms\n",
      "Sentiment(polarity=0.375, subjectivity=0.375, assessments=[(['top'], 0.5, 0.5, None), (['supporting'], 0.25, 0.25, None)])\n",
      "Resource Planning\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Form, lead, manage and monitor multi-functional team resources (internals and externals) to deliver and support projects & programs.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Partner with Procurement in order to manage suppliers for the projects & programs in scope, for example interviews, staffing, supplier costs.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Communication   stakeholder management\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Act as the key contact person for strategic stakeholders.\n",
      "Sentiment(polarity=0.0, subjectivity=1.0, assessments=[(['key'], 0.0, 1.0, None)])\n",
      "Apply appropriate and effective communication methods to senior management and important stakeholders (including vendor) throughout the project lifecycle.\n",
      "Sentiment(polarity=0.5, subjectivity=0.7666666666666666, assessments=[(['appropriate'], 0.5, 0.5, None), (['effective'], 0.6, 0.8, None), (['important'], 0.4, 1.0, None)])\n",
      "As conflicts and escalations arise within projects, identify solutions and manage the resolution in a timely and appropriate manner.\n",
      "Sentiment(polarity=0.5, subjectivity=0.5, assessments=[(['appropriate'], 0.5, 0.5, None)])\n",
      "Drive change management activities for respective projects & programs and ensure changes are smoothly and successfully implemented to achieve lasting benefits.\n",
      "Sentiment(polarity=0.2875, subjectivity=0.38749999999999996, assessments=[(['respective'], 0.0, 0.1, None), (['smoothly'], 0.4, 0.5, None), (['successfully'], 0.75, 0.95, None), (['lasting'], 0.0, 0.0, None)])\n",
      "Project Controlling\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Manage project controlling as an independent element to ensure that actual project costs are in line the committed budget.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.1125, assessments=[(['independent'], 0.0, 0.125, None), (['actual'], 0.0, 0.1, None)])\n",
      "Lead or conduct engagement reviews.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Verify implementation of quality assurance procedures.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Ensure project & program delivery against program KPIs.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Monitor project & program variables (cost, effort, scope, et cetera) against plan in order to implement corrective or preventive actions.\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "People Management\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Ensure appropriate leadership skills are present at every level by creating a motivational and supportive work environment in which employees are coached, trained and provided with career opportunities through development.\n",
      "Sentiment(polarity=0.3333333333333333, subjectivity=0.5, assessments=[(['appropriate'], 0.5, 0.5, None), (['present'], 0.0, 0.0, None), (['supportive'], 0.5, 1.0, None)])\n",
      "Continuously monitor and evaluate team workload and organizational efficiency with the support of IT systems, data and analysis and team feedback and make appropriate changes in order to meet business needs.\n",
      "Sentiment(polarity=0.5, subjectivity=0.5, assessments=[(['appropriate'], 0.5, 0.5, None)])\n",
      "Provide team members direct reports with clear direction and targets that are aligned with business needs and Digital objectives.\n",
      "Sentiment(polarity=0.06666666666666667, subjectivity=0.2611111111111111, assessments=[(['direct'], 0.1, 0.4, None), (['clear'], 0.10000000000000002, 0.3833333333333333, None), (['digital'], 0.0, 0.0, None)])\n",
      "Key Relationships:\n",
      "Sentiment(polarity=0.0, subjectivity=1.0, assessments=[(['key'], 0.0, 1.0, None)])\n",
      "Studio A: Creative, Operations & Production, Content Strategy\n",
      "Sentiment(polarity=0.5, subjectivity=1.0, assessments=[(['creative'], 0.5, 1.0, None)])\n",
      "Digital Teams (Planning, Experience Design, Activation...)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['digital'], 0.0, 0.0, None)])\n",
      "Major Global Stakeholders (Global comms teams, Global operations, Brand Design...)\n",
      "Sentiment(polarity=0.015625, subjectivity=0.125, assessments=[(['major'], 0.0625, 0.5, None), (['global'], 0.0, 0.0, None), (['global'], 0.0, 0.0, None), (['global'], 0.0, 0.0, None)])\n",
      "Major Digital teams (Digital Planning, Growth, Digital Products, DTO...)\n",
      "Sentiment(polarity=0.015625, subjectivity=0.125, assessments=[(['major'], 0.0625, 0.5, None), (['digital'], 0.0, 0.0, None), (['digital'], 0.0, 0.0, None), (['digital'], 0.0, 0.0, None)])\n",
      "Respective business function (GOPS, Finance, HR, Brand Marketing, Wholesale Retail)\n",
      "Sentiment(polarity=0.0, subjectivity=0.1, assessments=[(['respective'], 0.0, 0.1, None)])\n",
      "Global IT\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['global'], 0.0, 0.0, None)])\n",
      "External studios & agencies\n",
      "Sentiment(polarity=0.0, subjectivity=0.1, assessments=[(['external'], 0.0, 0.1, None)])\n",
      "Procurement\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Requirements\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Education & Experience\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Ideally Master degree with focus on Business Administration, Communication or related areas, or equivalent combination of education and experience\n",
      "Sentiment(polarity=0.45, subjectivity=0.7, assessments=[(['ideally'], 0.9, 1.0, None), (['related'], 0.0, 0.4, None)])\n",
      "10+ years of in-depth experience related to project management or similar topics\n",
      "Sentiment(polarity=0.0, subjectivity=0.4, assessments=[(['related'], 0.0, 0.4, None), (['similar'], 0.0, 0.4, None)])\n",
      "6-8 years of professional experience in the digital ecosystem environment\n",
      "Sentiment(polarity=0.05, subjectivity=0.05, assessments=[(['professional'], 0.1, 0.1, None), (['digital'], 0.0, 0.0, None)])\n",
      "Experience in in-house studio roll-out\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Understanding of eCom image video copy mass production\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Experience in working with agencies and or consultancy is a plus\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Experience working with stakeholders at various seniority levels as well as subject matter experts across various functions (Developers, business stakeholders, product and marketing teams, et cetera)\n",
      "Sentiment(polarity=-0.05555555555555555, subjectivity=0.4444444444444444, assessments=[(['various'], 0.0, 0.5, None), (['subject'], -0.16666666666666666, 0.3333333333333333, None), (['various'], 0.0, 0.5, None)])\n",
      "3+ years of experience in leading a team\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Soft-Skills\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Very good communication skills, especially when interacting with different levels of business\n",
      "Sentiment(polarity=0.3033333333333333, subjectivity=0.7933333333333334, assessments=[(['very', 'good'], 0.9099999999999999, 0.7800000000000001, None), (['especially'], 0.0, 1.0, None), (['different'], 0.0, 0.6, None)])\n",
      "Ability to work in a fast-paced environment with different international cultures\n",
      "Sentiment(polarity=0.0, subjectivity=0.3, assessments=[(['different'], 0.0, 0.6, None), (['international'], 0.0, 0.0, None)])\n",
      "Ability to handle ambiguity and untangle complex situations into actionable activities\n",
      "Sentiment(polarity=-0.3, subjectivity=0.4, assessments=[(['complex'], -0.3, 0.4, None)])\n",
      "Distinctive strategic mindset and ability to prioritize and delegate high numbers of tasks with varying workload and importance\n",
      "Sentiment(polarity=0.16, subjectivity=0.5399999999999999, assessments=[(['high'], 0.16, 0.5399999999999999, None)])\n",
      "Solutions-oriented approach and entrepreneurial mindset\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Good numerical and analytical skills\n",
      "Sentiment(polarity=0.7, subjectivity=0.6000000000000001, assessments=[(['good'], 0.7, 0.6000000000000001, None)])\n",
      "Highly developed leadership skills are required\n",
      "Sentiment(polarity=0.1, subjectivity=0.3, assessments=[(['highly', 'developed'], 0.1, 0.3, None)])\n",
      "Hard-Skills\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Knowledge of digital technologies and communications platforms and culture\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['digital'], 0.0, 0.0, None)])\n",
      "Strong MS-Office skills (Word, Excel, PowerPoint)\n",
      "Sentiment(polarity=0.4333333333333333, subjectivity=0.7333333333333333, assessments=[(['strong'], 0.4333333333333333, 0.7333333333333333, None)])\n",
      "Ability to travel, domestic or international, as required\n",
      "Sentiment(polarity=0.0, subjectivity=0.05, assessments=[(['domestic'], 0.0, 0.1, None), (['international'], 0.0, 0.0, None)])\n",
      "In-depth understanding of IT\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Fluent English both verbally and written\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[(['english'], 0.0, 0.0, None)])\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "# nlp.add_pipe('spacytextblob')\n",
    "sentiment = []\n",
    "for job_sentence in spacy_sentencized:\n",
    "    sentiment.append(nlp(job_sentence)._.blob.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06baee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = [\n",
    "    float(nlp(job_sentence)._.blob.polarity)\n",
    "    for job_sentence in spacy_sentencized\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f0e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description spacy_sentiment'] = df_jobs['Job Description spacy_sentencized'].apply(\n",
    "    lambda sentence: float(nlp(sentence)._.blob.polarity)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84363ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentim_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "df_jobs['Job Description nltk_sentiment'] = df_jobs['Job Description spacy_sentencized'].apply(\n",
    "    lambda sentence: float(sentim_analyzer.polarity_scores(sentence)['compound'])\n",
    "    if isinstance(sentence, str) else np.nan\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1031bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description nltk_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a0f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = get_sentiment(df_jobs, text_col='Job Description spacy_sentencized')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb854ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "for sent in spacy_sentencized:\n",
    "    print(vader.polarity_scores(sent)['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sentiment\n",
    "# from textblob import TextBlob, Word\n",
    "\n",
    "# for sent in spacy_sentencized:\n",
    "#     print(TextBlob(sent).sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Tokenizer\n",
    "from transformers import BertTokenizer, AutoTokenizer, BertForPreTraining, BertConfig, BertModel\n",
    "\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name, strip_accents = True)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "df_jobs['bert_tokenized'] = df_jobs['Job Description spacy_sentencized'].apply(lambda sentence: bert_tokenizer.tokenize(str(sentence)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f80932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['bert_tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import ENGLISH_CONNECTOR_WORDS, Phraser, Phrases\n",
    "\n",
    "# Bigrams\n",
    "bigram = Phraser(Phrases(df_jobs['Job Description spacy_tokenized'], connector_words=ENGLISH_CONNECTOR_WORDS, min_count=1, threshold=1))\n",
    "df_jobs['Job Description gensim_2garms'] = bigram[df_jobs['Job Description spacy_tokenized']]\n",
    "\n",
    "# Trigrams\n",
    "trigram = Phraser(Phrases(bigram_sentences, connector_words=ENGLISH_CONNECTOR_WORDS, min_count=1, threshold=1))\n",
    "df_jobs['Job Description gensim_3garms'] = trigram[bigram_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5299f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description gensim_3garms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85689ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_jobs['Job Description gensim_3garms'].items():\n",
    "    for token in row:\n",
    "        if '_' in token:\n",
    "            if re.search('_([^_]+)_', token):\n",
    "                print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b774b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_sentences = ''\n",
    "for token in spacy_tokenized:\n",
    "    spacy_sentences+= token + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81cfb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_sentences = [spacy_sentences.strip().lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90ca9067",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.span.Span' object has no attribute 'merge_noun_chunks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m job_sentence \u001b[38;5;129;01min\u001b[39;00m spacy_sentences:\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     print(job_sentence)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m noun_phrase \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(nlp(job_sentence)\u001b[38;5;241m.\u001b[39mnoun_chunks):\n\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[43mnoun_phrase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_noun_chunks\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#         print(noun_phrase.merge(noun_phrase.root.tag_, noun_phrase.root.lemma_, noun_phrase.root.ent_type_))\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#         if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars:\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#             spacy_tokenized.append(token.text)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.span.Span' object has no attribute 'merge_noun_chunks'"
     ]
    }
   ],
   "source": [
    "spacy_bigrams = []\n",
    "\n",
    "for job_sentence in spacy_sentences:\n",
    "#     print(job_sentence)\n",
    "    for noun_phrase in list(nlp(job_sentence).noun_chunks):\n",
    "        print(noun_phrase.merge_noun_chunks)\n",
    "#         print(noun_phrase.merge(noun_phrase.root.tag_, noun_phrase.root.lemma_, noun_phrase.root.ent_type_))\n",
    "#         if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars:\n",
    "#             spacy_tokenized.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a93ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huggingface_similarity(sentences, bert_model):\n",
    "\n",
    "    embeddings = bert_model.encode(sentences, show_progress_bar=True)\n",
    "    cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "    #Sort list by the highest cosine similarity score\n",
    "    all_sentence_combinations = sorted([[cos_sim[i][j], i, j] for i in range(len(cos_sim)-1) for j in range(i+1, len(cos_sim))], key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    if args['print_enabled'] is True:\n",
    "        print('Top-5 most similar pairs:')\n",
    "        for score, i, j in all_sentence_combinations[:5]:\n",
    "            print(f'{sentences[i]} \\t {sentences[j]} \\t {cos_sim[i][j]:.4f}')\n",
    "\n",
    "    if args['save_enabled'] is True:\n",
    "        bert_model.to_json_file('bert_config.json')\n",
    "\n",
    "    return all_sentence_combinations, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b58b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentences in spacy_sentencized:\n",
    "    print(bert_tokenizer.encode_plus(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c2e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "model = BertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d2e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7590d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls(\n",
    "    BertModel.from_pretrained(\n",
    "        bert_model_name,\n",
    "        output_attentions=True,\n",
    "        output_hidden_states=True,\n",
    "        output_additional_info=True,\n",
    "    ),\n",
    "    BertAligner.from_pretrained(bert_model_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy sentencizer\n",
    "# spacy_sentencized = []\n",
    "\n",
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    for job_description in job_descriptions:\n",
    "        for token in nlp(job_description):\n",
    "            print(token.text, token.tag_)\n",
    "#             for sent in re.split(pattern, sentence.text):\n",
    "#                 if len(sent) != 0:\n",
    "#                     spacy_sentencized.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "526da0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "bigram_patterns = [\n",
    "    ['VERB', 'ADJ', 'NOUN'],\n",
    "    ['NOUN', 'VERB', 'ADV'],\n",
    "    ['NOUN', 'ADP', 'NOUN'],\n",
    "    # more rules here...\n",
    "]\n",
    "\n",
    "rules = [\n",
    "    ['VERB', 'ADJ', 'NOUN'],\n",
    "    ['NOUN', 'VERB', 'ADV'],\n",
    "    ['NOUN', 'ADP', 'NOUN'],\n",
    "    # more rules here...\n",
    "]\n",
    "\n",
    "trigram_patterns = [[{\"POS\": i} for i in j] for j in rules]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fa22c7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'POS': 'VERB'}, {'POS': 'ADJ'}, {'POS': 'NOUN'}],\n",
       " [{'POS': 'NOUN'}, {'POS': 'VERB'}, {'POS': 'ADV'}],\n",
       " [{'POS': 'NOUN'}, {'POS': 'ADP'}, {'POS': 'NOUN'}]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2de96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_patterns = {\n",
    "    'noun_verb': [{'POS': 'NOUN'}, {'POS': 'VERB'}],\n",
    "    'verb_noun': [{'POS': 'VERB'}, {'POS': 'NOUN'}],\n",
    "    'adj_noun': [{'POS': 'ADJ'}, {'POS': 'NOUN'}],\n",
    "    'adj_propn': [{'POS': 'ADJ'}, {'POS': 'PROPN'}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern_name, pattern in patterns.items():\n",
    "    matcher.add(pattern_name, [pattern])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e002bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_description in job_descriptions:\n",
    "    doc = nlp(job_description)\n",
    "    matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e6da13c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/46/q15p556n1dd63z6gkwyh896c0000gn/T/ipykernel_12428/2603420453.py:4: UserWarning: [W036] The component 'matcher' does not have any patterns defined.\n",
      "  for _, start, end in matcher(nlp(job_description))\n"
     ]
    }
   ],
   "source": [
    "for job_description in job_descriptions:\n",
    "    spacy_bigrams = [\n",
    "        nlp(job_description)[start:end].text\n",
    "        for _, start, end in matcher(nlp(job_description))\n",
    "\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_id, start, end in matches:\n",
    "    \n",
    "    # Get string representation\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "\n",
    "    # The matched span\n",
    "    span = doc[start:end]\n",
    "    \n",
    "    print(repr(span.text))\n",
    "    print(match_id, string_id, start, end)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e73cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6595ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence in spacy_sentencized:\n",
    "#     print(model.encode(sentence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.electra.modeling_tf_electra import TFElectraMainLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pavanchhatpar/electra-base-sentence-splitter\")\n",
    "\n",
    "model = AutoModelForPreTraining.from_pretrained(\"pavanchhatpar/electra-base-sentence-splitter\", from_tf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ee3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline('sentence-splitter', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8d4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "study1_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
