{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7d3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189dea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "# columns\n",
    "cols=['Sector', \n",
    "      'Sector Code', \n",
    "      'Gender', \n",
    "      'Age', \n",
    "      'Language', \n",
    "      'Dutch Requirement', \n",
    "      'English Requirement', \n",
    "      'Gender_Female', \n",
    "      'Gender_Mixed', \n",
    "      'Gender_Male', \n",
    "      'Age_Older', \n",
    "      'Age_Mixed', \n",
    "      'Age_Younger', \n",
    "      'Gender_Num', \n",
    "      'Age_Num', \n",
    "      '% Female', \n",
    "      '% Male', \n",
    "      '% Older', \n",
    "      '% Younger']\n",
    "\n",
    "int_variable: str = 'Job ID'\n",
    "str_variable: str = 'Job Description'\n",
    "gender: str = 'Gender'\n",
    "age: str = 'Age'\n",
    "language: str = 'en'\n",
    "str_cols = ['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name', 'Location', 'Job Description', 'Company URL', 'Job URL', 'Tracking ID']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21414866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pygwalker as pyg\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tag import pos_tag, pos_tag_sents\n",
    "from spacy.pipeline import Sentencizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c22dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw_dropped.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8818717b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62577"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "523b4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].apply(\n",
    "    lambda job_description: ' '.join(job_description.split('/')) if '/' in job_description else job_description\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3727334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abb_dict = {\n",
    "    r'incl\\.': 'including', \n",
    "    r'e\\.g\\.': 'for example', \n",
    "    r'e\\.g': 'for example', \n",
    "    r'etc\\.': 'et cetera', \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a22cc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_fix_incl = 'Apply appropriate and effective communication methods to senior management and important stakeholders'\n",
    "str_fix_eg = 'Partner with Procurement in order to manage suppliers for the projects & programs in scope'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2fd4414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Description'] = df_jobs['Job Description'].replace(abb_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7159677a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35      Purpose\\n\\nAs a Studio A Director\\n\\nSpecial P...\n",
       "3423    Purpose:\\nAs a Manager Digital Strategy and Pr...\n",
       "Name: Job Description, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs['Job Description'][df_jobs['Job Description'].str.contains(str_fix_incl)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db1a3934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Partner with Procurement in order to manage suppliers for the projects & programs in scope']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(str_fix_eg, df_jobs['Job Description'][35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "952299c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(1461, 1551), match='Partner with Procurement in order to manage suppl>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(re.finditer(str_fix_eg, df_jobs['Job Description'][35]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d35af326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Partner with Procurement in order to manage suppliers for the projects & programs in scope, for example interviews, sta'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs['Job Description'][35][1461:1580]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd40a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].apply(\n",
    "#     lambda job_description: job_description.replace('incl.', 'including')\n",
    "# )\n",
    "\n",
    "# df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].apply(\n",
    "#     lambda job_description: job_description.replace('e.g.', 'e.g')\n",
    "# )\n",
    "\n",
    "# df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].apply(\n",
    "#     lambda job_description: job_description.replace('e.g', 'for example')\n",
    "# )\n",
    "\n",
    "# df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].apply(\n",
    "#     lambda job_description: job_description.replace('etc.', 'et cetera')\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15d45507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = df_jobs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1039d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = df_jobs.sample(n=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7b23278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw_glob_paths_10.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9c9ce03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62577 entries, 0 to 62576\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Search Keyword     62577 non-null  object \n",
      " 1   Platform           62577 non-null  object \n",
      " 2   Job ID             62577 non-null  object \n",
      " 3   Job Title          62577 non-null  object \n",
      " 4   Company Name       62574 non-null  object \n",
      " 5   Location           62577 non-null  object \n",
      " 6   Job Description    62577 non-null  object \n",
      " 7   Rating             3975 non-null   float64\n",
      " 8   Employment Type    61995 non-null  object \n",
      " 9   Company URL        59263 non-null  object \n",
      " 10  Job URL            62577 non-null  object \n",
      " 11  Job Age            62577 non-null  object \n",
      " 12  Job Age Number     62577 non-null  object \n",
      " 13  Collection Date    62577 non-null  object \n",
      " 14  Data Row           58599 non-null  float64\n",
      " 15  Tracking ID        58599 non-null  object \n",
      " 16  Industry           59184 non-null  object \n",
      " 17  Job Date           58602 non-null  object \n",
      " 18  Type of ownership  582 non-null    object \n",
      "dtypes: float64(2), object(17)\n",
      "memory usage: 9.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fee089f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name',\n",
       "       'Location', 'Job Description', 'Rating', 'Employment Type',\n",
       "       'Company URL', 'Job URL', 'Job Age', 'Job Age Number',\n",
       "       'Collection Date', 'Data Row', 'Tracking ID', 'Industry', 'Job Date',\n",
       "       'Type of ownership'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9884dfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_jobs.loc[(df_jobs['Job Description'].str.contains(str_fix_incl)) | (df_jobs['Job Description'].str.contains(str_fix_eg))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e556d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_descriptions = list(set(df_jobs['Job Description'].to_list()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9da09d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descriptions = list(\n",
    "    set(\n",
    "        df_jobs['Job Description'].loc[\n",
    "            (df_jobs['Job Description'].str.contains(str_fix_incl)) |\n",
    "            (df_jobs['Job Description'].str.contains(str_fix_eg))\n",
    "        ].to_list()\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0de4de75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87f15f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and important stakeholders throughout the project lifecycle.\\nAs conflicts and escalations arise within projects, identify solutions and drive their resolution in a timely and appropriate manner.\\nManage change within projects and ensure changes are smoothly and successfully implemented to achieve lasting benefits.\\nProject Controlling\\nManage project controlling as an independent element to ensure that actual project costs are in line the committed budget.\\nConduct engagement reviews. Verify complia'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_descriptions[0][1500:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c008f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import save_as_line_sentence, simple_preprocess\n",
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string, preprocess_documents\n",
    "\n",
    "simple_tokenization = preprocess_documents(job_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f3092d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['purpos',\n",
       "  'manag',\n",
       "  'digit',\n",
       "  'strategi',\n",
       "  'program',\n",
       "  'adida',\n",
       "  'market',\n",
       "  'ecom',\n",
       "  'organ',\n",
       "  'task',\n",
       "  'manag',\n",
       "  'deliv',\n",
       "  'small',\n",
       "  'digit',\n",
       "  'project',\n",
       "  'signific',\n",
       "  'rfc',\n",
       "  'sub',\n",
       "  'element',\n",
       "  'mid',\n",
       "  'scale',\n",
       "  'digit',\n",
       "  'project',\n",
       "  'project',\n",
       "  'scope',\n",
       "  'local',\n",
       "  'market',\n",
       "  'level',\n",
       "  'brand',\n",
       "  'function',\n",
       "  'object',\n",
       "  'conduct',\n",
       "  'project',\n",
       "  'boundari',\n",
       "  'time',\n",
       "  'cost',\n",
       "  'qualiti',\n",
       "  'focus',\n",
       "  'consum',\n",
       "  'expect',\n",
       "  'requir',\n",
       "  'plan',\n",
       "  'execut',\n",
       "  'track',\n",
       "  'project',\n",
       "  'cooper',\n",
       "  'respect',\n",
       "  'function',\n",
       "  'project',\n",
       "  'team',\n",
       "  'member',\n",
       "  'exampl',\n",
       "  'expect',\n",
       "  'role',\n",
       "  'addition',\n",
       "  'focus',\n",
       "  'resourc',\n",
       "  'manag',\n",
       "  'coordin',\n",
       "  'activ',\n",
       "  'act',\n",
       "  'central',\n",
       "  'interfac',\n",
       "  'local',\n",
       "  'stakehold',\n",
       "  'kei',\n",
       "  'respons',\n",
       "  'scope',\n",
       "  'manag',\n",
       "  'deliv',\n",
       "  'small',\n",
       "  'digit',\n",
       "  'project',\n",
       "  'local',\n",
       "  'market',\n",
       "  'level',\n",
       "  'project',\n",
       "  'program',\n",
       "  'deliveri',\n",
       "  'deliv',\n",
       "  'project',\n",
       "  'end',\n",
       "  'end',\n",
       "  'successfulli',\n",
       "  'ideal',\n",
       "  'effect',\n",
       "  'applic',\n",
       "  'pmi',\n",
       "  'agil',\n",
       "  'methodolog',\n",
       "  'develop',\n",
       "  'detail',\n",
       "  'plan',\n",
       "  'allow',\n",
       "  'provid',\n",
       "  'transpar',\n",
       "  'progress',\n",
       "  'identifi',\n",
       "  'risk',\n",
       "  'time',\n",
       "  'identifi',\n",
       "  'interdepend',\n",
       "  'project',\n",
       "  'solv',\n",
       "  'issu',\n",
       "  'proactiv',\n",
       "  'drive',\n",
       "  'continu',\n",
       "  'improv',\n",
       "  'product',\n",
       "  'process',\n",
       "  'system',\n",
       "  'project',\n",
       "  'scope',\n",
       "  'resourc',\n",
       "  'plan',\n",
       "  'lead',\n",
       "  'manag',\n",
       "  'team',\n",
       "  'resourc',\n",
       "  'intern',\n",
       "  'extern',\n",
       "  'deliv',\n",
       "  'support',\n",
       "  'project',\n",
       "  'program',\n",
       "  'commun',\n",
       "  'act',\n",
       "  'kei',\n",
       "  'contact',\n",
       "  'person',\n",
       "  'local',\n",
       "  'stakehold',\n",
       "  'appli',\n",
       "  'appropri',\n",
       "  'effect',\n",
       "  'commun',\n",
       "  'method',\n",
       "  'senior',\n",
       "  'manag',\n",
       "  'import',\n",
       "  'stakehold',\n",
       "  'project',\n",
       "  'lifecycl',\n",
       "  'conflict',\n",
       "  'escal',\n",
       "  'aris',\n",
       "  'project',\n",
       "  'identifi',\n",
       "  'solut',\n",
       "  'drive',\n",
       "  'resolut',\n",
       "  'time',\n",
       "  'appropri',\n",
       "  'manner',\n",
       "  'manag',\n",
       "  'chang',\n",
       "  'project',\n",
       "  'ensur',\n",
       "  'chang',\n",
       "  'smoothli',\n",
       "  'successfulli',\n",
       "  'implement',\n",
       "  'achiev',\n",
       "  'last',\n",
       "  'benefit',\n",
       "  'project',\n",
       "  'control',\n",
       "  'manag',\n",
       "  'project',\n",
       "  'control',\n",
       "  'independ',\n",
       "  'element',\n",
       "  'ensur',\n",
       "  'actual',\n",
       "  'project',\n",
       "  'cost',\n",
       "  'line',\n",
       "  'commit',\n",
       "  'budget',\n",
       "  'conduct',\n",
       "  'engag',\n",
       "  'review',\n",
       "  'verifi',\n",
       "  'complianc',\n",
       "  'qualiti',\n",
       "  'assur',\n",
       "  'procedur',\n",
       "  'valid',\n",
       "  'project',\n",
       "  'deliv',\n",
       "  'program',\n",
       "  'kpi',\n",
       "  'monitor',\n",
       "  'project',\n",
       "  'variabl',\n",
       "  'cost',\n",
       "  'effort',\n",
       "  'scope',\n",
       "  'cetera',\n",
       "  'plan',\n",
       "  'order',\n",
       "  'implement',\n",
       "  'correct',\n",
       "  'prevent',\n",
       "  'action',\n",
       "  'requir',\n",
       "  'respons',\n",
       "  'agil',\n",
       "  'transform',\n",
       "  'drive',\n",
       "  'implement',\n",
       "  'element',\n",
       "  'transform',\n",
       "  'agil',\n",
       "  'work',\n",
       "  'mode',\n",
       "  'facilit',\n",
       "  'agil',\n",
       "  'adopt',\n",
       "  'contribut',\n",
       "  'develop',\n",
       "  'orchestr',\n",
       "  'demand',\n",
       "  'deliveri',\n",
       "  'process',\n",
       "  'global',\n",
       "  'facilit',\n",
       "  'initi',\n",
       "  'demand',\n",
       "  'discuss',\n",
       "  'market',\n",
       "  'develop',\n",
       "  'creat',\n",
       "  'busi',\n",
       "  'case',\n",
       "  'market',\n",
       "  'support',\n",
       "  'local',\n",
       "  'global',\n",
       "  'analyt',\n",
       "  'team',\n",
       "  'evalu',\n",
       "  'growth',\n",
       "  'opportun',\n",
       "  'implement',\n",
       "  'base',\n",
       "  'platform',\n",
       "  'capabl',\n",
       "  'build',\n",
       "  'global',\n",
       "  'requir',\n",
       "  'fulfil',\n",
       "  'busi',\n",
       "  'case',\n",
       "  'kei',\n",
       "  'relationship',\n",
       "  'lead',\n",
       "  'project',\n",
       "  'manag',\n",
       "  'dir',\n",
       "  'digit',\n",
       "  'strategi',\n",
       "  'program',\n",
       "  'project',\n",
       "  'team',\n",
       "  'local',\n",
       "  'project',\n",
       "  'stakehold',\n",
       "  'global',\n",
       "  'digit',\n",
       "  'global',\n",
       "  'digit',\n",
       "  'sale',\n",
       "  'solut',\n",
       "  'respect',\n",
       "  'busi',\n",
       "  'function',\n",
       "  'op',\n",
       "  'financ',\n",
       "  'brand',\n",
       "  'market',\n",
       "  'wholesal',\n",
       "  'retail',\n",
       "  'manag',\n",
       "  'control',\n",
       "  'educ',\n",
       "  'experi',\n",
       "  'univers',\n",
       "  'degre',\n",
       "  'focu',\n",
       "  'busi',\n",
       "  'administr',\n",
       "  'commun',\n",
       "  'relat',\n",
       "  'area',\n",
       "  'equival',\n",
       "  'combin',\n",
       "  'educ',\n",
       "  'experi',\n",
       "  'year',\n",
       "  'depth',\n",
       "  'profession',\n",
       "  'experi',\n",
       "  'relat',\n",
       "  'project',\n",
       "  'manag',\n",
       "  'similar',\n",
       "  'topic',\n",
       "  'year',\n",
       "  'profession',\n",
       "  'experi',\n",
       "  'ecosystem',\n",
       "  'environ',\n",
       "  'project',\n",
       "  'area',\n",
       "  'scope',\n",
       "  'proven',\n",
       "  'market',\n",
       "  'busi',\n",
       "  'acumen',\n",
       "  'experi',\n",
       "  'ecommerc',\n",
       "  'plu',\n",
       "  'experi',\n",
       "  'financ',\n",
       "  'plu',\n",
       "  'experi',\n",
       "  'work',\n",
       "  'stakehold',\n",
       "  'senior',\n",
       "  'level',\n",
       "  'subject',\n",
       "  'matter',\n",
       "  'expert',\n",
       "  'function',\n",
       "  'develop',\n",
       "  'busi',\n",
       "  'stakehold',\n",
       "  'product',\n",
       "  'market',\n",
       "  'team',\n",
       "  'cetera',\n",
       "  'knowledg',\n",
       "  'skill',\n",
       "  'abil',\n",
       "  'soft',\n",
       "  'skill',\n",
       "  'good',\n",
       "  'commun',\n",
       "  'skill',\n",
       "  'especi',\n",
       "  'interact',\n",
       "  'differ',\n",
       "  'level',\n",
       "  'busi',\n",
       "  'abil',\n",
       "  'work',\n",
       "  'fast',\n",
       "  'pace',\n",
       "  'environ',\n",
       "  'differ',\n",
       "  'intern',\n",
       "  'cultur',\n",
       "  'solut',\n",
       "  'orient',\n",
       "  'approach',\n",
       "  'entrepreneuri',\n",
       "  'mindset',\n",
       "  'good',\n",
       "  'numer',\n",
       "  'analyt',\n",
       "  'skill',\n",
       "  'hard',\n",
       "  'skill',\n",
       "  'strong',\n",
       "  'offic',\n",
       "  'skill',\n",
       "  'word',\n",
       "  'excel',\n",
       "  'powerpoint',\n",
       "  'basic',\n",
       "  'experi',\n",
       "  'broad',\n",
       "  'understand',\n",
       "  'work',\n",
       "  'knowledg',\n",
       "  'agil',\n",
       "  'work',\n",
       "  'method',\n",
       "  'exampl',\n",
       "  'scrum',\n",
       "  'kanban',\n",
       "  'work',\n",
       "  'knowledg',\n",
       "  'pmi',\n",
       "  'method',\n",
       "  'ideal',\n",
       "  'certif',\n",
       "  'fluent',\n",
       "  'english',\n",
       "  'verbal',\n",
       "  'written'],\n",
       " ['purpos',\n",
       "  'studio',\n",
       "  'director',\n",
       "  'special',\n",
       "  'project',\n",
       "  'adida',\n",
       "  'digit',\n",
       "  'task',\n",
       "  'manag',\n",
       "  'deliv',\n",
       "  'studio',\n",
       "  'program',\n",
       "  'includ',\n",
       "  'project',\n",
       "  'roadmap',\n",
       "  'program',\n",
       "  'scope',\n",
       "  'compris',\n",
       "  'multipl',\n",
       "  'countri',\n",
       "  'function',\n",
       "  'object',\n",
       "  'conduct',\n",
       "  'project',\n",
       "  'boundari',\n",
       "  'time',\n",
       "  'cost',\n",
       "  'qualiti',\n",
       "  'focus',\n",
       "  'consum',\n",
       "  'expect',\n",
       "  'requir',\n",
       "  'plan',\n",
       "  'execut',\n",
       "  'track',\n",
       "  'project',\n",
       "  'program',\n",
       "  'cooper',\n",
       "  'respect',\n",
       "  'function',\n",
       "  'project',\n",
       "  'team',\n",
       "  'member',\n",
       "  'exampl',\n",
       "  'expect',\n",
       "  'role',\n",
       "  'addition',\n",
       "  'focus',\n",
       "  'resourc',\n",
       "  'plan',\n",
       "  'vendor',\n",
       "  'manag',\n",
       "  'coordin',\n",
       "  'activ',\n",
       "  'act',\n",
       "  'central',\n",
       "  'interfac',\n",
       "  'kei',\n",
       "  'stakehold',\n",
       "  'scope',\n",
       "  'manag',\n",
       "  'deliv',\n",
       "  'studio',\n",
       "  'program',\n",
       "  'includ',\n",
       "  'project',\n",
       "  'roadmap',\n",
       "  'project',\n",
       "  'program',\n",
       "  'deliveri',\n",
       "  'manag',\n",
       "  'set',\n",
       "  'roll',\n",
       "  'studio',\n",
       "  'hub',\n",
       "  'portland',\n",
       "  'shanghai',\n",
       "  'locat',\n",
       "  'ensur',\n",
       "  'clear',\n",
       "  'oper',\n",
       "  'interact',\n",
       "  'model',\n",
       "  'process',\n",
       "  'report',\n",
       "  'framework',\n",
       "  'manag',\n",
       "  'strateg',\n",
       "  'partnership',\n",
       "  'oliv',\n",
       "  'global',\n",
       "  'market',\n",
       "  'set',\n",
       "  'pilot',\n",
       "  'new',\n",
       "  'product',\n",
       "  'topic',\n",
       "  'tier',\n",
       "  'elev',\n",
       "  'content',\n",
       "  'manag',\n",
       "  'point',\n",
       "  'move',\n",
       "  'mass',\n",
       "  'product',\n",
       "  'scale',\n",
       "  'manag',\n",
       "  'creator',\n",
       "  'product',\n",
       "  'request',\n",
       "  'beyonc',\n",
       "  'pharrel',\n",
       "  'ceteramanag',\n",
       "  'support',\n",
       "  'platform',\n",
       "  'resourc',\n",
       "  'plan',\n",
       "  'form',\n",
       "  'lead',\n",
       "  'manag',\n",
       "  'monitor',\n",
       "  'multi',\n",
       "  'function',\n",
       "  'team',\n",
       "  'resourc',\n",
       "  'intern',\n",
       "  'extern',\n",
       "  'deliv',\n",
       "  'support',\n",
       "  'project',\n",
       "  'program',\n",
       "  'partner',\n",
       "  'procur',\n",
       "  'order',\n",
       "  'manag',\n",
       "  'supplier',\n",
       "  'project',\n",
       "  'program',\n",
       "  'scope',\n",
       "  'exampl',\n",
       "  'interview',\n",
       "  'staf',\n",
       "  'supplier',\n",
       "  'cost',\n",
       "  'commun',\n",
       "  'stakehold',\n",
       "  'manag',\n",
       "  'act',\n",
       "  'kei',\n",
       "  'contact',\n",
       "  'person',\n",
       "  'strateg',\n",
       "  'stakehold',\n",
       "  'appli',\n",
       "  'appropri',\n",
       "  'effect',\n",
       "  'commun',\n",
       "  'method',\n",
       "  'senior',\n",
       "  'manag',\n",
       "  'import',\n",
       "  'stakehold',\n",
       "  'includ',\n",
       "  'vendor',\n",
       "  'project',\n",
       "  'lifecycl',\n",
       "  'conflict',\n",
       "  'escal',\n",
       "  'aris',\n",
       "  'project',\n",
       "  'identifi',\n",
       "  'solut',\n",
       "  'manag',\n",
       "  'resolut',\n",
       "  'time',\n",
       "  'appropri',\n",
       "  'manner',\n",
       "  'drive',\n",
       "  'chang',\n",
       "  'manag',\n",
       "  'activ',\n",
       "  'respect',\n",
       "  'project',\n",
       "  'program',\n",
       "  'ensur',\n",
       "  'chang',\n",
       "  'smoothli',\n",
       "  'successfulli',\n",
       "  'implement',\n",
       "  'achiev',\n",
       "  'last',\n",
       "  'benefit',\n",
       "  'project',\n",
       "  'control',\n",
       "  'manag',\n",
       "  'project',\n",
       "  'control',\n",
       "  'independ',\n",
       "  'element',\n",
       "  'ensur',\n",
       "  'actual',\n",
       "  'project',\n",
       "  'cost',\n",
       "  'line',\n",
       "  'commit',\n",
       "  'budget',\n",
       "  'lead',\n",
       "  'conduct',\n",
       "  'engag',\n",
       "  'review',\n",
       "  'verifi',\n",
       "  'implement',\n",
       "  'qualiti',\n",
       "  'assur',\n",
       "  'procedur',\n",
       "  'ensur',\n",
       "  'project',\n",
       "  'program',\n",
       "  'deliveri',\n",
       "  'program',\n",
       "  'kpi',\n",
       "  'monitor',\n",
       "  'project',\n",
       "  'program',\n",
       "  'variabl',\n",
       "  'cost',\n",
       "  'effort',\n",
       "  'scope',\n",
       "  'cetera',\n",
       "  'plan',\n",
       "  'order',\n",
       "  'implement',\n",
       "  'correct',\n",
       "  'prevent',\n",
       "  'action',\n",
       "  'peopl',\n",
       "  'manag',\n",
       "  'ensur',\n",
       "  'appropri',\n",
       "  'leadership',\n",
       "  'skill',\n",
       "  'present',\n",
       "  'level',\n",
       "  'creat',\n",
       "  'motiv',\n",
       "  'support',\n",
       "  'work',\n",
       "  'environ',\n",
       "  'employe',\n",
       "  'coach',\n",
       "  'train',\n",
       "  'provid',\n",
       "  'career',\n",
       "  'opportun',\n",
       "  'develop',\n",
       "  'continu',\n",
       "  'monitor',\n",
       "  'evalu',\n",
       "  'team',\n",
       "  'workload',\n",
       "  'organiz',\n",
       "  'effici',\n",
       "  'support',\n",
       "  'system',\n",
       "  'data',\n",
       "  'analysi',\n",
       "  'team',\n",
       "  'feedback',\n",
       "  'appropri',\n",
       "  'chang',\n",
       "  'order',\n",
       "  'meet',\n",
       "  'busi',\n",
       "  'need',\n",
       "  'provid',\n",
       "  'team',\n",
       "  'member',\n",
       "  'direct',\n",
       "  'report',\n",
       "  'clear',\n",
       "  'direct',\n",
       "  'target',\n",
       "  'align',\n",
       "  'busi',\n",
       "  'need',\n",
       "  'digit',\n",
       "  'object',\n",
       "  'kei',\n",
       "  'relationship',\n",
       "  'studio',\n",
       "  'creativ',\n",
       "  'oper',\n",
       "  'product',\n",
       "  'content',\n",
       "  'strategi',\n",
       "  'digit',\n",
       "  'team',\n",
       "  'plan',\n",
       "  'experi',\n",
       "  'design',\n",
       "  'activ',\n",
       "  'major',\n",
       "  'global',\n",
       "  'stakehold',\n",
       "  'global',\n",
       "  'comm',\n",
       "  'team',\n",
       "  'global',\n",
       "  'oper',\n",
       "  'brand',\n",
       "  'design',\n",
       "  'major',\n",
       "  'digit',\n",
       "  'team',\n",
       "  'digit',\n",
       "  'plan',\n",
       "  'growth',\n",
       "  'digit',\n",
       "  'product',\n",
       "  'dto',\n",
       "  'respect',\n",
       "  'busi',\n",
       "  'function',\n",
       "  'gop',\n",
       "  'financ',\n",
       "  'brand',\n",
       "  'market',\n",
       "  'wholesal',\n",
       "  'retail',\n",
       "  'global',\n",
       "  'extern',\n",
       "  'studio',\n",
       "  'agenc',\n",
       "  'procur',\n",
       "  'requir',\n",
       "  'educ',\n",
       "  'experi',\n",
       "  'ideal',\n",
       "  'master',\n",
       "  'degre',\n",
       "  'focu',\n",
       "  'busi',\n",
       "  'administr',\n",
       "  'commun',\n",
       "  'relat',\n",
       "  'area',\n",
       "  'equival',\n",
       "  'combin',\n",
       "  'educ',\n",
       "  'experi',\n",
       "  'year',\n",
       "  'depth',\n",
       "  'experi',\n",
       "  'relat',\n",
       "  'project',\n",
       "  'manag',\n",
       "  'similar',\n",
       "  'topic',\n",
       "  'year',\n",
       "  'profession',\n",
       "  'experi',\n",
       "  'digit',\n",
       "  'ecosystem',\n",
       "  'environ',\n",
       "  'experi',\n",
       "  'hous',\n",
       "  'studio',\n",
       "  'roll',\n",
       "  'understand',\n",
       "  'ecom',\n",
       "  'imag',\n",
       "  'video',\n",
       "  'copi',\n",
       "  'mass',\n",
       "  'product',\n",
       "  'experi',\n",
       "  'work',\n",
       "  'agenc',\n",
       "  'consult',\n",
       "  'plu',\n",
       "  'experi',\n",
       "  'work',\n",
       "  'stakehold',\n",
       "  'senior',\n",
       "  'level',\n",
       "  'subject',\n",
       "  'matter',\n",
       "  'expert',\n",
       "  'function',\n",
       "  'develop',\n",
       "  'busi',\n",
       "  'stakehold',\n",
       "  'product',\n",
       "  'market',\n",
       "  'team',\n",
       "  'cetera',\n",
       "  'year',\n",
       "  'experi',\n",
       "  'lead',\n",
       "  'team',\n",
       "  'soft',\n",
       "  'skill',\n",
       "  'good',\n",
       "  'commun',\n",
       "  'skill',\n",
       "  'especi',\n",
       "  'interact',\n",
       "  'differ',\n",
       "  'level',\n",
       "  'busi',\n",
       "  'abil',\n",
       "  'work',\n",
       "  'fast',\n",
       "  'pace',\n",
       "  'environ',\n",
       "  'differ',\n",
       "  'intern',\n",
       "  'cultur',\n",
       "  'abil',\n",
       "  'handl',\n",
       "  'ambigu',\n",
       "  'untangl',\n",
       "  'complex',\n",
       "  'situat',\n",
       "  'action',\n",
       "  'activ',\n",
       "  'distinct',\n",
       "  'strateg',\n",
       "  'mindset',\n",
       "  'abil',\n",
       "  'priorit',\n",
       "  'deleg',\n",
       "  'high',\n",
       "  'number',\n",
       "  'task',\n",
       "  'vari',\n",
       "  'workload',\n",
       "  'import',\n",
       "  'solut',\n",
       "  'orient',\n",
       "  'approach',\n",
       "  'entrepreneuri',\n",
       "  'mindset',\n",
       "  'good',\n",
       "  'numer',\n",
       "  'analyt',\n",
       "  'skill',\n",
       "  'highli',\n",
       "  'develop',\n",
       "  'leadership',\n",
       "  'skill',\n",
       "  'requir',\n",
       "  'hard',\n",
       "  'skill',\n",
       "  'knowledg',\n",
       "  'digit',\n",
       "  'technolog',\n",
       "  'commun',\n",
       "  'platform',\n",
       "  'cultur',\n",
       "  'strong',\n",
       "  'offic',\n",
       "  'skill',\n",
       "  'word',\n",
       "  'excel',\n",
       "  'powerpoint',\n",
       "  'abil',\n",
       "  'travel',\n",
       "  'domest',\n",
       "  'intern',\n",
       "  'requir',\n",
       "  'depth',\n",
       "  'understand',\n",
       "  'fluent',\n",
       "  'english',\n",
       "  'verbal',\n",
       "  'written']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaf53549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/nyxinsane/Documents/Work - UvA/Automating\n",
      "[nltk_data]     Equity/Study 1/Study1_Code/data/Language\n",
      "[nltk_data]     Models/nltk...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Load NLK\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer, PorterStemmer, LancasterStemmer\n",
    "\n",
    "nltk_path = f'{llm_path}/nltk'\n",
    "nltk.data.path.append(nltk_path)\n",
    "\n",
    "nltk.download('words', download_dir = nltk_path)\n",
    "nltk.download('stopwords', download_dir = nltk_path)\n",
    "nltk.download('punkt', download_dir = nltk_path)\n",
    "nltk.download('averaged_perceptron_tagger', download_dir = nltk_path)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7771bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = r'[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?<=[a-z])(?=[A-Z])'\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n",
    "\n",
    "pattern_numbers = r'[^a-zA-Z0-9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "483e577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk_sentencized = []\n",
    "\n",
    "# for job_description in job_descriptions:\n",
    "#     for sentence in sent_tokenize(job_description):\n",
    "#         for sent in re.split(pattern, sentence):\n",
    "#             nltk_sentencized.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3defa20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentencized = [\n",
    "    sent \n",
    "    for job_description in job_descriptions \n",
    "    for sentence in sent_tokenize(job_description) \n",
    "    for sent in re.split(pattern, sentence)\n",
    "    if len(sent) != 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1126453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sentencized_lower = [\n",
    "    str(sent.strip().lower()) \n",
    "    for sent in nltk_sentencized\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6151cea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_sentencized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0d00571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_sentencized_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bde1c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(nltk_sentencized):\n",
    "    if str_fix_eg in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1548e80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(idx for idx, sent in enumerate(nltk_sentencized) if str_fix_eg in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fdc134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "# str_fix = 'Apply appropriate and effective communication methods to senior management and important stakeholders \\(incl.'\n",
    "\n",
    "for idx, sent in enumerate(nltk_sentencized):\n",
    "    if str_fix_incl.split('\\(')[0] in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "808b22b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Partner with Procurement in order to manage suppliers for the projects & programs in scope, for example interviews, staffing, supplier costs.',\n",
       " 'Communication   stakeholder management',\n",
       " 'Act as the key contact person for strategic stakeholders.',\n",
       " 'Apply appropriate and effective communication methods to senior management and important stakeholders (including vendor) throughout the project lifecycle.',\n",
       " 'As conflicts and escalations arise within projects, identify solutions and manage the resolution in a timely and appropriate manner.',\n",
       " 'Drive change management activities for respective projects & programs and ensure changes are smoothly and successfully implemented to achieve lasting benefits.',\n",
       " 'Project Controlling',\n",
       " 'Manage project controlling as an independent element to ensure that actual project costs are in line the committed budget.',\n",
       " 'Lead or conduct engagement reviews.',\n",
       " 'Verify implementation of quality assurance procedures.',\n",
       " 'Ensure project & program delivery against program KPIs.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_sentencized[84:95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1476b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentences split on e.g. and incl.\n",
    "nltk_sentencized[\n",
    "    next(idx for idx, sent in enumerate(nltk_sentencized) if str_fix_eg in sent):next(idx for idx, sent in enumerate(nltk_sentencized) if str_fix_incl.split('\\(')[0] in sent)+2\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4da72e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(nltk_sentencized):\n",
    "    if 'Power' in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3013d2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(idx for idx, sent in enumerate(nltk_sentencized) if 'Power' in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ece8b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Strong MS-Office skills (Word, Excel, PowerPoint)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_sentencized[next(idx for idx, sent in enumerate(nltk_sentencized) if 'Power' in sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47c2a40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Partner with Procurement in order to manage suppliers for the projects & programs in scope, for example interviews, staffing, supplier costs.\n",
      "\n",
      "Sentence 2: Communication   stakeholder management\n",
      "\n",
      "Sentence 3: Act as the key contact person for strategic stakeholders.\n",
      "\n",
      "Sentence 4: Apply appropriate and effective communication methods to senior management and important stakeholders (including vendor) throughout the project lifecycle.\n",
      "\n",
      "Sentence 5: As conflicts and escalations arise within projects, identify solutions and manage the resolution in a timely and appropriate manner.\n",
      "\n",
      "Sentence 6: Drive change management activities for respective projects & programs and ensure changes are smoothly and successfully implemented to achieve lasting benefits.\n",
      "\n",
      "Sentence 7: Project Controlling\n",
      "\n",
      "Sentence 8: Manage project controlling as an independent element to ensure that actual project costs are in line the committed budget.\n",
      "\n",
      "Sentence 9: Lead or conduct engagement reviews.\n",
      "\n",
      "Sentence 10: Verify implementation of quality assurance procedures.\n",
      "\n",
      "Sentence 11: Ensure project & program delivery against program KPIs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(nltk_sentencized[84:95]):\n",
    "    print(f'Sentence {idx+1}: {sentence}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb93bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk_tokenized = []\n",
    "\n",
    "# for job_sentence in nltk_sentencized:\n",
    "#     for token in word_tokenize(job_sentence):\n",
    "#         if len(token) != 0 and token != '...' and token.lower() not in set(stopwords.words('english')) and token.lower() not in list(string.punctuation):\n",
    "#             nltk_tokenized.append(str(token.strip().lower())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3eb3ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_tokenized = [\n",
    "    str(token.strip().lower()) \n",
    "    for job_sentence in nltk_sentencized \n",
    "    for token in word_tokenize(job_sentence) \n",
    "    if len(token) != 0 \n",
    "    and token != '...' \n",
    "    and not token.lower() in set(stopwords.words('english')) \n",
    "    and not token.lower() in list(string.punctuation) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d604e3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'...' in nltk_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c90fd54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "915"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "82b222c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_token_tags = pos_tag(nltk_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62222e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "915"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk_token_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5b74e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_token_tags[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "297d9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.machinelearningplus.com/nlp/lemmatization-examples-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50db3011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([token])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dda77df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: purpose | Stem: purpos | Lemma: purpose | POS Lemma: purpose\n",
      "Token: manager | Stem: manag | Lemma: manager | POS Lemma: manager\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: strategy | Stem: strategi | Lemma: strategy | POS Lemma: strategy\n",
      "Token: programs | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: adidas | Stem: adida | Lemma: adidas | POS Lemma: adidas\n",
      "Token: market | Stem: market | Lemma: market | POS Lemma: market\n",
      "Token: ecom | Stem: ecom | Lemma: ecom | POS Lemma: ecom\n",
      "Token: organization | Stem: organ | Lemma: organization | POS Lemma: organization\n",
      "Token: task | Stem: task | Lemma: task | POS Lemma: task\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: deliver | Stem: deliv | Lemma: deliver | POS Lemma: deliver\n",
      "Token: small | Stem: small | Lemma: small | POS Lemma: small\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: significant | Stem: signific | Lemma: significant | POS Lemma: significant\n",
      "Token: rfcs | Stem: rfcs | Lemma: rfcs | POS Lemma: rfcs\n",
      "Token: sub-elements | Stem: sub-el | Lemma: sub-elements | POS Lemma: sub-elements\n",
      "Token: mid-scale | Stem: mid-scal | Lemma: mid-scale | POS Lemma: mid-scale\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: scope | Stem: scope | Lemma: scope | POS Lemma: scope\n",
      "Token: local | Stem: local | Lemma: local | POS Lemma: local\n",
      "Token: market | Stem: market | Lemma: market | POS Lemma: market\n",
      "Token: level | Stem: level | Lemma: level | POS Lemma: level\n",
      "Token: across | Stem: across | Lemma: across | POS Lemma: across\n",
      "Token: brands | Stem: brand | Lemma: brand | POS Lemma: brand\n",
      "Token: functions | Stem: function | Lemma: function | POS Lemma: function\n",
      "Token: objective | Stem: object | Lemma: objective | POS Lemma: objective\n",
      "Token: conduct | Stem: conduct | Lemma: conduct | POS Lemma: conduct\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: within | Stem: within | Lemma: within | POS Lemma: within\n",
      "Token: boundaries | Stem: boundari | Lemma: boundary | POS Lemma: boundary\n",
      "Token: time | Stem: time | Lemma: time | POS Lemma: time\n",
      "Token: cost | Stem: cost | Lemma: cost | POS Lemma: cost\n",
      "Token: quality | Stem: qualiti | Lemma: quality | POS Lemma: quality\n",
      "Token: focusing | Stem: focus | Lemma: focusing | POS Lemma: focus\n",
      "Token: consumers | Stem: consum | Lemma: consumer | POS Lemma: consumer\n",
      "Token: expectations | Stem: expect | Lemma: expectation | POS Lemma: expectation\n",
      "Token: requirements | Stem: requir | Lemma: requirement | POS Lemma: requirement\n",
      "Token: planning | Stem: plan | Lemma: planning | POS Lemma: planning\n",
      "Token: executing | Stem: execut | Lemma: executing | POS Lemma: execute\n",
      "Token: tracking | Stem: track | Lemma: tracking | POS Lemma: track\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: cooperation | Stem: cooper | Lemma: cooperation | POS Lemma: cooperation\n",
      "Token: respective | Stem: respect | Lemma: respective | POS Lemma: respective\n",
      "Token: functions | Stem: function | Lemma: function | POS Lemma: function\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: team | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: members | Stem: member | Lemma: member | POS Lemma: member\n",
      "Token: examples | Stem: exampl | Lemma: example | POS Lemma: example\n",
      "Token: expected | Stem: expect | Lemma: expected | POS Lemma: expect\n",
      "Token: role | Stem: role | Lemma: role | POS Lemma: role\n",
      "Token: additionally | Stem: addit | Lemma: additionally | POS Lemma: additionally\n",
      "Token: focusing | Stem: focus | Lemma: focusing | POS Lemma: focus\n",
      "Token: resource | Stem: resourc | Lemma: resource | POS Lemma: resource\n",
      "Token: management | Stem: manag | Lemma: management | POS Lemma: management\n",
      "Token: coordination | Stem: coordin | Lemma: coordination | POS Lemma: coordination\n",
      "Token: activities | Stem: activ | Lemma: activity | POS Lemma: activity\n",
      "Token: acting | Stem: act | Lemma: acting | POS Lemma: act\n",
      "Token: central | Stem: central | Lemma: central | POS Lemma: central\n",
      "Token: interface | Stem: interfac | Lemma: interface | POS Lemma: interface\n",
      "Token: local | Stem: local | Lemma: local | POS Lemma: local\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: key | Stem: key | Lemma: key | POS Lemma: key\n",
      "Token: responsibilities | Stem: respons | Lemma: responsibility | POS Lemma: responsibility\n",
      "Token: scope | Stem: scope | Lemma: scope | POS Lemma: scope\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: deliver | Stem: deliv | Lemma: deliver | POS Lemma: deliver\n",
      "Token: small | Stem: small | Lemma: small | POS Lemma: small\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: local | Stem: local | Lemma: local | POS Lemma: local\n",
      "Token: market | Stem: market | Lemma: market | POS Lemma: market\n",
      "Token: level | Stem: level | Lemma: level | POS Lemma: level\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: program | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: delivery | Stem: deliveri | Lemma: delivery | POS Lemma: delivery\n",
      "Token: deliver | Stem: deliv | Lemma: deliver | POS Lemma: deliver\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: end-to-end | Stem: end-to-end | Lemma: end-to-end | POS Lemma: end-to-end\n",
      "Token: successfully | Stem: success | Lemma: successfully | POS Lemma: successfully\n",
      "Token: ideally | Stem: ideal | Lemma: ideally | POS Lemma: ideally\n",
      "Token: effective | Stem: effect | Lemma: effective | POS Lemma: effective\n",
      "Token: application | Stem: applic | Lemma: application | POS Lemma: application\n",
      "Token: pmi | Stem: pmi | Lemma: pmi | POS Lemma: pmi\n",
      "Token: agile | Stem: agil | Lemma: agile | POS Lemma: agile\n",
      "Token: methodology | Stem: methodolog | Lemma: methodology | POS Lemma: methodology\n",
      "Token: develop | Stem: develop | Lemma: develop | POS Lemma: develop\n",
      "Token: detailed | Stem: detail | Lemma: detailed | POS Lemma: detailed\n",
      "Token: plans | Stem: plan | Lemma: plan | POS Lemma: plan\n",
      "Token: allow | Stem: allow | Lemma: allow | POS Lemma: allow\n",
      "Token: providing | Stem: provid | Lemma: providing | POS Lemma: provide\n",
      "Token: transparency | Stem: transpar | Lemma: transparency | POS Lemma: transparency\n",
      "Token: progress | Stem: progress | Lemma: progress | POS Lemma: progress\n",
      "Token: identifying | Stem: identifi | Lemma: identifying | POS Lemma: identify\n",
      "Token: risks | Stem: risk | Lemma: risk | POS Lemma: risk\n",
      "Token: time | Stem: time | Lemma: time | POS Lemma: time\n",
      "Token: identify | Stem: identifi | Lemma: identify | POS Lemma: identify\n",
      "Token: interdependencies | Stem: interdepend | Lemma: interdependency | POS Lemma: interdependency\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: solve | Stem: solv | Lemma: solve | POS Lemma: solve\n",
      "Token: issues | Stem: issu | Lemma: issue | POS Lemma: issue\n",
      "Token: proactively | Stem: proactiv | Lemma: proactively | POS Lemma: proactively\n",
      "Token: drive | Stem: drive | Lemma: drive | POS Lemma: drive\n",
      "Token: continuous | Stem: continu | Lemma: continuous | POS Lemma: continuous\n",
      "Token: improvement | Stem: improv | Lemma: improvement | POS Lemma: improvement\n",
      "Token: products | Stem: product | Lemma: product | POS Lemma: product\n",
      "Token: processes | Stem: process | Lemma: process | POS Lemma: process\n",
      "Token: systems | Stem: system | Lemma: system | POS Lemma: system\n",
      "Token: within | Stem: within | Lemma: within | POS Lemma: within\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: scope | Stem: scope | Lemma: scope | POS Lemma: scope\n",
      "Token: resource | Stem: resourc | Lemma: resource | POS Lemma: resource\n",
      "Token: planning | Stem: plan | Lemma: planning | POS Lemma: planning\n",
      "Token: lead | Stem: lead | Lemma: lead | POS Lemma: lead\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: team | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: resources | Stem: resourc | Lemma: resource | POS Lemma: resource\n",
      "Token: internals | Stem: intern | Lemma: internals | POS Lemma: internals\n",
      "Token: externals | Stem: extern | Lemma: external | POS Lemma: external\n",
      "Token: deliver | Stem: deliv | Lemma: deliver | POS Lemma: deliver\n",
      "Token: support | Stem: support | Lemma: support | POS Lemma: support\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: programs | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: communication | Stem: communic | Lemma: communication | POS Lemma: communication\n",
      "Token: act | Stem: act | Lemma: act | POS Lemma: act\n",
      "Token: key | Stem: key | Lemma: key | POS Lemma: key\n",
      "Token: contact | Stem: contact | Lemma: contact | POS Lemma: contact\n",
      "Token: person | Stem: person | Lemma: person | POS Lemma: person\n",
      "Token: local | Stem: local | Lemma: local | POS Lemma: local\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: apply | Stem: appli | Lemma: apply | POS Lemma: apply\n",
      "Token: appropriate | Stem: appropri | Lemma: appropriate | POS Lemma: appropriate\n",
      "Token: effective | Stem: effect | Lemma: effective | POS Lemma: effective\n",
      "Token: communication | Stem: communic | Lemma: communication | POS Lemma: communication\n",
      "Token: methods | Stem: method | Lemma: method | POS Lemma: method\n",
      "Token: senior | Stem: senior | Lemma: senior | POS Lemma: senior\n",
      "Token: management | Stem: manag | Lemma: management | POS Lemma: management\n",
      "Token: important | Stem: import | Lemma: important | POS Lemma: important\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: throughout | Stem: throughout | Lemma: throughout | POS Lemma: throughout\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: lifecycle | Stem: lifecycl | Lemma: lifecycle | POS Lemma: lifecycle\n",
      "Token: conflicts | Stem: conflict | Lemma: conflict | POS Lemma: conflict\n",
      "Token: escalations | Stem: escal | Lemma: escalation | POS Lemma: escalation\n",
      "Token: arise | Stem: aris | Lemma: arise | POS Lemma: arise\n",
      "Token: within | Stem: within | Lemma: within | POS Lemma: within\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: identify | Stem: identifi | Lemma: identify | POS Lemma: identify\n",
      "Token: solutions | Stem: solut | Lemma: solution | POS Lemma: solution\n",
      "Token: drive | Stem: drive | Lemma: drive | POS Lemma: drive\n",
      "Token: resolution | Stem: resolut | Lemma: resolution | POS Lemma: resolution\n",
      "Token: timely | Stem: time | Lemma: timely | POS Lemma: timely\n",
      "Token: appropriate | Stem: appropri | Lemma: appropriate | POS Lemma: appropriate\n",
      "Token: manner | Stem: manner | Lemma: manner | POS Lemma: manner\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: change | Stem: chang | Lemma: change | POS Lemma: change\n",
      "Token: within | Stem: within | Lemma: within | POS Lemma: within\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: ensure | Stem: ensur | Lemma: ensure | POS Lemma: ensure\n",
      "Token: changes | Stem: chang | Lemma: change | POS Lemma: change\n",
      "Token: smoothly | Stem: smooth | Lemma: smoothly | POS Lemma: smoothly\n",
      "Token: successfully | Stem: success | Lemma: successfully | POS Lemma: successfully\n",
      "Token: implemented | Stem: implement | Lemma: implemented | POS Lemma: implement\n",
      "Token: achieve | Stem: achiev | Lemma: achieve | POS Lemma: achieve\n",
      "Token: lasting | Stem: last | Lemma: lasting | POS Lemma: last\n",
      "Token: benefits | Stem: benefit | Lemma: benefit | POS Lemma: benefit\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: controlling | Stem: control | Lemma: controlling | POS Lemma: control\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: controlling | Stem: control | Lemma: controlling | POS Lemma: control\n",
      "Token: independent | Stem: independ | Lemma: independent | POS Lemma: independent\n",
      "Token: element | Stem: element | Lemma: element | POS Lemma: element\n",
      "Token: ensure | Stem: ensur | Lemma: ensure | POS Lemma: ensure\n",
      "Token: actual | Stem: actual | Lemma: actual | POS Lemma: actual\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: costs | Stem: cost | Lemma: cost | POS Lemma: cost\n",
      "Token: line | Stem: line | Lemma: line | POS Lemma: line\n",
      "Token: committed | Stem: commit | Lemma: committed | POS Lemma: commit\n",
      "Token: budget | Stem: budget | Lemma: budget | POS Lemma: budget\n",
      "Token: conduct | Stem: conduct | Lemma: conduct | POS Lemma: conduct\n",
      "Token: engagement | Stem: engag | Lemma: engagement | POS Lemma: engagement\n",
      "Token: reviews | Stem: review | Lemma: review | POS Lemma: review\n",
      "Token: verify | Stem: verifi | Lemma: verify | POS Lemma: verify\n",
      "Token: compliance | Stem: complianc | Lemma: compliance | POS Lemma: compliance\n",
      "Token: quality | Stem: qualiti | Lemma: quality | POS Lemma: quality\n",
      "Token: assurance | Stem: assur | Lemma: assurance | POS Lemma: assurance\n",
      "Token: procedures | Stem: procedur | Lemma: procedure | POS Lemma: procedure\n",
      "Token: validate | Stem: valid | Lemma: validate | POS Lemma: validate\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: delivering | Stem: deliv | Lemma: delivering | POS Lemma: deliver\n",
      "Token: program | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: kpis | Stem: kpis | Lemma: kpis | POS Lemma: kpis\n",
      "Token: monitor | Stem: monitor | Lemma: monitor | POS Lemma: monitor\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: variables | Stem: variabl | Lemma: variable | POS Lemma: variable\n",
      "Token: cost | Stem: cost | Lemma: cost | POS Lemma: cost\n",
      "Token: effort | Stem: effort | Lemma: effort | POS Lemma: effort\n",
      "Token: scope | Stem: scope | Lemma: scope | POS Lemma: scope\n",
      "Token: et | Stem: et | Lemma: et | POS Lemma: et\n",
      "Token: cetera | Stem: cetera | Lemma: cetera | POS Lemma: cetera\n",
      "Token: plan | Stem: plan | Lemma: plan | POS Lemma: plan\n",
      "Token: order | Stem: order | Lemma: order | POS Lemma: order\n",
      "Token: implement | Stem: implement | Lemma: implement | POS Lemma: implement\n",
      "Token: corrective | Stem: correct | Lemma: corrective | POS Lemma: corrective\n",
      "Token: preventive | Stem: prevent | Lemma: preventive | POS Lemma: preventive\n",
      "Token: actions | Stem: action | Lemma: action | POS Lemma: action\n",
      "Token: `` | Stem: `` | Lemma: `` | POS Lemma: ``\n",
      "Token: required | Stem: requir | Lemma: required | POS Lemma: require\n",
      "Token: '' | Stem: '' | Lemma: '' | POS Lemma: ''\n",
      "Token: responsibilities | Stem: respons | Lemma: responsibility | POS Lemma: responsibility\n",
      "Token: agile | Stem: agil | Lemma: agile | POS Lemma: agile\n",
      "Token: transformation | Stem: transform | Lemma: transformation | POS Lemma: transformation\n",
      "Token: drive | Stem: drive | Lemma: drive | POS Lemma: drive\n",
      "Token: implementation | Stem: implement | Lemma: implementation | POS Lemma: implementation\n",
      "Token: elements | Stem: element | Lemma: element | POS Lemma: element\n",
      "Token: transformation | Stem: transform | Lemma: transformation | POS Lemma: transformation\n",
      "Token: full | Stem: full | Lemma: full | POS Lemma: full\n",
      "Token: agile | Stem: agil | Lemma: agile | POS Lemma: agile\n",
      "Token: working | Stem: work | Lemma: working | POS Lemma: work\n",
      "Token: mode | Stem: mode | Lemma: mode | POS Lemma: mode\n",
      "Token: facilitate | Stem: facilit | Lemma: facilitate | POS Lemma: facilitate\n",
      "Token: agile | Stem: agil | Lemma: agile | POS Lemma: agile\n",
      "Token: adoption | Stem: adopt | Lemma: adoption | POS Lemma: adoption\n",
      "Token: contribute | Stem: contribut | Lemma: contribute | POS Lemma: contribute\n",
      "Token: developing | Stem: develop | Lemma: developing | POS Lemma: develop\n",
      "Token: orchestrating | Stem: orchestr | Lemma: orchestrating | POS Lemma: orchestrate\n",
      "Token: demand | Stem: demand | Lemma: demand | POS Lemma: demand\n",
      "Token: delivery | Stem: deliveri | Lemma: delivery | POS Lemma: delivery\n",
      "Token: process | Stem: process | Lemma: process | POS Lemma: process\n",
      "Token: within | Stem: within | Lemma: within | POS Lemma: within\n",
      "Token: global | Stem: global | Lemma: global | POS Lemma: global\n",
      "Token: facilitate | Stem: facilit | Lemma: facilitate | POS Lemma: facilitate\n",
      "Token: initial | Stem: initi | Lemma: initial | POS Lemma: initial\n",
      "Token: demand | Stem: demand | Lemma: demand | POS Lemma: demand\n",
      "Token: discussions | Stem: discuss | Lemma: discussion | POS Lemma: discussion\n",
      "Token: market | Stem: market | Lemma: market | POS Lemma: market\n",
      "Token: development | Stem: develop | Lemma: development | POS Lemma: development\n",
      "Token: create | Stem: creat | Lemma: create | POS Lemma: create\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: cases | Stem: case | Lemma: case | POS Lemma: case\n",
      "Token: market | Stem: market | Lemma: market | POS Lemma: market\n",
      "Token: support | Stem: support | Lemma: support | POS Lemma: support\n",
      "Token: local | Stem: local | Lemma: local | POS Lemma: local\n",
      "Token: global | Stem: global | Lemma: global | POS Lemma: global\n",
      "Token: analytics | Stem: analyt | Lemma: analytics | POS Lemma: analytics\n",
      "Token: team | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: evaluate | Stem: evalu | Lemma: evaluate | POS Lemma: evaluate\n",
      "Token: growth | Stem: growth | Lemma: growth | POS Lemma: growth\n",
      "Token: opportunities | Stem: opportun | Lemma: opportunity | POS Lemma: opportunity\n",
      "Token: implement | Stem: implement | Lemma: implement | POS Lemma: implement\n",
      "Token: base | Stem: base | Lemma: base | POS Lemma: base\n",
      "Token: platform | Stem: platform | Lemma: platform | POS Lemma: platform\n",
      "Token: capabilities | Stem: capabl | Lemma: capability | POS Lemma: capability\n",
      "Token: build | Stem: build | Lemma: build | POS Lemma: build\n",
      "Token: global | Stem: global | Lemma: global | POS Lemma: global\n",
      "Token: required | Stem: requir | Lemma: required | POS Lemma: require\n",
      "Token: fulfill | Stem: fulfil | Lemma: fulfill | POS Lemma: fulfill\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: cases | Stem: case | Lemma: case | POS Lemma: case\n",
      "Token: together | Stem: togeth | Lemma: together | POS Lemma: together\n",
      "Token: key | Stem: key | Lemma: key | POS Lemma: key\n",
      "Token: relationships | Stem: relationship | Lemma: relationship | POS Lemma: relationship\n",
      "Token: leading | Stem: lead | Lemma: leading | POS Lemma: lead\n",
      "Token: sr | Stem: sr | Lemma: sr | POS Lemma: sr\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: manager | Stem: manag | Lemma: manager | POS Lemma: manager\n",
      "Token: sr. | Stem: sr. | Lemma: sr. | POS Lemma: sr.\n",
      "Token: dir | Stem: dir | Lemma: dir | POS Lemma: dir\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: strategy | Stem: strategi | Lemma: strategy | POS Lemma: strategy\n",
      "Token: programs | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: team | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: local | Stem: local | Lemma: local | POS Lemma: local\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: global | Stem: global | Lemma: global | POS Lemma: global\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: global | Stem: global | Lemma: global | POS Lemma: global\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: sales | Stem: sale | Lemma: sale | POS Lemma: sale\n",
      "Token: solutions | Stem: solut | Lemma: solution | POS Lemma: solution\n",
      "Token: respective | Stem: respect | Lemma: respective | POS Lemma: respective\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: functions | Stem: function | Lemma: function | POS Lemma: function\n",
      "Token: ops | Stem: op | Lemma: ops | POS Lemma: ops\n",
      "Token: finance | Stem: financ | Lemma: finance | POS Lemma: finance\n",
      "Token: hr | Stem: hr | Lemma: hr | POS Lemma: hr\n",
      "Token: brand | Stem: brand | Lemma: brand | POS Lemma: brand\n",
      "Token: marketing | Stem: market | Lemma: marketing | POS Lemma: marketing\n",
      "Token: wholesale | Stem: wholesal | Lemma: wholesale | POS Lemma: wholesale\n",
      "Token: retail | Stem: retail | Lemma: retail | POS Lemma: retail\n",
      "Token: hr | Stem: hr | Lemma: hr | POS Lemma: hr\n",
      "Token: management | Stem: manag | Lemma: management | POS Lemma: management\n",
      "Token: controlling | Stem: control | Lemma: controlling | POS Lemma: control\n",
      "Token: education | Stem: educ | Lemma: education | POS Lemma: education\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: university | Stem: univers | Lemma: university | POS Lemma: university\n",
      "Token: degree | Stem: degre | Lemma: degree | POS Lemma: degree\n",
      "Token: focus | Stem: focus | Lemma: focus | POS Lemma: focus\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: administration | Stem: administr | Lemma: administration | POS Lemma: administration\n",
      "Token: communication | Stem: communic | Lemma: communication | POS Lemma: communication\n",
      "Token: related | Stem: relat | Lemma: related | POS Lemma: related\n",
      "Token: areas | Stem: area | Lemma: area | POS Lemma: area\n",
      "Token: equivalent | Stem: equival | Lemma: equivalent | POS Lemma: equivalent\n",
      "Token: combination | Stem: combin | Lemma: combination | POS Lemma: combination\n",
      "Token: education | Stem: educ | Lemma: education | POS Lemma: education\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: 5+ | Stem: 5+ | Lemma: 5+ | POS Lemma: 5+\n",
      "Token: years | Stem: year | Lemma: year | POS Lemma: year\n",
      "Token: in-depth | Stem: in-depth | Lemma: in-depth | POS Lemma: in-depth\n",
      "Token: professional | Stem: profession | Lemma: professional | POS Lemma: professional\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: related | Stem: relat | Lemma: related | POS Lemma: related\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: management | Stem: manag | Lemma: management | POS Lemma: management\n",
      "Token: similar | Stem: similar | Lemma: similar | POS Lemma: similar\n",
      "Token: topics | Stem: topic | Lemma: topic | POS Lemma: topic\n",
      "Token: 1-3 | Stem: 1-3 | Lemma: 1-3 | POS Lemma: 1-3\n",
      "Token: years | Stem: year | Lemma: year | POS Lemma: year\n",
      "Token: professional | Stem: profession | Lemma: professional | POS Lemma: professional\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: ecosystem | Stem: ecosystem | Lemma: ecosystem | POS Lemma: ecosystem\n",
      "Token: environment | Stem: environ | Lemma: environment | POS Lemma: environment\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: area | Stem: area | Lemma: area | POS Lemma: area\n",
      "Token: scope | Stem: scope | Lemma: scope | POS Lemma: scope\n",
      "Token: proven | Stem: proven | Lemma: proven | POS Lemma: proven\n",
      "Token: market | Stem: market | Lemma: market | POS Lemma: market\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: acumen | Stem: acumen | Lemma: acumen | POS Lemma: acumen\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: ecommerce | Stem: ecommerc | Lemma: ecommerce | POS Lemma: ecommerce\n",
      "Token: plus | Stem: plus | Lemma: plus | POS Lemma: plus\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: finance | Stem: financ | Lemma: finance | POS Lemma: finance\n",
      "Token: plus | Stem: plus | Lemma: plus | POS Lemma: plus\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: working | Stem: work | Lemma: working | POS Lemma: work\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: various | Stem: various | Lemma: various | POS Lemma: various\n",
      "Token: seniority | Stem: senior | Lemma: seniority | POS Lemma: seniority\n",
      "Token: levels | Stem: level | Lemma: level | POS Lemma: level\n",
      "Token: well | Stem: well | Lemma: well | POS Lemma: well\n",
      "Token: subject | Stem: subject | Lemma: subject | POS Lemma: subject\n",
      "Token: matter | Stem: matter | Lemma: matter | POS Lemma: matter\n",
      "Token: experts | Stem: expert | Lemma: expert | POS Lemma: expert\n",
      "Token: across | Stem: across | Lemma: across | POS Lemma: across\n",
      "Token: various | Stem: various | Lemma: various | POS Lemma: various\n",
      "Token: functions | Stem: function | Lemma: function | POS Lemma: function\n",
      "Token: developers | Stem: develop | Lemma: developer | POS Lemma: developer\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: product | Stem: product | Lemma: product | POS Lemma: product\n",
      "Token: marketing | Stem: market | Lemma: marketing | POS Lemma: marketing\n",
      "Token: teams | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: et | Stem: et | Lemma: et | POS Lemma: et\n",
      "Token: cetera | Stem: cetera | Lemma: cetera | POS Lemma: cetera\n",
      "Token: knowledge | Stem: knowledg | Lemma: knowledge | POS Lemma: knowledge\n",
      "Token: skills | Stem: skill | Lemma: skill | POS Lemma: skill\n",
      "Token: abilities | Stem: abil | Lemma: ability | POS Lemma: ability\n",
      "Token: soft-skills | Stem: soft-skil | Lemma: soft-skills | POS Lemma: soft-skills\n",
      "Token: good | Stem: good | Lemma: good | POS Lemma: good\n",
      "Token: communication | Stem: communic | Lemma: communication | POS Lemma: communication\n",
      "Token: skills | Stem: skill | Lemma: skill | POS Lemma: skill\n",
      "Token: especially | Stem: especi | Lemma: especially | POS Lemma: especially\n",
      "Token: interacting | Stem: interact | Lemma: interacting | POS Lemma: interact\n",
      "Token: different | Stem: differ | Lemma: different | POS Lemma: different\n",
      "Token: levels | Stem: level | Lemma: level | POS Lemma: level\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: ability | Stem: abil | Lemma: ability | POS Lemma: ability\n",
      "Token: work | Stem: work | Lemma: work | POS Lemma: work\n",
      "Token: fast-paced | Stem: fast-pac | Lemma: fast-paced | POS Lemma: fast-paced\n",
      "Token: environment | Stem: environ | Lemma: environment | POS Lemma: environment\n",
      "Token: different | Stem: differ | Lemma: different | POS Lemma: different\n",
      "Token: international | Stem: intern | Lemma: international | POS Lemma: international\n",
      "Token: cultures | Stem: cultur | Lemma: culture | POS Lemma: culture\n",
      "Token: solutions-oriented | Stem: solutions-ori | Lemma: solutions-oriented | POS Lemma: solutions-oriented\n",
      "Token: approach | Stem: approach | Lemma: approach | POS Lemma: approach\n",
      "Token: entrepreneurial | Stem: entrepreneuri | Lemma: entrepreneurial | POS Lemma: entrepreneurial\n",
      "Token: mindset | Stem: mindset | Lemma: mindset | POS Lemma: mindset\n",
      "Token: good | Stem: good | Lemma: good | POS Lemma: good\n",
      "Token: numerical | Stem: numer | Lemma: numerical | POS Lemma: numerical\n",
      "Token: analytical | Stem: analyt | Lemma: analytical | POS Lemma: analytical\n",
      "Token: skills | Stem: skill | Lemma: skill | POS Lemma: skill\n",
      "Token: hard-skills | Stem: hard-skil | Lemma: hard-skills | POS Lemma: hard-skills\n",
      "Token: strong | Stem: strong | Lemma: strong | POS Lemma: strong\n",
      "Token: ms-office | Stem: ms-offic | Lemma: ms-office | POS Lemma: ms-office\n",
      "Token: skills | Stem: skill | Lemma: skill | POS Lemma: skill\n",
      "Token: word | Stem: word | Lemma: word | POS Lemma: word\n",
      "Token: excel | Stem: excel | Lemma: excel | POS Lemma: excel\n",
      "Token: powerpoint | Stem: powerpoint | Lemma: powerpoint | POS Lemma: powerpoint\n",
      "Token: basic | Stem: basic | Lemma: basic | POS Lemma: basic\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: broad | Stem: broad | Lemma: broad | POS Lemma: broad\n",
      "Token: understanding | Stem: understand | Lemma: understanding | POS Lemma: understand\n",
      "Token: working | Stem: work | Lemma: working | POS Lemma: work\n",
      "Token: knowledge | Stem: knowledg | Lemma: knowledge | POS Lemma: knowledge\n",
      "Token: agile | Stem: agil | Lemma: agile | POS Lemma: agile\n",
      "Token: working | Stem: work | Lemma: working | POS Lemma: work\n",
      "Token: methods | Stem: method | Lemma: method | POS Lemma: method\n",
      "Token: example | Stem: exampl | Lemma: example | POS Lemma: example\n",
      "Token: scrum | Stem: scrum | Lemma: scrum | POS Lemma: scrum\n",
      "Token: kanban | Stem: kanban | Lemma: kanban | POS Lemma: kanban\n",
      "Token: working | Stem: work | Lemma: working | POS Lemma: work\n",
      "Token: knowledge | Stem: knowledg | Lemma: knowledge | POS Lemma: knowledge\n",
      "Token: pmi | Stem: pmi | Lemma: pmi | POS Lemma: pmi\n",
      "Token: methods | Stem: method | Lemma: method | POS Lemma: method\n",
      "Token: ideally | Stem: ideal | Lemma: ideally | POS Lemma: ideally\n",
      "Token: certification | Stem: certif | Lemma: certification | POS Lemma: certification\n",
      "Token: fluent | Stem: fluent | Lemma: fluent | POS Lemma: fluent\n",
      "Token: english | Stem: english | Lemma: english | POS Lemma: english\n",
      "Token: verbally | Stem: verbal | Lemma: verbally | POS Lemma: verbally\n",
      "Token: written | Stem: written | Lemma: written | POS Lemma: write\n",
      "Token: purpose | Stem: purpos | Lemma: purpose | POS Lemma: purpose\n",
      "Token: studio | Stem: studio | Lemma: studio | POS Lemma: studio\n",
      "Token: director | Stem: director | Lemma: director | POS Lemma: director\n",
      "Token: special | Stem: special | Lemma: special | POS Lemma: special\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: adidas | Stem: adida | Lemma: adidas | POS Lemma: adidas\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: task | Stem: task | Lemma: task | POS Lemma: task\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: deliver | Stem: deliv | Lemma: deliver | POS Lemma: deliver\n",
      "Token: studio | Stem: studio | Lemma: studio | POS Lemma: studio\n",
      "Token: programs | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: including | Stem: includ | Lemma: including | POS Lemma: include\n",
      "Token: full | Stem: full | Lemma: full | POS Lemma: full\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: roadmap | Stem: roadmap | Lemma: roadmap | POS Lemma: roadmap\n",
      "Token: program | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: scope | Stem: scope | Lemma: scope | POS Lemma: scope\n",
      "Token: may | Stem: may | Lemma: may | POS Lemma: may\n",
      "Token: comprise | Stem: compris | Lemma: comprise | POS Lemma: comprise\n",
      "Token: multiple | Stem: multipl | Lemma: multiple | POS Lemma: multiple\n",
      "Token: countries | Stem: countri | Lemma: country | POS Lemma: country\n",
      "Token: functions | Stem: function | Lemma: function | POS Lemma: function\n",
      "Token: objective | Stem: object | Lemma: objective | POS Lemma: objective\n",
      "Token: conduct | Stem: conduct | Lemma: conduct | POS Lemma: conduct\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: within | Stem: within | Lemma: within | POS Lemma: within\n",
      "Token: boundaries | Stem: boundari | Lemma: boundary | POS Lemma: boundary\n",
      "Token: time | Stem: time | Lemma: time | POS Lemma: time\n",
      "Token: cost | Stem: cost | Lemma: cost | POS Lemma: cost\n",
      "Token: quality | Stem: qualiti | Lemma: quality | POS Lemma: quality\n",
      "Token: focusing | Stem: focus | Lemma: focusing | POS Lemma: focus\n",
      "Token: consumers | Stem: consum | Lemma: consumer | POS Lemma: consumer\n",
      "Token: expectations | Stem: expect | Lemma: expectation | POS Lemma: expectation\n",
      "Token: requirements | Stem: requir | Lemma: requirement | POS Lemma: requirement\n",
      "Token: planning | Stem: plan | Lemma: planning | POS Lemma: planning\n",
      "Token: executing | Stem: execut | Lemma: executing | POS Lemma: execute\n",
      "Token: tracking | Stem: track | Lemma: tracking | POS Lemma: track\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: programs | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: cooperation | Stem: cooper | Lemma: cooperation | POS Lemma: cooperation\n",
      "Token: respective | Stem: respect | Lemma: respective | POS Lemma: respective\n",
      "Token: functions | Stem: function | Lemma: function | POS Lemma: function\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: team | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: members | Stem: member | Lemma: member | POS Lemma: member\n",
      "Token: examples | Stem: exampl | Lemma: example | POS Lemma: example\n",
      "Token: expected | Stem: expect | Lemma: expected | POS Lemma: expect\n",
      "Token: role | Stem: role | Lemma: role | POS Lemma: role\n",
      "Token: additionally | Stem: addit | Lemma: additionally | POS Lemma: additionally\n",
      "Token: focusing | Stem: focus | Lemma: focusing | POS Lemma: focus\n",
      "Token: resource | Stem: resourc | Lemma: resource | POS Lemma: resource\n",
      "Token: planning | Stem: plan | Lemma: planning | POS Lemma: planning\n",
      "Token: vendor | Stem: vendor | Lemma: vendor | POS Lemma: vendor\n",
      "Token: management | Stem: manag | Lemma: management | POS Lemma: management\n",
      "Token: coordination | Stem: coordin | Lemma: coordination | POS Lemma: coordination\n",
      "Token: activities | Stem: activ | Lemma: activity | POS Lemma: activity\n",
      "Token: acting | Stem: act | Lemma: acting | POS Lemma: act\n",
      "Token: central | Stem: central | Lemma: central | POS Lemma: central\n",
      "Token: interface | Stem: interfac | Lemma: interface | POS Lemma: interface\n",
      "Token: key | Stem: key | Lemma: key | POS Lemma: key\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: scope | Stem: scope | Lemma: scope | POS Lemma: scope\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: deliver | Stem: deliv | Lemma: deliver | POS Lemma: deliver\n",
      "Token: studio | Stem: studio | Lemma: studio | POS Lemma: studio\n",
      "Token: programs | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: including | Stem: includ | Lemma: including | POS Lemma: include\n",
      "Token: full | Stem: full | Lemma: full | POS Lemma: full\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: roadmap | Stem: roadmap | Lemma: roadmap | POS Lemma: roadmap\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: program | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: delivery | Stem: deliveri | Lemma: delivery | POS Lemma: delivery\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: set | Stem: set | Lemma: set | POS Lemma: set\n",
      "Token: roll | Stem: roll | Lemma: roll | POS Lemma: roll\n",
      "Token: studio | Stem: studio | Lemma: studio | POS Lemma: studio\n",
      "Token: hubs | Stem: hub | Lemma: hub | POS Lemma: hub\n",
      "Token: portland | Stem: portland | Lemma: portland | POS Lemma: portland\n",
      "Token: shanghai | Stem: shanghai | Lemma: shanghai | POS Lemma: shanghai\n",
      "Token: locations | Stem: locat | Lemma: location | POS Lemma: location\n",
      "Token: ensure | Stem: ensur | Lemma: ensure | POS Lemma: ensure\n",
      "Token: clear | Stem: clear | Lemma: clear | POS Lemma: clear\n",
      "Token: operating | Stem: oper | Lemma: operating | POS Lemma: operating\n",
      "Token: interaction | Stem: interact | Lemma: interaction | POS Lemma: interaction\n",
      "Token: models | Stem: model | Lemma: model | POS Lemma: model\n",
      "Token: processes | Stem: process | Lemma: process | POS Lemma: process\n",
      "Token: reporting | Stem: report | Lemma: reporting | POS Lemma: reporting\n",
      "Token: frameworks | Stem: framework | Lemma: framework | POS Lemma: framework\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: strategic | Stem: strateg | Lemma: strategic | POS Lemma: strategic\n",
      "Token: partnership | Stem: partnership | Lemma: partnership | POS Lemma: partnership\n",
      "Token: oliver | Stem: oliv | Lemma: oliver | POS Lemma: oliver\n",
      "Token: globally | Stem: global | Lemma: globally | POS Lemma: globally\n",
      "Token: market | Stem: market | Lemma: market | POS Lemma: market\n",
      "Token: set | Stem: set | Lemma: set | POS Lemma: set\n",
      "Token: pilots | Stem: pilot | Lemma: pilot | POS Lemma: pilot\n",
      "Token: new | Stem: new | Lemma: new | POS Lemma: new\n",
      "Token: production | Stem: product | Lemma: production | POS Lemma: production\n",
      "Token: topics | Stem: topic | Lemma: topic | POS Lemma: topic\n",
      "Token: ie | Stem: ie | Lemma: ie | POS Lemma: ie\n",
      "Token: tier | Stem: tier | Lemma: tier | POS Lemma: tier\n",
      "Token: 1 | Stem: 1 | Lemma: 1 | POS Lemma: 1\n",
      "Token: elevated | Stem: elev | Lemma: elevated | POS Lemma: elevate\n",
      "Token: content | Stem: content | Lemma: content | POS Lemma: content\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: point | Stem: point | Lemma: point | POS Lemma: point\n",
      "Token: moved | Stem: move | Lemma: moved | POS Lemma: move\n",
      "Token: mass | Stem: mass | Lemma: mass | POS Lemma: mass\n",
      "Token: production | Stem: product | Lemma: production | POS Lemma: production\n",
      "Token: scale | Stem: scale | Lemma: scale | POS Lemma: scale\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: top | Stem: top | Lemma: top | POS Lemma: top\n",
      "Token: creator | Stem: creator | Lemma: creator | POS Lemma: creator\n",
      "Token: production | Stem: product | Lemma: production | POS Lemma: production\n",
      "Token: requests | Stem: request | Lemma: request | POS Lemma: request\n",
      "Token: ie | Stem: ie | Lemma: ie | POS Lemma: ie\n",
      "Token: beyonce | Stem: beyonc | Lemma: beyonce | POS Lemma: beyonce\n",
      "Token: pharrell | Stem: pharrel | Lemma: pharrell | POS Lemma: pharrell\n",
      "Token: et | Stem: et | Lemma: et | POS Lemma: et\n",
      "Token: ceteramanage | Stem: ceteramanag | Lemma: ceteramanage | POS Lemma: ceteramanage\n",
      "Token: supporting | Stem: support | Lemma: supporting | POS Lemma: support\n",
      "Token: system | Stem: system | Lemma: system | POS Lemma: system\n",
      "Token: platforms | Stem: platform | Lemma: platform | POS Lemma: platform\n",
      "Token: resource | Stem: resourc | Lemma: resource | POS Lemma: resource\n",
      "Token: planning | Stem: plan | Lemma: planning | POS Lemma: planning\n",
      "Token: form | Stem: form | Lemma: form | POS Lemma: form\n",
      "Token: lead | Stem: lead | Lemma: lead | POS Lemma: lead\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: monitor | Stem: monitor | Lemma: monitor | POS Lemma: monitor\n",
      "Token: multi-functional | Stem: multi-funct | Lemma: multi-functional | POS Lemma: multi-functional\n",
      "Token: team | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: resources | Stem: resourc | Lemma: resource | POS Lemma: resource\n",
      "Token: internals | Stem: intern | Lemma: internals | POS Lemma: internals\n",
      "Token: externals | Stem: extern | Lemma: external | POS Lemma: external\n",
      "Token: deliver | Stem: deliv | Lemma: deliver | POS Lemma: deliver\n",
      "Token: support | Stem: support | Lemma: support | POS Lemma: support\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: programs | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: partner | Stem: partner | Lemma: partner | POS Lemma: partner\n",
      "Token: procurement | Stem: procur | Lemma: procurement | POS Lemma: procurement\n",
      "Token: order | Stem: order | Lemma: order | POS Lemma: order\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: suppliers | Stem: supplier | Lemma: supplier | POS Lemma: supplier\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: programs | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: scope | Stem: scope | Lemma: scope | POS Lemma: scope\n",
      "Token: example | Stem: exampl | Lemma: example | POS Lemma: example\n",
      "Token: interviews | Stem: interview | Lemma: interview | POS Lemma: interview\n",
      "Token: staffing | Stem: staf | Lemma: staffing | POS Lemma: staff\n",
      "Token: supplier | Stem: supplier | Lemma: supplier | POS Lemma: supplier\n",
      "Token: costs | Stem: cost | Lemma: cost | POS Lemma: cost\n",
      "Token: communication | Stem: communic | Lemma: communication | POS Lemma: communication\n",
      "Token: stakeholder | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: management | Stem: manag | Lemma: management | POS Lemma: management\n",
      "Token: act | Stem: act | Lemma: act | POS Lemma: act\n",
      "Token: key | Stem: key | Lemma: key | POS Lemma: key\n",
      "Token: contact | Stem: contact | Lemma: contact | POS Lemma: contact\n",
      "Token: person | Stem: person | Lemma: person | POS Lemma: person\n",
      "Token: strategic | Stem: strateg | Lemma: strategic | POS Lemma: strategic\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: apply | Stem: appli | Lemma: apply | POS Lemma: apply\n",
      "Token: appropriate | Stem: appropri | Lemma: appropriate | POS Lemma: appropriate\n",
      "Token: effective | Stem: effect | Lemma: effective | POS Lemma: effective\n",
      "Token: communication | Stem: communic | Lemma: communication | POS Lemma: communication\n",
      "Token: methods | Stem: method | Lemma: method | POS Lemma: method\n",
      "Token: senior | Stem: senior | Lemma: senior | POS Lemma: senior\n",
      "Token: management | Stem: manag | Lemma: management | POS Lemma: management\n",
      "Token: important | Stem: import | Lemma: important | POS Lemma: important\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: including | Stem: includ | Lemma: including | POS Lemma: include\n",
      "Token: vendor | Stem: vendor | Lemma: vendor | POS Lemma: vendor\n",
      "Token: throughout | Stem: throughout | Lemma: throughout | POS Lemma: throughout\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: lifecycle | Stem: lifecycl | Lemma: lifecycle | POS Lemma: lifecycle\n",
      "Token: conflicts | Stem: conflict | Lemma: conflict | POS Lemma: conflict\n",
      "Token: escalations | Stem: escal | Lemma: escalation | POS Lemma: escalation\n",
      "Token: arise | Stem: aris | Lemma: arise | POS Lemma: arise\n",
      "Token: within | Stem: within | Lemma: within | POS Lemma: within\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: identify | Stem: identifi | Lemma: identify | POS Lemma: identify\n",
      "Token: solutions | Stem: solut | Lemma: solution | POS Lemma: solution\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: resolution | Stem: resolut | Lemma: resolution | POS Lemma: resolution\n",
      "Token: timely | Stem: time | Lemma: timely | POS Lemma: timely\n",
      "Token: appropriate | Stem: appropri | Lemma: appropriate | POS Lemma: appropriate\n",
      "Token: manner | Stem: manner | Lemma: manner | POS Lemma: manner\n",
      "Token: drive | Stem: drive | Lemma: drive | POS Lemma: drive\n",
      "Token: change | Stem: chang | Lemma: change | POS Lemma: change\n",
      "Token: management | Stem: manag | Lemma: management | POS Lemma: management\n",
      "Token: activities | Stem: activ | Lemma: activity | POS Lemma: activity\n",
      "Token: respective | Stem: respect | Lemma: respective | POS Lemma: respective\n",
      "Token: projects | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: programs | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: ensure | Stem: ensur | Lemma: ensure | POS Lemma: ensure\n",
      "Token: changes | Stem: chang | Lemma: change | POS Lemma: change\n",
      "Token: smoothly | Stem: smooth | Lemma: smoothly | POS Lemma: smoothly\n",
      "Token: successfully | Stem: success | Lemma: successfully | POS Lemma: successfully\n",
      "Token: implemented | Stem: implement | Lemma: implemented | POS Lemma: implement\n",
      "Token: achieve | Stem: achiev | Lemma: achieve | POS Lemma: achieve\n",
      "Token: lasting | Stem: last | Lemma: lasting | POS Lemma: last\n",
      "Token: benefits | Stem: benefit | Lemma: benefit | POS Lemma: benefit\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: controlling | Stem: control | Lemma: controlling | POS Lemma: control\n",
      "Token: manage | Stem: manag | Lemma: manage | POS Lemma: manage\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: controlling | Stem: control | Lemma: controlling | POS Lemma: control\n",
      "Token: independent | Stem: independ | Lemma: independent | POS Lemma: independent\n",
      "Token: element | Stem: element | Lemma: element | POS Lemma: element\n",
      "Token: ensure | Stem: ensur | Lemma: ensure | POS Lemma: ensure\n",
      "Token: actual | Stem: actual | Lemma: actual | POS Lemma: actual\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: costs | Stem: cost | Lemma: cost | POS Lemma: cost\n",
      "Token: line | Stem: line | Lemma: line | POS Lemma: line\n",
      "Token: committed | Stem: commit | Lemma: committed | POS Lemma: commit\n",
      "Token: budget | Stem: budget | Lemma: budget | POS Lemma: budget\n",
      "Token: lead | Stem: lead | Lemma: lead | POS Lemma: lead\n",
      "Token: conduct | Stem: conduct | Lemma: conduct | POS Lemma: conduct\n",
      "Token: engagement | Stem: engag | Lemma: engagement | POS Lemma: engagement\n",
      "Token: reviews | Stem: review | Lemma: review | POS Lemma: review\n",
      "Token: verify | Stem: verifi | Lemma: verify | POS Lemma: verify\n",
      "Token: implementation | Stem: implement | Lemma: implementation | POS Lemma: implementation\n",
      "Token: quality | Stem: qualiti | Lemma: quality | POS Lemma: quality\n",
      "Token: assurance | Stem: assur | Lemma: assurance | POS Lemma: assurance\n",
      "Token: procedures | Stem: procedur | Lemma: procedure | POS Lemma: procedure\n",
      "Token: ensure | Stem: ensur | Lemma: ensure | POS Lemma: ensure\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: program | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: delivery | Stem: deliveri | Lemma: delivery | POS Lemma: delivery\n",
      "Token: program | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: kpis | Stem: kpis | Lemma: kpis | POS Lemma: kpis\n",
      "Token: monitor | Stem: monitor | Lemma: monitor | POS Lemma: monitor\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: program | Stem: program | Lemma: program | POS Lemma: program\n",
      "Token: variables | Stem: variabl | Lemma: variable | POS Lemma: variable\n",
      "Token: cost | Stem: cost | Lemma: cost | POS Lemma: cost\n",
      "Token: effort | Stem: effort | Lemma: effort | POS Lemma: effort\n",
      "Token: scope | Stem: scope | Lemma: scope | POS Lemma: scope\n",
      "Token: et | Stem: et | Lemma: et | POS Lemma: et\n",
      "Token: cetera | Stem: cetera | Lemma: cetera | POS Lemma: cetera\n",
      "Token: plan | Stem: plan | Lemma: plan | POS Lemma: plan\n",
      "Token: order | Stem: order | Lemma: order | POS Lemma: order\n",
      "Token: implement | Stem: implement | Lemma: implement | POS Lemma: implement\n",
      "Token: corrective | Stem: correct | Lemma: corrective | POS Lemma: corrective\n",
      "Token: preventive | Stem: prevent | Lemma: preventive | POS Lemma: preventive\n",
      "Token: actions | Stem: action | Lemma: action | POS Lemma: action\n",
      "Token: people | Stem: peopl | Lemma: people | POS Lemma: people\n",
      "Token: management | Stem: manag | Lemma: management | POS Lemma: management\n",
      "Token: ensure | Stem: ensur | Lemma: ensure | POS Lemma: ensure\n",
      "Token: appropriate | Stem: appropri | Lemma: appropriate | POS Lemma: appropriate\n",
      "Token: leadership | Stem: leadership | Lemma: leadership | POS Lemma: leadership\n",
      "Token: skills | Stem: skill | Lemma: skill | POS Lemma: skill\n",
      "Token: present | Stem: present | Lemma: present | POS Lemma: present\n",
      "Token: every | Stem: everi | Lemma: every | POS Lemma: every\n",
      "Token: level | Stem: level | Lemma: level | POS Lemma: level\n",
      "Token: creating | Stem: creat | Lemma: creating | POS Lemma: create\n",
      "Token: motivational | Stem: motiv | Lemma: motivational | POS Lemma: motivational\n",
      "Token: supportive | Stem: support | Lemma: supportive | POS Lemma: supportive\n",
      "Token: work | Stem: work | Lemma: work | POS Lemma: work\n",
      "Token: environment | Stem: environ | Lemma: environment | POS Lemma: environment\n",
      "Token: employees | Stem: employe | Lemma: employee | POS Lemma: employee\n",
      "Token: coached | Stem: coach | Lemma: coached | POS Lemma: coached\n",
      "Token: trained | Stem: train | Lemma: trained | POS Lemma: train\n",
      "Token: provided | Stem: provid | Lemma: provided | POS Lemma: provide\n",
      "Token: career | Stem: career | Lemma: career | POS Lemma: career\n",
      "Token: opportunities | Stem: opportun | Lemma: opportunity | POS Lemma: opportunity\n",
      "Token: development | Stem: develop | Lemma: development | POS Lemma: development\n",
      "Token: continuously | Stem: continu | Lemma: continuously | POS Lemma: continuously\n",
      "Token: monitor | Stem: monitor | Lemma: monitor | POS Lemma: monitor\n",
      "Token: evaluate | Stem: evalu | Lemma: evaluate | POS Lemma: evaluate\n",
      "Token: team | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: workload | Stem: workload | Lemma: workload | POS Lemma: workload\n",
      "Token: organizational | Stem: organiz | Lemma: organizational | POS Lemma: organizational\n",
      "Token: efficiency | Stem: effici | Lemma: efficiency | POS Lemma: efficiency\n",
      "Token: support | Stem: support | Lemma: support | POS Lemma: support\n",
      "Token: systems | Stem: system | Lemma: system | POS Lemma: system\n",
      "Token: data | Stem: data | Lemma: data | POS Lemma: data\n",
      "Token: analysis | Stem: analysi | Lemma: analysis | POS Lemma: analysis\n",
      "Token: team | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: feedback | Stem: feedback | Lemma: feedback | POS Lemma: feedback\n",
      "Token: make | Stem: make | Lemma: make | POS Lemma: make\n",
      "Token: appropriate | Stem: appropri | Lemma: appropriate | POS Lemma: appropriate\n",
      "Token: changes | Stem: chang | Lemma: change | POS Lemma: change\n",
      "Token: order | Stem: order | Lemma: order | POS Lemma: order\n",
      "Token: meet | Stem: meet | Lemma: meet | POS Lemma: meet\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: needs | Stem: need | Lemma: need | POS Lemma: need\n",
      "Token: provide | Stem: provid | Lemma: provide | POS Lemma: provide\n",
      "Token: team | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: members | Stem: member | Lemma: member | POS Lemma: member\n",
      "Token: direct | Stem: direct | Lemma: direct | POS Lemma: direct\n",
      "Token: reports | Stem: report | Lemma: report | POS Lemma: report\n",
      "Token: clear | Stem: clear | Lemma: clear | POS Lemma: clear\n",
      "Token: direction | Stem: direct | Lemma: direction | POS Lemma: direction\n",
      "Token: targets | Stem: target | Lemma: target | POS Lemma: target\n",
      "Token: aligned | Stem: align | Lemma: aligned | POS Lemma: align\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: needs | Stem: need | Lemma: need | POS Lemma: need\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: objectives | Stem: object | Lemma: objective | POS Lemma: objective\n",
      "Token: key | Stem: key | Lemma: key | POS Lemma: key\n",
      "Token: relationships | Stem: relationship | Lemma: relationship | POS Lemma: relationship\n",
      "Token: studio | Stem: studio | Lemma: studio | POS Lemma: studio\n",
      "Token: creative | Stem: creativ | Lemma: creative | POS Lemma: creative\n",
      "Token: operations | Stem: oper | Lemma: operation | POS Lemma: operation\n",
      "Token: production | Stem: product | Lemma: production | POS Lemma: production\n",
      "Token: content | Stem: content | Lemma: content | POS Lemma: content\n",
      "Token: strategy | Stem: strategi | Lemma: strategy | POS Lemma: strategy\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: teams | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: planning | Stem: plan | Lemma: planning | POS Lemma: planning\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: design | Stem: design | Lemma: design | POS Lemma: design\n",
      "Token: activation | Stem: activ | Lemma: activation | POS Lemma: activation\n",
      "Token: major | Stem: major | Lemma: major | POS Lemma: major\n",
      "Token: global | Stem: global | Lemma: global | POS Lemma: global\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: global | Stem: global | Lemma: global | POS Lemma: global\n",
      "Token: comms | Stem: comm | Lemma: comms | POS Lemma: comms\n",
      "Token: teams | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: global | Stem: global | Lemma: global | POS Lemma: global\n",
      "Token: operations | Stem: oper | Lemma: operation | POS Lemma: operation\n",
      "Token: brand | Stem: brand | Lemma: brand | POS Lemma: brand\n",
      "Token: design | Stem: design | Lemma: design | POS Lemma: design\n",
      "Token: major | Stem: major | Lemma: major | POS Lemma: major\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: teams | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: planning | Stem: plan | Lemma: planning | POS Lemma: planning\n",
      "Token: growth | Stem: growth | Lemma: growth | POS Lemma: growth\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: products | Stem: product | Lemma: product | POS Lemma: product\n",
      "Token: dto | Stem: dto | Lemma: dto | POS Lemma: dto\n",
      "Token: respective | Stem: respect | Lemma: respective | POS Lemma: respective\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: function | Stem: function | Lemma: function | POS Lemma: function\n",
      "Token: gops | Stem: gop | Lemma: gop | POS Lemma: gop\n",
      "Token: finance | Stem: financ | Lemma: finance | POS Lemma: finance\n",
      "Token: hr | Stem: hr | Lemma: hr | POS Lemma: hr\n",
      "Token: brand | Stem: brand | Lemma: brand | POS Lemma: brand\n",
      "Token: marketing | Stem: market | Lemma: marketing | POS Lemma: marketing\n",
      "Token: wholesale | Stem: wholesal | Lemma: wholesale | POS Lemma: wholesale\n",
      "Token: retail | Stem: retail | Lemma: retail | POS Lemma: retail\n",
      "Token: global | Stem: global | Lemma: global | POS Lemma: global\n",
      "Token: external | Stem: extern | Lemma: external | POS Lemma: external\n",
      "Token: studios | Stem: studio | Lemma: studio | POS Lemma: studio\n",
      "Token: agencies | Stem: agenc | Lemma: agency | POS Lemma: agency\n",
      "Token: procurement | Stem: procur | Lemma: procurement | POS Lemma: procurement\n",
      "Token: requirements | Stem: requir | Lemma: requirement | POS Lemma: requirement\n",
      "Token: education | Stem: educ | Lemma: education | POS Lemma: education\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: ideally | Stem: ideal | Lemma: ideally | POS Lemma: ideally\n",
      "Token: master | Stem: master | Lemma: master | POS Lemma: master\n",
      "Token: degree | Stem: degre | Lemma: degree | POS Lemma: degree\n",
      "Token: focus | Stem: focus | Lemma: focus | POS Lemma: focus\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: administration | Stem: administr | Lemma: administration | POS Lemma: administration\n",
      "Token: communication | Stem: communic | Lemma: communication | POS Lemma: communication\n",
      "Token: related | Stem: relat | Lemma: related | POS Lemma: related\n",
      "Token: areas | Stem: area | Lemma: area | POS Lemma: area\n",
      "Token: equivalent | Stem: equival | Lemma: equivalent | POS Lemma: equivalent\n",
      "Token: combination | Stem: combin | Lemma: combination | POS Lemma: combination\n",
      "Token: education | Stem: educ | Lemma: education | POS Lemma: education\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: 10+ | Stem: 10+ | Lemma: 10+ | POS Lemma: 10+\n",
      "Token: years | Stem: year | Lemma: year | POS Lemma: year\n",
      "Token: in-depth | Stem: in-depth | Lemma: in-depth | POS Lemma: in-depth\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: related | Stem: relat | Lemma: related | POS Lemma: related\n",
      "Token: project | Stem: project | Lemma: project | POS Lemma: project\n",
      "Token: management | Stem: manag | Lemma: management | POS Lemma: management\n",
      "Token: similar | Stem: similar | Lemma: similar | POS Lemma: similar\n",
      "Token: topics | Stem: topic | Lemma: topic | POS Lemma: topic\n",
      "Token: 6-8 | Stem: 6-8 | Lemma: 6-8 | POS Lemma: 6-8\n",
      "Token: years | Stem: year | Lemma: year | POS Lemma: year\n",
      "Token: professional | Stem: profession | Lemma: professional | POS Lemma: professional\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: ecosystem | Stem: ecosystem | Lemma: ecosystem | POS Lemma: ecosystem\n",
      "Token: environment | Stem: environ | Lemma: environment | POS Lemma: environment\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: in-house | Stem: in-hous | Lemma: in-house | POS Lemma: in-house\n",
      "Token: studio | Stem: studio | Lemma: studio | POS Lemma: studio\n",
      "Token: roll-out | Stem: roll-out | Lemma: roll-out | POS Lemma: roll-out\n",
      "Token: understanding | Stem: understand | Lemma: understanding | POS Lemma: understand\n",
      "Token: ecom | Stem: ecom | Lemma: ecom | POS Lemma: ecom\n",
      "Token: image | Stem: imag | Lemma: image | POS Lemma: image\n",
      "Token: video | Stem: video | Lemma: video | POS Lemma: video\n",
      "Token: copy | Stem: copi | Lemma: copy | POS Lemma: copy\n",
      "Token: mass | Stem: mass | Lemma: mass | POS Lemma: mass\n",
      "Token: production | Stem: product | Lemma: production | POS Lemma: production\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: working | Stem: work | Lemma: working | POS Lemma: work\n",
      "Token: agencies | Stem: agenc | Lemma: agency | POS Lemma: agency\n",
      "Token: consultancy | Stem: consult | Lemma: consultancy | POS Lemma: consultancy\n",
      "Token: plus | Stem: plus | Lemma: plus | POS Lemma: plus\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: working | Stem: work | Lemma: working | POS Lemma: work\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: various | Stem: various | Lemma: various | POS Lemma: various\n",
      "Token: seniority | Stem: senior | Lemma: seniority | POS Lemma: seniority\n",
      "Token: levels | Stem: level | Lemma: level | POS Lemma: level\n",
      "Token: well | Stem: well | Lemma: well | POS Lemma: well\n",
      "Token: subject | Stem: subject | Lemma: subject | POS Lemma: subject\n",
      "Token: matter | Stem: matter | Lemma: matter | POS Lemma: matter\n",
      "Token: experts | Stem: expert | Lemma: expert | POS Lemma: expert\n",
      "Token: across | Stem: across | Lemma: across | POS Lemma: across\n",
      "Token: various | Stem: various | Lemma: various | POS Lemma: various\n",
      "Token: functions | Stem: function | Lemma: function | POS Lemma: function\n",
      "Token: developers | Stem: develop | Lemma: developer | POS Lemma: developer\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: stakeholders | Stem: stakehold | Lemma: stakeholder | POS Lemma: stakeholder\n",
      "Token: product | Stem: product | Lemma: product | POS Lemma: product\n",
      "Token: marketing | Stem: market | Lemma: marketing | POS Lemma: marketing\n",
      "Token: teams | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: et | Stem: et | Lemma: et | POS Lemma: et\n",
      "Token: cetera | Stem: cetera | Lemma: cetera | POS Lemma: cetera\n",
      "Token: 3+ | Stem: 3+ | Lemma: 3+ | POS Lemma: 3+\n",
      "Token: years | Stem: year | Lemma: year | POS Lemma: year\n",
      "Token: experience | Stem: experi | Lemma: experience | POS Lemma: experience\n",
      "Token: leading | Stem: lead | Lemma: leading | POS Lemma: lead\n",
      "Token: team | Stem: team | Lemma: team | POS Lemma: team\n",
      "Token: soft-skills | Stem: soft-skil | Lemma: soft-skills | POS Lemma: soft-skills\n",
      "Token: good | Stem: good | Lemma: good | POS Lemma: good\n",
      "Token: communication | Stem: communic | Lemma: communication | POS Lemma: communication\n",
      "Token: skills | Stem: skill | Lemma: skill | POS Lemma: skill\n",
      "Token: especially | Stem: especi | Lemma: especially | POS Lemma: especially\n",
      "Token: interacting | Stem: interact | Lemma: interacting | POS Lemma: interact\n",
      "Token: different | Stem: differ | Lemma: different | POS Lemma: different\n",
      "Token: levels | Stem: level | Lemma: level | POS Lemma: level\n",
      "Token: business | Stem: busi | Lemma: business | POS Lemma: business\n",
      "Token: ability | Stem: abil | Lemma: ability | POS Lemma: ability\n",
      "Token: work | Stem: work | Lemma: work | POS Lemma: work\n",
      "Token: fast-paced | Stem: fast-pac | Lemma: fast-paced | POS Lemma: fast-paced\n",
      "Token: environment | Stem: environ | Lemma: environment | POS Lemma: environment\n",
      "Token: different | Stem: differ | Lemma: different | POS Lemma: different\n",
      "Token: international | Stem: intern | Lemma: international | POS Lemma: international\n",
      "Token: cultures | Stem: cultur | Lemma: culture | POS Lemma: culture\n",
      "Token: ability | Stem: abil | Lemma: ability | POS Lemma: ability\n",
      "Token: handle | Stem: handl | Lemma: handle | POS Lemma: handle\n",
      "Token: ambiguity | Stem: ambigu | Lemma: ambiguity | POS Lemma: ambiguity\n",
      "Token: untangle | Stem: untangl | Lemma: untangle | POS Lemma: untangle\n",
      "Token: complex | Stem: complex | Lemma: complex | POS Lemma: complex\n",
      "Token: situations | Stem: situat | Lemma: situation | POS Lemma: situation\n",
      "Token: actionable | Stem: action | Lemma: actionable | POS Lemma: actionable\n",
      "Token: activities | Stem: activ | Lemma: activity | POS Lemma: activity\n",
      "Token: distinctive | Stem: distinct | Lemma: distinctive | POS Lemma: distinctive\n",
      "Token: strategic | Stem: strateg | Lemma: strategic | POS Lemma: strategic\n",
      "Token: mindset | Stem: mindset | Lemma: mindset | POS Lemma: mindset\n",
      "Token: ability | Stem: abil | Lemma: ability | POS Lemma: ability\n",
      "Token: prioritize | Stem: priorit | Lemma: prioritize | POS Lemma: prioritize\n",
      "Token: delegate | Stem: deleg | Lemma: delegate | POS Lemma: delegate\n",
      "Token: high | Stem: high | Lemma: high | POS Lemma: high\n",
      "Token: numbers | Stem: number | Lemma: number | POS Lemma: number\n",
      "Token: tasks | Stem: task | Lemma: task | POS Lemma: task\n",
      "Token: varying | Stem: vari | Lemma: varying | POS Lemma: vary\n",
      "Token: workload | Stem: workload | Lemma: workload | POS Lemma: workload\n",
      "Token: importance | Stem: import | Lemma: importance | POS Lemma: importance\n",
      "Token: solutions-oriented | Stem: solutions-ori | Lemma: solutions-oriented | POS Lemma: solutions-oriented\n",
      "Token: approach | Stem: approach | Lemma: approach | POS Lemma: approach\n",
      "Token: entrepreneurial | Stem: entrepreneuri | Lemma: entrepreneurial | POS Lemma: entrepreneurial\n",
      "Token: mindset | Stem: mindset | Lemma: mindset | POS Lemma: mindset\n",
      "Token: good | Stem: good | Lemma: good | POS Lemma: good\n",
      "Token: numerical | Stem: numer | Lemma: numerical | POS Lemma: numerical\n",
      "Token: analytical | Stem: analyt | Lemma: analytical | POS Lemma: analytical\n",
      "Token: skills | Stem: skill | Lemma: skill | POS Lemma: skill\n",
      "Token: highly | Stem: high | Lemma: highly | POS Lemma: highly\n",
      "Token: developed | Stem: develop | Lemma: developed | POS Lemma: developed\n",
      "Token: leadership | Stem: leadership | Lemma: leadership | POS Lemma: leadership\n",
      "Token: skills | Stem: skill | Lemma: skill | POS Lemma: skill\n",
      "Token: required | Stem: requir | Lemma: required | POS Lemma: require\n",
      "Token: hard-skills | Stem: hard-skil | Lemma: hard-skills | POS Lemma: hard-skills\n",
      "Token: knowledge | Stem: knowledg | Lemma: knowledge | POS Lemma: knowledge\n",
      "Token: digital | Stem: digit | Lemma: digital | POS Lemma: digital\n",
      "Token: technologies | Stem: technolog | Lemma: technology | POS Lemma: technology\n",
      "Token: communications | Stem: communic | Lemma: communication | POS Lemma: communication\n",
      "Token: platforms | Stem: platform | Lemma: platform | POS Lemma: platform\n",
      "Token: culture | Stem: cultur | Lemma: culture | POS Lemma: culture\n",
      "Token: strong | Stem: strong | Lemma: strong | POS Lemma: strong\n",
      "Token: ms-office | Stem: ms-offic | Lemma: ms-office | POS Lemma: ms-office\n",
      "Token: skills | Stem: skill | Lemma: skill | POS Lemma: skill\n",
      "Token: word | Stem: word | Lemma: word | POS Lemma: word\n",
      "Token: excel | Stem: excel | Lemma: excel | POS Lemma: excel\n",
      "Token: powerpoint | Stem: powerpoint | Lemma: powerpoint | POS Lemma: powerpoint\n",
      "Token: ability | Stem: abil | Lemma: ability | POS Lemma: ability\n",
      "Token: travel | Stem: travel | Lemma: travel | POS Lemma: travel\n",
      "Token: domestic | Stem: domest | Lemma: domestic | POS Lemma: domestic\n",
      "Token: international | Stem: intern | Lemma: international | POS Lemma: international\n",
      "Token: required | Stem: requir | Lemma: required | POS Lemma: require\n",
      "Token: in-depth | Stem: in-depth | Lemma: in-depth | POS Lemma: in-depth\n",
      "Token: understanding | Stem: understand | Lemma: understanding | POS Lemma: understand\n",
      "Token: fluent | Stem: fluent | Lemma: fluent | POS Lemma: fluent\n",
      "Token: english | Stem: english | Lemma: english | POS Lemma: english\n",
      "Token: verbally | Stem: verbal | Lemma: verbally | POS Lemma: verbally\n",
      "Token: written | Stem: written | Lemma: written | POS Lemma: write\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "nltk_lemmas = []\n",
    "nltk_stems = []\n",
    "\n",
    "for token in nltk_tokenized:\n",
    "    token = unicodedata.normalize('NFKD', str(token.strip().lower())).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    token_lemma = lemmatizer.lemmatize(token)\n",
    "    token_stem = stemmer.stem(token)\n",
    "    token_pos = get_wordnet_pos(token)\n",
    "    token_pos_lemma = lemmatizer.lemmatize(token, token_pos)\n",
    "    print(f'Token: {token} | Stem: {token_stem} | Lemma: {token_lemma} | POS Lemma: {token_pos_lemma}')\n",
    "    nltk_lemmas.append(token_pos_lemma)\n",
    "    nltk_stems.append(token_stem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d5e14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a list of punctuations that determine sentence boundry, i.e., split characters\n",
    "def make_custom_punct_chars(main_punct_chars = [':', '|'], repeated_punct_chars = ['\\n', ',']):\n",
    "    custom_punct_chars = []\n",
    "    temp_multi = []\n",
    "    temp_spaced = []\n",
    "\n",
    "    for punct_char in main_punct_chars:\n",
    "        custom_punct_chars+= f'{punct_char}', f'{punct_char} '\n",
    "\n",
    "    for idx in range(4):\n",
    "        for punct_char in repeated_punct_chars:\n",
    "            temp_multi.append(f'{punct_char}'*int(idx+1))\n",
    "            temp_spaced.append(f'{punct_char} '*int(idx+1))\n",
    "\n",
    "    for multi, spaced in zip(temp_multi, temp_spaced):\n",
    "        custom_punct_chars+= multi, spaced\n",
    "\n",
    "    custom_punct_chars.remove(',')\n",
    "    custom_punct_chars.remove(', ')\n",
    "\n",
    "    return custom_punct_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c7f61ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_punct_chars = make_custom_punct_chars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "183846a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':',\n",
       " ': ',\n",
       " '|',\n",
       " '| ',\n",
       " '\\n',\n",
       " '\\n ',\n",
       " '\\n\\n',\n",
       " '\\n \\n ',\n",
       " ',,',\n",
       " ', , ',\n",
       " '\\n\\n\\n',\n",
       " '\\n \\n \\n ',\n",
       " ',,,',\n",
       " ', , , ',\n",
       " '\\n\\n\\n\\n',\n",
       " '\\n \\n \\n \\n ',\n",
       " ',,,,',\n",
       " ', , , , ']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_punct_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c845236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Spacy\n",
    "import spacy\n",
    "from spacy.symbols import NORM, ORTH, LEMMA, POS\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cd2f4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencizer = nlp.add_pipe('sentencizer')\n",
    "sentencizer.punct_chars.update(custom_punct_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37292ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    with open(f'{data_dir}punctuations.txt', 'wb') as f:\n",
    "        pickle.dump(sentencizer.punct_chars, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08e8ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_dir}punctuations.txt', 'rb') as f:\n",
    "    custom_punct_char = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "52198bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_cases = {\":)\": [{\"ORTH\": \":)\"}]}\n",
    "# prefix_re = re.compile(r'''^[\\\\[\\\\(\"']''')\n",
    "# suffix_re = re.compile(r'''[\\\\]\\\\)\"']$''')\n",
    "# infix_re = re.compile(r'''[-~]''')\n",
    "# simple_url_re = re.compile(r'''^https?://''')\n",
    "\n",
    "# def custom_tokenizer(nlp):\n",
    "#     return Tokenizer(nlp.vocab, rules=special_cases,\n",
    "#                                 prefix_search=prefix_re.search,\n",
    "#                                 suffix_search=suffix_re.search,\n",
    "#                                 infix_finditer=infix_re.finditer,\n",
    "#                                 url_match=simple_url_re.match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a65795c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.tokenizer.add_special_case('incl', [{ORTH: u'incl', NORM: u'include', LEMMA: u'include', POS: u'VERB'}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6425cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH, LEMMA\n",
    "\n",
    "special_cases_dict = {\n",
    "    'incl.': [{65: 'incl', 67: 'including'}],\n",
    "    'incl. ': [{65: 'incl', 67: 'including'}],\n",
    "    '(incl.': [{65: 'incl', 67: 'including'}],\n",
    "    'etc.': [{65: 'etc', 67: 'et cetera'}],\n",
    "    'etc. ': [{65: 'etc', 67: 'et cetera'}],\n",
    "    'e.g.': [{65: 'e.g', 67: 'for example'}],\n",
    "    'e.g. ': [{65: 'e.g', 67: 'for example'}],\n",
    "}\n",
    "\n",
    "nlp.tokenizer.rules.update(special_cases_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4987aa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{65: 'e.g', 67: 'for example'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tokenizer.rules['e.g.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c760575c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy sentencizer\n",
    "# spacy_sentencized = []\n",
    "\n",
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     for job_description in job_descriptions:\n",
    "#         for sentence in nlp(job_description).sents:\n",
    "#             for sent in re.split(pattern, sentence.text):\n",
    "#                 if len(sent) != 0:\n",
    "#                     spacy_sentencized.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f0ea7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy sentencizer\n",
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    spacy_sentencized = [\n",
    "        sent \n",
    "        for job_description in job_descriptions \n",
    "        for sentence in nlp(job_description).sents \n",
    "        for sent in re.split(pattern, sentence.text) \n",
    "        if len(sent) != 0 \n",
    "    ]\n",
    "    \n",
    "    spacy_sentencized_lower = [\n",
    "        str(sent.strip().lower()) \n",
    "        for sent in spacy_sentencized\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "266c373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy sentencizer\n",
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     spacy_sentencized = [\n",
    "#         re.split(pattern, sentence.text) \n",
    "#         for job_description in job_descriptions \n",
    "#         for sentence in nlp(job_description).sents \n",
    "# #         for sent in re.split(pattern, sentence.text) \n",
    "#         if len(sentence) != 0 \n",
    "#     ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5d6eff4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Conduct engagement reviews.'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_sentencized[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa78330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy tokenizer\n",
    "# spacy_tokenized = []\n",
    "\n",
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     for job_sentence in spacy_sentencized:\n",
    "#         for token in nlp.tokenizer(job_sentence):\n",
    "#             if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars:\n",
    "#                 spacy_tokenized.append(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "78f574e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spacy_sentencized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b715ec90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacy_sentencized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6ce53cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(spacy_sentencized):\n",
    "    if str_fix_eg in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c222370e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(idx for idx, sent in enumerate(spacy_sentencized) if str_fix_eg in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a454eeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "# str_fix = 'Apply appropriate and effective communication methods to senior management and important stakeholders \\(incl.'\n",
    "\n",
    "\n",
    "for idx, sent in enumerate(spacy_sentencized):\n",
    "    if str_fix_incl.split('\\(')[0] in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bd2a7d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(idx for idx, sent in enumerate(spacy_sentencized) if str_fix_incl.split('\\(')[0] in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c515eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apply appropriate and effective communication methods to senior management and important stakeholders throughout the project lifecycle.',\n",
       " 'As conflicts and escalations arise within projects, identify solutions and drive their resolution in a timely and appropriate manner.',\n",
       " 'Manage change within projects and ensure changes are smoothly and successfully implemented to achieve lasting benefits.',\n",
       " 'Project Controlling',\n",
       " 'Manage project controlling as an independent element to ensure that actual project costs are in line the committed budget.',\n",
       " 'Conduct engagement reviews.',\n",
       " 'Verify compliance with quality assurance procedures.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_sentencized[18:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d97282ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "for idx, sent in enumerate(spacy_sentencized):\n",
    "    if 'Power' in sent:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2147d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(idx for idx, sent in enumerate(spacy_sentencized) if 'Power' in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b314b701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Strong MS-Office skills (Word, Excel, PowerPoint)'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_sentencized[63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5dcf1dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Apply appropriate and effective communication methods to senior management and important stakeholders throughout the project lifecycle.\n",
      "\n",
      "Sentence 2: As conflicts and escalations arise within projects, identify solutions and drive their resolution in a timely and appropriate manner.\n",
      "\n",
      "Sentence 3: Manage change within projects and ensure changes are smoothly and successfully implemented to achieve lasting benefits.\n",
      "\n",
      "Sentence 4: Project Controlling\n",
      "\n",
      "Sentence 5: Manage project controlling as an independent element to ensure that actual project costs are in line the committed budget.\n",
      "\n",
      "Sentence 6: Conduct engagement reviews.\n",
      "\n",
      "Sentence 7: Verify compliance with quality assurance procedures.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(spacy_sentencized[18:25]):\n",
    "    print(f'Sentence {idx+1}: {sentence}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "869b4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy tokenizer\n",
    "# spacy_tokenized = []\n",
    "\n",
    "# for job_sentence in spacy_sentencized:\n",
    "# #         doc = nlp.tokenizer(job_sentence)\n",
    "#     spacy_tokenized.extend(\n",
    "#         [\n",
    "#             token.text for token in nlp.tokenizer(job_sentence) \n",
    "#             if token.text not in custom_punct_chars\n",
    "#             and not token.is_stop \n",
    "\n",
    "#         ]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2eeddf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spacy_sentencized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "78d95615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Key Responsibilities'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_sentencized[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8d84b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy tokenizer\n",
    "\n",
    "spacy_tokenized = [\n",
    "    str(token.text.strip().lower()) \n",
    "    for job_sentence in spacy_sentencized \n",
    "    for token in nlp.tokenizer(job_sentence) \n",
    "    if len(token) != 0 \n",
    "    and not token.is_stop \n",
    "    and not token.is_punct \n",
    "    and not token.text in custom_punct_chars\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c5f6eb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacy_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c9a630b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['purpose',\n",
       " 'manager',\n",
       " 'digital',\n",
       " 'strategy',\n",
       " 'programs',\n",
       " 'adidas',\n",
       " 'market',\n",
       " 'ecom',\n",
       " 'organization',\n",
       " 'task']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tokenized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e6dcfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp.get_pipe('attribute_ruler').add([[{\"TEXT\":\"Angeltown\"}]],{\"LEMMA\":\"San Fransisco\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "91acafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spacy pos tagging\n",
    "# nlp_stemmer = LancasterStemmer()\n",
    "# nlp_stemmer = PorterStemmer()\n",
    "\n",
    "nlp_token_tags = []\n",
    "nlp_lemmas = []\n",
    "nlp_stems = []\n",
    "\n",
    "for job_description in job_descriptions:\n",
    "    for token in nlp(job_description):\n",
    "        if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars:\n",
    "            nlp_token_tags.append(tuple([token.text, token.tag_]))\n",
    "            nlp_lemmas.append(token.lemma_)\n",
    "            nlp_stems.append(stemmer.stem(token.text))\n",
    "#         for sentence in doc.sents:\n",
    "#             for sent in re.split(pattern, sentence.text):\n",
    "#                 if len(sent) != 0:\n",
    "#                     spacy_sentencized.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "84b610ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "#     nlp_token_tags = [\n",
    "#         tuple([token.text, token.tag_]) \n",
    "#         for job_description in job_descriptions \n",
    "#         for token in nlp(job_description) \n",
    "#         if len(token) != 0 \n",
    "#         and not token.is_stop \n",
    "#         and not token.is_punct \n",
    "#         and not token.text in custom_punct_chars\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "366d6b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_num_and_frequency(row, text_col):\n",
    "\n",
    "    row['num_words'] = len(str(row[f'{text_col}']).split())\n",
    "    row['num_unique_words'] = len(set(str(row[f'{text_col}']).split()))\n",
    "    row['num_chars'] = len(str(row[f'{text_col}']))\n",
    "    row['num_punctuations'] = len([c for c in str(row[f'{text_col}']) if c in string.punctuation])\n",
    "\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2ab5cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in spacy_sentencized:\n",
    "    num_words = len(sent.split())\n",
    "    num_unique_words = len(set(sent.split()))\n",
    "    num_chars = len(sent)\n",
    "    num_punctuations = len([c for c in sent if c in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a2e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(df_jobs_to_be_processed, text_col, algo='vader', sentiment_range=(-1,1)):\n",
    "\n",
    "    ## calculate sentiment\n",
    "    if algo == 'vader':\n",
    "        df_jobs_to_be_processed['sentiment'] = df_jobs_to_be_processed[text_col].progress_apply(lambda x: SentimentIntensityAnalyzer().polarity_scores(x)['compound'] if isinstance(x, str) else np.nan)\n",
    "    elif algo == 'textblob':\n",
    "        df_jobs_to_be_processed['sentiment'] = df_jobs_to_be_processed[text_col].progress_apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    ## rescaled\n",
    "    if sentiment_range != (-1,1):\n",
    "        df_jobs_to_be_processed['sentiment'] = preprocessing.MinMaxScaler(feature_range=sentiment_range).fit_transform(df_jobs_to_be_processed[['sentiment']])\n",
    "    # print(df_jobs_to_be_processed[['sentiment']].describe().T)\n",
    "\n",
    "    return df_jobs_to_be_processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1cb854ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.2023\n",
      "0.0\n",
      "0.0\n",
      "0.4215\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8442\n",
      "0.3818\n",
      "0.2023\n",
      "0.4588\n",
      "0.0\n",
      "0.4019\n",
      "0.0\n",
      "0.0\n",
      "0.5994\n",
      "-0.2263\n",
      "0.8126\n",
      "0.0\n",
      "0.5719\n",
      "0.4588\n",
      "0.34\n",
      "0.3612\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-0.128\n",
      "-0.128\n",
      "0.0\n",
      "0.8402\n",
      "0.4404\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.1779\n",
      "0.4215\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.296\n",
      "0.25\n",
      "0.0\n",
      "0.4404\n",
      "0.3182\n",
      "0.0\n",
      "0.4404\n",
      "0.0\n",
      "0.743\n",
      "0.0\n",
      "0.0\n",
      "0.4215\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.4019\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.4215\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6369\n",
      "0.0\n",
      "0.0\n",
      "0.5719\n",
      "0.0\n",
      "0.4019\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5994\n",
      "-0.2263\n",
      "0.8807\n",
      "0.0\n",
      "0.5719\n",
      "0.4588\n",
      "0.34\n",
      "0.3818\n",
      "0.0\n",
      "0.0\n",
      "0.8225\n",
      "0.6369\n",
      "0.3818\n",
      "0.0\n",
      "0.4404\n",
      "0.0\n",
      "0.0\n",
      "0.3818\n",
      "0.4215\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.4215\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.296\n",
      "0.0\n",
      "0.0\n",
      "0.4927\n",
      "0.3182\n",
      "0.3182\n",
      "0.5859\n",
      "0.0\n",
      "0.4404\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.743\n",
      "0.3182\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Sentiment\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "for sent in spacy_sentencized:\n",
    "    print(vader.polarity_scores(sent)['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2dd6c882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.025\n",
      "0.0\n",
      "0.0\n",
      "-0.10000000000000002\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-0.08333333333333333\n",
      "0.0\n",
      "0.6666666666666666\n",
      "0.4\n",
      "-0.125\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.3833333333333333\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.45\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-0.4\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03333333333333333\n",
      "0.1\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-0.05555555555555555\n",
      "0.0\n",
      "0.0\n",
      "0.2333333333333333\n",
      "0.0\n",
      "0.0\n",
      "0.7\n",
      "0.0\n",
      "0.4333333333333333\n",
      "0.03125\n",
      "0.5\n",
      "0.9\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.35714285714285715\n",
      "0.175\n",
      "0.0\n",
      "0.0\n",
      "-0.10000000000000002\n",
      "0.0\n",
      "0.0\n",
      "0.35\n",
      "0.0\n",
      "0.0\n",
      "0.10000000000000002\n",
      "0.0\n",
      "0.13636363636363635\n",
      "0.375\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "0.5\n",
      "0.2875\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.3333333333333333\n",
      "0.5\n",
      "0.06666666666666667\n",
      "0.0\n",
      "0.5\n",
      "0.0\n",
      "0.015625\n",
      "0.015625\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.45\n",
      "0.0\n",
      "0.05\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-0.05555555555555555\n",
      "0.0\n",
      "0.0\n",
      "0.3033333333333333\n",
      "0.0\n",
      "-0.3\n",
      "0.16\n",
      "0.0\n",
      "0.7\n",
      "0.1\n",
      "0.0\n",
      "0.0\n",
      "0.4333333333333333\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# # Sentiment\n",
    "# from textblob import TextBlob, Word\n",
    "\n",
    "# for sent in spacy_sentencized:\n",
    "#     print(TextBlob(sent).sentiment.polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy sentencizer\n",
    "# spacy_sentencized = []\n",
    "\n",
    "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
    "    for job_description in job_descriptions:\n",
    "        for token in nlp(job_description):\n",
    "            print(token.text, token.tag_)\n",
    "#             for sent in re.split(pattern, sentence.text):\n",
    "#                 if len(sent) != 0:\n",
    "#                     spacy_sentencized.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526da0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "bigram_rules = [\n",
    "    ['VERB', 'ADJ', 'NOUN'],\n",
    "    ['NOUN', 'VERB', 'ADV'],\n",
    "    ['NOUN', 'ADP', 'NOUN'],\n",
    "    # more rules here...\n",
    "]\n",
    "\n",
    "rules = [\n",
    "    ['VERB', 'ADJ', 'NOUN'],\n",
    "    ['NOUN', 'VERB', 'ADV'],\n",
    "    ['NOUN', 'ADP', 'NOUN'],\n",
    "    # more rules here...\n",
    "]\n",
    "\n",
    "trigram_patterns = [[{\"POS\": i} for i in j] for j in rules]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2de96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "    'noun_verb': [{'POS': 'NOUN'}, {'POS': 'VERB'}],\n",
    "    'verb_noun': [{'POS': 'VERB'}, {'POS': 'NOUN'}],\n",
    "    'adj_noun': [{'POS': 'ADJ'}, {'POS': 'NOUN'}],\n",
    "    'adj_propn': [{'POS': 'ADJ'}, {'POS': 'PROPN'}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pattern_name, pattern in patterns.items():\n",
    "    matcher.add(pattern_name, [pattern])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e002bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_description in job_descriptions:\n",
    "    doc = nlp(job_description)\n",
    "    matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_id, start, end in matches:\n",
    "    \n",
    "    # Get string representation\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "\n",
    "    # The matched span\n",
    "    span = doc[start:end]\n",
    "    \n",
    "    print(repr(span.text))\n",
    "    print(match_id, string_id, start, end)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e73cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6595ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence in spacy_sentencized:\n",
    "#     print(model.encode(sentence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.electra.modeling_tf_electra import TFElectraMainLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"pavanchhatpar/electra-base-sentence-splitter\")\n",
    "\n",
    "model = AutoModelForPreTraining.from_pretrained(\"pavanchhatpar/electra-base-sentence-splitter\", from_tf=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ee3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline('sentence-splitter', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8d4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "study1_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
