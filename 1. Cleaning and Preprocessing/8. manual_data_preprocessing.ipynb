{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a3d9bbd5",
            "metadata": {},
            "source": [
                "# ATTN: This script uses Google translate to detect job description language. Google translate will limit requests and take a very long time. Only run this script if redoing language detection."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ac2e2d85",
            "metadata": {},
            "source": [
                "# Read from scrapped data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "be8129d5",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "d2271ddb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using MPS\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "76fd03e89cfd4d2793f6c9f41f909bb4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "0it [00:00, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 640x480 with 0 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a840ebcc",
            "metadata": {},
            "source": [
                "#### Read paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "999bbb1d",
            "metadata": {},
            "outputs": [],
            "source": [
                "glob_paths = list(set(glob.glob(f'{scraped_data}Coding Material/*Folder/*/Job ID -*- Codebook (Automating Equity).xlsx')))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "4ad7c36f",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "244"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 244 xlsx files\n",
                "len(glob_paths)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fbfdd650",
            "metadata": {},
            "source": [
                "#### Use paths to open files, fix keywords, and drop unneeded columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "9f2edb5d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 5.59 s, sys: 118 ms, total: 5.71 s\n",
                        "Wall time: 5.91 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# columns\n",
                "cols=['Sector', \n",
                "      'Sector Code', \n",
                "      'Gender', \n",
                "      'Age', \n",
                "      'Language', \n",
                "      'Dutch Requirement', \n",
                "      'English Requirement', \n",
                "      'Gender_Female', \n",
                "      'Gender_Mixed', \n",
                "      'Gender_Male', \n",
                "      'Age_Older', \n",
                "      'Age_Mixed', \n",
                "      'Age_Younger', \n",
                "      'Gender_Num', \n",
                "      'Age_Num', \n",
                "      '% Female', \n",
                "      '% Male', \n",
                "      '% Older', \n",
                "      '% Younger']\n",
                "\n",
                "# Fix list catches all incorrect/faculty keyword search terms\n",
                "fix_list = []\n",
                "\n",
                "# Appended data catches all the fixed and cleaned dfs\n",
                "appended_data = []\n",
                "\n",
                "for glob_path in glob_paths:\n",
                "\n",
                "    try:\n",
                "        df_temp = pd.read_excel(glob_path).reset_index(drop=True)\n",
                "    except ValueError:\n",
                "        fix_list.append(glob_path)\n",
                "\n",
                "    if len(df_temp) > 0 and isinstance(df_temp, pd.DataFrame):\n",
                "        df_temp = df_temp.reset_index(drop=True)\n",
                "        df_temp = df_temp.drop(columns=cols, axis='columns', errors='ignore')\n",
                "        df_temp = df_temp.drop(\n",
                "        df_temp.columns[\n",
                "                df_temp.columns.str.contains(\n",
                "                    'unnamed|index|level', regex=True, case=False, flags=re.I\n",
                "                )\n",
                "            ],\n",
                "            axis='columns',\n",
                "            errors='ignore',\n",
                "        )\n",
                "\n",
                "        appended_data.append(df_temp.reset_index(drop=True))\n",
                "\n",
                "# Concatonate list of dfs into one large df_manual\n",
                "df_manual = pd.concat(appended_data, axis='index').reset_index(drop=True)\n",
                "\n",
                "# Save df_manual to file\n",
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_raw.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_raw.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "5de12303",
            "metadata": {},
            "outputs": [],
            "source": [
                "# If we couldn't fix some keywords, we add them to list fix_list and write to file\n",
                "if len(fix_list) != 0:\n",
                "    print('Some keywords to fix!')\n",
                "    with open(f'{data_dir}fix_list.txt', 'w') as f:\n",
                "        json.dump(fix_list, f)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "ae1a9362",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "244"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# List of dfs, len = 244\n",
                "len(appended_data)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "78c1c60f",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Concatonate list of dfs into one large df_manual\n",
                "df_manual = pd.concat(appended_data, axis='index').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "47b014ea",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "12400"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# len = 12400\n",
                "len(df_manual)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "0a4606db",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save df_manual to file\n",
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_raw.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_raw.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3eb6e2dd",
            "metadata": {},
            "source": [
                "# Drop duplicated and missing data"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bc049d41",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_RAW\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "eda9efcf",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "4b7e42cc",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "a080272c",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_raw.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "e92eeb12",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "12400"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# len = 12400\n",
                "len(df_manual)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "78c31c26",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 12400 entries, 0 to 12399\n",
                        "Data columns (total 7 columns):\n",
                        " #   Column           Non-Null Count  Dtype  \n",
                        "---  ------           --------------  -----  \n",
                        " 0   Job ID           12400 non-null  object \n",
                        " 1   Sentence         12396 non-null  object \n",
                        " 2   Warmth           12398 non-null  float64\n",
                        " 3   Competence       12400 non-null  int64  \n",
                        " 4   Task_Mentioned   12398 non-null  float64\n",
                        " 5   Task_Warmth      12398 non-null  float64\n",
                        " 6   Task_Competence  12398 non-null  float64\n",
                        "dtypes: float64(4), int64(1), object(2)\n",
                        "memory usage: 678.2+ KB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "1b37b39d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a1b5947b180e40b78e7c02f83b8efb61",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/7 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Clean columns\n",
                "df_manual.columns = df_manual.columns.to_series().progress_apply(lambda x: str(x).strip())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "8571e7f7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove columns 'Task_Mentioned', 'Task_Warmth', 'Task_Competence'\n",
                "df_manual = df_manual.drop(\n",
                "    columns=['Task_Mentioned', 'Task_Warmth', 'Task_Competence'],\n",
                "    axis='columns',\n",
                "    errors='ignore'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "bfef72ba",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 12400 entries, 0 to 12399\n",
                        "Data columns (total 4 columns):\n",
                        " #   Column      Non-Null Count  Dtype  \n",
                        "---  ------      --------------  -----  \n",
                        " 0   Job ID      12400 non-null  object \n",
                        " 1   Sentence    12396 non-null  object \n",
                        " 2   Warmth      12398 non-null  float64\n",
                        " 3   Competence  12400 non-null  int64  \n",
                        "dtypes: float64(1), int64(1), object(2)\n",
                        "memory usage: 387.6+ KB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "2044253e",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Job ID        0\n",
                            "Sentence      4\n",
                            "Warmth        2\n",
                            "Competence    0\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Missing values: Sentence = 4, Warmth = 2, Competence = 0\n",
                "df_manual.isna().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "46ab64d1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop NA\n",
                "df_manual = df_manual.dropna(axis='index', how='all')\n",
                "df_manual = df_manual.dropna(axis='columns', how='all')\n",
                "df_manual = df_manual.dropna(\n",
                "    subset = ['Sentence', 'Warmth', 'Competence'],\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "b539d479",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Job ID        0\n",
                            "Sentence      0\n",
                            "Warmth        0\n",
                            "Competence    0\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# No na values\n",
                "df_manual.isna().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "82e2a312",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['Job ID', 'Sentence', 'Warmth', 'Competence'], dtype='object')"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual.columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "1c5a7d46",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7e2a4e8426894cada23315560e4e4e06",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/12394 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Warmth converted to int.\n",
                        "Warmth value counts:\n",
                        "0    9568\n",
                        "1    2826\n",
                        "Name: Warmth, dtype: int64\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cc049be58d7d487a9bc75d3c122d994c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/12394 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Competence converted to int.\n",
                        "Competence value counts:\n",
                        "0    7330\n",
                        "1    5064\n",
                        "Name: Competence, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# Convert Warmth and Competence to int\n",
                "int_cols = [\n",
                "    'Warmth',\n",
                "    'Competence',\n",
                "]\n",
                "\n",
                "for col in int_cols:\n",
                "    df_manual[col] = df_manual[col].astype(np.int64, errors='ignore')\n",
                "    print(f'{col} converted to int.' if all(df_manual[col].progress_apply(lambda x: isinstance(x, int))) else f'{col} NOT converted to int.')\n",
                "    print(f'{col} value counts:\\n{df_manual[col].value_counts()}')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "a7666d35",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Int64Index: 12394 entries, 0 to 12399\n",
                        "Data columns (total 4 columns):\n",
                        " #   Column      Non-Null Count  Dtype \n",
                        "---  ------      --------------  ----- \n",
                        " 0   Job ID      12394 non-null  object\n",
                        " 1   Sentence    12394 non-null  object\n",
                        " 2   Warmth      12394 non-null  int64 \n",
                        " 3   Competence  12394 non-null  int64 \n",
                        "dtypes: int64(2), object(2)\n",
                        "memory usage: 484.1+ KB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "793c8461",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0dd505acc52d49c99d0f64f8532a9013",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/12394 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cf3bcfb4756e461aa58fe009e7c774a3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/12394 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Job ID converted to str.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d5c016c63f7e4cfca6b3cdd3f89180bd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/12394 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "fef061e8f8264725a779d674332839ba",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/12394 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sentence converted to str.\n",
                        "CPU times: user 65.1 ms, sys: 5.85 ms, total: 70.9 ms\n",
                        "Wall time: 96.3 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Conver Job ID and Sentence to str\n",
                "str_cols = [\n",
                "    'Job ID',\n",
                "    'Sentence',\n",
                "]\n",
                "\n",
                "for col in str_cols:\n",
                "    df_manual[col] = df_manual[col].astype(str, errors='ignore').progress_apply(lambda x: x.strip().replace('[', '').replace(']', ''))\n",
                "    print(f'{col} converted to str.' if all(df_manual[col].progress_apply(lambda x: isinstance(x, str))) else f'{col} NOT converted to str.')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "e8d0d7a5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove any rows with missing 'Job ID'\n",
                "df_manual = df_manual.drop(\n",
                "    df_manual[\n",
                "        (df_manual['Sentence'].isin(nan_list)) | \n",
                "        (df_manual['Sentence'].isnull()) | \n",
                "        (df_manual['Sentence'].isna())\n",
                "    ].index, \n",
                "    axis='index',\n",
                "    errors='ignore'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "2286ff2e",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = df_manual.drop_duplicates(subset=['Sentence'], keep='first', ignore_index=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "a5caf8c5",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "5681"
                        ]
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# len = 5681\n",
                "len(df_manual)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "4d2cacdb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5681 entries, 0 to 5680\n",
                        "Data columns (total 4 columns):\n",
                        " #   Column      Non-Null Count  Dtype \n",
                        "---  ------      --------------  ----- \n",
                        " 0   Job ID      5681 non-null   object\n",
                        " 1   Sentence    5681 non-null   object\n",
                        " 2   Warmth      5681 non-null   int64 \n",
                        " 3   Competence  5681 non-null   int64 \n",
                        "dtypes: int64(2), object(2)\n",
                        "memory usage: 177.7+ KB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "e57a9f32",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Rename Sentence to 'Job Description spacy_sentencized'\n",
                "df_manual = df_manual.rename(\n",
                "    columns = {\n",
                "        'Sentence': 'Job Description spacy_sentencized'\n",
                "    },\n",
                "    errors='ignore'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "1a32f64c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['Job ID', 'Job Description spacy_sentencized', 'Warmth', 'Competence'], dtype='object')"
                        ]
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual.columns\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "3fb59e5d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop NA\n",
                "df_manual = df_manual.dropna(axis='index', how='all')\n",
                "df_manual = df_manual.dropna(axis='columns', how='all')\n",
                "df_manual = df_manual.dropna(\n",
                "    subset = ['Job Description spacy_sentencized', 'Warmth', 'Competence'],\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "25218a8b",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "5681"
                        ]
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# len = 5681\n",
                "len(df_manual)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "id": "025e7b62",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "126"
                        ]
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# len = 126\n",
                "len(df_manual.groupby(['Job ID'])['Job ID'].unique())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "e3126f47",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop duplicates on subset of 'Job Description'\n",
                "df_manual = df_manual.drop_duplicates(subset=['Job Description spacy_sentencized'], keep='first', ignore_index=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "id": "67baaa73",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "5681"
                        ]
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# len = 5681\n",
                "len(df_manual)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "id": "3ec0bc22",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove any rows with missing 'Job ID'\n",
                "df_manual = df_manual.drop(\n",
                "    df_manual[\n",
                "        (df_manual['Job ID'].isin(nan_list)) | \n",
                "        (df_manual['Job ID'].isnull()) | \n",
                "        (df_manual['Job ID'].isna())\n",
                "    ].index, \n",
                "    axis='index',\n",
                "    errors='ignore'\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "id": "c7a71aef",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove any rows with missing 'Job Description'\n",
                "df_manual = df_manual.drop(\n",
                "    df_manual[\n",
                "        (df_manual['Job Description spacy_sentencized'].isin(nan_list)) | \n",
                "        (df_manual['Job Description spacy_sentencized'].isnull()) | \n",
                "        (df_manual['Job Description spacy_sentencized'].isna())\n",
                "    ].index, \n",
                "    axis='index',\n",
                "    errors='ignore'\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "id": "21a098a0",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "5681"
                        ]
                    },
                    "execution_count": 39,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# len = 5681\n",
                "len(df_manual)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "id": "19e08303",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save df_manual to file\n",
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_raw_dropped.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_raw_dropped.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3bae0b99",
            "metadata": {},
            "source": [
                "# Add English and Dutch language requirement columns"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eb838f06",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_RAW_DROPPED\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "id": "489a38aa",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "id": "f7cda531",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "id": "a13ef5b9",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_raw_dropped.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "id": "3b5aa5a8",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "5681"
                        ]
                    },
                    "execution_count": 44,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 5681\n",
                "len(df_manual)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "id": "e2e2a0c6",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5681 entries, 0 to 5680\n",
                        "Data columns (total 4 columns):\n",
                        " #   Column                             Non-Null Count  Dtype \n",
                        "---  ------                             --------------  ----- \n",
                        " 0   Job ID                             5681 non-null   object\n",
                        " 1   Job Description spacy_sentencized  5681 non-null   object\n",
                        " 2   Warmth                             5681 non-null   int64 \n",
                        " 3   Competence                         5681 non-null   int64 \n",
                        "dtypes: int64(2), object(2)\n",
                        "memory usage: 177.7+ KB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "id": "8418d404",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 62 ms, sys: 2.33 ms, total: 64.4 ms\n",
                        "Wall time: 63.6 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Add language requirement column\n",
                "# Use regex to find language requirement\n",
                "dutch_requirement_pattern = r'[Ll]anguage: [Dd]utch|[Dd]utch [Pp]referred|[Dd]utch [Re]quired|[Dd]utch [Ll]anguage|[Pp]roficient in [Dd]utch|[Ss]peak [Dd]utch|[Kk]now [Dd]utch'\n",
                "english_requirement_pattern = r'[Ll]anguage: [Ee]nglish|[Ee]nglish [Pp]referred|[Ee]nglish [Re]quired|[Ee]nglish [Ll]anguage|[Pp]roficient in [Ee]nglish|[Ss]peak [Ee]nglish|[Kk]now [Ee]nglish'\n",
                "\n",
                "lang_requirements = {\n",
                "    'Dutch Requirement': dutch_requirement_pattern, 'English Requirement': english_requirement_pattern\n",
                "}\n",
                "\n",
                "for lang_req, lang_req_pattern in lang_requirements.items():\n",
                "\n",
                "    if lang_req in df_manual.columns:\n",
                "        df_manual = df_manual.drop(columns=[lang_req])\n",
                "    df_manual[lang_req] = np.where(\n",
                "        df_manual['Job Description spacy_sentencized'].str.contains(lang_req_pattern),\n",
                "        1,\n",
                "        0,\n",
                "    )\n",
                "\n",
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_raw_language_requirement.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_raw_english_requirement.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "id": "33b1e721",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Dutch Requirement  English Requirement\n",
                            "0                  0                      5667\n",
                            "                   1                         8\n",
                            "1                  0                         6\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 47,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Dutch Yes = 6, English Yes = 8\n",
                "df_manual[['Dutch Requirement', 'English Requirement']].value_counts()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "id": "5c3ddedd",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_raw_language_requirement.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_raw_language_requirement.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e79cea97",
            "metadata": {},
            "source": [
                "# Add data from Sectors dataframe (see CBS directory under scrapped_data directory) and Categorical data\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "69513116",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_RAW_LANGUAGE_REQUIREMENT\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "id": "10b32849",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "id": "875fd370",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "id": "6873d7c6",
            "metadata": {},
            "outputs": [],
            "source": [
                "def df_gender_age_info(df, ivs_all=None):\n",
                "    if ivs_all is None:\n",
                "        ivs_all = [\n",
                "            'Gender',\n",
                "            'Gender_Num',\n",
                "            'Gender_Female',\n",
                "            'Gender_Mixed',\n",
                "            'Gender_Male',\n",
                "            'Age',\n",
                "            'Age_Num',\n",
                "            'Age_Older',\n",
                "            'Age_Mixed',\n",
                "            'Age_Younger',\n",
                "        ]\n",
                "    # Print Info\n",
                "    print('\\nDF INFO:\\n')\n",
                "    df.info()\n",
                "\n",
                "    for iv in ivs_all:\n",
                "        try:\n",
                "            counts = df[iv].value_counts()\n",
                "            percentages = df[iv].value_counts(normalize=True).mul(100).round(1).astype(float)\n",
                "            print('='*20)\n",
                "            print(f'{iv}:')\n",
                "            print('-'*20)\n",
                "            print(f'{iv} Counts:\\n{counts}')\n",
                "            print('-'*20)\n",
                "            print(f'{iv} Percentages:\\n{percentages}')\n",
                "\n",
                "            with contextlib.suppress(Exception):\n",
                "                mean = df[f\"{iv}\"].mean().round(2).astype(float)\n",
                "                sd = df[f\"{iv}\"].std().round(2).astype(float)\n",
                "                print('-'*20)\n",
                "                print(f'{iv} Mean: {mean}')\n",
                "                print('-'*20)\n",
                "                print(f'{iv} Standard Deviation: {sd}')\n",
                "\n",
                "        except Exception:\n",
                "            print(f'{iv} not available.')\n",
                "\n",
                "    print('\\n')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "id": "79fe759f",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_raw_language_requirement.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "id": "40156303",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5681 entries, 0 to 5680\n",
                        "Data columns (total 6 columns):\n",
                        " #   Column                             Non-Null Count  Dtype \n",
                        "---  ------                             --------------  ----- \n",
                        " 0   Job ID                             5681 non-null   object\n",
                        " 1   Job Description spacy_sentencized  5681 non-null   object\n",
                        " 2   Warmth                             5681 non-null   int64 \n",
                        " 3   Competence                         5681 non-null   int64 \n",
                        " 4   Dutch Requirement                  5681 non-null   int64 \n",
                        " 5   English Requirement                5681 non-null   int64 \n",
                        "dtypes: int64(4), object(2)\n",
                        "memory usage: 266.4+ KB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "id": "db503aad",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f103cccd850244ceadd2f997fee01512",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5681 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "df_manual['Job ID'] = df_manual['Job ID'].progress_apply(lambda x: str(x).lower().strip())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "id": "98694f16",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_including_sector_genage_data.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "id": "8d5116df",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 17599 entries, 0 to 17598\n",
                        "Data columns (total 60 columns):\n",
                        " #   Column                               Non-Null Count  Dtype   \n",
                        "---  ------                               --------------  -----   \n",
                        " 0   Search Keyword                       17599 non-null  object  \n",
                        " 1   Platform                             17599 non-null  category\n",
                        " 2   Job ID                               17599 non-null  object  \n",
                        " 3   Job Title                            17599 non-null  object  \n",
                        " 4   Company Name                         17597 non-null  object  \n",
                        " 5   Location                             17599 non-null  object  \n",
                        " 6   Job Description                      17599 non-null  object  \n",
                        " 7   Rating                               3780 non-null   float64 \n",
                        " 8   Employment Type                      17017 non-null  object  \n",
                        " 9   Company URL                          15959 non-null  object  \n",
                        " 10  Job URL                              17599 non-null  object  \n",
                        " 11  Job Age                              17599 non-null  object  \n",
                        " 12  Job Age Number                       17599 non-null  object  \n",
                        " 13  Collection Date                      17599 non-null  object  \n",
                        " 14  Data Row                             13816 non-null  float64 \n",
                        " 15  Tracking ID                          13816 non-null  object  \n",
                        " 16  Industry                             14401 non-null  object  \n",
                        " 17  Job Date                             13819 non-null  object  \n",
                        " 18  Type of ownership                    582 non-null    object  \n",
                        " 19  Language                             17599 non-null  object  \n",
                        " 20  Dutch Requirement                    17599 non-null  int64   \n",
                        " 21  English Requirement                  17599 non-null  int64   \n",
                        " 22  Sector Code                          17599 non-null  object  \n",
                        " 23  Sector                               17599 non-null  object  \n",
                        " 24  Keywords Count                       17599 non-null  float64 \n",
                        " 25  % per Sector                         17599 non-null  float64 \n",
                        " 26  % per Social Category                17599 non-null  float64 \n",
                        " 27  % per Workforce                      17599 non-null  float64 \n",
                        " 28  Gender_Female_n                      17599 non-null  float64 \n",
                        " 29  Gender_Female_% per Sector           17599 non-null  float64 \n",
                        " 30  Gender_Female_% per Social Category  17599 non-null  float64 \n",
                        " 31  Gender_Female_% per Workforce        17599 non-null  float64 \n",
                        " 32  Gender_Male_n                        17599 non-null  float64 \n",
                        " 33  Gender_Male_% per Sector             17599 non-null  float64 \n",
                        " 34  Gender_Male_% per Social Category    17599 non-null  float64 \n",
                        " 35  Gender_Male_% per Workforce          17599 non-null  float64 \n",
                        " 36  Gender                               17599 non-null  category\n",
                        " 37  Age_Older_n                          17599 non-null  float64 \n",
                        " 38  Age_Older_% per Sector               17599 non-null  float64 \n",
                        " 39  Age_Older_% per Social Category      17599 non-null  float64 \n",
                        " 40  Age_Older_% per Workforce            17599 non-null  float64 \n",
                        " 41  Age_Younger_n                        17599 non-null  float64 \n",
                        " 42  Age_Younger_% per Sector             17599 non-null  float64 \n",
                        " 43  Age_Younger_% per Social Category    17599 non-null  float64 \n",
                        " 44  Age_Younger_% per Workforce          17599 non-null  float64 \n",
                        " 45  Age                                  17599 non-null  category\n",
                        " 46  Sector_n                             17599 non-null  float64 \n",
                        " 47  % Sector per Workforce               17599 non-null  float64 \n",
                        " 48  Gender_Female                        17599 non-null  int64   \n",
                        " 49  Gender_Male                          17599 non-null  int64   \n",
                        " 50  Gender_Mixed                         17599 non-null  int64   \n",
                        " 51  Age_Mixed                            17599 non-null  int64   \n",
                        " 52  Age_Older                            17599 non-null  int64   \n",
                        " 53  Age_Younger                          17599 non-null  int64   \n",
                        " 54  Gender_Num                           17599 non-null  int64   \n",
                        " 55  Age_Num                              17599 non-null  int64   \n",
                        " 56  Platform_Num                         17599 non-null  int64   \n",
                        " 57  Platform_LinkedIn                    17599 non-null  int64   \n",
                        " 58  Platform_Indeed                      17599 non-null  int64   \n",
                        " 59  Platform_Glassdoor                   17599 non-null  int64   \n",
                        "dtypes: category(3), float64(24), int64(14), object(19)\n",
                        "memory usage: 7.7+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_jobs.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "id": "49391453",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9bf30c1b3ce541c39f714785cfb2501e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/17599 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "df_jobs['Job ID'] = df_jobs['Job ID'].progress_apply(lambda x: str(x).lower().strip())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "id": "f5aa6dcf",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name', 'Location', 'Job Description', 'Rating', 'Employment Type', 'Company URL', 'Job URL', 'Job Age', 'Job Age Number', 'Collection Date', 'Data Row', 'Tracking ID', 'Industry', 'Job Date', 'Type of ownership', 'Language', 'Dutch Requirement', 'English Requirement', 'Sector Code', 'Sector', 'Keywords Count', '% per Sector', '% per Social Category', '% per Workforce', 'Gender_Female_n', 'Gender_Female_% per Sector', 'Gender_Female_% per Social Category', 'Gender_Female_% per Workforce', 'Gender_Male_n', 'Gender_Male_% per Sector', 'Gender_Male_% per Social Category', 'Gender_Male_% per Workforce', 'Gender', 'Age_Older_n', 'Age_Older_% per Sector', 'Age_Older_% per Social Category', 'Age_Older_% per Workforce', 'Age_Younger_n', 'Age_Younger_% per Sector', 'Age_Younger_% per Social Category', 'Age_Younger_% per Workforce', 'Age', 'Sector_n', '% Sector per Workforce', 'Gender_Female', 'Gender_Male', 'Gender_Mixed', 'Age_Mixed', 'Age_Older', 'Age_Younger', 'Gender_Num', 'Age_Num', 'Platform_Num', 'Platform_LinkedIn', 'Platform_Indeed', 'Platform_Glassdoor'], dtype='object')"
                        ]
                    },
                    "execution_count": 58,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_jobs.columns\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "id": "82178d30",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = df_jobs.drop(\n",
                "    columns = [\n",
                "        'Job Description', 'Rating',\n",
                "        'Company URL', 'Job URL', 'Job Age', 'Job Age Number',\n",
                "        'Collection Date', 'Data Row', 'Tracking ID', 'Job Date',\n",
                "        'Type of ownership', 'Language', 'Dutch Requirement', 'English Requirement', \n",
                "    ],\n",
                "    errors='ignore'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "id": "9bba117b",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name', 'Location', 'Employment Type', 'Industry', 'Type of ownership', 'Sector Code', 'Sector', 'Keywords Count', '% per Sector', '% per Social Category', '% per Workforce', 'Gender_Female_n', 'Gender_Female_% per Sector', 'Gender_Female_% per Social Category', 'Gender_Female_% per Workforce', 'Gender_Male_n', 'Gender_Male_% per Sector', 'Gender_Male_% per Social Category', 'Gender_Male_% per Workforce', 'Gender', 'Age_Older_n', 'Age_Older_% per Sector', 'Age_Older_% per Social Category', 'Age_Older_% per Workforce', 'Age_Younger_n', 'Age_Younger_% per Sector', 'Age_Younger_% per Social Category', 'Age_Younger_% per Workforce', 'Age', 'Sector_n', '% Sector per Workforce', 'Gender_Female', 'Gender_Male', 'Gender_Mixed', 'Age_Mixed', 'Age_Older', 'Age_Younger', 'Gender_Num', 'Age_Num', 'Platform_Num', 'Platform_LinkedIn', 'Platform_Indeed', 'Platform_Glassdoor'], dtype='object')"
                        ]
                    },
                    "execution_count": 60,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_jobs.columns\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "id": "f11e0e01",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add sector and categorical data from df_jobs\n",
                "df_manual = df_manual.merge(df_jobs, on='Job ID', how='inner')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "id": "47f24060",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "5365"
                        ]
                    },
                    "execution_count": 62,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# len = 5298\n",
                "len(df_manual)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "id": "4fa2c4a7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Int64Index: 5365 entries, 0 to 5364\n",
                        "Data columns (total 52 columns):\n",
                        " #   Column                               Non-Null Count  Dtype   \n",
                        "---  ------                               --------------  -----   \n",
                        " 0   Job ID                               5365 non-null   object  \n",
                        " 1   Job Description spacy_sentencized    5365 non-null   object  \n",
                        " 2   Warmth                               5365 non-null   int64   \n",
                        " 3   Competence                           5365 non-null   int64   \n",
                        " 4   Dutch Requirement                    5365 non-null   int64   \n",
                        " 5   English Requirement                  5365 non-null   int64   \n",
                        " 6   Search Keyword                       5365 non-null   object  \n",
                        " 7   Platform                             5365 non-null   category\n",
                        " 8   Job Title                            5365 non-null   object  \n",
                        " 9   Company Name                         5365 non-null   object  \n",
                        " 10  Location                             5365 non-null   object  \n",
                        " 11  Employment Type                      5137 non-null   object  \n",
                        " 12  Industry                             228 non-null    object  \n",
                        " 13  Type of ownership                    228 non-null    object  \n",
                        " 14  Sector Code                          5365 non-null   object  \n",
                        " 15  Sector                               5365 non-null   object  \n",
                        " 16  Keywords Count                       5365 non-null   float64 \n",
                        " 17  % per Sector                         5365 non-null   float64 \n",
                        " 18  % per Social Category                5365 non-null   float64 \n",
                        " 19  % per Workforce                      5365 non-null   float64 \n",
                        " 20  Gender_Female_n                      5365 non-null   float64 \n",
                        " 21  Gender_Female_% per Sector           5365 non-null   float64 \n",
                        " 22  Gender_Female_% per Social Category  5365 non-null   float64 \n",
                        " 23  Gender_Female_% per Workforce        5365 non-null   float64 \n",
                        " 24  Gender_Male_n                        5365 non-null   float64 \n",
                        " 25  Gender_Male_% per Sector             5365 non-null   float64 \n",
                        " 26  Gender_Male_% per Social Category    5365 non-null   float64 \n",
                        " 27  Gender_Male_% per Workforce          5365 non-null   float64 \n",
                        " 28  Gender                               5365 non-null   category\n",
                        " 29  Age_Older_n                          5365 non-null   float64 \n",
                        " 30  Age_Older_% per Sector               5365 non-null   float64 \n",
                        " 31  Age_Older_% per Social Category      5365 non-null   float64 \n",
                        " 32  Age_Older_% per Workforce            5365 non-null   float64 \n",
                        " 33  Age_Younger_n                        5365 non-null   float64 \n",
                        " 34  Age_Younger_% per Sector             5365 non-null   float64 \n",
                        " 35  Age_Younger_% per Social Category    5365 non-null   float64 \n",
                        " 36  Age_Younger_% per Workforce          5365 non-null   float64 \n",
                        " 37  Age                                  5365 non-null   category\n",
                        " 38  Sector_n                             5365 non-null   float64 \n",
                        " 39  % Sector per Workforce               5365 non-null   float64 \n",
                        " 40  Gender_Female                        5365 non-null   int64   \n",
                        " 41  Gender_Male                          5365 non-null   int64   \n",
                        " 42  Gender_Mixed                         5365 non-null   int64   \n",
                        " 43  Age_Mixed                            5365 non-null   int64   \n",
                        " 44  Age_Older                            5365 non-null   int64   \n",
                        " 45  Age_Younger                          5365 non-null   int64   \n",
                        " 46  Gender_Num                           5365 non-null   int64   \n",
                        " 47  Age_Num                              5365 non-null   int64   \n",
                        " 48  Platform_Num                         5365 non-null   int64   \n",
                        " 49  Platform_LinkedIn                    5365 non-null   int64   \n",
                        " 50  Platform_Indeed                      5365 non-null   int64   \n",
                        " 51  Platform_Glassdoor                   5365 non-null   int64   \n",
                        "dtypes: category(3), float64(22), int64(16), object(11)\n",
                        "memory usage: 2.1+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "id": "40fa3bc0",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: center;\">\n",
                            "      <th></th>\n",
                            "      <th>Job ID</th>\n",
                            "      <th>Job Description spacy_sentencized</th>\n",
                            "      <th>Warmth</th>\n",
                            "      <th>Competence</th>\n",
                            "      <th>Dutch Requirement</th>\n",
                            "      <th>English Requirement</th>\n",
                            "      <th>Search Keyword</th>\n",
                            "      <th>Platform</th>\n",
                            "      <th>Job Title</th>\n",
                            "      <th>Company Name</th>\n",
                            "      <th>Location</th>\n",
                            "      <th>Employment Type</th>\n",
                            "      <th>Industry</th>\n",
                            "      <th>Type of ownership</th>\n",
                            "      <th>Sector Code</th>\n",
                            "      <th>Sector</th>\n",
                            "      <th>Keywords Count</th>\n",
                            "      <th>% per Sector</th>\n",
                            "      <th>% per Social Category</th>\n",
                            "      <th>% per Workforce</th>\n",
                            "      <th>Gender_Female_n</th>\n",
                            "      <th>Gender_Female_% per Sector</th>\n",
                            "      <th>Gender_Female_% per Social Category</th>\n",
                            "      <th>Gender_Female_% per Workforce</th>\n",
                            "      <th>Gender_Male_n</th>\n",
                            "      <th>Gender_Male_% per Sector</th>\n",
                            "      <th>Gender_Male_% per Social Category</th>\n",
                            "      <th>Gender_Male_% per Workforce</th>\n",
                            "      <th>Gender</th>\n",
                            "      <th>Age_Older_n</th>\n",
                            "      <th>Age_Older_% per Sector</th>\n",
                            "      <th>Age_Older_% per Social Category</th>\n",
                            "      <th>Age_Older_% per Workforce</th>\n",
                            "      <th>Age_Younger_n</th>\n",
                            "      <th>Age_Younger_% per Sector</th>\n",
                            "      <th>Age_Younger_% per Social Category</th>\n",
                            "      <th>Age_Younger_% per Workforce</th>\n",
                            "      <th>Age</th>\n",
                            "      <th>Sector_n</th>\n",
                            "      <th>% Sector per Workforce</th>\n",
                            "      <th>Gender_Female</th>\n",
                            "      <th>Gender_Male</th>\n",
                            "      <th>Gender_Mixed</th>\n",
                            "      <th>Age_Mixed</th>\n",
                            "      <th>Age_Older</th>\n",
                            "      <th>Age_Younger</th>\n",
                            "      <th>Gender_Num</th>\n",
                            "      <th>Age_Num</th>\n",
                            "      <th>Platform_Num</th>\n",
                            "      <th>Platform_LinkedIn</th>\n",
                            "      <th>Platform_Indeed</th>\n",
                            "      <th>Platform_Glassdoor</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>3768944208</td>\n",
                            "      <td>Were growing our Sales team for the EMEA Mark...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>social work activity</td>\n",
                            "      <td>Glassdoor</td>\n",
                            "      <td>Inbound Marketer</td>\n",
                            "      <td>Happeo</td>\n",
                            "      <td>Amsterdam</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>Ondernemingssoftware en netwerkoplossingen</td>\n",
                            "      <td>Privbedrijf</td>\n",
                            "      <td>Q</td>\n",
                            "      <td>Health and social work activities</td>\n",
                            "      <td>11.00</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>0.11</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>1208.00</td>\n",
                            "      <td>0.84</td>\n",
                            "      <td>0.10</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>224.00</td>\n",
                            "      <td>0.16</td>\n",
                            "      <td>0.02</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>Female</td>\n",
                            "      <td>661.00</td>\n",
                            "      <td>0.46</td>\n",
                            "      <td>0.06</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>770.00</td>\n",
                            "      <td>0.54</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>Mixed Age</td>\n",
                            "      <td>1433.00</td>\n",
                            "      <td>0.06</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>3768944208</td>\n",
                            "      <td>Are you looking for an adventure  one with bi...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>social work activity</td>\n",
                            "      <td>Glassdoor</td>\n",
                            "      <td>Inbound Marketer</td>\n",
                            "      <td>Happeo</td>\n",
                            "      <td>Amsterdam</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>Ondernemingssoftware en netwerkoplossingen</td>\n",
                            "      <td>Privbedrijf</td>\n",
                            "      <td>Q</td>\n",
                            "      <td>Health and social work activities</td>\n",
                            "      <td>11.00</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>0.11</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>1208.00</td>\n",
                            "      <td>0.84</td>\n",
                            "      <td>0.10</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>224.00</td>\n",
                            "      <td>0.16</td>\n",
                            "      <td>0.02</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>Female</td>\n",
                            "      <td>661.00</td>\n",
                            "      <td>0.46</td>\n",
                            "      <td>0.06</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>770.00</td>\n",
                            "      <td>0.54</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>Mixed Age</td>\n",
                            "      <td>1433.00</td>\n",
                            "      <td>0.06</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>3768944208</td>\n",
                            "      <td>Do you have experience closing B2B Saa</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>social work activity</td>\n",
                            "      <td>Glassdoor</td>\n",
                            "      <td>Inbound Marketer</td>\n",
                            "      <td>Happeo</td>\n",
                            "      <td>Amsterdam</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>Ondernemingssoftware en netwerkoplossingen</td>\n",
                            "      <td>Privbedrijf</td>\n",
                            "      <td>Q</td>\n",
                            "      <td>Health and social work activities</td>\n",
                            "      <td>11.00</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>0.11</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>1208.00</td>\n",
                            "      <td>0.84</td>\n",
                            "      <td>0.10</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>224.00</td>\n",
                            "      <td>0.16</td>\n",
                            "      <td>0.02</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>Female</td>\n",
                            "      <td>661.00</td>\n",
                            "      <td>0.46</td>\n",
                            "      <td>0.06</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>770.00</td>\n",
                            "      <td>0.54</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>Mixed Age</td>\n",
                            "      <td>1433.00</td>\n",
                            "      <td>0.06</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>3768944208</td>\n",
                            "      <td>S deals in the mid-market and enterprise space?</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>social work activity</td>\n",
                            "      <td>Glassdoor</td>\n",
                            "      <td>Inbound Marketer</td>\n",
                            "      <td>Happeo</td>\n",
                            "      <td>Amsterdam</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>Ondernemingssoftware en netwerkoplossingen</td>\n",
                            "      <td>Privbedrijf</td>\n",
                            "      <td>Q</td>\n",
                            "      <td>Health and social work activities</td>\n",
                            "      <td>11.00</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>0.11</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>1208.00</td>\n",
                            "      <td>0.84</td>\n",
                            "      <td>0.10</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>224.00</td>\n",
                            "      <td>0.16</td>\n",
                            "      <td>0.02</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>Female</td>\n",
                            "      <td>661.00</td>\n",
                            "      <td>0.46</td>\n",
                            "      <td>0.06</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>770.00</td>\n",
                            "      <td>0.54</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>Mixed Age</td>\n",
                            "      <td>1433.00</td>\n",
                            "      <td>0.06</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>3768944208</td>\n",
                            "      <td>Then you might be ready to become part of the ...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>social work activity</td>\n",
                            "      <td>Glassdoor</td>\n",
                            "      <td>Inbound Marketer</td>\n",
                            "      <td>Happeo</td>\n",
                            "      <td>Amsterdam</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>Ondernemingssoftware en netwerkoplossingen</td>\n",
                            "      <td>Privbedrijf</td>\n",
                            "      <td>Q</td>\n",
                            "      <td>Health and social work activities</td>\n",
                            "      <td>11.00</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>0.11</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>1208.00</td>\n",
                            "      <td>0.84</td>\n",
                            "      <td>0.10</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>224.00</td>\n",
                            "      <td>0.16</td>\n",
                            "      <td>0.02</td>\n",
                            "      <td>0.01</td>\n",
                            "      <td>Female</td>\n",
                            "      <td>661.00</td>\n",
                            "      <td>0.46</td>\n",
                            "      <td>0.06</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>770.00</td>\n",
                            "      <td>0.54</td>\n",
                            "      <td>0.05</td>\n",
                            "      <td>0.03</td>\n",
                            "      <td>Mixed Age</td>\n",
                            "      <td>1433.00</td>\n",
                            "      <td>0.06</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "     Job ID           Job Description spacy_sentencized           Warmth  Competence  Dutch Requirement  English Requirement     Search Keyword     Platform      Job Title     Company Name  Location  Employment Type                   Industry                  Type of ownership Sector Code               Sector                Keywords Count  % per Sector  % per Social Category  % per Workforce  Gender_Female_n  Gender_Female_% per Sector  Gender_Female_% per Social Category  Gender_Female_% per Workforce  Gender_Male_n  Gender_Male_% per Sector  Gender_Male_% per Social Category  Gender_Male_% per Workforce  Gender  Age_Older_n  Age_Older_% per Sector  Age_Older_% per Social Category  Age_Older_% per Workforce  Age_Younger_n  Age_Younger_% per Sector  Age_Younger_% per Social Category  Age_Younger_% per Workforce    Age      Sector_n  % Sector per Workforce  Gender_Female  Gender_Male  Gender_Mixed  Age_Mixed  Age_Older  Age_Younger  Gender_Num  Age_Num  Platform_Num  Platform_LinkedIn  Platform_Indeed  Platform_Glassdoor\n",
                            "0  3768944208  Were growing our Sales team for the EMEA Mark...     1         0              0                   0           social work activity  Glassdoor  Inbound Marketer    Happeo     Amsterdam        NaN       Ondernemingssoftware en netwerkoplossingen    Privbedrijf         Q      Health and social work activities      11.00           0.01              0.11                0.00           1208.00                  0.84                            0.10                              0.05                  224.00                0.16                          0.02                            0.01              Female    661.00              0.46                        0.06                          0.03                770.00                0.54                          0.05                            0.03              Mixed Age  1433.00            0.06                 1             0             0           1          0           0            0         1           2               0                 0                  1        \n",
                            "1  3768944208  Are you looking for an adventure  one with bi...     0         1              0                   0           social work activity  Glassdoor  Inbound Marketer    Happeo     Amsterdam        NaN       Ondernemingssoftware en netwerkoplossingen    Privbedrijf         Q      Health and social work activities      11.00           0.01              0.11                0.00           1208.00                  0.84                            0.10                              0.05                  224.00                0.16                          0.02                            0.01              Female    661.00              0.46                        0.06                          0.03                770.00                0.54                          0.05                            0.03              Mixed Age  1433.00            0.06                 1             0             0           1          0           0            0         1           2               0                 0                  1        \n",
                            "2  3768944208             Do you have experience closing B2B Saa     0         0              0                   0           social work activity  Glassdoor  Inbound Marketer    Happeo     Amsterdam        NaN       Ondernemingssoftware en netwerkoplossingen    Privbedrijf         Q      Health and social work activities      11.00           0.01              0.11                0.00           1208.00                  0.84                            0.10                              0.05                  224.00                0.16                          0.02                            0.01              Female    661.00              0.46                        0.06                          0.03                770.00                0.54                          0.05                            0.03              Mixed Age  1433.00            0.06                 1             0             0           1          0           0            0         1           2               0                 0                  1        \n",
                            "3  3768944208    S deals in the mid-market and enterprise space?     0         0              0                   0           social work activity  Glassdoor  Inbound Marketer    Happeo     Amsterdam        NaN       Ondernemingssoftware en netwerkoplossingen    Privbedrijf         Q      Health and social work activities      11.00           0.01              0.11                0.00           1208.00                  0.84                            0.10                              0.05                  224.00                0.16                          0.02                            0.01              Female    661.00              0.46                        0.06                          0.03                770.00                0.54                          0.05                            0.03              Mixed Age  1433.00            0.06                 1             0             0           1          0           0            0         1           2               0                 0                  1        \n",
                            "4  3768944208  Then you might be ready to become part of the ...     0         1              0                   0           social work activity  Glassdoor  Inbound Marketer    Happeo     Amsterdam        NaN       Ondernemingssoftware en netwerkoplossingen    Privbedrijf         Q      Health and social work activities      11.00           0.01              0.11                0.00           1208.00                  0.84                            0.10                              0.05                  224.00                0.16                          0.02                            0.01              Female    661.00              0.46                        0.06                          0.03                770.00                0.54                          0.05                            0.03              Mixed Age  1433.00            0.06                 1             0             0           1          0           0            0         1           2               0                 0                  1        "
                        ]
                    },
                    "execution_count": 64,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1d889ec9",
            "metadata": {},
            "source": [
                "#### Check if there is any missing sector data in the merged dataframe"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "id": "43ddadb7",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0"
                        ]
                    },
                    "execution_count": 65,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual['Sector'].isna().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "id": "cb5b9064",
            "metadata": {},
            "outputs": [],
            "source": [
                "if df_manual['Sector'].isna().sum() != 0:\n",
                "    print('Some search keywords did not match a sector. Fixing')\n",
                "    print(set(df_manual['Search Keyword'].loc[df_manual['Sector'].isna()].to_list()))\n",
                "    print(len(df_manual['Search Keyword'].loc[df_manual['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n",
                "    df_manual = fix_keywords(df_manual)\n",
                "    print(set(df_manual['Search Keyword'].loc[df_manual['Sector'].isna()].to_list()))\n",
                "    print(len(df_manual['Search Keyword'].loc[df_manual['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "id": "d0d24ae2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "DF INFO:\n",
                        "\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Index: 114 entries, 3768944208 to pj_a4ac3e531abef752\n",
                        "Data columns (total 51 columns):\n",
                        " #   Column                               Non-Null Count  Dtype   \n",
                        "---  ------                               --------------  -----   \n",
                        " 0   Job Description spacy_sentencized    114 non-null    object  \n",
                        " 1   Warmth                               114 non-null    int64   \n",
                        " 2   Competence                           114 non-null    int64   \n",
                        " 3   Dutch Requirement                    114 non-null    int64   \n",
                        " 4   English Requirement                  114 non-null    int64   \n",
                        " 5   Search Keyword                       114 non-null    object  \n",
                        " 6   Platform                             114 non-null    category\n",
                        " 7   Job Title                            114 non-null    object  \n",
                        " 8   Company Name                         114 non-null    object  \n",
                        " 9   Location                             114 non-null    object  \n",
                        " 10  Employment Type                      109 non-null    object  \n",
                        " 11  Industry                             5 non-null      object  \n",
                        " 12  Type of ownership                    5 non-null      object  \n",
                        " 13  Sector Code                          114 non-null    object  \n",
                        " 14  Sector                               114 non-null    object  \n",
                        " 15  Keywords Count                       114 non-null    float64 \n",
                        " 16  % per Sector                         114 non-null    float64 \n",
                        " 17  % per Social Category                114 non-null    float64 \n",
                        " 18  % per Workforce                      114 non-null    float64 \n",
                        " 19  Gender_Female_n                      114 non-null    float64 \n",
                        " 20  Gender_Female_% per Sector           114 non-null    float64 \n",
                        " 21  Gender_Female_% per Social Category  114 non-null    float64 \n",
                        " 22  Gender_Female_% per Workforce        114 non-null    float64 \n",
                        " 23  Gender_Male_n                        114 non-null    float64 \n",
                        " 24  Gender_Male_% per Sector             114 non-null    float64 \n",
                        " 25  Gender_Male_% per Social Category    114 non-null    float64 \n",
                        " 26  Gender_Male_% per Workforce          114 non-null    float64 \n",
                        " 27  Gender                               114 non-null    category\n",
                        " 28  Age_Older_n                          114 non-null    float64 \n",
                        " 29  Age_Older_% per Sector               114 non-null    float64 \n",
                        " 30  Age_Older_% per Social Category      114 non-null    float64 \n",
                        " 31  Age_Older_% per Workforce            114 non-null    float64 \n",
                        " 32  Age_Younger_n                        114 non-null    float64 \n",
                        " 33  Age_Younger_% per Sector             114 non-null    float64 \n",
                        " 34  Age_Younger_% per Social Category    114 non-null    float64 \n",
                        " 35  Age_Younger_% per Workforce          114 non-null    float64 \n",
                        " 36  Age                                  114 non-null    category\n",
                        " 37  Sector_n                             114 non-null    float64 \n",
                        " 38  % Sector per Workforce               114 non-null    float64 \n",
                        " 39  Gender_Female                        114 non-null    int64   \n",
                        " 40  Gender_Male                          114 non-null    int64   \n",
                        " 41  Gender_Mixed                         114 non-null    int64   \n",
                        " 42  Age_Mixed                            114 non-null    int64   \n",
                        " 43  Age_Older                            114 non-null    int64   \n",
                        " 44  Age_Younger                          114 non-null    int64   \n",
                        " 45  Gender_Num                           114 non-null    int64   \n",
                        " 46  Age_Num                              114 non-null    int64   \n",
                        " 47  Platform_Num                         114 non-null    int64   \n",
                        " 48  Platform_LinkedIn                    114 non-null    int64   \n",
                        " 49  Platform_Indeed                      114 non-null    int64   \n",
                        " 50  Platform_Glassdoor                   114 non-null    int64   \n",
                        "dtypes: category(3), float64(22), int64(16), object(10)\n",
                        "memory usage: 44.4+ KB\n",
                        "====================\n",
                        "Gender:\n",
                        "--------------------\n",
                        "Gender Counts:\n",
                        "Mixed Gender    86\n",
                        "Male            16\n",
                        "Female          12\n",
                        "Name: Gender, dtype: int64\n",
                        "--------------------\n",
                        "Gender Percentages:\n",
                        "Mixed Gender   75.40\n",
                        "Male           14.00\n",
                        "Female         10.50\n",
                        "Name: Gender, dtype: float64\n",
                        "====================\n",
                        "Gender_Num:\n",
                        "--------------------\n",
                        "Gender_Num Counts:\n",
                        "1    86\n",
                        "2    16\n",
                        "0    12\n",
                        "Name: Gender_Num, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Num Percentages:\n",
                        "1   75.40\n",
                        "2   14.00\n",
                        "0   10.50\n",
                        "Name: Gender_Num, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Num Mean: 1.04\n",
                        "--------------------\n",
                        "Gender_Num Standard Deviation: 0.5\n",
                        "====================\n",
                        "Gender_Female:\n",
                        "--------------------\n",
                        "Gender_Female Counts:\n",
                        "0    102\n",
                        "1     12\n",
                        "Name: Gender_Female, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Female Percentages:\n",
                        "0   89.50\n",
                        "1   10.50\n",
                        "Name: Gender_Female, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Female Mean: 0.11\n",
                        "--------------------\n",
                        "Gender_Female Standard Deviation: 0.31\n",
                        "====================\n",
                        "Gender_Mixed:\n",
                        "--------------------\n",
                        "Gender_Mixed Counts:\n",
                        "1    86\n",
                        "0    28\n",
                        "Name: Gender_Mixed, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Mixed Percentages:\n",
                        "1   75.40\n",
                        "0   24.60\n",
                        "Name: Gender_Mixed, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Mixed Mean: 0.75\n",
                        "--------------------\n",
                        "Gender_Mixed Standard Deviation: 0.43\n",
                        "====================\n",
                        "Gender_Male:\n",
                        "--------------------\n",
                        "Gender_Male Counts:\n",
                        "0    98\n",
                        "1    16\n",
                        "Name: Gender_Male, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Male Percentages:\n",
                        "0   86.00\n",
                        "1   14.00\n",
                        "Name: Gender_Male, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Male Mean: 0.14\n",
                        "--------------------\n",
                        "Gender_Male Standard Deviation: 0.35\n",
                        "====================\n",
                        "Age:\n",
                        "--------------------\n",
                        "Age Counts:\n",
                        "Younger      58\n",
                        "Mixed Age    41\n",
                        "Older        15\n",
                        "Name: Age, dtype: int64\n",
                        "--------------------\n",
                        "Age Percentages:\n",
                        "Younger     50.90\n",
                        "Mixed Age   36.00\n",
                        "Older       13.20\n",
                        "Name: Age, dtype: float64\n",
                        "====================\n",
                        "Age_Num:\n",
                        "--------------------\n",
                        "Age_Num Counts:\n",
                        "2    58\n",
                        "1    41\n",
                        "0    15\n",
                        "Name: Age_Num, dtype: int64\n",
                        "--------------------\n",
                        "Age_Num Percentages:\n",
                        "2   50.90\n",
                        "1   36.00\n",
                        "0   13.20\n",
                        "Name: Age_Num, dtype: float64\n",
                        "--------------------\n",
                        "Age_Num Mean: 1.38\n",
                        "--------------------\n",
                        "Age_Num Standard Deviation: 0.71\n",
                        "====================\n",
                        "Age_Older:\n",
                        "--------------------\n",
                        "Age_Older Counts:\n",
                        "0    99\n",
                        "1    15\n",
                        "Name: Age_Older, dtype: int64\n",
                        "--------------------\n",
                        "Age_Older Percentages:\n",
                        "0   86.80\n",
                        "1   13.20\n",
                        "Name: Age_Older, dtype: float64\n",
                        "--------------------\n",
                        "Age_Older Mean: 0.13\n",
                        "--------------------\n",
                        "Age_Older Standard Deviation: 0.34\n",
                        "====================\n",
                        "Age_Mixed:\n",
                        "--------------------\n",
                        "Age_Mixed Counts:\n",
                        "0    73\n",
                        "1    41\n",
                        "Name: Age_Mixed, dtype: int64\n",
                        "--------------------\n",
                        "Age_Mixed Percentages:\n",
                        "0   64.00\n",
                        "1   36.00\n",
                        "Name: Age_Mixed, dtype: float64\n",
                        "--------------------\n",
                        "Age_Mixed Mean: 0.36\n",
                        "--------------------\n",
                        "Age_Mixed Standard Deviation: 0.48\n",
                        "====================\n",
                        "Age_Younger:\n",
                        "--------------------\n",
                        "Age_Younger Counts:\n",
                        "1    58\n",
                        "0    56\n",
                        "Name: Age_Younger, dtype: int64\n",
                        "--------------------\n",
                        "Age_Younger Percentages:\n",
                        "1   50.90\n",
                        "0   49.10\n",
                        "Name: Age_Younger, dtype: float64\n",
                        "--------------------\n",
                        "Age_Younger Mean: 0.51\n",
                        "--------------------\n",
                        "Age_Younger Standard Deviation: 0.5\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Manual Job Ad info, len = 113\n",
                "df_gender_age_info(df_manual.groupby(['Job ID']).first())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "id": "d4d65547",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "DF INFO:\n",
                        "\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Int64Index: 5365 entries, 0 to 5364\n",
                        "Data columns (total 52 columns):\n",
                        " #   Column                               Non-Null Count  Dtype   \n",
                        "---  ------                               --------------  -----   \n",
                        " 0   Job ID                               5365 non-null   object  \n",
                        " 1   Job Description spacy_sentencized    5365 non-null   object  \n",
                        " 2   Warmth                               5365 non-null   int64   \n",
                        " 3   Competence                           5365 non-null   int64   \n",
                        " 4   Dutch Requirement                    5365 non-null   int64   \n",
                        " 5   English Requirement                  5365 non-null   int64   \n",
                        " 6   Search Keyword                       5365 non-null   object  \n",
                        " 7   Platform                             5365 non-null   category\n",
                        " 8   Job Title                            5365 non-null   object  \n",
                        " 9   Company Name                         5365 non-null   object  \n",
                        " 10  Location                             5365 non-null   object  \n",
                        " 11  Employment Type                      5137 non-null   object  \n",
                        " 12  Industry                             228 non-null    object  \n",
                        " 13  Type of ownership                    228 non-null    object  \n",
                        " 14  Sector Code                          5365 non-null   object  \n",
                        " 15  Sector                               5365 non-null   object  \n",
                        " 16  Keywords Count                       5365 non-null   float64 \n",
                        " 17  % per Sector                         5365 non-null   float64 \n",
                        " 18  % per Social Category                5365 non-null   float64 \n",
                        " 19  % per Workforce                      5365 non-null   float64 \n",
                        " 20  Gender_Female_n                      5365 non-null   float64 \n",
                        " 21  Gender_Female_% per Sector           5365 non-null   float64 \n",
                        " 22  Gender_Female_% per Social Category  5365 non-null   float64 \n",
                        " 23  Gender_Female_% per Workforce        5365 non-null   float64 \n",
                        " 24  Gender_Male_n                        5365 non-null   float64 \n",
                        " 25  Gender_Male_% per Sector             5365 non-null   float64 \n",
                        " 26  Gender_Male_% per Social Category    5365 non-null   float64 \n",
                        " 27  Gender_Male_% per Workforce          5365 non-null   float64 \n",
                        " 28  Gender                               5365 non-null   category\n",
                        " 29  Age_Older_n                          5365 non-null   float64 \n",
                        " 30  Age_Older_% per Sector               5365 non-null   float64 \n",
                        " 31  Age_Older_% per Social Category      5365 non-null   float64 \n",
                        " 32  Age_Older_% per Workforce            5365 non-null   float64 \n",
                        " 33  Age_Younger_n                        5365 non-null   float64 \n",
                        " 34  Age_Younger_% per Sector             5365 non-null   float64 \n",
                        " 35  Age_Younger_% per Social Category    5365 non-null   float64 \n",
                        " 36  Age_Younger_% per Workforce          5365 non-null   float64 \n",
                        " 37  Age                                  5365 non-null   category\n",
                        " 38  Sector_n                             5365 non-null   float64 \n",
                        " 39  % Sector per Workforce               5365 non-null   float64 \n",
                        " 40  Gender_Female                        5365 non-null   int64   \n",
                        " 41  Gender_Male                          5365 non-null   int64   \n",
                        " 42  Gender_Mixed                         5365 non-null   int64   \n",
                        " 43  Age_Mixed                            5365 non-null   int64   \n",
                        " 44  Age_Older                            5365 non-null   int64   \n",
                        " 45  Age_Younger                          5365 non-null   int64   \n",
                        " 46  Gender_Num                           5365 non-null   int64   \n",
                        " 47  Age_Num                              5365 non-null   int64   \n",
                        " 48  Platform_Num                         5365 non-null   int64   \n",
                        " 49  Platform_LinkedIn                    5365 non-null   int64   \n",
                        " 50  Platform_Indeed                      5365 non-null   int64   \n",
                        " 51  Platform_Glassdoor                   5365 non-null   int64   \n",
                        "dtypes: category(3), float64(22), int64(16), object(11)\n",
                        "memory usage: 2.1+ MB\n",
                        "====================\n",
                        "Gender:\n",
                        "--------------------\n",
                        "Gender Counts:\n",
                        "Mixed Gender    4184\n",
                        "Male             636\n",
                        "Female           545\n",
                        "Name: Gender, dtype: int64\n",
                        "--------------------\n",
                        "Gender Percentages:\n",
                        "Mixed Gender   78.00\n",
                        "Male           11.90\n",
                        "Female         10.20\n",
                        "Name: Gender, dtype: float64\n",
                        "====================\n",
                        "Gender_Num:\n",
                        "--------------------\n",
                        "Gender_Num Counts:\n",
                        "1    4184\n",
                        "2     636\n",
                        "0     545\n",
                        "Name: Gender_Num, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Num Percentages:\n",
                        "1   78.00\n",
                        "2   11.90\n",
                        "0   10.20\n",
                        "Name: Gender_Num, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Num Mean: 1.02\n",
                        "--------------------\n",
                        "Gender_Num Standard Deviation: 0.47\n",
                        "====================\n",
                        "Gender_Female:\n",
                        "--------------------\n",
                        "Gender_Female Counts:\n",
                        "0    4820\n",
                        "1     545\n",
                        "Name: Gender_Female, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Female Percentages:\n",
                        "0   89.80\n",
                        "1   10.20\n",
                        "Name: Gender_Female, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Female Mean: 0.1\n",
                        "--------------------\n",
                        "Gender_Female Standard Deviation: 0.3\n",
                        "====================\n",
                        "Gender_Mixed:\n",
                        "--------------------\n",
                        "Gender_Mixed Counts:\n",
                        "1    4184\n",
                        "0    1181\n",
                        "Name: Gender_Mixed, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Mixed Percentages:\n",
                        "1   78.00\n",
                        "0   22.00\n",
                        "Name: Gender_Mixed, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Mixed Mean: 0.78\n",
                        "--------------------\n",
                        "Gender_Mixed Standard Deviation: 0.41\n",
                        "====================\n",
                        "Gender_Male:\n",
                        "--------------------\n",
                        "Gender_Male Counts:\n",
                        "0    4729\n",
                        "1     636\n",
                        "Name: Gender_Male, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Male Percentages:\n",
                        "0   88.10\n",
                        "1   11.90\n",
                        "Name: Gender_Male, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Male Mean: 0.12\n",
                        "--------------------\n",
                        "Gender_Male Standard Deviation: 0.32\n",
                        "====================\n",
                        "Age:\n",
                        "--------------------\n",
                        "Age Counts:\n",
                        "Younger      2828\n",
                        "Mixed Age    1894\n",
                        "Older         643\n",
                        "Name: Age, dtype: int64\n",
                        "--------------------\n",
                        "Age Percentages:\n",
                        "Younger     52.70\n",
                        "Mixed Age   35.30\n",
                        "Older       12.00\n",
                        "Name: Age, dtype: float64\n",
                        "====================\n",
                        "Age_Num:\n",
                        "--------------------\n",
                        "Age_Num Counts:\n",
                        "2    2828\n",
                        "1    1894\n",
                        "0     643\n",
                        "Name: Age_Num, dtype: int64\n",
                        "--------------------\n",
                        "Age_Num Percentages:\n",
                        "2   52.70\n",
                        "1   35.30\n",
                        "0   12.00\n",
                        "Name: Age_Num, dtype: float64\n",
                        "--------------------\n",
                        "Age_Num Mean: 1.41\n",
                        "--------------------\n",
                        "Age_Num Standard Deviation: 0.69\n",
                        "====================\n",
                        "Age_Older:\n",
                        "--------------------\n",
                        "Age_Older Counts:\n",
                        "0    4722\n",
                        "1     643\n",
                        "Name: Age_Older, dtype: int64\n",
                        "--------------------\n",
                        "Age_Older Percentages:\n",
                        "0   88.00\n",
                        "1   12.00\n",
                        "Name: Age_Older, dtype: float64\n",
                        "--------------------\n",
                        "Age_Older Mean: 0.12\n",
                        "--------------------\n",
                        "Age_Older Standard Deviation: 0.32\n",
                        "====================\n",
                        "Age_Mixed:\n",
                        "--------------------\n",
                        "Age_Mixed Counts:\n",
                        "0    3471\n",
                        "1    1894\n",
                        "Name: Age_Mixed, dtype: int64\n",
                        "--------------------\n",
                        "Age_Mixed Percentages:\n",
                        "0   64.70\n",
                        "1   35.30\n",
                        "Name: Age_Mixed, dtype: float64\n",
                        "--------------------\n",
                        "Age_Mixed Mean: 0.35\n",
                        "--------------------\n",
                        "Age_Mixed Standard Deviation: 0.48\n",
                        "====================\n",
                        "Age_Younger:\n",
                        "--------------------\n",
                        "Age_Younger Counts:\n",
                        "1    2828\n",
                        "0    2537\n",
                        "Name: Age_Younger, dtype: int64\n",
                        "--------------------\n",
                        "Age_Younger Percentages:\n",
                        "1   52.70\n",
                        "0   47.30\n",
                        "Name: Age_Younger, dtype: float64\n",
                        "--------------------\n",
                        "Age_Younger Mean: 0.53\n",
                        "--------------------\n",
                        "Age_Younger Standard Deviation: 0.5\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Manual Job Sentence info\n",
                "df_gender_age_info(df_manual)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "id": "d1d8a085",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "DF INFO:\n",
                        "\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Int64Index: 5365 entries, 0 to 5364\n",
                        "Data columns (total 52 columns):\n",
                        " #   Column                               Non-Null Count  Dtype   \n",
                        "---  ------                               --------------  -----   \n",
                        " 0   Job ID                               5365 non-null   object  \n",
                        " 1   Job Description spacy_sentencized    5365 non-null   object  \n",
                        " 2   Warmth                               5365 non-null   int64   \n",
                        " 3   Competence                           5365 non-null   int64   \n",
                        " 4   Dutch Requirement                    5365 non-null   int64   \n",
                        " 5   English Requirement                  5365 non-null   int64   \n",
                        " 6   Search Keyword                       5365 non-null   object  \n",
                        " 7   Platform                             5365 non-null   category\n",
                        " 8   Job Title                            5365 non-null   object  \n",
                        " 9   Company Name                         5365 non-null   object  \n",
                        " 10  Location                             5365 non-null   object  \n",
                        " 11  Employment Type                      5137 non-null   object  \n",
                        " 12  Industry                             228 non-null    object  \n",
                        " 13  Type of ownership                    228 non-null    object  \n",
                        " 14  Sector Code                          5365 non-null   object  \n",
                        " 15  Sector                               5365 non-null   object  \n",
                        " 16  Keywords Count                       5365 non-null   float64 \n",
                        " 17  % per Sector                         5365 non-null   float64 \n",
                        " 18  % per Social Category                5365 non-null   float64 \n",
                        " 19  % per Workforce                      5365 non-null   float64 \n",
                        " 20  Gender_Female_n                      5365 non-null   float64 \n",
                        " 21  Gender_Female_% per Sector           5365 non-null   float64 \n",
                        " 22  Gender_Female_% per Social Category  5365 non-null   float64 \n",
                        " 23  Gender_Female_% per Workforce        5365 non-null   float64 \n",
                        " 24  Gender_Male_n                        5365 non-null   float64 \n",
                        " 25  Gender_Male_% per Sector             5365 non-null   float64 \n",
                        " 26  Gender_Male_% per Social Category    5365 non-null   float64 \n",
                        " 27  Gender_Male_% per Workforce          5365 non-null   float64 \n",
                        " 28  Gender                               5365 non-null   category\n",
                        " 29  Age_Older_n                          5365 non-null   float64 \n",
                        " 30  Age_Older_% per Sector               5365 non-null   float64 \n",
                        " 31  Age_Older_% per Social Category      5365 non-null   float64 \n",
                        " 32  Age_Older_% per Workforce            5365 non-null   float64 \n",
                        " 33  Age_Younger_n                        5365 non-null   float64 \n",
                        " 34  Age_Younger_% per Sector             5365 non-null   float64 \n",
                        " 35  Age_Younger_% per Social Category    5365 non-null   float64 \n",
                        " 36  Age_Younger_% per Workforce          5365 non-null   float64 \n",
                        " 37  Age                                  5365 non-null   category\n",
                        " 38  Sector_n                             5365 non-null   float64 \n",
                        " 39  % Sector per Workforce               5365 non-null   float64 \n",
                        " 40  Gender_Female                        5365 non-null   int64   \n",
                        " 41  Gender_Male                          5365 non-null   int64   \n",
                        " 42  Gender_Mixed                         5365 non-null   int64   \n",
                        " 43  Age_Mixed                            5365 non-null   int64   \n",
                        " 44  Age_Older                            5365 non-null   int64   \n",
                        " 45  Age_Younger                          5365 non-null   int64   \n",
                        " 46  Gender_Num                           5365 non-null   int64   \n",
                        " 47  Age_Num                              5365 non-null   int64   \n",
                        " 48  Platform_Num                         5365 non-null   int64   \n",
                        " 49  Platform_LinkedIn                    5365 non-null   int64   \n",
                        " 50  Platform_Indeed                      5365 non-null   int64   \n",
                        " 51  Platform_Glassdoor                   5365 non-null   int64   \n",
                        "dtypes: category(3), float64(22), int64(16), object(11)\n",
                        "memory usage: 2.1+ MB\n",
                        "====================\n",
                        "Warmth:\n",
                        "--------------------\n",
                        "Warmth Counts:\n",
                        "0    4017\n",
                        "1    1348\n",
                        "Name: Warmth, dtype: int64\n",
                        "--------------------\n",
                        "Warmth Percentages:\n",
                        "0   74.90\n",
                        "1   25.10\n",
                        "Name: Warmth, dtype: float64\n",
                        "--------------------\n",
                        "Warmth Mean: 0.25\n",
                        "--------------------\n",
                        "Warmth Standard Deviation: 0.43\n",
                        "====================\n",
                        "Competence:\n",
                        "--------------------\n",
                        "Competence Counts:\n",
                        "0    2926\n",
                        "1    2439\n",
                        "Name: Competence, dtype: int64\n",
                        "--------------------\n",
                        "Competence Percentages:\n",
                        "0   54.50\n",
                        "1   45.50\n",
                        "Name: Competence, dtype: float64\n",
                        "--------------------\n",
                        "Competence Mean: 0.45\n",
                        "--------------------\n",
                        "Competence Standard Deviation: 0.5\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Manual Job Sentence info\n",
                "df_gender_age_info(df_manual, ivs_all=['Warmth', 'Competence'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "id": "f599e9cd",
            "metadata": {},
            "outputs": [],
            "source": [
                "if df_manual['Sector'].isna().sum() == 0:\n",
                "    assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "    df_manual.to_pickle(f'{df_save_dir}df_manual_including_sector_genage_data.pkl')\n",
                "    df_manual.to_csv(f'{df_save_dir}df_manual_including_sector_genage_data.csv', index=False)\n",
                "else:\n",
                "    print(f\"MISSING SECTOR DATA: COUNT {df_manual['Sector'].isna().sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6373c116",
            "metadata": {},
            "source": [
                "# ATTN: This script should be run AFTER spacy sentence splitting is completed.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "993064a6",
            "metadata": {},
            "source": [
                "# Use spacy to tokenize sentences\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c744a550",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_SENTENCIZED\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "id": "b997d96c",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "id": "390017aa",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "id": "4c3b98f1",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_word_num_and_frequency(row, text_col):\n",
                "\n",
                "    with open(f'{data_dir}punctuations.txt', 'rb') as f:\n",
                "        custom_punct_chars = pickle.load(f)\n",
                "    row['Job Description num_words'] = len(str(row[text_col]).split())\n",
                "    row['Job Description num_unique_words'] = len(set(str(row[text_col]).split()))\n",
                "    row['Job Description num_chars'] = len(str(row[text_col]))\n",
                "    row['Job Description num_chars_no_whitespact_and_punt'] = len(\n",
                "        [\n",
                "            c.translate({ord(s): None for s in string.whitespace})\n",
                "            for c in str(row[text_col])\n",
                "            if c not in custom_punct_chars and c not in string.punctuation\n",
                "        ]\n",
                "    )\n",
                "    row['Job Description num_punctuations'] = len(\n",
                "        [\n",
                "            c\n",
                "            for c in str(row[text_col])\n",
                "            if c in custom_punct_chars and c in string.punctuation\n",
                "        ]\n",
                "    )\n",
                "\n",
                "    return row\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "id": "3d31a583",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_including_sector_genage_data.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "id": "bc21643d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "97d02983b77a4d96bdf984e36aa67203",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "df_manual['Job Description spacy_sentencized_lower'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "    lambda job_sentence: job_sentence.strip().lower()\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "id": "1b8dac3e",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: center;\">\n",
                            "      <th></th>\n",
                            "      <th>Job Description spacy_sentencized</th>\n",
                            "      <th>Job Description spacy_sentencized_lower</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Were growing our Sales team for the EMEA Mark...</td>\n",
                            "      <td>were growing our sales team for the emea mark...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Are you looking for an adventure  one with bi...</td>\n",
                            "      <td>are you looking for an adventure  one with bi...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Do you have experience closing B2B Saa</td>\n",
                            "      <td>do you have experience closing b2b saa</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>S deals in the mid-market and enterprise space?</td>\n",
                            "      <td>s deals in the mid-market and enterprise space?</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Then you might be ready to become part of the ...</td>\n",
                            "      <td>then you might be ready to become part of the ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "          Job Description spacy_sentencized               Job Description spacy_sentencized_lower      \n",
                            "0  Were growing our Sales team for the EMEA Mark...  were growing our sales team for the emea mark...\n",
                            "1  Are you looking for an adventure  one with bi...  are you looking for an adventure  one with bi...\n",
                            "2             Do you have experience closing B2B Saa             do you have experience closing b2b saa\n",
                            "3    S deals in the mid-market and enterprise space?    s deals in the mid-market and enterprise space?\n",
                            "4  Then you might be ready to become part of the ...  then you might be ready to become part of the ..."
                        ]
                    },
                    "execution_count": 76,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual[['Job Description spacy_sentencized', 'Job Description spacy_sentencized_lower']].head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "id": "1cf56055",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e1239f10ffc04b38a92e07afd7eb5aa6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 470 ms, sys: 15.7 ms, total: 486 ms\n",
                        "Wall time: 492 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Spacy tokenize\n",
                "with open(f'{data_dir}punctuations.txt', 'rb') as f:\n",
                "    custom_punct_chars = pickle.load(f)\n",
                "\n",
                "df_manual['Job Description spacy_tokenized'] = df_manual[\n",
                "    'Job Description spacy_sentencized'\n",
                "].progress_apply(\n",
                "    lambda job_sentence: [\n",
                "        str(token.text.strip().lower())\n",
                "        for token in nlp.tokenizer(job_sentence)\n",
                "        if len(token) != 0\n",
                "        and not token.is_space\n",
                "        and not token.is_stop\n",
                "        and not token.is_punct\n",
                "        and not token.is_bracket\n",
                "        and not token.like_email\n",
                "        and token.text not in custom_punct_chars\n",
                "    ]\n",
                ")\n",
                "\n",
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tokenized_spacy.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tokenized_spacy.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "id": "bd443d94",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual['Job Description spacy_sentencized_cleaned'] = df_manual['Job Description spacy_tokenized'].str.join(' ')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "id": "65043f92",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "279788e7132a4d0da392b11ef500c691",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 5.15 s, sys: 167 ms, total: 5.31 s\n",
                        "Wall time: 5.49 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Get sentence word frequencies\n",
                "df_manual = df_manual.progress_apply(\n",
                "    lambda row: get_word_num_and_frequency(\n",
                "        row=row, text_col='Job Description spacy_sentencized'\n",
                "    ), \n",
                "    axis='columns',\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "id": "fba80745",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: center;\">\n",
                            "      <th></th>\n",
                            "      <th>Job Description spacy_sentencized</th>\n",
                            "      <th>Job Description num_words</th>\n",
                            "      <th>Job Description num_unique_words</th>\n",
                            "      <th>Job Description num_chars</th>\n",
                            "      <th>Job Description num_chars_no_whitespact_and_punt</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Were growing our Sales team for the EMEA Mark...</td>\n",
                            "      <td>19</td>\n",
                            "      <td>19</td>\n",
                            "      <td>91</td>\n",
                            "      <td>90</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Are you looking for an adventure  one with bi...</td>\n",
                            "      <td>11</td>\n",
                            "      <td>11</td>\n",
                            "      <td>63</td>\n",
                            "      <td>62</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Do you have experience closing B2B Saa</td>\n",
                            "      <td>7</td>\n",
                            "      <td>7</td>\n",
                            "      <td>38</td>\n",
                            "      <td>38</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>S deals in the mid-market and enterprise space?</td>\n",
                            "      <td>8</td>\n",
                            "      <td>8</td>\n",
                            "      <td>47</td>\n",
                            "      <td>45</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Then you might be ready to become part of the ...</td>\n",
                            "      <td>17</td>\n",
                            "      <td>17</td>\n",
                            "      <td>91</td>\n",
                            "      <td>89</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "          Job Description spacy_sentencized           Job Description num_words  Job Description num_unique_words  Job Description num_chars  Job Description num_chars_no_whitespact_and_punt\n",
                            "0  Were growing our Sales team for the EMEA Mark...             19                             19                            91                                     90                       \n",
                            "1  Are you looking for an adventure  one with bi...             11                             11                            63                                     62                       \n",
                            "2             Do you have experience closing B2B Saa              7                              7                            38                                     38                       \n",
                            "3    S deals in the mid-market and enterprise space?              8                              8                            47                                     45                       \n",
                            "4  Then you might be ready to become part of the ...             17                             17                            91                                     89                       "
                        ]
                    },
                    "execution_count": 81,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual[\n",
                "    [\n",
                "        'Job Description spacy_sentencized',\n",
                "        'Job Description num_words', 'Job Description num_unique_words',\n",
                "        'Job Description num_chars', 'Job Description num_chars_no_whitespact_and_punt'\n",
                "    ]\n",
                "].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "id": "f2acfe7f",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['Job ID', 'Job Description spacy_sentencized', 'Warmth', 'Competence', 'Dutch Requirement', 'English Requirement', 'Search Keyword', 'Platform', 'Job Title', 'Company Name', 'Location', 'Employment Type', 'Industry', 'Type of ownership', 'Sector Code', 'Sector', 'Keywords Count', '% per Sector', '% per Social Category', '% per Workforce', 'Gender_Female_n', 'Gender_Female_% per Sector', 'Gender_Female_% per Social Category', 'Gender_Female_% per Workforce', 'Gender_Male_n', 'Gender_Male_% per Sector', 'Gender_Male_% per Social Category', 'Gender_Male_% per Workforce', 'Gender', 'Age_Older_n', 'Age_Older_% per Sector', 'Age_Older_% per Social Category', 'Age_Older_% per Workforce', 'Age_Younger_n', 'Age_Younger_% per Sector', 'Age_Younger_% per Social Category', 'Age_Younger_% per Workforce', 'Age', 'Sector_n', '% Sector per Workforce', 'Gender_Female', 'Gender_Male', 'Gender_Mixed', 'Age_Mixed', 'Age_Older', 'Age_Younger', 'Gender_Num', 'Age_Num', 'Platform_Num', 'Platform_LinkedIn', 'Platform_Indeed', 'Platform_Glassdoor', 'Job Description spacy_sentencized_lower', 'Job Description spacy_tokenized', 'Job Description spacy_sentencized_cleaned', 'Job Description num_words', 'Job Description num_unique_words', 'Job Description num_chars', 'Job Description num_chars_no_whitespact_and_punt', 'Job Description num_punctuations'], dtype='object')"
                        ]
                    },
                    "execution_count": 82,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual.columns\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "id": "3ec60c46",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "DF INFO:\n",
                        "\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5365 entries, 0 to 5364\n",
                        "Data columns (total 60 columns):\n",
                        " #   Column                                            Non-Null Count  Dtype  \n",
                        "---  ------                                            --------------  -----  \n",
                        " 0   Job ID                                            5365 non-null   object \n",
                        " 1   Job Description spacy_sentencized                 5365 non-null   object \n",
                        " 2   Warmth                                            5365 non-null   int64  \n",
                        " 3   Competence                                        5365 non-null   int64  \n",
                        " 4   Dutch Requirement                                 5365 non-null   int64  \n",
                        " 5   English Requirement                               5365 non-null   int64  \n",
                        " 6   Search Keyword                                    5365 non-null   object \n",
                        " 7   Platform                                          5365 non-null   object \n",
                        " 8   Job Title                                         5365 non-null   object \n",
                        " 9   Company Name                                      5365 non-null   object \n",
                        " 10  Location                                          5365 non-null   object \n",
                        " 11  Employment Type                                   5137 non-null   object \n",
                        " 12  Industry                                          228 non-null    object \n",
                        " 13  Type of ownership                                 228 non-null    object \n",
                        " 14  Sector Code                                       5365 non-null   object \n",
                        " 15  Sector                                            5365 non-null   object \n",
                        " 16  Keywords Count                                    5365 non-null   float64\n",
                        " 17  % per Sector                                      5365 non-null   float64\n",
                        " 18  % per Social Category                             5365 non-null   float64\n",
                        " 19  % per Workforce                                   5365 non-null   float64\n",
                        " 20  Gender_Female_n                                   5365 non-null   float64\n",
                        " 21  Gender_Female_% per Sector                        5365 non-null   float64\n",
                        " 22  Gender_Female_% per Social Category               5365 non-null   float64\n",
                        " 23  Gender_Female_% per Workforce                     5365 non-null   float64\n",
                        " 24  Gender_Male_n                                     5365 non-null   float64\n",
                        " 25  Gender_Male_% per Sector                          5365 non-null   float64\n",
                        " 26  Gender_Male_% per Social Category                 5365 non-null   float64\n",
                        " 27  Gender_Male_% per Workforce                       5365 non-null   float64\n",
                        " 28  Gender                                            5365 non-null   object \n",
                        " 29  Age_Older_n                                       5365 non-null   float64\n",
                        " 30  Age_Older_% per Sector                            5365 non-null   float64\n",
                        " 31  Age_Older_% per Social Category                   5365 non-null   float64\n",
                        " 32  Age_Older_% per Workforce                         5365 non-null   float64\n",
                        " 33  Age_Younger_n                                     5365 non-null   float64\n",
                        " 34  Age_Younger_% per Sector                          5365 non-null   float64\n",
                        " 35  Age_Younger_% per Social Category                 5365 non-null   float64\n",
                        " 36  Age_Younger_% per Workforce                       5365 non-null   float64\n",
                        " 37  Age                                               5365 non-null   object \n",
                        " 38  Sector_n                                          5365 non-null   float64\n",
                        " 39  % Sector per Workforce                            5365 non-null   float64\n",
                        " 40  Gender_Female                                     5365 non-null   int64  \n",
                        " 41  Gender_Male                                       5365 non-null   int64  \n",
                        " 42  Gender_Mixed                                      5365 non-null   int64  \n",
                        " 43  Age_Mixed                                         5365 non-null   int64  \n",
                        " 44  Age_Older                                         5365 non-null   int64  \n",
                        " 45  Age_Younger                                       5365 non-null   int64  \n",
                        " 46  Gender_Num                                        5365 non-null   int64  \n",
                        " 47  Age_Num                                           5365 non-null   int64  \n",
                        " 48  Platform_Num                                      5365 non-null   int64  \n",
                        " 49  Platform_LinkedIn                                 5365 non-null   int64  \n",
                        " 50  Platform_Indeed                                   5365 non-null   int64  \n",
                        " 51  Platform_Glassdoor                                5365 non-null   int64  \n",
                        " 52  Job Description spacy_sentencized_lower           5365 non-null   object \n",
                        " 53  Job Description spacy_tokenized                   5365 non-null   object \n",
                        " 54  Job Description spacy_sentencized_cleaned         5365 non-null   object \n",
                        " 55  Job Description num_words                         5365 non-null   int64  \n",
                        " 56  Job Description num_unique_words                  5365 non-null   int64  \n",
                        " 57  Job Description num_chars                         5365 non-null   int64  \n",
                        " 58  Job Description num_chars_no_whitespact_and_punt  5365 non-null   int64  \n",
                        " 59  Job Description num_punctuations                  5365 non-null   int64  \n",
                        "dtypes: float64(22), int64(21), object(17)\n",
                        "memory usage: 2.5+ MB\n",
                        "====================\n",
                        "Gender:\n",
                        "--------------------\n",
                        "Gender Counts:\n",
                        "Mixed Gender    4184\n",
                        "Male             636\n",
                        "Female           545\n",
                        "Name: Gender, dtype: int64\n",
                        "--------------------\n",
                        "Gender Percentages:\n",
                        "Mixed Gender   78.00\n",
                        "Male           11.90\n",
                        "Female         10.20\n",
                        "Name: Gender, dtype: float64\n",
                        "====================\n",
                        "Gender_Num:\n",
                        "--------------------\n",
                        "Gender_Num Counts:\n",
                        "1    4184\n",
                        "2     636\n",
                        "0     545\n",
                        "Name: Gender_Num, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Num Percentages:\n",
                        "1   78.00\n",
                        "2   11.90\n",
                        "0   10.20\n",
                        "Name: Gender_Num, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Num Mean: 1.02\n",
                        "--------------------\n",
                        "Gender_Num Standard Deviation: 0.47\n",
                        "====================\n",
                        "Gender_Female:\n",
                        "--------------------\n",
                        "Gender_Female Counts:\n",
                        "0    4820\n",
                        "1     545\n",
                        "Name: Gender_Female, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Female Percentages:\n",
                        "0   89.80\n",
                        "1   10.20\n",
                        "Name: Gender_Female, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Female Mean: 0.1\n",
                        "--------------------\n",
                        "Gender_Female Standard Deviation: 0.3\n",
                        "====================\n",
                        "Gender_Mixed:\n",
                        "--------------------\n",
                        "Gender_Mixed Counts:\n",
                        "1    4184\n",
                        "0    1181\n",
                        "Name: Gender_Mixed, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Mixed Percentages:\n",
                        "1   78.00\n",
                        "0   22.00\n",
                        "Name: Gender_Mixed, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Mixed Mean: 0.78\n",
                        "--------------------\n",
                        "Gender_Mixed Standard Deviation: 0.41\n",
                        "====================\n",
                        "Gender_Male:\n",
                        "--------------------\n",
                        "Gender_Male Counts:\n",
                        "0    4729\n",
                        "1     636\n",
                        "Name: Gender_Male, dtype: int64\n",
                        "--------------------\n",
                        "Gender_Male Percentages:\n",
                        "0   88.10\n",
                        "1   11.90\n",
                        "Name: Gender_Male, dtype: float64\n",
                        "--------------------\n",
                        "Gender_Male Mean: 0.12\n",
                        "--------------------\n",
                        "Gender_Male Standard Deviation: 0.32\n",
                        "====================\n",
                        "Age:\n",
                        "--------------------\n",
                        "Age Counts:\n",
                        "Younger      2828\n",
                        "Mixed Age    1894\n",
                        "Older         643\n",
                        "Name: Age, dtype: int64\n",
                        "--------------------\n",
                        "Age Percentages:\n",
                        "Younger     52.70\n",
                        "Mixed Age   35.30\n",
                        "Older       12.00\n",
                        "Name: Age, dtype: float64\n",
                        "====================\n",
                        "Age_Num:\n",
                        "--------------------\n",
                        "Age_Num Counts:\n",
                        "2    2828\n",
                        "1    1894\n",
                        "0     643\n",
                        "Name: Age_Num, dtype: int64\n",
                        "--------------------\n",
                        "Age_Num Percentages:\n",
                        "2   52.70\n",
                        "1   35.30\n",
                        "0   12.00\n",
                        "Name: Age_Num, dtype: float64\n",
                        "--------------------\n",
                        "Age_Num Mean: 1.41\n",
                        "--------------------\n",
                        "Age_Num Standard Deviation: 0.69\n",
                        "====================\n",
                        "Age_Older:\n",
                        "--------------------\n",
                        "Age_Older Counts:\n",
                        "0    4722\n",
                        "1     643\n",
                        "Name: Age_Older, dtype: int64\n",
                        "--------------------\n",
                        "Age_Older Percentages:\n",
                        "0   88.00\n",
                        "1   12.00\n",
                        "Name: Age_Older, dtype: float64\n",
                        "--------------------\n",
                        "Age_Older Mean: 0.12\n",
                        "--------------------\n",
                        "Age_Older Standard Deviation: 0.32\n",
                        "====================\n",
                        "Age_Mixed:\n",
                        "--------------------\n",
                        "Age_Mixed Counts:\n",
                        "0    3471\n",
                        "1    1894\n",
                        "Name: Age_Mixed, dtype: int64\n",
                        "--------------------\n",
                        "Age_Mixed Percentages:\n",
                        "0   64.70\n",
                        "1   35.30\n",
                        "Name: Age_Mixed, dtype: float64\n",
                        "--------------------\n",
                        "Age_Mixed Mean: 0.35\n",
                        "--------------------\n",
                        "Age_Mixed Standard Deviation: 0.48\n",
                        "====================\n",
                        "Age_Younger:\n",
                        "--------------------\n",
                        "Age_Younger Counts:\n",
                        "1    2828\n",
                        "0    2537\n",
                        "Name: Age_Younger, dtype: int64\n",
                        "--------------------\n",
                        "Age_Younger Percentages:\n",
                        "1   52.70\n",
                        "0   47.30\n",
                        "Name: Age_Younger, dtype: float64\n",
                        "--------------------\n",
                        "Age_Younger Mean: 0.53\n",
                        "--------------------\n",
                        "Age_Younger Standard Deviation: 0.5\n",
                        "\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Job Sentence info\n",
                "df_gender_age_info(df_manual)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "id": "5deddb9d",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tokenized_spacy.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tokenized_spacy.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e7f002d2",
            "metadata": {},
            "source": [
                "# Use NLTK to tokenize sentences\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "92922872",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_TOKENIZED_SPACY\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "id": "9fae46f4",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "id": "3d4f11d1",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "id": "5011ea0a",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_tokenized_spacy.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "id": "9c8a9f1e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5365 entries, 0 to 5364\n",
                        "Data columns (total 60 columns):\n",
                        " #   Column                                            Non-Null Count  Dtype  \n",
                        "---  ------                                            --------------  -----  \n",
                        " 0   Job ID                                            5365 non-null   object \n",
                        " 1   Job Description spacy_sentencized                 5365 non-null   object \n",
                        " 2   Warmth                                            5365 non-null   int64  \n",
                        " 3   Competence                                        5365 non-null   int64  \n",
                        " 4   Dutch Requirement                                 5365 non-null   int64  \n",
                        " 5   English Requirement                               5365 non-null   int64  \n",
                        " 6   Search Keyword                                    5365 non-null   object \n",
                        " 7   Platform                                          5365 non-null   object \n",
                        " 8   Job Title                                         5365 non-null   object \n",
                        " 9   Company Name                                      5365 non-null   object \n",
                        " 10  Location                                          5365 non-null   object \n",
                        " 11  Employment Type                                   5137 non-null   object \n",
                        " 12  Industry                                          228 non-null    object \n",
                        " 13  Type of ownership                                 228 non-null    object \n",
                        " 14  Sector Code                                       5365 non-null   object \n",
                        " 15  Sector                                            5365 non-null   object \n",
                        " 16  Keywords Count                                    5365 non-null   float64\n",
                        " 17  % per Sector                                      5365 non-null   float64\n",
                        " 18  % per Social Category                             5365 non-null   float64\n",
                        " 19  % per Workforce                                   5365 non-null   float64\n",
                        " 20  Gender_Female_n                                   5365 non-null   float64\n",
                        " 21  Gender_Female_% per Sector                        5365 non-null   float64\n",
                        " 22  Gender_Female_% per Social Category               5365 non-null   float64\n",
                        " 23  Gender_Female_% per Workforce                     5365 non-null   float64\n",
                        " 24  Gender_Male_n                                     5365 non-null   float64\n",
                        " 25  Gender_Male_% per Sector                          5365 non-null   float64\n",
                        " 26  Gender_Male_% per Social Category                 5365 non-null   float64\n",
                        " 27  Gender_Male_% per Workforce                       5365 non-null   float64\n",
                        " 28  Gender                                            5365 non-null   object \n",
                        " 29  Age_Older_n                                       5365 non-null   float64\n",
                        " 30  Age_Older_% per Sector                            5365 non-null   float64\n",
                        " 31  Age_Older_% per Social Category                   5365 non-null   float64\n",
                        " 32  Age_Older_% per Workforce                         5365 non-null   float64\n",
                        " 33  Age_Younger_n                                     5365 non-null   float64\n",
                        " 34  Age_Younger_% per Sector                          5365 non-null   float64\n",
                        " 35  Age_Younger_% per Social Category                 5365 non-null   float64\n",
                        " 36  Age_Younger_% per Workforce                       5365 non-null   float64\n",
                        " 37  Age                                               5365 non-null   object \n",
                        " 38  Sector_n                                          5365 non-null   float64\n",
                        " 39  % Sector per Workforce                            5365 non-null   float64\n",
                        " 40  Gender_Female                                     5365 non-null   int64  \n",
                        " 41  Gender_Male                                       5365 non-null   int64  \n",
                        " 42  Gender_Mixed                                      5365 non-null   int64  \n",
                        " 43  Age_Mixed                                         5365 non-null   int64  \n",
                        " 44  Age_Older                                         5365 non-null   int64  \n",
                        " 45  Age_Younger                                       5365 non-null   int64  \n",
                        " 46  Gender_Num                                        5365 non-null   int64  \n",
                        " 47  Age_Num                                           5365 non-null   int64  \n",
                        " 48  Platform_Num                                      5365 non-null   int64  \n",
                        " 49  Platform_LinkedIn                                 5365 non-null   int64  \n",
                        " 50  Platform_Indeed                                   5365 non-null   int64  \n",
                        " 51  Platform_Glassdoor                                5365 non-null   int64  \n",
                        " 52  Job Description spacy_sentencized_lower           5365 non-null   object \n",
                        " 53  Job Description spacy_tokenized                   5365 non-null   object \n",
                        " 54  Job Description spacy_sentencized_cleaned         5365 non-null   object \n",
                        " 55  Job Description num_words                         5365 non-null   int64  \n",
                        " 56  Job Description num_unique_words                  5365 non-null   int64  \n",
                        " 57  Job Description num_chars                         5365 non-null   int64  \n",
                        " 58  Job Description num_chars_no_whitespact_and_punt  5365 non-null   int64  \n",
                        " 59  Job Description num_punctuations                  5365 non-null   int64  \n",
                        "dtypes: float64(22), int64(21), object(17)\n",
                        "memory usage: 2.5+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "id": "4475248f",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "056dca629a5849e48a6fa01076758b3e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 4.96 s, sys: 1.71 s, total: 6.67 s\n",
                        "Wall time: 8.82 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Tokenize with NLTK\n",
                "# stop_words = set(stopwords.words('english'))\n",
                "# punctuations = list(string.punctuation)\n",
                "# lemmatizer = WordNetLemmatizer()\n",
                "# stemmer = PorterStemmer()\n",
                "\n",
                "df_manual['Job Description nltk_tokenized'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "    lambda job_sentence: [\n",
                "        str(token.strip().lower()) \n",
                "        for token in word_tokenize(job_sentence) \n",
                "        if len(token) != 0 \n",
                "        and token != '...' \n",
                "        and not token.lower() in set(stopwords.words('english')) \n",
                "        and not token.lower() in list(string.punctuation) \n",
                "    ]\n",
                ")\n",
                "\n",
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tokenized_spacy_nltk.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tokenized_spacy_nltk.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "id": "3bbd5d3f",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0    [, growing, sales, team, emea, market, want, ...\n",
                            "1    [looking, adventure, , one, big, responsibility]\n",
                            "2                      [experience, closing, b2b, saa]\n",
                            "3               [deals, mid-market, enterprise, space]\n",
                            "4    [might, ready, become, part, team, drives, hap...\n",
                            "Name: Job Description nltk_tokenized, dtype: object"
                        ]
                    },
                    "execution_count": 90,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual['Job Description nltk_tokenized'].head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "id": "86da6772",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5365 entries, 0 to 5364\n",
                        "Data columns (total 61 columns):\n",
                        " #   Column                                            Non-Null Count  Dtype  \n",
                        "---  ------                                            --------------  -----  \n",
                        " 0   Job ID                                            5365 non-null   object \n",
                        " 1   Job Description spacy_sentencized                 5365 non-null   object \n",
                        " 2   Warmth                                            5365 non-null   int64  \n",
                        " 3   Competence                                        5365 non-null   int64  \n",
                        " 4   Dutch Requirement                                 5365 non-null   int64  \n",
                        " 5   English Requirement                               5365 non-null   int64  \n",
                        " 6   Search Keyword                                    5365 non-null   object \n",
                        " 7   Platform                                          5365 non-null   object \n",
                        " 8   Job Title                                         5365 non-null   object \n",
                        " 9   Company Name                                      5365 non-null   object \n",
                        " 10  Location                                          5365 non-null   object \n",
                        " 11  Employment Type                                   5137 non-null   object \n",
                        " 12  Industry                                          228 non-null    object \n",
                        " 13  Type of ownership                                 228 non-null    object \n",
                        " 14  Sector Code                                       5365 non-null   object \n",
                        " 15  Sector                                            5365 non-null   object \n",
                        " 16  Keywords Count                                    5365 non-null   float64\n",
                        " 17  % per Sector                                      5365 non-null   float64\n",
                        " 18  % per Social Category                             5365 non-null   float64\n",
                        " 19  % per Workforce                                   5365 non-null   float64\n",
                        " 20  Gender_Female_n                                   5365 non-null   float64\n",
                        " 21  Gender_Female_% per Sector                        5365 non-null   float64\n",
                        " 22  Gender_Female_% per Social Category               5365 non-null   float64\n",
                        " 23  Gender_Female_% per Workforce                     5365 non-null   float64\n",
                        " 24  Gender_Male_n                                     5365 non-null   float64\n",
                        " 25  Gender_Male_% per Sector                          5365 non-null   float64\n",
                        " 26  Gender_Male_% per Social Category                 5365 non-null   float64\n",
                        " 27  Gender_Male_% per Workforce                       5365 non-null   float64\n",
                        " 28  Gender                                            5365 non-null   object \n",
                        " 29  Age_Older_n                                       5365 non-null   float64\n",
                        " 30  Age_Older_% per Sector                            5365 non-null   float64\n",
                        " 31  Age_Older_% per Social Category                   5365 non-null   float64\n",
                        " 32  Age_Older_% per Workforce                         5365 non-null   float64\n",
                        " 33  Age_Younger_n                                     5365 non-null   float64\n",
                        " 34  Age_Younger_% per Sector                          5365 non-null   float64\n",
                        " 35  Age_Younger_% per Social Category                 5365 non-null   float64\n",
                        " 36  Age_Younger_% per Workforce                       5365 non-null   float64\n",
                        " 37  Age                                               5365 non-null   object \n",
                        " 38  Sector_n                                          5365 non-null   float64\n",
                        " 39  % Sector per Workforce                            5365 non-null   float64\n",
                        " 40  Gender_Female                                     5365 non-null   int64  \n",
                        " 41  Gender_Male                                       5365 non-null   int64  \n",
                        " 42  Gender_Mixed                                      5365 non-null   int64  \n",
                        " 43  Age_Mixed                                         5365 non-null   int64  \n",
                        " 44  Age_Older                                         5365 non-null   int64  \n",
                        " 45  Age_Younger                                       5365 non-null   int64  \n",
                        " 46  Gender_Num                                        5365 non-null   int64  \n",
                        " 47  Age_Num                                           5365 non-null   int64  \n",
                        " 48  Platform_Num                                      5365 non-null   int64  \n",
                        " 49  Platform_LinkedIn                                 5365 non-null   int64  \n",
                        " 50  Platform_Indeed                                   5365 non-null   int64  \n",
                        " 51  Platform_Glassdoor                                5365 non-null   int64  \n",
                        " 52  Job Description spacy_sentencized_lower           5365 non-null   object \n",
                        " 53  Job Description spacy_tokenized                   5365 non-null   object \n",
                        " 54  Job Description spacy_sentencized_cleaned         5365 non-null   object \n",
                        " 55  Job Description num_words                         5365 non-null   int64  \n",
                        " 56  Job Description num_unique_words                  5365 non-null   int64  \n",
                        " 57  Job Description num_chars                         5365 non-null   int64  \n",
                        " 58  Job Description num_chars_no_whitespact_and_punt  5365 non-null   int64  \n",
                        " 59  Job Description num_punctuations                  5365 non-null   int64  \n",
                        " 60  Job Description nltk_tokenized                    5365 non-null   object \n",
                        "dtypes: float64(22), int64(21), object(18)\n",
                        "memory usage: 2.5+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "id": "69e6640b",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tokenized_spacy_nltk.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tokenized_spacy_nltk.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "81e54149",
            "metadata": {},
            "source": [
                "# Use gensim to tokenize sentences\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ff307dba",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_TOKENIZED_SPACY_NLTK\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "id": "3f89cb65",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "id": "ac2ae121",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "id": "c13d88fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_tokenized_spacy_nltk.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "id": "bc48f290",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5365 entries, 0 to 5364\n",
                        "Data columns (total 61 columns):\n",
                        " #   Column                                            Non-Null Count  Dtype  \n",
                        "---  ------                                            --------------  -----  \n",
                        " 0   Job ID                                            5365 non-null   object \n",
                        " 1   Job Description spacy_sentencized                 5365 non-null   object \n",
                        " 2   Warmth                                            5365 non-null   int64  \n",
                        " 3   Competence                                        5365 non-null   int64  \n",
                        " 4   Dutch Requirement                                 5365 non-null   int64  \n",
                        " 5   English Requirement                               5365 non-null   int64  \n",
                        " 6   Search Keyword                                    5365 non-null   object \n",
                        " 7   Platform                                          5365 non-null   object \n",
                        " 8   Job Title                                         5365 non-null   object \n",
                        " 9   Company Name                                      5365 non-null   object \n",
                        " 10  Location                                          5365 non-null   object \n",
                        " 11  Employment Type                                   5137 non-null   object \n",
                        " 12  Industry                                          228 non-null    object \n",
                        " 13  Type of ownership                                 228 non-null    object \n",
                        " 14  Sector Code                                       5365 non-null   object \n",
                        " 15  Sector                                            5365 non-null   object \n",
                        " 16  Keywords Count                                    5365 non-null   float64\n",
                        " 17  % per Sector                                      5365 non-null   float64\n",
                        " 18  % per Social Category                             5365 non-null   float64\n",
                        " 19  % per Workforce                                   5365 non-null   float64\n",
                        " 20  Gender_Female_n                                   5365 non-null   float64\n",
                        " 21  Gender_Female_% per Sector                        5365 non-null   float64\n",
                        " 22  Gender_Female_% per Social Category               5365 non-null   float64\n",
                        " 23  Gender_Female_% per Workforce                     5365 non-null   float64\n",
                        " 24  Gender_Male_n                                     5365 non-null   float64\n",
                        " 25  Gender_Male_% per Sector                          5365 non-null   float64\n",
                        " 26  Gender_Male_% per Social Category                 5365 non-null   float64\n",
                        " 27  Gender_Male_% per Workforce                       5365 non-null   float64\n",
                        " 28  Gender                                            5365 non-null   object \n",
                        " 29  Age_Older_n                                       5365 non-null   float64\n",
                        " 30  Age_Older_% per Sector                            5365 non-null   float64\n",
                        " 31  Age_Older_% per Social Category                   5365 non-null   float64\n",
                        " 32  Age_Older_% per Workforce                         5365 non-null   float64\n",
                        " 33  Age_Younger_n                                     5365 non-null   float64\n",
                        " 34  Age_Younger_% per Sector                          5365 non-null   float64\n",
                        " 35  Age_Younger_% per Social Category                 5365 non-null   float64\n",
                        " 36  Age_Younger_% per Workforce                       5365 non-null   float64\n",
                        " 37  Age                                               5365 non-null   object \n",
                        " 38  Sector_n                                          5365 non-null   float64\n",
                        " 39  % Sector per Workforce                            5365 non-null   float64\n",
                        " 40  Gender_Female                                     5365 non-null   int64  \n",
                        " 41  Gender_Male                                       5365 non-null   int64  \n",
                        " 42  Gender_Mixed                                      5365 non-null   int64  \n",
                        " 43  Age_Mixed                                         5365 non-null   int64  \n",
                        " 44  Age_Older                                         5365 non-null   int64  \n",
                        " 45  Age_Younger                                       5365 non-null   int64  \n",
                        " 46  Gender_Num                                        5365 non-null   int64  \n",
                        " 47  Age_Num                                           5365 non-null   int64  \n",
                        " 48  Platform_Num                                      5365 non-null   int64  \n",
                        " 49  Platform_LinkedIn                                 5365 non-null   int64  \n",
                        " 50  Platform_Indeed                                   5365 non-null   int64  \n",
                        " 51  Platform_Glassdoor                                5365 non-null   int64  \n",
                        " 52  Job Description spacy_sentencized_lower           5365 non-null   object \n",
                        " 53  Job Description spacy_tokenized                   5365 non-null   object \n",
                        " 54  Job Description spacy_sentencized_cleaned         5365 non-null   object \n",
                        " 55  Job Description num_words                         5365 non-null   int64  \n",
                        " 56  Job Description num_unique_words                  5365 non-null   int64  \n",
                        " 57  Job Description num_chars                         5365 non-null   int64  \n",
                        " 58  Job Description num_chars_no_whitespact_and_punt  5365 non-null   int64  \n",
                        " 59  Job Description num_punctuations                  5365 non-null   int64  \n",
                        " 60  Job Description nltk_tokenized                    5365 non-null   object \n",
                        "dtypes: float64(22), int64(21), object(18)\n",
                        "memory usage: 2.5+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "id": "e95fec77",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5d693de5e6ff4b088111e2fd4feb0c5d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 486 ms, sys: 19.7 ms, total: 505 ms\n",
                        "Wall time: 559 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "df_manual['Job Description gensim_tokenized'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "    lambda sentence: preprocess_string(re.sub(pattern, ' ', sentence.strip().lower()))\n",
                ")\n",
                "\n",
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tokenized_spacy_nltk_gensim.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tokenized_spacy_nltk_gensim.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "id": "1cc29198",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0    [wer, grow, sale, team, emea, market, want, j...\n",
                            "1                       [look, adventur, big, respons]\n",
                            "2                                 [experi, close, saa]\n",
                            "3                [deal, mid, market, enterpris, space]\n",
                            "4    [readi, team, drive, happeo, sky, high, worldwid]\n",
                            "Name: Job Description gensim_tokenized, dtype: object"
                        ]
                    },
                    "execution_count": 98,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual['Job Description gensim_tokenized'].head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "id": "0a69a8de",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5365 entries, 0 to 5364\n",
                        "Data columns (total 62 columns):\n",
                        " #   Column                                            Non-Null Count  Dtype  \n",
                        "---  ------                                            --------------  -----  \n",
                        " 0   Job ID                                            5365 non-null   object \n",
                        " 1   Job Description spacy_sentencized                 5365 non-null   object \n",
                        " 2   Warmth                                            5365 non-null   int64  \n",
                        " 3   Competence                                        5365 non-null   int64  \n",
                        " 4   Dutch Requirement                                 5365 non-null   int64  \n",
                        " 5   English Requirement                               5365 non-null   int64  \n",
                        " 6   Search Keyword                                    5365 non-null   object \n",
                        " 7   Platform                                          5365 non-null   object \n",
                        " 8   Job Title                                         5365 non-null   object \n",
                        " 9   Company Name                                      5365 non-null   object \n",
                        " 10  Location                                          5365 non-null   object \n",
                        " 11  Employment Type                                   5137 non-null   object \n",
                        " 12  Industry                                          228 non-null    object \n",
                        " 13  Type of ownership                                 228 non-null    object \n",
                        " 14  Sector Code                                       5365 non-null   object \n",
                        " 15  Sector                                            5365 non-null   object \n",
                        " 16  Keywords Count                                    5365 non-null   float64\n",
                        " 17  % per Sector                                      5365 non-null   float64\n",
                        " 18  % per Social Category                             5365 non-null   float64\n",
                        " 19  % per Workforce                                   5365 non-null   float64\n",
                        " 20  Gender_Female_n                                   5365 non-null   float64\n",
                        " 21  Gender_Female_% per Sector                        5365 non-null   float64\n",
                        " 22  Gender_Female_% per Social Category               5365 non-null   float64\n",
                        " 23  Gender_Female_% per Workforce                     5365 non-null   float64\n",
                        " 24  Gender_Male_n                                     5365 non-null   float64\n",
                        " 25  Gender_Male_% per Sector                          5365 non-null   float64\n",
                        " 26  Gender_Male_% per Social Category                 5365 non-null   float64\n",
                        " 27  Gender_Male_% per Workforce                       5365 non-null   float64\n",
                        " 28  Gender                                            5365 non-null   object \n",
                        " 29  Age_Older_n                                       5365 non-null   float64\n",
                        " 30  Age_Older_% per Sector                            5365 non-null   float64\n",
                        " 31  Age_Older_% per Social Category                   5365 non-null   float64\n",
                        " 32  Age_Older_% per Workforce                         5365 non-null   float64\n",
                        " 33  Age_Younger_n                                     5365 non-null   float64\n",
                        " 34  Age_Younger_% per Sector                          5365 non-null   float64\n",
                        " 35  Age_Younger_% per Social Category                 5365 non-null   float64\n",
                        " 36  Age_Younger_% per Workforce                       5365 non-null   float64\n",
                        " 37  Age                                               5365 non-null   object \n",
                        " 38  Sector_n                                          5365 non-null   float64\n",
                        " 39  % Sector per Workforce                            5365 non-null   float64\n",
                        " 40  Gender_Female                                     5365 non-null   int64  \n",
                        " 41  Gender_Male                                       5365 non-null   int64  \n",
                        " 42  Gender_Mixed                                      5365 non-null   int64  \n",
                        " 43  Age_Mixed                                         5365 non-null   int64  \n",
                        " 44  Age_Older                                         5365 non-null   int64  \n",
                        " 45  Age_Younger                                       5365 non-null   int64  \n",
                        " 46  Gender_Num                                        5365 non-null   int64  \n",
                        " 47  Age_Num                                           5365 non-null   int64  \n",
                        " 48  Platform_Num                                      5365 non-null   int64  \n",
                        " 49  Platform_LinkedIn                                 5365 non-null   int64  \n",
                        " 50  Platform_Indeed                                   5365 non-null   int64  \n",
                        " 51  Platform_Glassdoor                                5365 non-null   int64  \n",
                        " 52  Job Description spacy_sentencized_lower           5365 non-null   object \n",
                        " 53  Job Description spacy_tokenized                   5365 non-null   object \n",
                        " 54  Job Description spacy_sentencized_cleaned         5365 non-null   object \n",
                        " 55  Job Description num_words                         5365 non-null   int64  \n",
                        " 56  Job Description num_unique_words                  5365 non-null   int64  \n",
                        " 57  Job Description num_chars                         5365 non-null   int64  \n",
                        " 58  Job Description num_chars_no_whitespact_and_punt  5365 non-null   int64  \n",
                        " 59  Job Description num_punctuations                  5365 non-null   int64  \n",
                        " 60  Job Description nltk_tokenized                    5365 non-null   object \n",
                        " 61  Job Description gensim_tokenized                  5365 non-null   object \n",
                        "dtypes: float64(22), int64(21), object(19)\n",
                        "memory usage: 2.5+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "id": "a62be70e",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tokenized_spacy_nltk_gensim.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tokenized_spacy_nltk_gensim.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eeb0131f",
            "metadata": {},
            "source": [
                "# Use BERT to tokenize sentences\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "efcf30fc",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_TOKENIZED_SPACY_NLTK_GENSIM\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "id": "c81e981f",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "id": "6f6ae091",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "id": "ec899945",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_tokenized_spacy_nltk_gensim.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "id": "d42a3b60",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5365 entries, 0 to 5364\n",
                        "Data columns (total 62 columns):\n",
                        " #   Column                                            Non-Null Count  Dtype  \n",
                        "---  ------                                            --------------  -----  \n",
                        " 0   Job ID                                            5365 non-null   object \n",
                        " 1   Job Description spacy_sentencized                 5365 non-null   object \n",
                        " 2   Warmth                                            5365 non-null   int64  \n",
                        " 3   Competence                                        5365 non-null   int64  \n",
                        " 4   Dutch Requirement                                 5365 non-null   int64  \n",
                        " 5   English Requirement                               5365 non-null   int64  \n",
                        " 6   Search Keyword                                    5365 non-null   object \n",
                        " 7   Platform                                          5365 non-null   object \n",
                        " 8   Job Title                                         5365 non-null   object \n",
                        " 9   Company Name                                      5365 non-null   object \n",
                        " 10  Location                                          5365 non-null   object \n",
                        " 11  Employment Type                                   5137 non-null   object \n",
                        " 12  Industry                                          228 non-null    object \n",
                        " 13  Type of ownership                                 228 non-null    object \n",
                        " 14  Sector Code                                       5365 non-null   object \n",
                        " 15  Sector                                            5365 non-null   object \n",
                        " 16  Keywords Count                                    5365 non-null   float64\n",
                        " 17  % per Sector                                      5365 non-null   float64\n",
                        " 18  % per Social Category                             5365 non-null   float64\n",
                        " 19  % per Workforce                                   5365 non-null   float64\n",
                        " 20  Gender_Female_n                                   5365 non-null   float64\n",
                        " 21  Gender_Female_% per Sector                        5365 non-null   float64\n",
                        " 22  Gender_Female_% per Social Category               5365 non-null   float64\n",
                        " 23  Gender_Female_% per Workforce                     5365 non-null   float64\n",
                        " 24  Gender_Male_n                                     5365 non-null   float64\n",
                        " 25  Gender_Male_% per Sector                          5365 non-null   float64\n",
                        " 26  Gender_Male_% per Social Category                 5365 non-null   float64\n",
                        " 27  Gender_Male_% per Workforce                       5365 non-null   float64\n",
                        " 28  Gender                                            5365 non-null   object \n",
                        " 29  Age_Older_n                                       5365 non-null   float64\n",
                        " 30  Age_Older_% per Sector                            5365 non-null   float64\n",
                        " 31  Age_Older_% per Social Category                   5365 non-null   float64\n",
                        " 32  Age_Older_% per Workforce                         5365 non-null   float64\n",
                        " 33  Age_Younger_n                                     5365 non-null   float64\n",
                        " 34  Age_Younger_% per Sector                          5365 non-null   float64\n",
                        " 35  Age_Younger_% per Social Category                 5365 non-null   float64\n",
                        " 36  Age_Younger_% per Workforce                       5365 non-null   float64\n",
                        " 37  Age                                               5365 non-null   object \n",
                        " 38  Sector_n                                          5365 non-null   float64\n",
                        " 39  % Sector per Workforce                            5365 non-null   float64\n",
                        " 40  Gender_Female                                     5365 non-null   int64  \n",
                        " 41  Gender_Male                                       5365 non-null   int64  \n",
                        " 42  Gender_Mixed                                      5365 non-null   int64  \n",
                        " 43  Age_Mixed                                         5365 non-null   int64  \n",
                        " 44  Age_Older                                         5365 non-null   int64  \n",
                        " 45  Age_Younger                                       5365 non-null   int64  \n",
                        " 46  Gender_Num                                        5365 non-null   int64  \n",
                        " 47  Age_Num                                           5365 non-null   int64  \n",
                        " 48  Platform_Num                                      5365 non-null   int64  \n",
                        " 49  Platform_LinkedIn                                 5365 non-null   int64  \n",
                        " 50  Platform_Indeed                                   5365 non-null   int64  \n",
                        " 51  Platform_Glassdoor                                5365 non-null   int64  \n",
                        " 52  Job Description spacy_sentencized_lower           5365 non-null   object \n",
                        " 53  Job Description spacy_tokenized                   5365 non-null   object \n",
                        " 54  Job Description spacy_sentencized_cleaned         5365 non-null   object \n",
                        " 55  Job Description num_words                         5365 non-null   int64  \n",
                        " 56  Job Description num_unique_words                  5365 non-null   int64  \n",
                        " 57  Job Description num_chars                         5365 non-null   int64  \n",
                        " 58  Job Description num_chars_no_whitespact_and_punt  5365 non-null   int64  \n",
                        " 59  Job Description num_punctuations                  5365 non-null   int64  \n",
                        " 60  Job Description nltk_tokenized                    5365 non-null   object \n",
                        " 61  Job Description gensim_tokenized                  5365 non-null   object \n",
                        "dtypes: float64(22), int64(21), object(19)\n",
                        "memory usage: 2.5+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 105,
            "id": "f8bc6622",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using MPS\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
                        "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
                        "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
                        "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f8cc66abcfb744179beef61e499c48d0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e7d543341fa14a3db58aa5fb4cc783cd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "fa8b5e3351ad43c7ba817fc0d80324e5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 3.59 s, sys: 840 ms, total: 4.43 s\n",
                        "Wall time: 5.6 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "max_length = 512\n",
                "returned_tensor = 'pt'\n",
                "cpu_counts = torch.multiprocessing.cpu_count()\n",
                "device = torch.device('mps') if torch.has_mps and torch.backends.mps.is_built() and torch.backends.mps.is_available() else torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "device_name = str(device.type)\n",
                "print(f'Using {device_name.upper()}')\n",
                "bert_model_name = 'bert-base-uncased'\n",
                "bert_tokenizer = BertTokenizerFast.from_pretrained(bert_model_name, strip_accents = True)\n",
                "bert_model = BertForSequenceClassification.from_pretrained(bert_model_name).to(device)\n",
                "\n",
                "df_manual['Job Description bert_encodings'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "    lambda sentence: bert_tokenizer(\n",
                "        str(sentence), truncation=True, padding=True, max_length=max_length, return_tensors=returned_tensor\n",
                "    )\n",
                ")\n",
                "\n",
                "df_manual['Job Description bert_tokenized'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "    lambda sentence: bert_tokenizer.tokenize(str(sentence))\n",
                ")\n",
                "\n",
                "df_manual['Job Description bert_tokenized_to_id'] = df_manual['Job Description bert_tokenized'].progress_apply(\n",
                "    lambda sentence: bert_tokenizer.convert_tokens_to_ids(str(sentence))\n",
                ")\n",
                "\n",
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tokenized_spacy_nltk_gensim_bert.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tokenized_spacy_nltk_gensim_bert.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 106,
            "id": "1d996bc4",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0    [input_ids, token_type_ids, attention_mask]\n",
                            "1    [input_ids, token_type_ids, attention_mask]\n",
                            "2    [input_ids, token_type_ids, attention_mask]\n",
                            "3    [input_ids, token_type_ids, attention_mask]\n",
                            "4    [input_ids, token_type_ids, attention_mask]\n",
                            "Name: Job Description bert_encodings, dtype: object"
                        ]
                    },
                    "execution_count": 106,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual['Job Description bert_encodings'].head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 107,
            "id": "9ae92181",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0    [we, , re, growing, our, sales, team, for, th...\n",
                            "1    [are, you, looking, for, an, adventure, , one...\n",
                            "2    [do, you, have, experience, closing, b, ##2, #...\n",
                            "3    [s, deals, in, the, mid, -, market, and, enter...\n",
                            "4    [then, you, might, be, ready, to, become, part...\n",
                            "Name: Job Description bert_tokenized, dtype: object"
                        ]
                    },
                    "execution_count": 107,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual['Job Description bert_tokenized'].head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "id": "5f7a4ae3",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0    100\n",
                            "1    100\n",
                            "2    100\n",
                            "3    100\n",
                            "4    100\n",
                            "Name: Job Description bert_tokenized_to_id, dtype: int64"
                        ]
                    },
                    "execution_count": 108,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual['Job Description bert_tokenized_to_id'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "id": "8936c818",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tokenized_spacy_nltk_gensim_bert.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tokenized_spacy_nltk_gensim_bert.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6c0bfad5",
            "metadata": {},
            "source": [
                "# ATTN: This script should be run AFTER all tokenization (spacy, nltk, gensim, and BERT) completed.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e4a62460",
            "metadata": {},
            "source": [
                "# Use spacy to create Parts-Of-Speech (POS) tags, lemmas, and stems\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "374d2178",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_TOKENIZED_SPACY_NLTK_GENSIM_BERT\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "id": "c74f96a0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "id": "0053cd25",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "id": "10424739",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_tokenized_spacy_nltk_gensim_bert.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "id": "08c5b9fb",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5365 entries, 0 to 5364\n",
                        "Data columns (total 65 columns):\n",
                        " #   Column                                            Non-Null Count  Dtype  \n",
                        "---  ------                                            --------------  -----  \n",
                        " 0   Job ID                                            5365 non-null   object \n",
                        " 1   Job Description spacy_sentencized                 5365 non-null   object \n",
                        " 2   Warmth                                            5365 non-null   int64  \n",
                        " 3   Competence                                        5365 non-null   int64  \n",
                        " 4   Dutch Requirement                                 5365 non-null   int64  \n",
                        " 5   English Requirement                               5365 non-null   int64  \n",
                        " 6   Search Keyword                                    5365 non-null   object \n",
                        " 7   Platform                                          5365 non-null   object \n",
                        " 8   Job Title                                         5365 non-null   object \n",
                        " 9   Company Name                                      5365 non-null   object \n",
                        " 10  Location                                          5365 non-null   object \n",
                        " 11  Employment Type                                   5137 non-null   object \n",
                        " 12  Industry                                          228 non-null    object \n",
                        " 13  Type of ownership                                 228 non-null    object \n",
                        " 14  Sector Code                                       5365 non-null   object \n",
                        " 15  Sector                                            5365 non-null   object \n",
                        " 16  Keywords Count                                    5365 non-null   float64\n",
                        " 17  % per Sector                                      5365 non-null   float64\n",
                        " 18  % per Social Category                             5365 non-null   float64\n",
                        " 19  % per Workforce                                   5365 non-null   float64\n",
                        " 20  Gender_Female_n                                   5365 non-null   float64\n",
                        " 21  Gender_Female_% per Sector                        5365 non-null   float64\n",
                        " 22  Gender_Female_% per Social Category               5365 non-null   float64\n",
                        " 23  Gender_Female_% per Workforce                     5365 non-null   float64\n",
                        " 24  Gender_Male_n                                     5365 non-null   float64\n",
                        " 25  Gender_Male_% per Sector                          5365 non-null   float64\n",
                        " 26  Gender_Male_% per Social Category                 5365 non-null   float64\n",
                        " 27  Gender_Male_% per Workforce                       5365 non-null   float64\n",
                        " 28  Gender                                            5365 non-null   object \n",
                        " 29  Age_Older_n                                       5365 non-null   float64\n",
                        " 30  Age_Older_% per Sector                            5365 non-null   float64\n",
                        " 31  Age_Older_% per Social Category                   5365 non-null   float64\n",
                        " 32  Age_Older_% per Workforce                         5365 non-null   float64\n",
                        " 33  Age_Younger_n                                     5365 non-null   float64\n",
                        " 34  Age_Younger_% per Sector                          5365 non-null   float64\n",
                        " 35  Age_Younger_% per Social Category                 5365 non-null   float64\n",
                        " 36  Age_Younger_% per Workforce                       5365 non-null   float64\n",
                        " 37  Age                                               5365 non-null   object \n",
                        " 38  Sector_n                                          5365 non-null   float64\n",
                        " 39  % Sector per Workforce                            5365 non-null   float64\n",
                        " 40  Gender_Female                                     5365 non-null   int64  \n",
                        " 41  Gender_Male                                       5365 non-null   int64  \n",
                        " 42  Gender_Mixed                                      5365 non-null   int64  \n",
                        " 43  Age_Mixed                                         5365 non-null   int64  \n",
                        " 44  Age_Older                                         5365 non-null   int64  \n",
                        " 45  Age_Younger                                       5365 non-null   int64  \n",
                        " 46  Gender_Num                                        5365 non-null   int64  \n",
                        " 47  Age_Num                                           5365 non-null   int64  \n",
                        " 48  Platform_Num                                      5365 non-null   int64  \n",
                        " 49  Platform_LinkedIn                                 5365 non-null   int64  \n",
                        " 50  Platform_Indeed                                   5365 non-null   int64  \n",
                        " 51  Platform_Glassdoor                                5365 non-null   int64  \n",
                        " 52  Job Description spacy_sentencized_lower           5365 non-null   object \n",
                        " 53  Job Description spacy_tokenized                   5365 non-null   object \n",
                        " 54  Job Description spacy_sentencized_cleaned         5365 non-null   object \n",
                        " 55  Job Description num_words                         5365 non-null   int64  \n",
                        " 56  Job Description num_unique_words                  5365 non-null   int64  \n",
                        " 57  Job Description num_chars                         5365 non-null   int64  \n",
                        " 58  Job Description num_chars_no_whitespact_and_punt  5365 non-null   int64  \n",
                        " 59  Job Description num_punctuations                  5365 non-null   int64  \n",
                        " 60  Job Description nltk_tokenized                    5365 non-null   object \n",
                        " 61  Job Description gensim_tokenized                  5365 non-null   object \n",
                        " 62  Job Description bert_encodings                    5365 non-null   object \n",
                        " 63  Job Description bert_tokenized                    5365 non-null   object \n",
                        " 64  Job Description bert_tokenized_to_id              5365 non-null   int64  \n",
                        "dtypes: float64(22), int64(22), object(21)\n",
                        "memory usage: 2.7+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "id": "45e45b2c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7f9b49af89fc43fe80abd7ac064ff89a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "efae00dfc41341aabda0ddd6117946a1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1711007f572a4bb8a65b9bcc72b7c035",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 1min 19s, sys: 1.58 s, total: 1min 21s\n",
                        "Wall time: 1min 32s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Load customer characters\n",
                "with open(f'{data_dir}punctuations.txt', 'rb') as f:\n",
                "    custom_punct_chars = pickle.load(f)\n",
                "\n",
                "# POS tagging\n",
                "df_manual['Job Description spacy_token_tags'] = df_manual[\n",
                "    'Job Description spacy_sentencized'\n",
                "].progress_apply(\n",
                "    lambda job_sentence: [\n",
                "        (token.text.strip().lower(), token.tag_) for token in nlp(job_sentence)\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Lemmatization\n",
                "df_manual['Job Description spacy_lemmas'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "    lambda job_sentence: [\n",
                "        token.lemma_.strip().lower()\n",
                "        for token in nlp(job_sentence)\n",
                "        if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Stemming\n",
                "df_manual['Job Description spacy_stems'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "    lambda job_sentence: [\n",
                "        stemmer.stem(token.text.strip().lower())\n",
                "        for token in nlp(job_sentence)\n",
                "        if len(token) != 0 and not token.is_stop and not token.is_punct and token.text not in custom_punct_chars\n",
                "    ]\n",
                ")\n",
                "\n",
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "id": "9d8332f9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5365 entries, 0 to 5364\n",
                        "Data columns (total 68 columns):\n",
                        " #   Column                                            Non-Null Count  Dtype  \n",
                        "---  ------                                            --------------  -----  \n",
                        " 0   Job ID                                            5365 non-null   object \n",
                        " 1   Job Description spacy_sentencized                 5365 non-null   object \n",
                        " 2   Warmth                                            5365 non-null   int64  \n",
                        " 3   Competence                                        5365 non-null   int64  \n",
                        " 4   Dutch Requirement                                 5365 non-null   int64  \n",
                        " 5   English Requirement                               5365 non-null   int64  \n",
                        " 6   Search Keyword                                    5365 non-null   object \n",
                        " 7   Platform                                          5365 non-null   object \n",
                        " 8   Job Title                                         5365 non-null   object \n",
                        " 9   Company Name                                      5365 non-null   object \n",
                        " 10  Location                                          5365 non-null   object \n",
                        " 11  Employment Type                                   5137 non-null   object \n",
                        " 12  Industry                                          228 non-null    object \n",
                        " 13  Type of ownership                                 228 non-null    object \n",
                        " 14  Sector Code                                       5365 non-null   object \n",
                        " 15  Sector                                            5365 non-null   object \n",
                        " 16  Keywords Count                                    5365 non-null   float64\n",
                        " 17  % per Sector                                      5365 non-null   float64\n",
                        " 18  % per Social Category                             5365 non-null   float64\n",
                        " 19  % per Workforce                                   5365 non-null   float64\n",
                        " 20  Gender_Female_n                                   5365 non-null   float64\n",
                        " 21  Gender_Female_% per Sector                        5365 non-null   float64\n",
                        " 22  Gender_Female_% per Social Category               5365 non-null   float64\n",
                        " 23  Gender_Female_% per Workforce                     5365 non-null   float64\n",
                        " 24  Gender_Male_n                                     5365 non-null   float64\n",
                        " 25  Gender_Male_% per Sector                          5365 non-null   float64\n",
                        " 26  Gender_Male_% per Social Category                 5365 non-null   float64\n",
                        " 27  Gender_Male_% per Workforce                       5365 non-null   float64\n",
                        " 28  Gender                                            5365 non-null   object \n",
                        " 29  Age_Older_n                                       5365 non-null   float64\n",
                        " 30  Age_Older_% per Sector                            5365 non-null   float64\n",
                        " 31  Age_Older_% per Social Category                   5365 non-null   float64\n",
                        " 32  Age_Older_% per Workforce                         5365 non-null   float64\n",
                        " 33  Age_Younger_n                                     5365 non-null   float64\n",
                        " 34  Age_Younger_% per Sector                          5365 non-null   float64\n",
                        " 35  Age_Younger_% per Social Category                 5365 non-null   float64\n",
                        " 36  Age_Younger_% per Workforce                       5365 non-null   float64\n",
                        " 37  Age                                               5365 non-null   object \n",
                        " 38  Sector_n                                          5365 non-null   float64\n",
                        " 39  % Sector per Workforce                            5365 non-null   float64\n",
                        " 40  Gender_Female                                     5365 non-null   int64  \n",
                        " 41  Gender_Male                                       5365 non-null   int64  \n",
                        " 42  Gender_Mixed                                      5365 non-null   int64  \n",
                        " 43  Age_Mixed                                         5365 non-null   int64  \n",
                        " 44  Age_Older                                         5365 non-null   int64  \n",
                        " 45  Age_Younger                                       5365 non-null   int64  \n",
                        " 46  Gender_Num                                        5365 non-null   int64  \n",
                        " 47  Age_Num                                           5365 non-null   int64  \n",
                        " 48  Platform_Num                                      5365 non-null   int64  \n",
                        " 49  Platform_LinkedIn                                 5365 non-null   int64  \n",
                        " 50  Platform_Indeed                                   5365 non-null   int64  \n",
                        " 51  Platform_Glassdoor                                5365 non-null   int64  \n",
                        " 52  Job Description spacy_sentencized_lower           5365 non-null   object \n",
                        " 53  Job Description spacy_tokenized                   5365 non-null   object \n",
                        " 54  Job Description spacy_sentencized_cleaned         5365 non-null   object \n",
                        " 55  Job Description num_words                         5365 non-null   int64  \n",
                        " 56  Job Description num_unique_words                  5365 non-null   int64  \n",
                        " 57  Job Description num_chars                         5365 non-null   int64  \n",
                        " 58  Job Description num_chars_no_whitespact_and_punt  5365 non-null   int64  \n",
                        " 59  Job Description num_punctuations                  5365 non-null   int64  \n",
                        " 60  Job Description nltk_tokenized                    5365 non-null   object \n",
                        " 61  Job Description gensim_tokenized                  5365 non-null   object \n",
                        " 62  Job Description bert_encodings                    5365 non-null   object \n",
                        " 63  Job Description bert_tokenized                    5365 non-null   object \n",
                        " 64  Job Description bert_tokenized_to_id              5365 non-null   int64  \n",
                        " 65  Job Description spacy_token_tags                  5365 non-null   object \n",
                        " 66  Job Description spacy_lemmas                      5365 non-null   object \n",
                        " 67  Job Description spacy_stems                       5365 non-null   object \n",
                        "dtypes: float64(22), int64(22), object(24)\n",
                        "memory usage: 2.8+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 116,
            "id": "5d8d37b3",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: center;\">\n",
                            "      <th></th>\n",
                            "      <th>Job Description spacy_token_tags</th>\n",
                            "      <th>Job Description spacy_lemmas</th>\n",
                            "      <th>Job Description spacy_stems</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>[(we, PRP), (re, VBP), (growing, VBG), (our, ...</td>\n",
                            "      <td>[grow, sale, team, emea, market, want, journey]</td>\n",
                            "      <td>[grow, sale, team, emea, market, want, journey]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>[(are, VBP), (you, PRP), (looking, VBG), (for,...</td>\n",
                            "      <td>[look, adventure, big, responsibility]</td>\n",
                            "      <td>[look, adventur, big, respons]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>[(do, VBP), (you, PRP), (have, VB), (experienc...</td>\n",
                            "      <td>[experience, close, b2b, saa]</td>\n",
                            "      <td>[experi, close, b2b, saa]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>[(s, NN), (deals, VBZ), (in, IN), (the, DT), (...</td>\n",
                            "      <td>[s, deal, mid, market, enterprise, space]</td>\n",
                            "      <td>[s, deal, mid, market, enterpris, space]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>[(then, RB), (you, PRP), (might, MD), (be, VB)...</td>\n",
                            "      <td>[ready, team, drive, happeo, sky, high, worldw...</td>\n",
                            "      <td>[readi, team, drive, happeo, sky, high, worldwid]</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "           Job Description spacy_token_tags                     Job Description spacy_lemmas                       Job Description spacy_stems            \n",
                            "0  [(we, PRP), (re, VBP), (growing, VBG), (our, ...    [grow, sale, team, emea, market, want, journey]    [grow, sale, team, emea, market, want, journey]\n",
                            "1  [(are, VBP), (you, PRP), (looking, VBG), (for,...             [look, adventure, big, responsibility]                     [look, adventur, big, respons]\n",
                            "2  [(do, VBP), (you, PRP), (have, VB), (experienc...                      [experience, close, b2b, saa]                          [experi, close, b2b, saa]\n",
                            "3  [(s, NN), (deals, VBZ), (in, IN), (the, DT), (...          [s, deal, mid, market, enterprise, space]           [s, deal, mid, market, enterpris, space]\n",
                            "4  [(then, RB), (you, PRP), (might, MD), (be, VB)...  [ready, team, drive, happeo, sky, high, worldw...  [readi, team, drive, happeo, sky, high, worldwid]"
                        ]
                    },
                    "execution_count": 116,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual[\n",
                "    [\n",
                "        'Job Description spacy_token_tags',\n",
                "        'Job Description spacy_lemmas',\n",
                "        'Job Description spacy_stems'\n",
                "    ]\n",
                "].head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 117,
            "id": "fa7acdc1",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8c74665a",
            "metadata": {},
            "source": [
                "# Use NLTK to create Parts-Of-Speech (POS) tags, lemmas, and stems\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "12fe6cb2",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_TAGS_LEMMAS_STEMS_SPACY\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 118,
            "id": "7c765e8d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 119,
            "id": "d114a298",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 120,
            "id": "ac327ec6",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_wordnet_pos(token):\n",
                "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
                "    tag = nltk.pos_tag([token])[0][1][0].upper()\n",
                "    tag_dict = {\"J\": wordnet.ADJ,\n",
                "                \"N\": wordnet.NOUN,\n",
                "                \"V\": wordnet.VERB,\n",
                "                \"R\": wordnet.ADV}\n",
                "\n",
                "    return tag_dict.get(tag, wordnet.NOUN)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 121,
            "id": "0b5e476b",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 122,
            "id": "6f5c1c44",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5365 entries, 0 to 5364\n",
                        "Data columns (total 68 columns):\n",
                        " #   Column                                            Non-Null Count  Dtype  \n",
                        "---  ------                                            --------------  -----  \n",
                        " 0   Job ID                                            5365 non-null   object \n",
                        " 1   Job Description spacy_sentencized                 5365 non-null   object \n",
                        " 2   Warmth                                            5365 non-null   int64  \n",
                        " 3   Competence                                        5365 non-null   int64  \n",
                        " 4   Dutch Requirement                                 5365 non-null   int64  \n",
                        " 5   English Requirement                               5365 non-null   int64  \n",
                        " 6   Search Keyword                                    5365 non-null   object \n",
                        " 7   Platform                                          5365 non-null   object \n",
                        " 8   Job Title                                         5365 non-null   object \n",
                        " 9   Company Name                                      5365 non-null   object \n",
                        " 10  Location                                          5365 non-null   object \n",
                        " 11  Employment Type                                   5137 non-null   object \n",
                        " 12  Industry                                          228 non-null    object \n",
                        " 13  Type of ownership                                 228 non-null    object \n",
                        " 14  Sector Code                                       5365 non-null   object \n",
                        " 15  Sector                                            5365 non-null   object \n",
                        " 16  Keywords Count                                    5365 non-null   float64\n",
                        " 17  % per Sector                                      5365 non-null   float64\n",
                        " 18  % per Social Category                             5365 non-null   float64\n",
                        " 19  % per Workforce                                   5365 non-null   float64\n",
                        " 20  Gender_Female_n                                   5365 non-null   float64\n",
                        " 21  Gender_Female_% per Sector                        5365 non-null   float64\n",
                        " 22  Gender_Female_% per Social Category               5365 non-null   float64\n",
                        " 23  Gender_Female_% per Workforce                     5365 non-null   float64\n",
                        " 24  Gender_Male_n                                     5365 non-null   float64\n",
                        " 25  Gender_Male_% per Sector                          5365 non-null   float64\n",
                        " 26  Gender_Male_% per Social Category                 5365 non-null   float64\n",
                        " 27  Gender_Male_% per Workforce                       5365 non-null   float64\n",
                        " 28  Gender                                            5365 non-null   object \n",
                        " 29  Age_Older_n                                       5365 non-null   float64\n",
                        " 30  Age_Older_% per Sector                            5365 non-null   float64\n",
                        " 31  Age_Older_% per Social Category                   5365 non-null   float64\n",
                        " 32  Age_Older_% per Workforce                         5365 non-null   float64\n",
                        " 33  Age_Younger_n                                     5365 non-null   float64\n",
                        " 34  Age_Younger_% per Sector                          5365 non-null   float64\n",
                        " 35  Age_Younger_% per Social Category                 5365 non-null   float64\n",
                        " 36  Age_Younger_% per Workforce                       5365 non-null   float64\n",
                        " 37  Age                                               5365 non-null   object \n",
                        " 38  Sector_n                                          5365 non-null   float64\n",
                        " 39  % Sector per Workforce                            5365 non-null   float64\n",
                        " 40  Gender_Female                                     5365 non-null   int64  \n",
                        " 41  Gender_Male                                       5365 non-null   int64  \n",
                        " 42  Gender_Mixed                                      5365 non-null   int64  \n",
                        " 43  Age_Mixed                                         5365 non-null   int64  \n",
                        " 44  Age_Older                                         5365 non-null   int64  \n",
                        " 45  Age_Younger                                       5365 non-null   int64  \n",
                        " 46  Gender_Num                                        5365 non-null   int64  \n",
                        " 47  Age_Num                                           5365 non-null   int64  \n",
                        " 48  Platform_Num                                      5365 non-null   int64  \n",
                        " 49  Platform_LinkedIn                                 5365 non-null   int64  \n",
                        " 50  Platform_Indeed                                   5365 non-null   int64  \n",
                        " 51  Platform_Glassdoor                                5365 non-null   int64  \n",
                        " 52  Job Description spacy_sentencized_lower           5365 non-null   object \n",
                        " 53  Job Description spacy_tokenized                   5365 non-null   object \n",
                        " 54  Job Description spacy_sentencized_cleaned         5365 non-null   object \n",
                        " 55  Job Description num_words                         5365 non-null   int64  \n",
                        " 56  Job Description num_unique_words                  5365 non-null   int64  \n",
                        " 57  Job Description num_chars                         5365 non-null   int64  \n",
                        " 58  Job Description num_chars_no_whitespact_and_punt  5365 non-null   int64  \n",
                        " 59  Job Description num_punctuations                  5365 non-null   int64  \n",
                        " 60  Job Description nltk_tokenized                    5365 non-null   object \n",
                        " 61  Job Description gensim_tokenized                  5365 non-null   object \n",
                        " 62  Job Description bert_encodings                    5365 non-null   object \n",
                        " 63  Job Description bert_tokenized                    5365 non-null   object \n",
                        " 64  Job Description bert_tokenized_to_id              5365 non-null   int64  \n",
                        " 65  Job Description spacy_token_tags                  5365 non-null   object \n",
                        " 66  Job Description spacy_lemmas                      5365 non-null   object \n",
                        " 67  Job Description spacy_stems                       5365 non-null   object \n",
                        "dtypes: float64(22), int64(22), object(24)\n",
                        "memory usage: 2.8+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 123,
            "id": "92fb117a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9df4e7b0de434344ac70c27431811424",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0eed2ed6913d4c6e86ea6ac9fe3ebbf5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0186e2d8ce784df08b4ec4786a09c954",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 8.56 s, sys: 1.55 s, total: 10.1 s\n",
                        "Wall time: 11.3 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# POS tagging\n",
                "df_manual['Job Description nltk_token_tags'] = df_manual['Job Description spacy_tokenized'].progress_apply(\n",
                "    lambda token: pos_tag(token)\n",
                ")\n",
                "\n",
                "# Lemmatization\n",
                "df_manual['Job Description nltk_lemmas'] = df_manual['Job Description spacy_tokenized'].progress_apply(\n",
                "    lambda tokens: [\n",
                "        lemmatizer.lemmatize(\n",
                "            token, get_wordnet_pos(\n",
                "                unicodedata.normalize('NFKD', str(token.strip().lower())).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
                "            )\n",
                "        )\n",
                "        for token in tokens\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Stemming\n",
                "df_manual['Job Description nltk_stems'] = df_manual['Job Description spacy_tokenized'].progress_apply(\n",
                "    lambda tokens: [\n",
                "        stemmer.stem(\n",
                "            unicodedata.normalize('NFKD', str(token.strip().lower())).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
                "        )\n",
                "        for token in tokens\n",
                "    ]\n",
                ")\n",
                "\n",
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy_nltk.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy_nltk.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 124,
            "id": "2893388c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 5365 entries, 0 to 5364\n",
                        "Data columns (total 71 columns):\n",
                        " #   Column                                            Non-Null Count  Dtype  \n",
                        "---  ------                                            --------------  -----  \n",
                        " 0   Job ID                                            5365 non-null   object \n",
                        " 1   Job Description spacy_sentencized                 5365 non-null   object \n",
                        " 2   Warmth                                            5365 non-null   int64  \n",
                        " 3   Competence                                        5365 non-null   int64  \n",
                        " 4   Dutch Requirement                                 5365 non-null   int64  \n",
                        " 5   English Requirement                               5365 non-null   int64  \n",
                        " 6   Search Keyword                                    5365 non-null   object \n",
                        " 7   Platform                                          5365 non-null   object \n",
                        " 8   Job Title                                         5365 non-null   object \n",
                        " 9   Company Name                                      5365 non-null   object \n",
                        " 10  Location                                          5365 non-null   object \n",
                        " 11  Employment Type                                   5137 non-null   object \n",
                        " 12  Industry                                          228 non-null    object \n",
                        " 13  Type of ownership                                 228 non-null    object \n",
                        " 14  Sector Code                                       5365 non-null   object \n",
                        " 15  Sector                                            5365 non-null   object \n",
                        " 16  Keywords Count                                    5365 non-null   float64\n",
                        " 17  % per Sector                                      5365 non-null   float64\n",
                        " 18  % per Social Category                             5365 non-null   float64\n",
                        " 19  % per Workforce                                   5365 non-null   float64\n",
                        " 20  Gender_Female_n                                   5365 non-null   float64\n",
                        " 21  Gender_Female_% per Sector                        5365 non-null   float64\n",
                        " 22  Gender_Female_% per Social Category               5365 non-null   float64\n",
                        " 23  Gender_Female_% per Workforce                     5365 non-null   float64\n",
                        " 24  Gender_Male_n                                     5365 non-null   float64\n",
                        " 25  Gender_Male_% per Sector                          5365 non-null   float64\n",
                        " 26  Gender_Male_% per Social Category                 5365 non-null   float64\n",
                        " 27  Gender_Male_% per Workforce                       5365 non-null   float64\n",
                        " 28  Gender                                            5365 non-null   object \n",
                        " 29  Age_Older_n                                       5365 non-null   float64\n",
                        " 30  Age_Older_% per Sector                            5365 non-null   float64\n",
                        " 31  Age_Older_% per Social Category                   5365 non-null   float64\n",
                        " 32  Age_Older_% per Workforce                         5365 non-null   float64\n",
                        " 33  Age_Younger_n                                     5365 non-null   float64\n",
                        " 34  Age_Younger_% per Sector                          5365 non-null   float64\n",
                        " 35  Age_Younger_% per Social Category                 5365 non-null   float64\n",
                        " 36  Age_Younger_% per Workforce                       5365 non-null   float64\n",
                        " 37  Age                                               5365 non-null   object \n",
                        " 38  Sector_n                                          5365 non-null   float64\n",
                        " 39  % Sector per Workforce                            5365 non-null   float64\n",
                        " 40  Gender_Female                                     5365 non-null   int64  \n",
                        " 41  Gender_Male                                       5365 non-null   int64  \n",
                        " 42  Gender_Mixed                                      5365 non-null   int64  \n",
                        " 43  Age_Mixed                                         5365 non-null   int64  \n",
                        " 44  Age_Older                                         5365 non-null   int64  \n",
                        " 45  Age_Younger                                       5365 non-null   int64  \n",
                        " 46  Gender_Num                                        5365 non-null   int64  \n",
                        " 47  Age_Num                                           5365 non-null   int64  \n",
                        " 48  Platform_Num                                      5365 non-null   int64  \n",
                        " 49  Platform_LinkedIn                                 5365 non-null   int64  \n",
                        " 50  Platform_Indeed                                   5365 non-null   int64  \n",
                        " 51  Platform_Glassdoor                                5365 non-null   int64  \n",
                        " 52  Job Description spacy_sentencized_lower           5365 non-null   object \n",
                        " 53  Job Description spacy_tokenized                   5365 non-null   object \n",
                        " 54  Job Description spacy_sentencized_cleaned         5365 non-null   object \n",
                        " 55  Job Description num_words                         5365 non-null   int64  \n",
                        " 56  Job Description num_unique_words                  5365 non-null   int64  \n",
                        " 57  Job Description num_chars                         5365 non-null   int64  \n",
                        " 58  Job Description num_chars_no_whitespact_and_punt  5365 non-null   int64  \n",
                        " 59  Job Description num_punctuations                  5365 non-null   int64  \n",
                        " 60  Job Description nltk_tokenized                    5365 non-null   object \n",
                        " 61  Job Description gensim_tokenized                  5365 non-null   object \n",
                        " 62  Job Description bert_encodings                    5365 non-null   object \n",
                        " 63  Job Description bert_tokenized                    5365 non-null   object \n",
                        " 64  Job Description bert_tokenized_to_id              5365 non-null   int64  \n",
                        " 65  Job Description spacy_token_tags                  5365 non-null   object \n",
                        " 66  Job Description spacy_lemmas                      5365 non-null   object \n",
                        " 67  Job Description spacy_stems                       5365 non-null   object \n",
                        " 68  Job Description nltk_token_tags                   5365 non-null   object \n",
                        " 69  Job Description nltk_lemmas                       5365 non-null   object \n",
                        " 70  Job Description nltk_stems                        5365 non-null   object \n",
                        "dtypes: float64(22), int64(22), object(27)\n",
                        "memory usage: 2.9+ MB\n"
                    ]
                }
            ],
            "source": [
                "df_manual.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 125,
            "id": "84e2af7a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: center;\">\n",
                            "      <th></th>\n",
                            "      <th>Job Description nltk_token_tags</th>\n",
                            "      <th>Job Description nltk_lemmas</th>\n",
                            "      <th>Job Description nltk_stems</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>[(growing, VBG), (sales, NNS), (team, NN), (em...</td>\n",
                            "      <td>[grow, sale, team, emea, market, want, journey]</td>\n",
                            "      <td>[grow, sale, team, emea, market, want, journey]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>[(looking, VBG), (adventure, NN), (big, JJ), (...</td>\n",
                            "      <td>[look, adventure, big, responsibility]</td>\n",
                            "      <td>[look, adventur, big, respons]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>[(experience, NN), (closing, NN), (b2b, NN), (...</td>\n",
                            "      <td>[experience, closing, b2b, saa]</td>\n",
                            "      <td>[experi, close, b2b, saa]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>[(s, JJ), (deals, NNS), (mid, VBP), (market, N...</td>\n",
                            "      <td>[s, deal, mid, market, enterprise, space]</td>\n",
                            "      <td>[s, deal, mid, market, enterpris, space]</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>[(ready, JJ), (team, NN), (drives, NNS), (happ...</td>\n",
                            "      <td>[ready, team, drive, happeo, sky, high, worldw...</td>\n",
                            "      <td>[readi, team, drive, happeo, sky, high, worldwid]</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "           Job Description nltk_token_tags                      Job Description nltk_lemmas                         Job Description nltk_stems            \n",
                            "0  [(growing, VBG), (sales, NNS), (team, NN), (em...    [grow, sale, team, emea, market, want, journey]    [grow, sale, team, emea, market, want, journey]\n",
                            "1  [(looking, VBG), (adventure, NN), (big, JJ), (...             [look, adventure, big, responsibility]                     [look, adventur, big, respons]\n",
                            "2  [(experience, NN), (closing, NN), (b2b, NN), (...                    [experience, closing, b2b, saa]                          [experi, close, b2b, saa]\n",
                            "3  [(s, JJ), (deals, NNS), (mid, VBP), (market, N...          [s, deal, mid, market, enterprise, space]           [s, deal, mid, market, enterpris, space]\n",
                            "4  [(ready, JJ), (team, NN), (drives, NNS), (happ...  [ready, team, drive, happeo, sky, high, worldw...  [readi, team, drive, happeo, sky, high, worldwid]"
                        ]
                    },
                    "execution_count": 125,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual[['Job Description nltk_token_tags', 'Job Description nltk_lemmas', 'Job Description nltk_stems']].head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 126,
            "id": "102509c1",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy_nltk.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy_nltk.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e5f98098",
            "metadata": {},
            "source": [
                "# Use BERT to create Parts-Of-Speech (POS) tags, lemmas, and stems\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "03dd84df",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_TAGS_LEMMAS_STEMS_SPACY_NLTK\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 127,
            "id": "cfc8511b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "# import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "# from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "# mod = sys.modules[__name__]\n",
                "\n",
                "# code_dir = None\n",
                "# code_dir_name = 'Code'\n",
                "# unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "# for _ in range(5):\n",
                "\n",
                "#     parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "#     if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "#         code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "#         if code_dir is not None:\n",
                "#             break\n",
                "\n",
                "# sys.path.append(code_dir)\n",
                "# # %load_ext autoreload\n",
                "# # %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 128,
            "id": "ec559046",
            "metadata": {},
            "outputs": [],
            "source": [
                "# from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 129,
            "id": "81972d25",
            "metadata": {},
            "outputs": [],
            "source": [
                "# df_manual = pd.read_pickle(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy_nltk.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 130,
            "id": "e0a48ebd",
            "metadata": {},
            "outputs": [],
            "source": [
                "# %%time\n",
                "# bert_pos_model_name = 'QCRI/bert-base-multilingual-cased-pos-english'\n",
                "# bert_pos_model = AutoModelForTokenClassification.from_pretrained(bert_pos_model_name).to(device)\n",
                "# bert_pos_tagger = TokenClassificationPipeline(model=bert_pos_model, tokenizer=bert_tokenizer).to(device)\n",
                "\n",
                "# df_manual['Job Description bert_token_tags_with_scores'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "#     lambda sentence: [\n",
                "#         (bert_pos_tag['word'], bert_pos_tag['entity'], bert_pos_tag['score'])\n",
                "#         for i in range(len(sentence.split()))\n",
                "#         for bert_pos_tag in bert_pos_tagger(sentence)\n",
                "#     ]\n",
                "# )\n",
                "\n",
                "# df_manual['Job Description bert_token_tags'] = df_manual['Job Description bert_token_tags_with_scores'].progress_apply(\n",
                "#     lambda tag_list: [\n",
                "#         [(tag_list[i][0], tag_list[i][1])]\n",
                "#         for tag_tuple in tag_list\n",
                "#         for i in range(len(tag_list))\n",
                "#     ]\n",
                "# )\n",
                "\n",
                "\n",
                "# assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "# df_manual.to_pickle(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy_nltk_bert.pkl')\n",
                "# df_manual.to_csv(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy_nltk_bert.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 131,
            "id": "f4e99e0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# df_manual['Job Description bert_token_tags'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 132,
            "id": "0f7e50a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "# df_manual.to_pickle(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy_nltk_bert.pkl')\n",
                "# df_manual.to_csv(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy_nltk_bert.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1122d883",
            "metadata": {},
            "source": [
                "# ATTN: This script should be run AFTER all POS tagging, lemmatization, and stemming (spacy and nltk) completed.\n",
                "# If BERT POS tagging was done, change pkl file loading\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "206a80dd",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_TAGS_LEMMAS_STEMS_SPACY_NLTK\n",
                "### IF BERT POS TAGGING WAS DONE, SOURCING FROM df_manual_TAGS_LEMMAS_STEMS_SPACY_NLTK_BERT\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e54cb736",
            "metadata": {},
            "source": [
                "# Use spacy to create bi and trigrams\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 133,
            "id": "980b3608",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import importlib\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 134,
            "id": "520614c1",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 135,
            "id": "405cfdc3",
            "metadata": {},
            "outputs": [],
            "source": [
                "def spacy_make_ngrams(sentence, matcher, gram_type):\n",
                "\n",
                "    doc = nlp(sentence)\n",
                "    matches = matcher(doc)\n",
                "    matches_list = []\n",
                "\n",
                "    for idx in range(len(matches)):\n",
                "        for match_id, start, end in matches:\n",
                "            if nlp.vocab.strings[match_id].split('_')[0] == gram_type:\n",
                "                match = doc[matches[idx][1]: matches[idx][2]].text\n",
                "                matches_list.append(match.lower())\n",
                "    \n",
                "    return list(set(matches_list))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 136,
            "id": "b6d7a1b4",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_tags_lemmas_stems_spacy_nltk.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 137,
            "id": "ae54c422",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6c9557b4bc584ba3832789f3e1731682",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 20.6 ms, sys: 5.3 ms, total: 25.9 ms\n",
                        "Wall time: 28 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "df_manual['Job Description spacy_1grams_original_list'] = df_manual['Job Description spacy_tokenized']\n",
                "df_manual['Job Description spacy_1grams'] = df_manual['Job Description spacy_tokenized'].progress_apply(\n",
                "    lambda tokens: [\n",
                "        tuple(token.split())\n",
                "        for token in tokens\n",
                "    ]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 138,
            "id": "1a0c8ffe",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "347cd4c9937e47c28ee38ee2c59347fd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1a3f6840507c40089ba4d4321ec72218",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "228661219ea0410c991847eacf542cca",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b41c751a88b64e76ac0e360eb32ae6fa",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 1min 59s, sys: 1.86 s, total: 2min 1s\n",
                        "Wall time: 2min 7s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Spacy bi and trigrams\n",
                "matcher = Matcher(nlp.vocab)\n",
                "\n",
                "bigram_rules = [\n",
                "    ['NOUN', 'VERB'],\n",
                "    ['VERB', 'NOUN'],\n",
                "    ['ADJ', 'NOUN'],\n",
                "    ['ADJ', 'PROPN'],\n",
                "    # more rules here...\n",
                "]\n",
                "\n",
                "trigram_rules = [\n",
                "    ['VERB', 'ADJ', 'NOUN'],\n",
                "    ['NOUN', 'VERB', 'ADV'],\n",
                "    ['NOUN', 'ADP', 'NOUN'],\n",
                "    # more rules here...\n",
                "]\n",
                "\n",
                "patters_dict = {\n",
                "    'bigram_patterns': [[{'POS': i} for i in j] for j in bigram_rules],\n",
                "    'trigram_patterns': [[{'POS': i} for i in j] for j in trigram_rules],\n",
                "}\n",
                "\n",
                "ngram_dict = {\n",
                "    'bigram': 2,\n",
                "    'trigram': 3,\n",
                "}\n",
                "\n",
                "for ngram_name, ngram_num in tqdm.tqdm(ngram_dict.items()):\n",
                "\n",
                "    matcher.add(f'{ngram_name}_patterns', patters_dict[f'{ngram_name}_patterns'])\n",
                "\n",
                "    df_manual[f'Job Description spacy_{str(ngram_num)}grams_original_list'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "        lambda sentence: \n",
                "            [\n",
                "                '_'.join(ngram_.split())\n",
                "                for ngram_ in spacy_make_ngrams(sentence, matcher, ngram_name)\n",
                "            ]\n",
                "    )\n",
                "\n",
                "    df_manual[f'Job Description spacy_{str(ngram_num)}grams'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "        lambda sentence: \n",
                "            [\n",
                "                tuple(ngram_.split())\n",
                "                for ngram_ in spacy_make_ngrams(sentence, matcher, ngram_name)\n",
                "            ]\n",
                "    )\n",
                "\n",
                "    df_manual[f'Job Description spacy_{str(ngram_num)}grams_in_sent'] = df_manual['Job Description spacy_sentencized'].str.lower().replace(\n",
                "        regex = {\n",
                "            re.escape(' '.join(ngram_.split('_'))): re.escape(ngram_)\n",
                "            for ngrams_list in df_manual[f'Job Description spacy_{str(ngram_num)}grams_original_list']\n",
                "            for ngram_ in ngrams_list\n",
                "            if '_' in ngram_\n",
                "        }\n",
                "    )\n",
                "\n",
                "    if f'{ngram_name}_patterns' in matcher:\n",
                "        matcher.remove(f'{ngram_name}_patterns')\n",
                "    assert f'{ngram_name}_patterns' not in matcher\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 139,
            "id": "9fc3ad40",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 21.6 s, sys: 260 ms, total: 21.8 s\n",
                        "Wall time: 23.4 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Spacy Allgrams\n",
                "df_manual['Job Description spacy_123grams_original_list'] = df_manual['Job Description spacy_tokenized'] + df_manual['Job Description spacy_2grams_original_list'] + df_manual['Job Description spacy_3grams_original_list']\n",
                "df_manual['Job Description spacy_123grams'] = df_manual['Job Description spacy_1grams'] + df_manual['Job Description spacy_2grams'] + df_manual['Job Description spacy_3grams']\n",
                "df_manual['Job Description spacy_123grams_in_sent'] = (\n",
                "    df_manual['Job Description spacy_sentencized']\n",
                "    .str.lower()\n",
                "    .replace(\n",
                "        regex={\n",
                "            re.escape(' '.join(ngram_.split('_'))): re.escape(ngram_)\n",
                "            for ngrams_list in df_manual[\n",
                "                'Job Description spacy_123grams_original_list'\n",
                "            ]\n",
                "            for ngram_ in ngrams_list\n",
                "            if '_' in ngram_\n",
                "        }\n",
                "    )\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 140,
            "id": "d68848b6",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_ngrams_spacy.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_ngrams_spacy.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d258e491",
            "metadata": {},
            "source": [
                "# Use NLTK to create bi and trigrams\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0e767712",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_NGRAMS_SPACY\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 141,
            "id": "45f3b2f6",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 142,
            "id": "10cde291",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 143,
            "id": "a61db031",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_ngrams_spacy.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 144,
            "id": "2afc29c7",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7b3c2ab196d445c99511a9f3cb8842dc",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 15.7 ms, sys: 1.91 ms, total: 17.6 ms\n",
                        "Wall time: 22.5 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "df_manual['Job Description nltk_1grams_original_list'] = df_manual['Job Description nltk_tokenized']\n",
                "df_manual['Job Description nltk_1grams'] = df_manual['Job Description nltk_tokenized'].progress_apply(\n",
                "    lambda tokens: [\n",
                "        tuple(token.split())\n",
                "        for token in tokens\n",
                "    ]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 145,
            "id": "6c5e1032",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8c8564e5161c4d5683f797552b233142",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b3b882486e03484db324a42edd1473ac",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7bc46080a062414f95ade3a654f6f750",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d520dbd8f597454189ee7ea7dcb96d15",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 3min 10s, sys: 1.67 s, total: 3min 12s\n",
                        "Wall time: 3min 30s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# NLTK bi and trigrams\n",
                "ngram_dict = {\n",
                "    'bigram': 2,\n",
                "    'trigram': 3\n",
                "}\n",
                "\n",
                "for ngram_name, ngram_num in tqdm.tqdm(ngram_dict.items()):\n",
                "\n",
                "    df_manual[f'Job Description nltk_{str(ngram_num)}grams_original_list'] = df_manual['Job Description nltk_tokenized'].progress_apply(\n",
                "        lambda tokens:\n",
                "            list(\n",
                "                '_'.join(ngram_list)\n",
                "                for ngram_list in nltk.ngrams(tokens, ngram_num)\n",
                "            )\n",
                "    )\n",
                "\n",
                "    df_manual[f'Job Description nltk_{str(ngram_num)}grams'] = df_manual['Job Description nltk_tokenized'].progress_apply(\n",
                "        lambda tokens: list(nltk.ngrams(tokens, ngram_num))\n",
                "    )\n",
                "\n",
                "    df_manual[f'Job Description nltk_{str(ngram_num)}grams_in_sent'] = df_manual['Job Description spacy_sentencized'].str.lower().replace(\n",
                "        regex = {\n",
                "            re.escape(' '.join(ngram_.split('_'))): re.escape(ngram_)\n",
                "            for ngrams_list in df_manual[f'Job Description nltk_{str(ngram_num)}grams_original_list']\n",
                "            for ngram_ in ngrams_list\n",
                "            if '_' in ngram_\n",
                "        }\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 146,
            "id": "32f3ae0a",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 3min 9s, sys: 1.45 s, total: 3min 11s\n",
                        "Wall time: 3min 20s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# NLTK Allgrams\n",
                "df_manual['Job Description nltk_123grams_original_list'] = (\n",
                "    df_manual['Job Description nltk_tokenized']\n",
                "    + df_manual['Job Description nltk_2grams_original_list']\n",
                "    + df_manual['Job Description nltk_3grams_original_list']\n",
                ")\n",
                "df_manual['Job Description nltk_123grams'] = (\n",
                "    df_manual['Job Description nltk_1grams']\n",
                "    + df_manual['Job Description nltk_2grams']\n",
                "    + df_manual['Job Description nltk_3grams']\n",
                ")\n",
                "df_manual['Job Description nltk_123grams_in_sent'] = (\n",
                "    df_manual['Job Description spacy_sentencized']\n",
                "    .str.lower()\n",
                "    .replace(\n",
                "        regex={\n",
                "            re.escape(' '.join(ngram_.split('_'))): re.escape(ngram_)\n",
                "            for ngrams_list in df_manual[\n",
                "                'Job Description nltk_123grams_original_list'\n",
                "            ]\n",
                "            for ngram_ in ngrams_list\n",
                "            if '_' in ngram_\n",
                "        }\n",
                "    )\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 147,
            "id": "17610cd5",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_ngrams_spacy_nltk.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_ngrams_spacy_nltk.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1440bd34",
            "metadata": {},
            "source": [
                "# Use Gensim to create bi and trigrams\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0494636f",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_NGRAMS_SPACY_NLTK\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 148,
            "id": "dad74074",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 149,
            "id": "067dda8f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 150,
            "id": "8c9c33c2",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_ngrams_spacy_nltk.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 151,
            "id": "59d29aaf",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8c5cd2edb6d249848f3fe3f51e0291a8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "df_manual['Job Description gensim_1grams_original_list'] = df_manual['Job Description gensim_tokenized']\n",
                "df_manual['Job Description gensim_1grams'] = df_manual['Job Description gensim_tokenized'].progress_apply(\n",
                "    lambda tokens: [\n",
                "        tuple(token.split())\n",
                "        for token in tokens\n",
                "    ]\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 152,
            "id": "becdbf23",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "601538da7cc94e1598ccd353b523f68b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8508f28dda984206b5f4f5112c6108df",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a55b671c2c784426a7b3255f1c1ce910",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2a73e62dae9a4314bd5f19bcf559dc08",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "307ba32f603546ba8a382066f371f0f3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b62b6d93833240b9bdf1725c89e10349",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 16.2 s, sys: 218 ms, total: 16.4 s\n",
                        "Wall time: 17.4 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Gensim bi and trigrams\n",
                "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n",
                "\n",
                "# Gensim Bigrams\n",
                "bigram = Phraser(Phrases(df_manual['Job Description gensim_tokenized'], connector_words=ENGLISH_CONNECTOR_WORDS, min_count=1, threshold=1))\n",
                "df_manual['Job Description gensim_2grams_original_list_all'] = bigram[df_manual['Job Description gensim_tokenized']]\n",
                "df_manual['Job Description gensim_2grams_original_list'] = df_manual['Job Description gensim_2grams_original_list_all'].progress_apply(\n",
                "    lambda ngrams_list: [\n",
                "        ngram_\n",
                "        for ngram_ in ngrams_list\n",
                "        if len(re.findall('[a-zA-Z]*\\_[a-zA-Z]*', ngram_)) != 0\n",
                "    ]\n",
                ")\n",
                "df_manual['Job Description gensim_2grams'] = df_manual['Job Description gensim_2grams_original_list'].progress_apply(\n",
                "    lambda ngrams: [\n",
                "        tuple(ngram.split('_'))\n",
                "        for ngram in ngrams\n",
                "        if '_' in ngram\n",
                "    ]\n",
                ")\n",
                "df_manual['Job Description gensim_2grams_in_sent'] = (\n",
                "    df_manual['Job Description spacy_sentencized']\n",
                "    .str.lower()\n",
                "    .progress_apply(\n",
                "        lambda sentence: ' '.join(\n",
                "            preprocess_string(re.sub(pattern, ' ', sentence.strip().lower()))\n",
                "        )\n",
                "    )\n",
                "    .replace(\n",
                "        regex={\n",
                "            re.escape(' '.join(ngram_.split('_'))): re.escape(ngram_)\n",
                "            for ngrams_list in df_manual[\n",
                "                'Job Description gensim_2grams_original_list'\n",
                "            ]\n",
                "            for ngram_ in ngrams_list\n",
                "            if '_' in ngram_\n",
                "        }\n",
                "    )\n",
                ")\n",
                "\n",
                "# Gensim Trigrams\n",
                "trigram = Phraser(Phrases(df_manual['Job Description gensim_2grams_original_list_all'], connector_words=ENGLISH_CONNECTOR_WORDS, min_count=1, threshold=1))\n",
                "df_manual['Job Description gensim_3grams_original_list_all'] = trigram[df_manual['Job Description gensim_2grams_original_list_all']]\n",
                "df_manual['Job Description gensim_3grams_original_list'] = df_manual['Job Description gensim_3grams_original_list_all'].progress_apply(\n",
                "    lambda ngrams_list: [\n",
                "        ngram_\n",
                "        for ngram_ in ngrams_list\n",
                "        if len(re.findall('[a-zA-Z]*\\_[a-zA-Z]*\\_[a-zA-Z]*', ngram_)) != 0\n",
                "    ]\n",
                ")\n",
                "df_manual['Job Description gensim_3grams'] = df_manual['Job Description gensim_3grams_original_list'].progress_apply(\n",
                "    lambda ngrams: [\n",
                "        tuple(ngram.split('_'))\n",
                "        for ngram in ngrams\n",
                "        if '_' in ngram\n",
                "    ]\n",
                ")\n",
                "df_manual['Job Description gensim_3grams_in_sent'] = (\n",
                "    df_manual['Job Description spacy_sentencized']\n",
                "    .str.lower()\n",
                "    .progress_apply(\n",
                "        lambda sentence: ' '.join(\n",
                "            preprocess_string(re.sub(pattern, ' ', sentence.strip().lower()))\n",
                "        )\n",
                "    )\n",
                "    .replace(\n",
                "        regex={\n",
                "            re.escape(' '.join(ngram_.split('_'))): re.escape(ngram_)\n",
                "            for ngrams_list in df_manual[\n",
                "                'Job Description gensim_3grams_original_list'\n",
                "            ]\n",
                "            for ngram_ in ngrams_list\n",
                "            if '_' in ngram_\n",
                "        }\n",
                "    )\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 153,
            "id": "84d89c0a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "da06884033f8437f8ff21b38acd94823",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 17.3 s, sys: 361 ms, total: 17.7 s\n",
                        "Wall time: 22.2 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Gensim Allgrams\n",
                "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n",
                "\n",
                "df_manual['Job Description gensim_123grams_original_list'] = (\n",
                "    df_manual['Job Description gensim_tokenized']\n",
                "    + df_manual['Job Description gensim_2grams_original_list']\n",
                "    + df_manual['Job Description gensim_3grams_original_list']\n",
                ")\n",
                "df_manual['Job Description gensim_123grams'] = (\n",
                "    df_manual['Job Description gensim_1grams']\n",
                "    + df_manual['Job Description gensim_2grams']\n",
                "    + df_manual['Job Description gensim_3grams']\n",
                ")\n",
                "df_manual['Job Description gensim_123grams_in_sent'] = (\n",
                "    df_manual['Job Description spacy_sentencized']\n",
                "    .str.lower()\n",
                "    .progress_apply(\n",
                "        lambda sentence: ' '.join(\n",
                "            preprocess_string(re.sub(pattern, ' ', sentence.strip().lower()))\n",
                "        )\n",
                "    )\n",
                "    .replace(\n",
                "        regex={\n",
                "            re.escape(' '.join(ngram_.split('_'))): re.escape(ngram_)\n",
                "            for ngrams_list in df_manual[\n",
                "                'Job Description gensim_123grams_original_list'\n",
                "            ]\n",
                "            for ngram_ in ngrams_list\n",
                "            if '_' in ngram_\n",
                "        }\n",
                "    )\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 154,
            "id": "17e46331",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_ngrams_spacy_nltk_gensim.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_ngrams_spacy_nltk_gensim.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6ac58f92",
            "metadata": {},
            "source": [
                "# Create word frequencies for uni, bi, and trigrams\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7c33d9ab",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_NGRAMS_SPACY_NLTK_GENSIM\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 155,
            "id": "735bed8e",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 156,
            "id": "024dc14f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 157,
            "id": "8731dee4",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_abs_frequency(row, text_col, ngram_num, embedding_library):\n",
                "\n",
                "    abs_word_freq = defaultdict(int)\n",
                "    for word in row[f'Job Description {embedding_library}_{ngram_num}grams_original_list']:\n",
                "        abs_word_freq[word] += 1\n",
                "\n",
                "        abs_wtd_df = (\n",
                "            pd.DataFrame.from_dict(abs_word_freq, orient='index')\n",
                "            .rename(columns={0: 'abs_word_freq'})\n",
                "            .sort_values(by=['abs_word_freq'], ascending=False)\n",
                "            )\n",
                "        abs_wtd_df.insert(1, 'abs_word_perc', value=abs_wtd_df['abs_word_freq'] / abs_wtd_df['abs_word_freq'].sum())\n",
                "        abs_wtd_df.insert(2, 'abs_word_perc_cum', abs_wtd_df['abs_word_perc'].cumsum())\n",
                "\n",
                "        row[f'Job Description {embedding_library}_{ngram_num}grams_abs_word_freq'] = str(abs_wtd_df['abs_word_freq'].to_dict())\n",
                "        row[f'Job Description {embedding_library}_{ngram_num}grams_abs_word_perc'] = str(abs_wtd_df['abs_word_perc'].to_dict())\n",
                "        row[f'Job Description {embedding_library}_{ngram_num}grams_abs_word_perc_cum'] = str(abs_wtd_df['abs_word_perc_cum'].to_dict())\n",
                "\n",
                "    return row\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 158,
            "id": "8e4a92a0",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_ngrams_spacy_nltk_gensim.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 159,
            "id": "43206134",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b4c7baa746b342aaadc28c8f2e9b82e5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/12 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "29c4786dbac543abb3dcf65b572f0e08",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<timed exec>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b074542a205143ed94b377d442a69fc2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<timed exec>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "13ab4cfb718443a8b9eca7200dbba3b6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<timed exec>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "937f2f4e5fb84f80a514ed945c66b185",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<timed exec>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e2fc2f8d656548c8b744fa81a32053ea",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<timed exec>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f498030dde444375b06ac96157e718e9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<timed exec>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4ab91f4d8dac4078825f6353ecb2237d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<timed exec>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b16045630ad44788b136548ab8b0faea",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<timed exec>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a92f13f9cb51411db4a5ec00ab4b8413",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<timed exec>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bc771cb7263a4de0bb87b99b71611fd1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<timed exec>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "71a9b365a0554b97a842cf554125a227",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "<timed exec>:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4a4c8cbb97cb471cb8b9c0caebd08fa7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 7min 24s, sys: 35.4 s, total: 7min 59s\n",
                        "Wall time: 8min 25s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "ngrams_list=[1, 2, 3, 123]\n",
                "embedding_libraries_list = ['spacy', 'nltk', 'gensim']\n",
                "\n",
                "for embedding_library, ngram_num in tqdm_product(embedding_libraries_list, ngrams_list):\n",
                "    df_manual[f'Job Description {embedding_library}_{ngram_num}grams_count'] = df_manual[f'Job Description {embedding_library}_{ngram_num}grams'].apply(lambda x: len(x))\n",
                "    df_manual = df_manual.progress_apply(lambda row: get_abs_frequency(row=row, text_col='Job Description spacy_tokenized', ngram_num=ngram_num, embedding_library=embedding_library), axis='columns')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 160,
            "id": "30affd16",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_ngrams_frequency.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_ngrams_frequency.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1670f255",
            "metadata": {},
            "source": [
                "# Create BoW dictionary, corpus, and tfidf matrix for uni, bi, and trigrams\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "16989aa0",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_NGRAMS_FREQUENCY\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 161,
            "id": "051454b4",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 162,
            "id": "e09d527a",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 163,
            "id": "57359916",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_corpus_and_dictionary(row, ngram_num, embedding_library):\n",
                "    \n",
                "    ngrams_original_list = row[f'Job Description {embedding_library}_{ngram_num}grams_original_list']\n",
                "    dictionary = Dictionary([ngrams_original_list])\n",
                "    BoW_corpus = [dictionary.doc2bow(ngrams_original_list)]\n",
                "    tfidf = TfidfModel(BoW_corpus, smartirs='ntc')\n",
                "    tfidf_matrix = [tfidf[doc] for doc in BoW_corpus]\n",
                "\n",
                "    row[f'Job Description {embedding_library}_{ngram_num}grams_dictionary'] = dictionary\n",
                "    row[f'Job Description {embedding_library}_{ngram_num}grams_BoW_corpus'] = BoW_corpus\n",
                "    row[f'Job Description {embedding_library}_{ngram_num}grams_tfidf'] = tfidf\n",
                "    row[f'Job Description {embedding_library}_{ngram_num}grams_tfidf_matrix'] = tfidf_matrix\n",
                "    \n",
                "    return row\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 164,
            "id": "30b00a00",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_ngrams_frequency.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 165,
            "id": "ba6a2c99",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9622deb1f6aa44c0a074c39b35cbbf22",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/12 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0778371506f1472a99f82422d010a34c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "af5a431c915547a3826578f6e59e840a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "70b5edbdaee94aab9887fa5f49a5c137",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9aebf88e09474357a7e5e15738678523",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "be4f5201602d4578a6709cdaf10c5445",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a82ef63ac1554af59197e846bec46bba",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "44d7bc5116b64e9f9ea4d4207a54bbd9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7c0f4324e2264bde8797d6f3cd1dab27",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ffa70efbcf5b4e3ca9591d5e818aa5f1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8a028ba747ac41758693e93bd3fb7886",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "16c230777581476d9a2c9679bbf54f74",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "89e2d2a40ea94f47a4de1de8f1845c2f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 1min 5s, sys: 6.83 s, total: 1min 12s\n",
                        "Wall time: 1min 21s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "ngrams_list=[1, 2, 3, 123]\n",
                "embedding_libraries_list = ['spacy', 'nltk', 'gensim']\n",
                "for embedding_library, ngram_num in tqdm_product(embedding_libraries_list, ngrams_list):\n",
                "    df_manual = df_manual.progress_apply(\n",
                "        lambda row: get_corpus_and_dictionary(\n",
                "            row=row, ngram_num=ngram_num, embedding_library=embedding_library\n",
                "        ),\n",
                "        axis='columns'\n",
                "    )\n",
                "\n",
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_ngrams_frequency.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_ngrams_BoW.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 166,
            "id": "b51eae79",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['% Sector per Workforce', '% per Sector', '% per Social Category', '% per Workforce', 'Age', 'Age_Mixed', 'Age_Num', 'Age_Older', 'Age_Older_% per Sector', 'Age_Older_% per Social Category',\n",
                            "       ...\n",
                            "       'Job Description gensim_2grams_tfidf', 'Job Description gensim_2grams_tfidf_matrix', 'Job Description gensim_3grams_dictionary', 'Job Description gensim_3grams_BoW_corpus', 'Job Description gensim_3grams_tfidf', 'Job Description gensim_3grams_tfidf_matrix', 'Job Description gensim_123grams_dictionary', 'Job Description gensim_123grams_BoW_corpus', 'Job Description gensim_123grams_tfidf', 'Job Description gensim_123grams_tfidf_matrix'], dtype='object', length=202)"
                        ]
                    },
                    "execution_count": 166,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_manual.columns\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 167,
            "id": "a03d8769",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_ngrams_BoW.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_ngrams_BoW.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ec31f120",
            "metadata": {},
            "source": [
                "# ATTN: This script should be run AFTER all bi and trigrams (spacy, nltk, and gensim) completed.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c976d079",
            "metadata": {},
            "source": [
                "# Use spacy and nltk for sentiment scoring\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d61138e8",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_NGRAMS_BOW\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 168,
            "id": "47bdc9a2",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 169,
            "id": "d1bc37fc",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 170,
            "id": "25a35056",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_ngrams_BoW.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 171,
            "id": "795034b1",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "640e1987eb04454c968cb3f92ca67fa0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 26.7 s, sys: 317 ms, total: 27 s\n",
                        "Wall time: 28.1 s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Spacy sentiment\n",
                "if 'spacytextblob' not in nlp.pipe_names:\n",
                "    nlp.add_pipe('spacytextblob')\n",
                "\n",
                "df_manual['Job Description spacy_sentiment'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "    lambda sentence: float(nlp(sentence)._.blob.polarity)\n",
                "    if isinstance(sentence, str) else np.nan\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 172,
            "id": "58173ce5",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2fab0601044a421d82d9719ac09ff2b9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 572 ms, sys: 16.5 ms, total: 589 ms\n",
                        "Wall time: 665 ms\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# NLTK sentiment\n",
                "df_manual['Job Description nltk_sentiment'] = df_manual['Job Description spacy_sentencized'].progress_apply(\n",
                "    lambda sentence: float(sentim_analyzer.polarity_scores(sentence)['compound'])\n",
                "    if isinstance(sentence, str) else np.nan\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 173,
            "id": "ec80fe6a",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_sentiment_spacy_nltk.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_sentiment_spacy_nltk.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9db5cf4e",
            "metadata": {},
            "source": [
                "# ATTN: This script should be run AFTER all sentiment scoring (spacy and nltk) completed.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "baad73af",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM df_manual_SENTIMENT_SPACY_NLTK\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "48122d98",
            "metadata": {},
            "source": [
                "# Word2Vec and FastText embeddings\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 174,
            "id": "57105477",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 175,
            "id": "fb13e58e",
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import *  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 176,
            "id": "91117606",
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_train_word2vec(df, ngram_number, embedding_library, size = 300, words=None, t = time.time(), cores = multiprocessing.cpu_count()):\n",
                "    if words is None:\n",
                "        words = [\n",
                "            'she',\n",
                "            'he',\n",
                "            'support',\n",
                "            'leader',\n",
                "            'management',\n",
                "            'team',\n",
                "            'business',\n",
                "            'customer',\n",
                "            'risk',\n",
                "            'build',\n",
                "            'computer',\n",
                "            'programmer',\n",
                "        ]\n",
                "    sentences = df[f'Job Description {embedding_library}_{ngram_number}grams_original_list'].values\n",
                "\n",
                "    w2v_model = Word2Vec(\n",
                "        sentences=sentences,\n",
                "        vector_size=size,\n",
                "        min_count=0,\n",
                "        window=2,\n",
                "        sample=6e-5,\n",
                "        alpha=0.03,\n",
                "        min_alpha=0.0007,\n",
                "        negative=20,\n",
                "        workers=cores - 1,\n",
                "        sg = 1,\n",
                "    )\n",
                "\n",
                "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
                "    print(f'Time to train the model for {size}: {round((time.time() - t) / 60, 2)} mins')\n",
                "\n",
                "    w2v_model.train(\n",
                "        sentences,\n",
                "        total_examples=w2v_model.corpus_count,\n",
                "        epochs=30,\n",
                "        report_delay=1,\n",
                "    )\n",
                "\n",
                "    print(f'Time to build w2v_vocab for {size}: {round((time.time() - t) / 60, 2)} mins')\n",
                "    w2v_vocab = list(w2v_model.wv.index_to_key)\n",
                "\n",
                "    print(f'Checking words form list of length {len(words)}')\n",
                "    print(f'WORDS LIST: {words}')\n",
                "\n",
                "#     for word in words:\n",
                "#         print(f'Checking word:\\n{word.upper()}:')\n",
                "#         try:\n",
                "# #             print(f'Word2Vec {size}: {w2v_model.wv[word]}')\n",
                "#             print(f'Length of {size} model vobal: {len(w2v_vocab)}')\n",
                "#             print(f'{size} - Positive most similar to {word}: {w2v_model.wv.most_similar(positive=word, topn=5)}')\n",
                "#             print(f'{size} - Negative most similar to {word}: {w2v_model.wv.most_similar(negative=word, topn=5)}')\n",
                "\n",
                "#         except KeyError as e:\n",
                "#             print(e)\n",
                "\n",
                "    return w2v_vocab, w2v_model\n",
                "\n",
                "def word2vec_embeddings(sentences, w2v_vocab, w2v_model, size=300):\n",
                "\n",
                "    sentences = [word for word in sentences if word in w2v_vocab]\n",
                "\n",
                "    return (\n",
                "        np.mean(w2v_model.wv[sentences], axis=0)\n",
                "        if sentences\n",
                "        else np.zeros(size)\n",
                "    )\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 177,
            "id": "69dc70f3",
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_train_fasttext(df, ngram_number, embedding_library, size = 300, words=None, t = time.time(), cores = multiprocessing.cpu_count()):\n",
                "    if words is None:\n",
                "        words = [\n",
                "            'she',\n",
                "            'he',\n",
                "            'support',\n",
                "            'leader',\n",
                "            'management',\n",
                "            'team',\n",
                "            'business',\n",
                "            'customer',\n",
                "            'risk',\n",
                "            'build',\n",
                "            'computer',\n",
                "            'programmer',\n",
                "        ]\n",
                "    sentences = df[f'Job Description {embedding_library}_{ngram_number}grams_original_list'].values\n",
                "\n",
                "    ft_model = FastText(\n",
                "        sentences=sentences,\n",
                "        vector_size=size,\n",
                "        min_count=0,\n",
                "        window=2,\n",
                "        sample=6e-5,\n",
                "        alpha=0.03,\n",
                "        min_alpha=0.0007,\n",
                "        negative=20,\n",
                "        workers=cores - 1,\n",
                "        sg = 1,\n",
                "    )\n",
                "\n",
                "    ft_model.build_vocab(sentences, progress_per=10000)\n",
                "    print(f'Time to train the model for {size}: {round((time.time() - t) / 60, 2)} mins')\n",
                "\n",
                "    ft_model.train(\n",
                "        sentences,\n",
                "        total_examples=ft_model.corpus_count,\n",
                "        epochs=30,\n",
                "        report_delay=1,\n",
                "    )\n",
                "\n",
                "    print(f'Time to build vocab for {size}: {round((time.time() - t) / 60, 2)} mins')\n",
                "    ft_vocab = list(ft_model.wv.index_to_key)\n",
                "\n",
                "    print(f'Checking words form list of length {len(words)}')\n",
                "    print(f'WORDS LIST: {words}')\n",
                "\n",
                "#     for word in words:\n",
                "#         print(f'Checking word:\\n{word.upper()}:')\n",
                "#         try:\n",
                "# #             print(f'FastText {size}: {ft_model_300.wv[word]}')\n",
                "#             print(f'Length of {size} model vobal: {len(ft_vocab)}')\n",
                "#             print(f'{size} - Positive most similar to {word}: {ft_model.wv.most_similar(positive=word, topn=5)}')\n",
                "#             print(f'{size} - Negative most similar to {word}: {ft_model.wv.most_similar(negative=word, topn=5)}')\n",
                "\n",
                "#         except KeyError as e:\n",
                "#             print(e)\n",
                "\n",
                "    return ft_vocab, ft_model\n",
                "\n",
                "def fasttext_embeddings(sentences, ft_vocab, ft_model, size=300):\n",
                "\n",
                "    sentences = [word for word in sentences if word in ft_vocab]\n",
                "\n",
                "    return np.mean(ft_model.wv[sentences], axis=0) if sentences else np.zeros(size)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 178,
            "id": "b6d43d45",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_glove(glove_file = f'{llm_path}/gensim/glove/glove.840B.300d.txt'):\n",
                "    embeddings_index = {}\n",
                "    with open(glove_file, 'r', encoding='utf8') as glove:\n",
                "\n",
                "        for line in glove:\n",
                "            values = line.split()\n",
                "            word = values[0]\n",
                "\n",
                "            with contextlib.suppress(ValueError):\n",
                "                coefs = np.asarray(values[1:], dtype='float32')\n",
                "                embeddings_index[word] = coefs\n",
                "    print(f'Found {len(embeddings_index)} word vectors.')\n",
                "\n",
                "    return embeddings_index\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 179,
            "id": "1022f815",
            "metadata": {},
            "outputs": [],
            "source": [
                "def sent2vec(sentences, embeddings_index=None, external_glove=True, extra_preprocessing_enabled=False):\n",
                "\n",
                "    if external_glove is False and embeddings_index is None:\n",
                "        embeddings_index= get_glove()\n",
                "\n",
                "    if extra_preprocessing_enabled is False:\n",
                "        words = sentences\n",
                "\n",
                "    elif extra_preprocessing_enabled is True:\n",
                "        stop_words = set(sw.words('english'))\n",
                "        words = str(sentences).lower()\n",
                "        words = word_tokenize(words)\n",
                "        words = [w for w in words if (w not in stop_words) and (w.isalpha())]\n",
                "\n",
                "    M = []\n",
                "\n",
                "    try:\n",
                "        for w in words:\n",
                "            try:\n",
                "                M.append(embeddings_index[w])\n",
                "            except Exception:\n",
                "                continue\n",
                "\n",
                "        M = np.array(M)\n",
                "        v = M.sum(axis='index')\n",
                "        return np.zeros(300) if type(v) != np.ndarray else v / np.sqrt((v ** 2).sum())\n",
                "\n",
                "    except Exception:\n",
                "        return np.zeros(300)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 180,
            "id": "a512f2b4",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_manual = pd.read_pickle(f'{df_save_dir}df_manual_sentiment_spacy_nltk.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 181,
            "id": "5c0675fd",
            "metadata": {},
            "outputs": [],
            "source": [
                "embedding_models_dict = {\n",
                "    'w2v': [build_train_word2vec, word2vec_embeddings, Word2Vec],\n",
                "    'ft': [build_train_fasttext, fasttext_embeddings, FastText],\n",
                "}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 182,
            "id": "bd6f55d3",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f5e622674fcc4a399d011e18c8451712",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/12 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building spacy_1grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 0.08 mins\n",
                        "Time to build w2v_vocab for 300: 0.13 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0e954c2e951d4587bef2dd3c84a690e3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 0.22 mins\n",
                        "Time to build vocab for 300: 0.33 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a208a2297c0d4fdca6e686fbd5f8f108",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7b74f565485b455ba3964151a93aa90d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "Building spacy_2grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 1.68 mins\n",
                        "Time to build w2v_vocab for 300: 1.71 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7446f33e36094523b00560490317fd56",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 1.86 mins\n",
                        "Time to build vocab for 300: 1.95 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "db0ba511caa54dda87ee4f4d09ff93fb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bcd394a715b141e9b7feea22b1afff14",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "Building spacy_3grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n",
                        "Time to train the model for 300: 3.78 mins\n",
                        "Time to build w2v_vocab for 300: 3.78 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "53719f005e6244ca8f7998aae2e242b5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 3.91 mins\n",
                        "Time to build vocab for 300: 3.92 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "28bf254ec08843dbbbc86460142515c1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cc5e131fcfa54ec69d76d86fa5df1fe4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "Building spacy_123grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 5.71 mins\n",
                        "Time to build w2v_vocab for 300: 5.81 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "187bfe54f73d46178b16e8869c5901ce",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 6.02 mins\n",
                        "Time to build vocab for 300: 6.24 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "499579ba785040309fc138793ef97ed5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e008ad566938461c9608807147047cf5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "Building nltk_1grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 8.03 mins\n",
                        "Time to build w2v_vocab for 300: 8.11 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7cf2843786f84b6c810809fb615f6245",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 8.34 mins\n",
                        "Time to build vocab for 300: 8.49 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "65d708daebb74fbd958fe5aad96bd42b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2e43428341e24b1b9b977569170e042a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "Building nltk_2grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 10.37 mins\n",
                        "Time to build w2v_vocab for 300: 10.56 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a8c0c67c141c48cd8b4a4a06d2a8d1ea",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 10.98 mins\n",
                        "Time to build vocab for 300: 11.45 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "afbc6799b24d40d7bd4680c78e94c82d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3af57bc465114d739b6bb8052010ee17",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "Building nltk_3grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 13.5 mins\n",
                        "Time to build w2v_vocab for 300: 13.68 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bbc33216897442a9a9d96fbf76531e31",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 14.86 mins\n",
                        "Time to build vocab for 300: 15.57 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "69607251a5574380be613433217cf48a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0dcf242ab64b4b1e8fe6db35c841c80a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "Building nltk_123grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 17.95 mins\n",
                        "Time to build w2v_vocab for 300: 18.48 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7718dcc33bfa4660935a15759f6fd102",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 19.47 mins\n",
                        "Time to build vocab for 300: 20.46 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b7236be62cd749a4b3cc3661cf47e70a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4c48fcd0f8694628937282971a7e0fe0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "Building gensim_1grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 22.59 mins\n",
                        "Time to build w2v_vocab for 300: 22.65 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0b3a9a52c7274051963f585cb6f18bc4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 22.75 mins\n",
                        "Time to build vocab for 300: 22.82 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cb4d2fd4be2a485fbb4feffa9b6d1fee",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2ae86b4e367f4cdca65f0ca12fe71c29",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "Building gensim_2grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 24.51 mins\n",
                        "Time to build w2v_vocab for 300: 24.55 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "78fe9c3e2fe64abc8571830dc95f46f3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 24.67 mins\n",
                        "Time to build vocab for 300: 24.8 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f8b7327015a74b828f9dfc05002fcb22",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "40bdda04bc1b44f4916fffd2f2483582",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "Building gensim_3grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 26.43 mins\n",
                        "Time to build w2v_vocab for 300: 26.43 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "3756ca865aa0400fb455c9fd63d0ceb7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 26.49 mins\n",
                        "Time to build vocab for 300: 26.5 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c09d42614c4e4adaa5c76dc7a7ab6a7a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ff6a12aeae414fe68e2d3094e3138c21",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "Building gensim_123grams model and vocabulary.\n",
                        "Building w2v from word2vec_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 28.19 mins\n",
                        "Time to build w2v_vocab for 300: 28.28 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting w2v embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e19da6354ad94a7e884cc3767b4bfc8a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building ft from fasttext_embeddings function.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "WARNING:gensim.models.keyedvectors:sorting after vectors have been allocated is expensive & error-prone\n",
                        "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Time to train the model for 300: 28.41 mins\n",
                        "Time to build vocab for 300: 28.57 mins\n",
                        "Checking words form list of length 12\n",
                        "WORDS LIST: ['she', 'he', 'support', 'leader', 'management', 'team', 'business', 'customer', 'risk', 'build', 'computer', 'programmer']\n",
                        "Getting ft embeddings.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "df9d69172d3b464a9a465a2de77e43b2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Getting sent2vec embeddings.\n",
                        "Found 2195885 word vectors.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8942d5257b3d4fb2a543b8c674b4089b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "progress-bar:   0%|          | 0/5365 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done getting sent2vec embeddings.\n",
                        "CPU times: user 30min 54s, sys: 2min 53s, total: 33min 47s\n",
                        "Wall time: 30min 3s\n"
                    ]
                }
            ],
            "source": [
                "%%time\n",
                "# Make embeddings\n",
                "ngrams_list=[1, 2, 3, 123]\n",
                "embedding_libraries_list = ['spacy', 'nltk', 'gensim']\n",
                "\n",
                "for embedding_library, ngram_number in tqdm_product(embedding_libraries_list, ngrams_list):\n",
                "    print(f'Building {embedding_library}_{ngram_number}grams model and vocabulary.')\n",
                "\n",
                "    for embed_model_name, embed_func_list in embedding_models_dict.items():\n",
                "\n",
                "        build_train_func, embed_func, model_loader = embed_func_list\n",
                "        print(f'Building {embed_model_name} from {embed_func.__name__} function.')\n",
                "\n",
                "        vocab, model = build_train_func(\n",
                "            df=df_manual,\n",
                "            ngram_number=ngram_number,\n",
                "            embedding_library=embedding_library,\n",
                "        )\n",
                "\n",
                "        print(f'Getting {embed_model_name} embeddings.')\n",
                "\n",
                "        df_manual[\n",
                "            f'Job Description {embedding_library}_{ngram_number}grams_mean_{embed_model_name}_embeddings'\n",
                "        ] = df_manual[\n",
                "            f'Job Description {embedding_library}_{ngram_number}grams_original_list'\n",
                "        ].progress_apply(\n",
                "            lambda sentences: embed_func(sentences, vocab, model)\n",
                "        )\n",
                "        model.save(f'{data_dir}embeddings models/{embedding_library}_{ngram_number}grams_{embed_model_name}_model.model')\n",
                "\n",
                "    # Sent2Vec\n",
                "    print('Getting sent2vec embeddings.')\n",
                "    embeddings_index = get_glove()\n",
                "    df_manual[f'Job Description {embedding_library}_{ngram_number}grams_sent2vec_embeddings'] = df_manual[f'Job Description {embedding_library}_{ngram_number}grams'].progress_apply(lambda sentences: sent2vec(sentences, embeddings_index=embeddings_index, external_glove=True, extra_preprocessing_enabled=False))\n",
                "    print('Done getting sent2vec embeddings.')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 183,
            "id": "f1cd59ac",
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_manual) > 0 and isinstance(df_manual, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_manual)}'\n",
                "df_manual.to_pickle(f'{df_save_dir}df_manual_for_trainning.pkl')\n",
                "df_manual.to_csv(f'{df_save_dir}df_manual_for_trainning.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 188,
            "id": "85d3eef0",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saving df_manual length 5365 to txt file.\n"
                    ]
                }
            ],
            "source": [
                "print(f'Saving df_manual length {len(df_manual)} to txt file.')\n",
                "with open(f'{data_dir}df_manual_len.txt', 'w') as f:\n",
                "    f.write(str(len(df_manual)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "51036d5e",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "study1_3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.10"
        },
        "varInspector": {
            "cols": {
                "lenName": 16,
                "lenType": 16,
                "lenVar": 40
            },
            "kernels_config": {
                "python": {
                    "delete_cmd_postfix": "",
                    "delete_cmd_prefix": "del ",
                    "library": "var_list.py",
                    "varRefreshCmd": "print(var_dic_list())"
                },
                "r": {
                    "delete_cmd_postfix": ") ",
                    "delete_cmd_prefix": "rm(",
                    "library": "var_list.r",
                    "varRefreshCmd": "cat(var_dic_list()) "
                }
            },
            "types_to_exclude": [
                "module",
                "function",
                "builtin_function_or_method",
                "instance",
                "_Feature"
            ],
            "window_display": false
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
