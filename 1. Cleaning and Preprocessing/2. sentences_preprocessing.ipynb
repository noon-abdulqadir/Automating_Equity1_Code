{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ATTN: This script should be run AFTER language detection is completed."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Drop non-English job descriptions"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM DF_JOBS_RAW_LANGUAGE_DETECTED\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_raw_language_detected.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# len = 62577\n",
                "df_jobs.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# nl = 44863, en = 17591, ['en', 'nl'] = 8, ['nl', 'en'] = 9\n",
                "df_jobs['Language'].value_counts()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "# The majority of ['en', 'nl'] labeled job descriptions contain mostly English\n",
                "df_jobs['Language'] = df_jobs['Language'].progress_apply(\n",
                "    lambda lang: 'en' if lang == \"['en', 'nl']\" else lang\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop non-English ads\n",
                "df_jobs = df_jobs.drop(\n",
                "    df_jobs[\n",
                "        df_jobs['Language'] != 'en'\n",
                "    ].index, \n",
                "        axis='index', \n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 17599\n",
                "len(df_jobs)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "df_jobs.to_pickle(f'{df_save_dir}df_jobs_raw_english_only.pkl')\n",
                "df_jobs.to_csv(f'{df_save_dir}df_jobs_raw_english_only.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fix abbreviations in job descriptions"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM DF_JOBS_RAW_ENGLISH_ONLY\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_raw_english_only.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# len = 17599\n",
                "df_jobs.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Job Description'] = df_jobs.loc[df_jobs['Job Description'].notnull(), 'Job Description'].progress_apply(\n",
                "    lambda job_description: ' '.join(job_description.split('/')) if '/' in job_description else job_description\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "abb_dict = {\n",
                "    r'incl\\.': 'including', \n",
                "    r'e\\.g\\.': 'for example', \n",
                "    r'e\\.g': 'for example', \n",
                "    r'etc\\.': 'et cetera', \n",
                "}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "df_jobs['Job Description'] = df_jobs['Job Description'].replace(abb_dict, regex=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "df_jobs.to_pickle(f'{df_save_dir}df_jobs_raw_fixed_abbreviations.pkl')\n",
                "df_jobs.to_csv(f'{df_save_dir}df_jobs_raw_fixed_abbreviations.csv', index=False)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Add English and Dutch language requirement columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM DF_JOBS_RAW_FIXED_ABBREVIATIONS\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_raw_fixed_abbreviations.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "# Add language requirement column\n",
                "# Use regex to find language requirement\n",
                "dutch_requirement_pattern = r'[Ll]anguage: [Dd]utch|[Dd]utch [Pp]referred|[Dd]utch [Re]quired|[Dd]utch [Ll]anguage|[Pp]roficient in [Dd]utch|[Ss]peak [Dd]utch|[Kk]now [Dd]utch'\n",
                "english_requirement_pattern = r'[Ll]anguage: [Ee]nglish|[Ee]nglish [Pp]referred|[Ee]nglish [Re]quired|[Ee]nglish [Ll]anguage|[Pp]roficient in [Ee]nglish|[Ss]peak [Ee]nglish|[Kk]now [Ee]nglish'\n",
                "\n",
                "lang_requirements = {\n",
                "    'Dutch Requirement': dutch_requirement_pattern, 'English Requirement': english_requirement_pattern\n",
                "}\n",
                "\n",
                "for lang_req, lang_req_pattern in lang_requirements.items():\n",
                "\n",
                "    if lang_req in df_jobs.columns:\n",
                "        df_jobs = df_jobs.drop(columns=[lang_req])\n",
                "    df_jobs[lang_req] = np.where(\n",
                "        df_jobs['Job Description'].str.contains(lang_req_pattern),\n",
                "        1,\n",
                "        0,\n",
                "    )\n",
                "    df_jobs[lang_req] = df_jobs[lang_req].astype('category').cat.reorder_categories([0, 1], ordered=True)\n",
                "    df_jobs[lang_req] = pd.Categorical(df_jobs[lang_req], categories=[0, 1], ordered=True)\n",
                "\n",
                "assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "df_jobs.to_pickle(f'{df_save_dir}df_jobs_raw_language_requirement.pkl')\n",
                "df_jobs.to_csv(f'{df_save_dir}df_jobs_raw_english_requirement.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Yes = 235\n",
                "df_jobs['Dutch Requirement'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Yes = 526\n",
                "df_jobs['English Requirement'].value_counts()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "df_jobs.to_pickle(f'{df_save_dir}df_jobs_raw_language_requirement.pkl')\n",
                "df_jobs.to_csv(f'{df_save_dir}df_jobs_raw_language_requirement.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Add data from Sectors dataframe (see CBS directory under scrapped_data directory)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM DF_JOBS_RAW_LANGUAGE_REQUIREMENT\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_raw_language_requirement.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sectors = pd.read_pickle(f'{scraped_data}CBS/Data/Sectors Output from script.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sectors.columns\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sectors.columns = [\n",
                "    '_'.join(col) \n",
                "    if 'SBI Sector Titles' not in col \n",
                "    and 'Total Workforce' not in col \n",
                "    else col[-1] \n",
                "    for col in df_sectors.columns\n",
                "]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sectors = df_sectors.rename(\n",
                "    columns={\n",
                "        'Keywords': 'Search Keyword', \n",
                "        'Code': 'Sector Code', \n",
                "        'Sector Name': 'Sector', \n",
                "        'Gender_Sectoral Gender Segregation_Dominant Category': 'Gender', \n",
                "        'Age_Sectoral Age Segregation_Dominant Category': 'Age', \n",
                "        'n': 'Sector_n', \n",
                "    },\n",
                ")\n",
                "df_sectors = df_sectors.rename(columns={element: re.sub(r' \\(\\W*45 years\\)', '', element) for element in df_sectors.columns.tolist()})\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sectors.columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sectors = df_sectors.explode(\n",
                "    'Search Keyword', ignore_index=True\n",
                ").reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sectors.columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# len 101\n",
                "len(df_sectors)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Before adding sector data, make sure keywords are correct as to not have any missing sector data when merging"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# This is a manually collected dictionary of incorrect/faulty keywords in scraped site data\n",
                "with open(f'{scraped_data}CBS/Data/keyword_trans_dict.txt') as f:\n",
                "    keyword_trans_dict = json.load(f)\n",
                "\n",
                "def fix_keywords(df_temp):\n",
                "\n",
                "    if len(df_temp) > 0 and isinstance(df_temp, pd.DataFrame):\n",
                "        for key, value in keyword_trans_dict.items():\n",
                "            df_temp.loc[\n",
                "                df_temp[df_temp['Search Keyword'].notnull()]['Search Keyword'].astype(str).progress_apply(\n",
                "                lambda x: x.lower().strip()\n",
                "                ) == str(key).lower().strip(), 'Search Keyword'\n",
                "            ] = str(value).lower().strip()\n",
                "\n",
                "        unfixed = df_temp.loc[\n",
                "            df_temp[df_temp['Search Keyword'].notnull()]['Search Keyword'].astype(str).progress_apply(lambda x: x.lower().strip()).isin([x.lower().strip() for x in list(keyword_trans_dict.keys())])\n",
                "        ]\n",
                "\n",
                "        if len(unfixed) != 0:\n",
                "            for key, value in keyword_trans_dict.items():\n",
                "                for idx, row in df_temp.iterrows():\n",
                "                    if row['Search Keyword'].astype(str).lower().strip() == str(key).lower().strip():\n",
                "                        df_temp.loc[idx, 'Search Keyword'] = str(value).lower().strip()\n",
                "    \n",
                "        unfixed = df_temp.loc[\n",
                "                df_temp[df_temp['Search Keyword'].notnull()]['Search Keyword'].astype(str).progress_apply(lambda x: x.lower().strip()).isin([x.lower().strip() for x in list(keyword_trans_dict.keys())])\n",
                "            ]\n",
                "        if len(unfixed) != 0:\n",
                "            print('Some keywords were not fixed. Please check file unfixed_keywords.txt in data directory.')\n",
                "            with open(f'{data_dir}unfixed_keywords.txt', 'w') as f:\n",
                "                json.dump(unfixed, f)\n",
                "    \n",
                "    return df_temp\n",
                "\n",
                "# Fix keywords\n",
                "if len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]) != 0:\n",
                "    print('Some search keywords did not match a sector. Fixing')\n",
                "#     print(set(df_jobs['Search Keyword'].loc[df_jobs['Sector'].isna()].to_list()))\n",
                "    print(len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n",
                "    df_jobs = fix_keywords(df_jobs)\n",
                "#     print(set(df_jobs['Search Keyword'].loc[df_jobs['Sector'].isna()].to_list()))\n",
                "    print(len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = df_jobs.merge(df_sectors, on='Search Keyword', how='left')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 17599\n",
                "len(df_jobs)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.info()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Check if there is any missing sector data in the merged dataframe"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Sector'].isna().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if df_jobs['Sector'].isna().sum() != 0:\n",
                "    print('Some search keywords did not match a sector. Fixing')\n",
                "    print(set(df_jobs['Search Keyword'].loc[df_jobs['Sector'].isna()].to_list()))\n",
                "    print(len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n",
                "    df_jobs = fix_keywords(df_jobs)\n",
                "    print(set(df_jobs['Search Keyword'].loc[df_jobs['Sector'].isna()].to_list()))\n",
                "    print(len(df_jobs['Search Keyword'].loc[df_jobs['Search Keyword'].isin(list(keyword_trans_dict.keys()))]))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Gender'].value_counts()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Age'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if df_jobs['Sector'].isna().sum() == 0:\n",
                "    assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "    df_jobs.to_pickle(f'{df_save_dir}df_jobs_including_sector_data.pkl')\n",
                "    df_jobs.to_csv(f'{df_save_dir}df_jobs_including_sector_data.csv', index=False)\n",
                "\n",
                "else:\n",
                "    print(f\"MISSING SECTOR DATA: COUNT {df_jobs['Sector'].isna().sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Add categorical data\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM DF_JOBS_INCLUDING_SECTOR_DATA\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import * # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to order categories\n",
                "def categorize_df_gender_age(df, gender_order=None, age_order=None, ivs=None):\n",
                "    if gender_order is None:\n",
                "        gender_order = ['Female', 'Mixed Gender', 'Male']\n",
                "    if age_order is None:\n",
                "        age_order = ['Older', 'Mixed Age', 'Younger']\n",
                "    if ivs is None:\n",
                "        ivs = ['Gender', 'Age']\n",
                "    # Arrange Categories\n",
                "    for iv in ivs:\n",
                "        if iv == 'Gender':\n",
                "            order = gender_order\n",
                "        elif iv == 'Age':\n",
                "            order = age_order\n",
                "        try:\n",
                "            df[iv] = df[iv].astype('category').cat.reorder_categories(order, ordered=True)\n",
                "\n",
                "            df[iv] = pd.Categorical(\n",
                "                df[iv], categories=order, ordered=True\n",
                "            )\n",
                "            df[f'{iv}_Num'] = pd.to_numeric(df[iv].cat.codes).astype('int64')\n",
                "        except ValueError as e:\n",
                "            print(e)\n",
                "\n",
                "    return df\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Funtion to print df gender and age info (also for warmth and competence)\n",
                "def get_df_info(df, ivs_all=None):\n",
                "    if ivs_all is None:\n",
                "        ivs_all = [\n",
                "            'Gender',\n",
                "            'Gender_Num',\n",
                "            'Gender_Female',\n",
                "            'Gender_Mixed',\n",
                "            'Gender_Male',\n",
                "            'Age',\n",
                "            'Age_Num',\n",
                "            'Age_Older',\n",
                "            'Age_Mixed',\n",
                "            'Age_Younger',\n",
                "        ]\n",
                "    # Print Info\n",
                "    print('\\nDF INFO:\\n')\n",
                "    df.info()\n",
                "\n",
                "    for iv in ivs_all:\n",
                "        try:\n",
                "            print('='*20)\n",
                "            print(f'{iv}:')\n",
                "            print('-'*20)\n",
                "            print(f'{iv} Counts:\\n{df[iv].value_counts()}')\n",
                "            print('-'*20)\n",
                "            print(f'{iv} Percentages:\\n{df[iv].value_counts(normalize=True).mul(100).round(1).astype(float)}')\n",
                "            try:\n",
                "                print('-'*20)\n",
                "                print(f'{iv} Mean: {df[iv].mean().round(2).astype(float)}')\n",
                "                print('-'*20)\n",
                "                print(f'{iv} Standard Deviation: {df[iv].std().round(2).astype(float)}')\n",
                "            except Exception:\n",
                "                pass\n",
                "        except Exception:\n",
                "            print(f'{iv} not available.')\n",
                "\n",
                "    print('\\n')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_including_sector_data.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = df_jobs.join(pd.get_dummies(df_jobs[['Gender', 'Age']], dtype='int64'))\n",
                "df_jobs = df_jobs.rename({'Gender_Mixed Gender': 'Gender_Mixed', 'Age_Mixed Age': 'Age_Mixed'}, axis='columns')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = categorize_df_gender_age(df_jobs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Gender'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Gender_Female'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Gender_Num'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Platform'].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "platform_order = ['LinkedIn', 'Indeed', 'Glassdoor']\n",
                "df_jobs['Platform'] = df_jobs['Platform'].astype('category').cat.reorder_categories(platform_order, ordered=True)\n",
                "df_jobs['Platform'] = pd.Categorical(df_jobs['Platform'], categories=platform_order, ordered=True)\n",
                "df_jobs['Platform_Num'] = pd.to_numeric(df_jobs['Platform'].cat.codes).astype('int64')\n",
                "df_jobs = df_jobs.join(pd.get_dummies(df_jobs[['Platform']], dtype='int64'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs[['Platform_Num', 'Platform_LinkedIn', 'Platform_Indeed', 'Platform_Glassdoor']].value_counts()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "df_jobs.to_pickle(f'{df_save_dir}df_jobs_including_sector_genage_data.pkl')\n",
                "df_jobs.to_csv(f'{df_save_dir}df_jobs_including_sector_genage_data.csv', index=False)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Use spacy to split job ads to sentences\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### START HERE IF SOURCING FROM DF_JOBS_INCLUDING_SECTOR_GENAGE_DATA\n",
                "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "import sys # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "from pathlib import Path # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n",
                "\n",
                "mod = sys.modules[__name__]\n",
                "\n",
                "code_dir = None\n",
                "code_dir_name = 'Code'\n",
                "unwanted_subdir_name = 'Analysis'\n",
                "\n",
                "for _ in range(5):\n",
                "\n",
                "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
                "\n",
                "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
                "\n",
                "        code_dir = str(Path.cwd().parents[_])\n",
                "\n",
                "        if code_dir is not None:\n",
                "            break\n",
                "\n",
                "sys.path.append(code_dir)\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from setup_module.imports import *  # type:ignore # isort:skip # fmt:skip # noqa # nopep8\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs = pd.read_pickle(f'{df_save_dir}df_jobs_including_sector_genage_data.pkl').reset_index(drop=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs.info()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to make a list of punctuations that determine sentence boundry, i.e., split characters\n",
                "def make_custom_punct_chars(main_punct_chars=None, repeated_punct_chars=None):\n",
                "    if main_punct_chars is None:\n",
                "        main_punct_chars = [':', '|']\n",
                "    if repeated_punct_chars is None:\n",
                "        repeated_punct_chars = ['\\n', ',']\n",
                "    custom_punct_chars = []\n",
                "    temp_multi = []\n",
                "    temp_spaced = []\n",
                "\n",
                "    for punct_char in main_punct_chars:\n",
                "        custom_punct_chars+= f'{punct_char}', f'{punct_char} '\n",
                "\n",
                "    for idx in range(4):\n",
                "        for punct_char in repeated_punct_chars:\n",
                "            temp_multi.append(f'{punct_char}'*int(idx+1))\n",
                "            temp_spaced.append(f'{punct_char} '*int(idx+1))\n",
                "\n",
                "    for multi, spaced in zip(temp_multi, temp_spaced):\n",
                "        custom_punct_chars+= multi, spaced\n",
                "\n",
                "    custom_punct_chars.remove(',')\n",
                "    custom_punct_chars.remove(', ')\n",
                "\n",
                "    return custom_punct_chars\n",
                "\n",
                "custom_punct_chars = make_custom_punct_chars()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "custom_punct_chars\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "# Add sentencizer to spacy pipe and set custom punctuations\n",
                "if 'sentencizer' not in nlp.pipe_names:\n",
                "    sentencizer = nlp.add_pipe('sentencizer')\n",
                "sentencizer.punct_chars.update(custom_punct_chars)\n",
                "\n",
                "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
                "    with open(f'{data_dir}punctuations.txt', 'wb') as f:\n",
                "        pickle.dump(sentencizer.punct_chars, f)\n",
                "\n",
                "with open(f'{data_dir}punctuations.txt', 'rb') as f:\n",
                "    custom_punct_chars = pickle.load(f)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add special cases to spacy\n",
                "special_cases_dict = {\n",
                "    'incl.': [{65: 'incl', 67: 'including'}],\n",
                "    'incl. ': [{65: 'incl', 67: 'including'}],\n",
                "    '(incl.': [{65: 'incl', 67: 'including'}],\n",
                "    'etc.': [{65: 'etc', 67: 'et cetera'}],\n",
                "    'etc. ': [{65: 'etc', 67: 'et cetera'}],\n",
                "    'e.g.': [{65: 'e.g', 67: 'for example'}],\n",
                "    'e.g. ': [{65: 'e.g', 67: 'for example'}],\n",
                "}\n",
                "\n",
                "nlp.tokenizer.rules.update(special_cases_dict)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "# Spacy sentencize\n",
                "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n",
                "if all(custom_punct_char in sentencizer.punct_chars for custom_punct_char in custom_punct_chars):\n",
                "    df_jobs['Job Description spacy_sentencized'] = df_jobs['Job Description'].progress_apply(\n",
                "        lambda job_description: [\n",
                "            sent \n",
                "            for sentence in nlp(job_description).sents \n",
                "            for sent in re.split(pattern, sentence.text) \n",
                "            if len(sent) != 0 \n",
                "        ]\n",
                "    )\n",
                "\n",
                "assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "df_jobs.to_pickle(f'{df_save_dir}df_jobs_sentencized.pkl')\n",
                "df_jobs.to_csv(f'{df_save_dir}df_jobs_sentencized.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_jobs['Job Description spacy_sentencized'].head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame), f'ERORR: LENGTH OF DF = {len(df_jobs)}'\n",
                "df_jobs.to_pickle(f'{df_save_dir}df_jobs_sentencized.pkl')\n",
                "df_jobs.to_csv(f'{df_save_dir}df_jobs_sentencized.csv', index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "study1_3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.10"
        },
        "varInspector": {
            "cols": {
                "lenName": 16,
                "lenType": 16,
                "lenVar": 40
            },
            "kernels_config": {
                "python": {
                    "delete_cmd_postfix": "",
                    "delete_cmd_prefix": "del ",
                    "library": "var_list.py",
                    "varRefreshCmd": "print(var_dic_list())"
                },
                "r": {
                    "delete_cmd_postfix": ") ",
                    "delete_cmd_prefix": "rm(",
                    "library": "var_list.r",
                    "varRefreshCmd": "cat(var_dic_list()) "
                }
            },
            "types_to_exclude": [
                "module",
                "function",
                "builtin_function_or_method",
                "instance",
                "_Feature"
            ],
            "window_display": false
        },
        "widgets": {
            "application/vnd.jupyter.widget-state+json": {
                "state": {},
                "version_major": 2,
                "version_minor": 0
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
