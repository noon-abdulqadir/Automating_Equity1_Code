{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "# columns\n",
    "cols=['Sector', \n",
    "      'Sector Code', \n",
    "      'Gender', \n",
    "      'Age', \n",
    "      'Language', \n",
    "      'Dutch Requirement', \n",
    "      'English Requirement', \n",
    "      'Gender_Female', \n",
    "      'Gender_Mixed', \n",
    "      'Gender_Male', \n",
    "      'Age_Older', \n",
    "      'Age_Mixed', \n",
    "      'Age_Younger', \n",
    "      'Gender_Num', \n",
    "      'Age_Num', \n",
    "      '% Female', \n",
    "      '% Male', \n",
    "      '% Older', \n",
    "      '% Younger']\n",
    "\n",
    "int_variable: str = 'Job ID'\n",
    "str_variable: str = 'Job Description'\n",
    "gender: str = 'Gender'\n",
    "age: str = 'Age'\n",
    "language: str = 'en'\n",
    "str_cols = ['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name', 'Location', 'Job Description', 'Company URL', 'Job URL', 'Tracking ID']\n",
    "nan_list = [None, 'None', '', ' ', [], -1, '-1', 0, '0', 'nan', np.nan, 'Nan']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from spacy.pipeline import Sentencizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a manually collected dictionary of incorrect/faulty keywords in scraped site data\n",
    "with open(f'{scraped_data}CBS/Data/keyword_trans_dict.txt') as f:\n",
    "    keyword_trans_dict = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 111 words to fix\n",
    "len(keyword_trans_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_broken_linkedin_files(glob_path):\n",
    "    fix_list = []\n",
    "    data_dict = {}\n",
    "    data_list = []\n",
    "\n",
    "    if glob_path.endswith('.json'):\n",
    "\n",
    "        with open(glob_path, encoding = 'utf-8') as csv_file_handler:\n",
    "            csv_reader = csv.DictReader(csv_file_handler)\n",
    "\n",
    "            for rows in csv_reader:\n",
    "                first_key = str(list(rows.keys())[0])\n",
    "                key = rows[first_key]\n",
    "                data_dict[key] = rows\n",
    "\n",
    "        for num in data_dict:\n",
    "            data_list.append(data_dict[num])\n",
    "\n",
    "        with open(glob_path, 'w', encoding = 'utf-8') as json_file_handler:\n",
    "            json_file_handler.write(json.dumps(data_list, indent = 4))\n",
    "    \n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_keywords(df_temp):\n",
    "    if len(df_temp) > 0 and isinstance(df_temp, pd.DataFrame):\n",
    "        for key, value in keyword_trans_dict.items():\n",
    "            df_temp.loc[\n",
    "                df_temp['Search Keyword'].astype(str).apply(\n",
    "                lambda x: x.lower().strip()\n",
    "                ) == str(key).lower().strip(), 'Search Keyword'\n",
    "            ] = str(value).lower().strip()\n",
    "\n",
    "        unfixed = df_temp.loc[\n",
    "            df_temp['Search Keyword'].astype(str).apply(lambda x: x.lower().strip()).isin([x.lower().strip() for x in list(keyword_trans_dict.keys())])\n",
    "        ]\n",
    "\n",
    "        if len(unfixed) != 0:\n",
    "            for key, value in keyword_trans_dict.items():\n",
    "                for idx, row in df_temp.iterrows():\n",
    "                    if row['Search Keyword'].astype(str).lower().strip() == str(key).lower().strip():\n",
    "                        df_temp.loc[idx, 'Search Keyword'] = str(value).lower().strip()\n",
    "    \n",
    "\n",
    "    return df_temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_paths = []\n",
    "\n",
    "for site in site_list:\n",
    "    glob_paths.extend(glob.glob(f'{scraped_data}/{site}/Data/*.json')+glob.glob(f'{scraped_data}/{site}/Data/*.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 955 json and csv files\n",
    "len(glob_paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use paths to open files, fix keywords, and drop unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix list catches all incorrect/faculty keyword search terms\n",
    "\n",
    "fix_list = []\n",
    "\n",
    "# Appended data catches all the fixed and cleaned dfs\n",
    "appended_data = []\n",
    "\n",
    "for glob_path in glob_paths:\n",
    "\n",
    "    if glob_path.endswith('.json'):\n",
    "        try:\n",
    "            df_temp = pd.read_json(glob_path).reset_index(drop=True)\n",
    "        except ValueError:\n",
    "            fix_list.append(glob_path)\n",
    "            if 'scraped_data/LinkedIn/Data/linkedin_jobs_df_' in glob_path:\n",
    "                data_json = fix_broken_linkedin_files(glob_path)\n",
    "                try:\n",
    "                    df_temp = pd.read_json(glob_path).reset_index(drop=True)\n",
    "                except ValueError:\n",
    "                    fix_list.append(glob_path)\n",
    "    elif glob_path.endswith('.csv'):\n",
    "        df_temp = pd.read_csv(glob_path).reset_index(drop=True)\n",
    "\n",
    "    if len(df_temp) > 0 and isinstance(df_temp, pd.DataFrame):\n",
    "        df_temp = fix_keywords(df_temp)\n",
    "        df_temp.reset_index(drop=True, inplace=True)\n",
    "        df_temp.drop(columns=cols, axis='columns', inplace=True, errors='ignore')\n",
    "        df_temp.drop(\n",
    "        df_temp.columns[\n",
    "                df_temp.columns.str.contains(\n",
    "                    'unnamed|index|level', regex=True, case=False, flags=re.I\n",
    "                )\n",
    "            ],\n",
    "            axis='columns',\n",
    "            inplace=True,\n",
    "            errors='ignore',\n",
    "        )\n",
    "    \n",
    "        if glob_path.endswith('.json'):\n",
    "            df_temp.to_json(glob_path, orient='records')\n",
    "        elif glob_path.endswith('.csv'):\n",
    "            df_temp.to_csv(glob_path, index=False)\n",
    "\n",
    "        appended_data.append(df_temp.reset_index(drop=True))\n",
    "\n",
    "# Concatonate list of dfs into one large df_jobs\n",
    "df_jobs = pd.concat(appended_data).reset_index(drop=True)\n",
    "\n",
    "# Save df_jobs to file\n",
    "if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "    df_jobs.to_pickle(f'{data_dir}df_jobs_raw.pkl')\n",
    "    \n",
    "    df_jobs.to_csv(f'{data_dir}df_jobs_raw.csv', index=False)\n",
    "else:\n",
    "    print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dfs, len = 527\n",
    "len(appended_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len = 204394\n",
    "len(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we couldn't fix some keywords, we add them to list fix_list and write to file\n",
    "if len(fix_list) != 0:\n",
    "    print('Some keywords to fix!')\n",
    "    with open(f'{data_dir}fix_list.txt', 'w') as f:\n",
    "        json.dump(fix_list, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START HERE IF SOURCING FROM DF_RAW\n",
    "### PLEASE SET CORRECT DIRECTORY PATHS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "# columns\n",
    "cols=['Sector', \n",
    "      'Sector Code', \n",
    "      'Gender', \n",
    "      'Age', \n",
    "      'Language', \n",
    "      'Dutch Requirement', \n",
    "      'English Requirement', \n",
    "      'Gender_Female', \n",
    "      'Gender_Mixed', \n",
    "      'Gender_Male', \n",
    "      'Age_Older', \n",
    "      'Age_Mixed', \n",
    "      'Age_Younger', \n",
    "      'Gender_Num', \n",
    "      'Age_Num', \n",
    "      '% Female', \n",
    "      '% Male', \n",
    "      '% Older', \n",
    "      '% Younger']\n",
    "\n",
    "int_variable: str = 'Job ID'\n",
    "str_variable: str = 'Job Description'\n",
    "gender: str = 'Gender'\n",
    "age: str = 'Age'\n",
    "language: str = 'en'\n",
    "str_cols = ['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name', 'Location', 'Job Description', 'Company URL', 'Job URL', 'Tracking ID']\n",
    "nan_list = [None, 'None', '', ' ', [], -1, '-1', 0, '0', 'nan', np.nan, 'Nan']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import googletrans\n",
    "from pathlib import Path\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from spacy.pipeline import Sentencizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len = 204394\n",
    "len(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean columns\n",
    "df_jobs.columns = df_jobs.columns.to_series().apply(lambda x: str(x).strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA\n",
    "df_jobs.dropna(axis='index', how='all', inplace=True)\n",
    "df_jobs.dropna(axis='columns', how='all', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len = 204394\n",
    "len(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates on subset of 'Job Description'\n",
    "df_jobs.drop_duplicates(subset=['Company Name', 'Job Description'], keep='first', ignore_index=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len = 64694\n",
    "len(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows with missing 'Job Description'\n",
    "df_jobs.drop(\n",
    "    df_jobs.index[\n",
    "        df_jobs['Job Description'].isin(nan_list)\n",
    "    ], \n",
    "    axis='index',\n",
    "    inplace=True,\n",
    "    errors='ignore'\n",
    "\n",
    ")\n",
    "\n",
    "# Save df_jobs to file\n",
    "if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "    df_jobs.to_pickle(f'{data_dir}df_jobs_raw_dropped.pkl')\n",
    "    \n",
    "    df_jobs.to_csv(f'{data_dir}df_jobs_raw_dropped.csv', index=False)\n",
    "else:\n",
    "    print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START HERE IF SOURCING FROM DF_RAW_DROPPED\n",
    "### PLEASE SET CORRECT DIRECTORY PATHS BELOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "mod = sys.modules[__name__]\n",
    "\n",
    "code_dir = None\n",
    "code_dir_name = 'Code'\n",
    "unwanted_subdir_name = 'Analysis'\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    parent_path = str(Path.cwd().parents[_]).split('/')[-1]\n",
    "\n",
    "    if (code_dir_name in parent_path) and (unwanted_subdir_name not in parent_path):\n",
    "\n",
    "        code_dir = str(Path.cwd().parents[_])\n",
    "\n",
    "        if code_dir is not None:\n",
    "            break\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN DIR\n",
    "main_dir = f'{str(Path(code_dir).parents[0])}/'\n",
    "\n",
    "# code_dir\n",
    "code_dir = f'{code_dir}/'\n",
    "sys.path.append(code_dir)\n",
    "\n",
    "# scraping dir\n",
    "scraped_data = f'{code_dir}scraped_data/'\n",
    "\n",
    "# data dir\n",
    "data_dir = f'{code_dir}data/'\n",
    "\n",
    "# lang models dir\n",
    "llm_path = f'{data_dir}Language Models'\n",
    "\n",
    "# sites\n",
    "site_list=['Indeed', 'Glassdoor', 'LinkedIn']\n",
    "\n",
    "# columns\n",
    "cols=['Sector', \n",
    "      'Sector Code', \n",
    "      'Gender', \n",
    "      'Age', \n",
    "      'Language', \n",
    "      'Dutch Requirement', \n",
    "      'English Requirement', \n",
    "      'Gender_Female', \n",
    "      'Gender_Mixed', \n",
    "      'Gender_Male', \n",
    "      'Age_Older', \n",
    "      'Age_Mixed', \n",
    "      'Age_Younger', \n",
    "      'Gender_Num', \n",
    "      'Age_Num', \n",
    "      '% Female', \n",
    "      '% Male', \n",
    "      '% Older', \n",
    "      '% Younger']\n",
    "\n",
    "int_variable: str = 'Job ID'\n",
    "str_variable: str = 'Job Description'\n",
    "gender: str = 'Gender'\n",
    "age: str = 'Age'\n",
    "language: str = 'en'\n",
    "str_cols = ['Search Keyword', 'Platform', 'Job ID', 'Job Title', 'Company Name', 'Location', 'Job Description', 'Company URL', 'Job URL', 'Tracking ID']\n",
    "nan_list = [None, 'None', '', ' ', [], -1, '-1', 0, '0', 'nan', np.nan, 'Nan']\n",
    "pattern = r'[\\n]+|[,]{2,}|[|]{2,}|[\\n\\r]+|(?<=[a-z]\\.)(?=\\s*[A-Z])|(?=\\:+[A-Z])'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import googletrans\n",
    "from pathlib import Path\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from spacy.pipeline import Sentencizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw_dropped.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64684"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 64684\n",
    "len(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64684 entries, 0 to 64683\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Search Keyword     64684 non-null  object \n",
      " 1   Platform           64684 non-null  object \n",
      " 2   Job ID             64684 non-null  object \n",
      " 3   Job Title          64684 non-null  object \n",
      " 4   Company Name       64679 non-null  object \n",
      " 5   Location           64684 non-null  object \n",
      " 6   Job Description    64684 non-null  object \n",
      " 7   Rating             4130 non-null   float64\n",
      " 8   Employment Type    63959 non-null  object \n",
      " 9   Company URL        61360 non-null  object \n",
      " 10  Job URL            64684 non-null  object \n",
      " 11  Job Age            64684 non-null  object \n",
      " 12  Job Age Number     64684 non-null  object \n",
      " 13  Collection Date    64684 non-null  object \n",
      " 14  Data Row           60551 non-null  float64\n",
      " 15  Tracking ID        60551 non-null  object \n",
      " 16  Industry           61279 non-null  object \n",
      " 17  Job Date           60554 non-null  object \n",
      " 18  Type of ownership  725 non-null    object \n",
      "dtypes: float64(2), object(17)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_jobs.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw_language_detected.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64684"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 64684\n",
    "len(df_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    1785\n",
       "nl     193\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jobs['Language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1978: Translation in progress.\n",
      "Row 1978: Translation done.\n",
      "Row 1979: Translation in progress.\n",
      "Row 1979: Translation done.\n",
      "Row 1980: Translation in progress.\n",
      "Row 1980: Translation done.\n",
      "Row 1981: Translation in progress.\n",
      "Row 1981: Translation done.\n",
      "Row 1982: Translation in progress.\n",
      "Row 1982: Translation done.\n",
      "Row 1983: Translation in progress.\n",
      "Row 1983: Translation done.\n",
      "Row 1984: Translation in progress.\n",
      "Row 1984: Translation done.\n",
      "Row 1985: Translation in progress.\n",
      "Row 1985: Translation done.\n",
      "Row 1986: Translation in progress.\n",
      "Row 1986: Translation done.\n",
      "Row 1987: Translation in progress.\n",
      "Row 1987: Translation done.\n",
      "Row 1988: Translation in progress.\n",
      "Row 1988: Translation done.\n",
      "Row 1989: Translation in progress.\n",
      "Row 1989: Translation done.\n",
      "Row 1990: Translation in progress.\n",
      "Row 1990: Translation done.\n",
      "Row 1991: Translation in progress.\n",
      "Row 1991: Translation done.\n",
      "Row 1992: Translation in progress.\n",
      "Row 1992: Translation done.\n",
      "Row 1993: Translation in progress.\n",
      "Row 1993: Translation done.\n",
      "Row 1994: Translation in progress.\n",
      "Row 1994: Translation done.\n",
      "Row 1995: Translation in progress.\n",
      "Row 1995: Translation done.\n",
      "Row 1996: Translation in progress.\n",
      "Row 1996: Translation done.\n",
      "Row 1997: Translation in progress.\n",
      "Row 1997: Translation done.\n",
      "Row 1998: Translation in progress.\n",
      "Row 1998: Translation done.\n",
      "Row 1999: Translation in progress.\n",
      "Row 1999: Translation done.\n",
      "Row 2000: Translation in progress.\n",
      "Row 2000: Translation done.\n",
      "Row 2001: Translation in progress.\n",
      "Row 2001: Translation done.\n",
      "Row 2002: Translation in progress.\n",
      "Row 2002: Translation done.\n",
      "Row 2003: Translation in progress.\n",
      "Row 2003: Translation done.\n",
      "Row 2004: Translation in progress.\n",
      "Row 2004: Translation done.\n",
      "Row 2005: Translation in progress.\n",
      "Row 2005: Translation done.\n",
      "Row 2006: Translation in progress.\n",
      "Row 2006: Translation done.\n",
      "Row 2007: Translation in progress.\n",
      "Row 2007: Translation done.\n",
      "Row 2008: Translation in progress.\n",
      "Row 2008: Translation done.\n",
      "Row 2009: Translation in progress.\n",
      "Row 2009: Translation done.\n",
      "Row 2010: Translation in progress.\n",
      "Row 2010: Translation done.\n",
      "Row 2011: Translation in progress.\n",
      "Row 2011: Translation done.\n",
      "Row 2012: Translation in progress.\n",
      "Row 2012: Translation done.\n",
      "Row 2013: Translation in progress.\n",
      "Row 2013: Translation done.\n",
      "Row 2014: Translation in progress.\n",
      "Row 2014: Translation done.\n",
      "Row 2015: Translation in progress.\n",
      "Row 2015: Translation done.\n",
      "Row 2016: Translation in progress.\n",
      "Row 2016: Translation done.\n",
      "Row 2017: Translation in progress.\n",
      "Row 2017: Translation done.\n",
      "Row 2018: Translation in progress.\n",
      "Row 2018: Translation done.\n",
      "Row 2019: Translation in progress.\n",
      "Row 2019: Translation done.\n",
      "Row 2020: Translation in progress.\n",
      "Row 2020: Translation done.\n",
      "Row 2021: Translation in progress.\n",
      "Row 2021: Translation done.\n",
      "Row 2022: Translation in progress.\n",
      "Row 2022: Translation done.\n",
      "Row 2023: Translation in progress.\n",
      "Row 2023: Translation done.\n",
      "Row 2024: Translation in progress.\n",
      "Row 2024: Translation done.\n",
      "Row 2025: Translation in progress.\n",
      "Row 2025: Translation done.\n",
      "Row 2026: Translation in progress.\n",
      "Row 2026: Translation done.\n",
      "Row 2027: Translation in progress.\n",
      "Row 2027: Translation done.\n",
      "Row 2028: Translation in progress.\n",
      "Row 2028: Translation done.\n",
      "Row 2029: Translation in progress.\n",
      "Row 2029: Translation done.\n",
      "Row 2030: Translation in progress.\n",
      "Row 2030: Translation done.\n",
      "Row 2031: Translation in progress.\n",
      "Row 2031: Translation done.\n",
      "Row 2032: Translation in progress.\n",
      "Row 2032: Translation done.\n",
      "Row 2033: Translation in progress.\n",
      "Row 2033: Translation done.\n",
      "Row 2034: Translation in progress.\n",
      "Row 2034: Translation done.\n",
      "Row 2035: Translation in progress.\n",
      "Row 2035: Translation done.\n",
      "Row 2036: Translation in progress.\n",
      "Row 2036: Translation done.\n",
      "Row 2037: Translation in progress.\n",
      "Row 2037: Translation done.\n",
      "Row 2038: Translation in progress.\n",
      "Row 2038: Translation done.\n",
      "Row 2039: Translation in progress.\n",
      "Row 2039: Translation done.\n",
      "Row 2040: Translation in progress.\n",
      "Row 2040: Translation done.\n",
      "Row 2041: Translation in progress.\n",
      "Row 2041: Translation done.\n",
      "Row 2042: Translation in progress.\n",
      "Row 2042: Translation done.\n",
      "Row 2043: Translation in progress.\n",
      "Row 2043: Translation done.\n",
      "Row 2044: Translation in progress.\n",
      "Row 2044: Translation done.\n",
      "Row 2045: Translation in progress.\n",
      "Row 2045: Translation done.\n",
      "Row 2046: Translation in progress.\n",
      "Row 2046: Translation done.\n",
      "Row 2047: Translation in progress.\n",
      "Row 2047: Translation done.\n",
      "Row 2048: Translation in progress.\n",
      "Row 2048: Translation done.\n",
      "Row 2049: Translation in progress.\n",
      "Row 2049: Translation done.\n",
      "Row 2050: Translation in progress.\n",
      "Row 2050: Translation done.\n",
      "Row 2051: Translation in progress.\n",
      "Row 2051: Translation done.\n",
      "Row 2052: Translation in progress.\n",
      "Row 2052: Translation done.\n",
      "Row 2053: Translation in progress.\n",
      "Row 2053: Translation done.\n",
      "Row 2054: Translation in progress.\n",
      "Row 2054: Translation done.\n",
      "Row 2055: Translation in progress.\n",
      "Row 2055: Translation done.\n",
      "Row 2056: Translation in progress.\n",
      "Row 2056: Translation done.\n",
      "Row 2057: Translation in progress.\n",
      "Row 2057: Translation done.\n",
      "Row 2058: Translation in progress.\n",
      "Row 2058: Translation done.\n",
      "Row 2059: Translation in progress.\n",
      "Row 2059: Translation done.\n",
      "Row 2060: Translation in progress.\n",
      "Row 2060: Translation done.\n",
      "Row 2061: Translation in progress.\n",
      "Row 2061: Translation done.\n",
      "Row 2062: Translation in progress.\n",
      "Row 2062: Translation done.\n",
      "Row 2063: Translation in progress.\n",
      "Row 2063: Translation done.\n",
      "Row 2064: Translation in progress.\n",
      "Row 2064: Translation done.\n",
      "Row 2065: Translation in progress.\n",
      "Row 2065: Translation done.\n",
      "Row 2066: Translation in progress.\n",
      "Row 2066: Translation done.\n",
      "Row 2067: Translation in progress.\n",
      "Row 2067: Translation done.\n",
      "Row 2068: Translation in progress.\n",
      "Row 2068: Translation done.\n",
      "Row 2069: Translation in progress.\n",
      "Row 2069: Translation done.\n",
      "Row 2070: Translation in progress.\n",
      "Row 2070: Translation done.\n",
      "Row 2071: Translation in progress.\n",
      "Row 2071: Translation done.\n",
      "Row 2072: Translation in progress.\n",
      "Row 2072: Translation done.\n",
      "Row 2073: Translation in progress.\n",
      "Row 2073: Translation done.\n",
      "Row 2074: Translation in progress.\n",
      "Row 2074: Translation done.\n",
      "Row 2075: Translation in progress.\n",
      "Row 2075: Translation done.\n",
      "Row 2076: Translation in progress.\n",
      "Row 2076: Translation done.\n",
      "Row 2077: Translation in progress.\n",
      "Row 2077: Translation done.\n",
      "Row 2078: Translation in progress.\n",
      "Row 2078: Translation done.\n",
      "Row 2079: Translation in progress.\n",
      "Row 2079: Translation done.\n",
      "Row 2080: Translation in progress.\n",
      "Row 2080: Translation done.\n",
      "Row 2081: Translation in progress.\n",
      "Row 2081: Translation done.\n",
      "Row 2082: Translation in progress.\n",
      "Row 2082: Translation done.\n",
      "Row 2083: Translation in progress.\n",
      "Row 2083: Translation done.\n",
      "Row 2084: Translation in progress.\n",
      "Row 2084: Translation done.\n",
      "Row 2085: Translation in progress.\n",
      "Row 2085: Translation done.\n",
      "Row 2086: Translation in progress.\n",
      "Row 2086: Translation done.\n",
      "Row 2087: Translation in progress.\n",
      "Row 2087: Translation done.\n",
      "Row 2088: Translation in progress.\n",
      "Row 2088: Translation done.\n",
      "Row 2089: Translation in progress.\n",
      "Row 2089: Translation done.\n",
      "Row 2090: Translation in progress.\n",
      "Row 2090: Translation done.\n",
      "Row 2091: Translation in progress.\n",
      "Row 2091: Translation done.\n",
      "Row 2092: Translation in progress.\n",
      "Row 2092: Translation done.\n",
      "Row 2093: Translation in progress.\n",
      "Row 2093: Translation done.\n",
      "Row 2094: Translation in progress.\n",
      "Row 2094: Translation done.\n",
      "Row 2095: Translation in progress.\n",
      "Row 2095: Translation done.\n",
      "Row 2096: Translation in progress.\n",
      "Row 2096: Translation done.\n",
      "Row 2097: Translation in progress.\n",
      "Row 2097: Translation done.\n",
      "Row 2098: Translation in progress.\n",
      "Row 2098: Translation done.\n",
      "Row 2099: Translation in progress.\n",
      "Row 2099: Translation done.\n",
      "Row 2100: Translation in progress.\n",
      "Row 2100: Translation done.\n",
      "Row 2101: Translation in progress.\n",
      "Row 2101: Translation done.\n",
      "Row 2102: Translation in progress.\n",
      "Row 2102: Translation done.\n",
      "Row 2103: Translation in progress.\n",
      "Row 2103: Translation done.\n",
      "Row 2104: Translation in progress.\n",
      "Row 2104: Translation done.\n",
      "Row 2105: Translation in progress.\n",
      "Row 2105: Translation done.\n",
      "Row 2106: Translation in progress.\n",
      "Row 2106: Translation done.\n",
      "Row 2107: Translation in progress.\n",
      "Row 2107: Translation done.\n",
      "Row 2108: Translation in progress.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2108: Translation done.\n",
      "Row 2109: Translation in progress.\n",
      "Row 2109: Translation done.\n",
      "Row 2110: Translation in progress.\n",
      "Row 2110: Translation done.\n",
      "Row 2111: Translation in progress.\n",
      "Row 2111: Translation done.\n",
      "Row 2112: Translation in progress.\n",
      "Row 2112: Translation done.\n",
      "Row 2113: Translation in progress.\n",
      "Row 2113: Translation done.\n",
      "Row 2114: Translation in progress.\n",
      "Row 2114: Translation done.\n",
      "Row 2115: Translation in progress.\n",
      "Row 2115: Translation done.\n",
      "Row 2116: Translation in progress.\n",
      "Row 2116: Translation done.\n",
      "Row 2117: Translation in progress.\n",
      "Row 2117: Translation done.\n",
      "Row 2118: Translation in progress.\n",
      "Row 2118: Translation done.\n",
      "Row 2119: Translation in progress.\n",
      "Row 2119: Translation done.\n",
      "Row 2120: Translation in progress.\n",
      "Row 2120: Translation done.\n",
      "Row 2121: Translation in progress.\n",
      "Row 2121: Translation done.\n",
      "Row 2122: Translation in progress.\n",
      "Row 2122: Translation done.\n",
      "Row 2123: Translation in progress.\n",
      "Row 2123: Translation done.\n",
      "Row 2124: Translation in progress.\n",
      "Row 2124: Translation done.\n",
      "Row 2125: Translation in progress.\n",
      "Row 2125: Translation done.\n",
      "Row 2126: Translation in progress.\n",
      "Row 2126: Translation done.\n",
      "Row 2127: Translation in progress.\n",
      "Row 2127: Translation done.\n",
      "Row 2128: Translation in progress.\n",
      "Row 2128: Translation done.\n",
      "Row 2129: Translation in progress.\n",
      "Row 2129: Translation done.\n",
      "Row 2130: Translation in progress.\n",
      "Row 2130: Translation done.\n",
      "Row 2131: Translation in progress.\n",
      "Row 2131: Translation done.\n",
      "Row 2132: Translation in progress.\n",
      "Row 2132: Translation done.\n",
      "Row 2133: Translation in progress.\n",
      "Row 2133: Translation done.\n",
      "Row 2134: Translation in progress.\n",
      "Row 2134: Translation done.\n",
      "Row 2135: Translation in progress.\n",
      "Row 2135: Translation done.\n",
      "Row 2136: Translation in progress.\n",
      "Row 2136: Translation done.\n",
      "Row 2137: Translation in progress.\n",
      "Row 2137: Translation done.\n",
      "Row 2138: Translation in progress.\n",
      "Row 2138: Translation done.\n",
      "Row 2139: Translation in progress.\n",
      "Row 2139: Translation done.\n",
      "Row 2140: Translation in progress.\n",
      "Row 2140: Translation done.\n",
      "Row 2141: Translation in progress.\n",
      "Row 2141: Translation done.\n",
      "Row 2142: Translation in progress.\n",
      "Row 2142: Translation done.\n",
      "Row 2143: Translation in progress.\n",
      "Row 2143: Translation done.\n",
      "Row 2144: Translation in progress.\n",
      "Row 2144: Translation done.\n",
      "Row 2145: Translation in progress.\n",
      "Row 2145: Translation done.\n",
      "Row 2146: Translation in progress.\n",
      "Row 2146: Translation done.\n",
      "Row 2147: Translation in progress.\n",
      "Row 2147: Translation done.\n",
      "Row 2148: Translation in progress.\n",
      "Row 2148: Translation done.\n",
      "Row 2149: Translation in progress.\n",
      "Row 2149: Translation done.\n",
      "Row 2150: Translation in progress.\n",
      "Row 2150: Translation done.\n",
      "Row 2151: Translation in progress.\n",
      "Row 2151: Translation done.\n",
      "Row 2152: Translation in progress.\n",
      "Row 2152: Translation done.\n",
      "Row 2153: Translation in progress.\n",
      "Row 2153: Translation done.\n",
      "Row 2154: Translation in progress.\n",
      "Row 2154: Translation done.\n",
      "Row 2155: Translation in progress.\n",
      "Row 2155: Translation done.\n",
      "Row 2156: Translation in progress.\n",
      "Row 2156: Translation done.\n",
      "Row 2157: Translation in progress.\n",
      "Row 2157: Translation done.\n",
      "Row 2158: Translation in progress.\n",
      "Row 2158: Translation done.\n",
      "Row 2159: Translation in progress.\n",
      "Row 2159: Translation done.\n",
      "Row 2160: Translation in progress.\n",
      "Row 2160: Translation done.\n",
      "Row 2161: Translation in progress.\n",
      "Row 2161: Translation done.\n",
      "Row 2162: Translation in progress.\n",
      "Row 2162: Translation done.\n",
      "Row 2163: Translation in progress.\n",
      "Row 2163: Translation done.\n",
      "Row 2164: Translation in progress.\n",
      "Row 2164: Translation done.\n",
      "Row 2165: Translation in progress.\n",
      "Row 2165: Translation done.\n",
      "Row 2166: Translation in progress.\n",
      "Row 2166: Translation done.\n",
      "Row 2167: Translation in progress.\n",
      "Row 2167: Translation done.\n",
      "Row 2168: Translation in progress.\n",
      "Row 2168: Translation done.\n",
      "Row 2169: Translation in progress.\n",
      "Row 2169: Translation done.\n",
      "Row 2170: Translation in progress.\n",
      "Row 2170: Translation done.\n",
      "Row 2171: Translation in progress.\n",
      "Row 2171: Translation done.\n",
      "Row 2172: Translation in progress.\n",
      "Row 2172: Translation done.\n",
      "Row 2173: Translation in progress.\n",
      "Row 2173: Translation done.\n",
      "Row 2174: Translation in progress.\n",
      "Row 2174: Translation done.\n",
      "Row 2175: Translation in progress.\n",
      "Row 2175: Translation done.\n",
      "Row 2176: Translation in progress.\n",
      "Row 2176: Translation done.\n",
      "Row 2177: Translation in progress.\n",
      "Row 2177: Translation done.\n",
      "Row 2178: Translation in progress.\n",
      "Row 2178: Translation done.\n",
      "Row 2179: Translation in progress.\n",
      "Row 2179: Translation done.\n",
      "Row 2180: Translation in progress.\n",
      "Row 2180: Translation done.\n",
      "Row 2181: Translation in progress.\n",
      "Row 2181: Translation done.\n",
      "Row 2182: Translation in progress.\n",
      "Row 2182: Translation done.\n",
      "Row 2183: Translation in progress.\n",
      "Row 2183: Translation done.\n",
      "Row 2184: Translation in progress.\n",
      "Row 2184: Translation done.\n",
      "Row 2185: Translation in progress.\n",
      "Row 2185: Translation done.\n",
      "Row 2186: Translation in progress.\n",
      "Row 2186: Translation done.\n",
      "Row 2187: Translation in progress.\n",
      "Row 2187: Translation done.\n",
      "Row 2188: Translation in progress.\n",
      "Row 2188: Translation done.\n",
      "Row 2189: Translation in progress.\n",
      "Row 2189: Translation done.\n",
      "Row 2190: Translation in progress.\n",
      "Row 2190: Translation done.\n",
      "Row 2191: Translation in progress.\n",
      "Row 2191: Translation done.\n",
      "Row 2192: Translation in progress.\n",
      "Row 2192: Translation done.\n",
      "Row 2193: Translation in progress.\n",
      "Row 2193: Translation done.\n",
      "Row 2194: Translation in progress.\n",
      "Row 2194: Translation done.\n",
      "Row 2195: Translation in progress.\n",
      "Row 2195: Translation done.\n",
      "Row 2196: Translation in progress.\n",
      "Row 2196: Translation done.\n",
      "Row 2197: Translation in progress.\n",
      "Row 2197: Translation done.\n",
      "Row 2198: Translation in progress.\n",
      "Row 2198: Translation done.\n",
      "Row 2199: Translation in progress.\n",
      "Row 2199: Translation done.\n",
      "Row 2200: Translation in progress.\n",
      "Row 2200: Translation done.\n",
      "Row 2201: Translation in progress.\n",
      "Row 2201: Translation done.\n",
      "Row 2202: Translation in progress.\n",
      "Row 2202: Translation done.\n",
      "Row 2203: Translation in progress.\n",
      "Row 2203: Translation done.\n",
      "Row 2204: Translation in progress.\n",
      "Row 2204: Translation done.\n",
      "Row 2205: Translation in progress.\n",
      "Row 2205: Translation done.\n",
      "Row 2206: Translation in progress.\n",
      "Row 2206: Translation done.\n",
      "Row 2207: Translation in progress.\n",
      "Row 2207: Translation done.\n",
      "Row 2208: Translation in progress.\n",
      "Row 2208: Translation done.\n",
      "Row 2209: Translation in progress.\n",
      "Row 2209: Translation done.\n",
      "Row 2210: Translation in progress.\n",
      "Row 2210: Translation done.\n",
      "Row 2211: Translation in progress.\n",
      "Row 2211: Translation done.\n",
      "Row 2212: Translation in progress.\n",
      "Row 2212: Translation done.\n",
      "Row 2213: Translation in progress.\n",
      "Row 2213: Translation done.\n",
      "Row 2214: Translation in progress.\n",
      "Row 2214: Translation done.\n",
      "Row 2215: Translation in progress.\n",
      "Row 2215: Translation done.\n",
      "Row 2216: Translation in progress.\n",
      "Row 2216: Translation done.\n",
      "Row 2217: Translation in progress.\n",
      "Row 2217: Translation done.\n",
      "Row 2218: Translation in progress.\n",
      "Row 2218: Translation done.\n",
      "Row 2219: Translation in progress.\n",
      "Row 2219: Translation done.\n",
      "Row 2220: Translation in progress.\n",
      "Row 2220: Translation done.\n",
      "Row 2221: Translation in progress.\n",
      "Row 2221: Translation done.\n",
      "Row 2222: Translation in progress.\n",
      "Row 2222: Translation done.\n",
      "Row 2223: Translation in progress.\n",
      "Row 2223: Translation done.\n",
      "Row 2224: Translation in progress.\n",
      "Row 2224: Translation done.\n",
      "Row 2225: Translation in progress.\n",
      "Row 2225: Translation done.\n",
      "Row 2226: Translation in progress.\n",
      "Row 2226: Translation done.\n",
      "Row 2227: Translation in progress.\n",
      "Row 2227: Translation done.\n",
      "Row 2228: Translation in progress.\n",
      "Row 2228: Translation done.\n",
      "Row 2229: Translation in progress.\n",
      "Row 2229: Translation done.\n",
      "Row 2230: Translation in progress.\n",
      "Row 2230: Translation done.\n",
      "Row 2231: Translation in progress.\n",
      "Row 2231: Translation done.\n",
      "Row 2232: Translation in progress.\n"
     ]
    }
   ],
   "source": [
    "translator = Translator()\n",
    "googletrans_readtime_error = googletrans.client.httpx._client.httpcore._exceptions.ReadTimeout\n",
    "\n",
    "# try:\n",
    "#     time.sleep(60)\n",
    "#     df_jobs['Language'] = df_jobs['Job Description'].apply(lambda x: translator.detect(str(x).lower().strip()).lang)\n",
    "# except:\n",
    "#     time.sleep(3600)\n",
    "#     df_jobs['Language'] = df_jobs['Job Description'].apply(lambda x: translator.detect(str(x).lower().strip()).lang)\n",
    "\n",
    "for idx, row in df_jobs.iterrows():\n",
    "    # This part ensures we don't start lang detection from index 0 if some lang detection was already done\n",
    "    if (len(str(row['Job Description'])) != 0) and ('Language' in df_jobs.columns) and (type(row['Language']) == float and np.isnan(row['Language'])):\n",
    "\n",
    "        try:\n",
    "            print(f'Row {idx}: Translation in progress.')\n",
    "            time.sleep(60)\n",
    "            df_jobs.loc[idx, 'Language'] = str(translator.detect(str(row['Job Description']).lower().strip()).lang)\n",
    "            print(f'Row {idx}: Translation done.')\n",
    "        except googletrans_readtime_error:\n",
    "            print(f'Row {idx}: Sleeping for an hour.')\n",
    "            print('-'*30)\n",
    "            time.sleep(3600)\n",
    "            print(f'Row {idx}: Done sleeping.')\n",
    "            print('-'*30)\n",
    "            df_jobs.loc[idx, 'Language'] = str(translator.detect(str(row['Job Description']).lower().strip()).lang)\n",
    "\n",
    "if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "    df_jobs.to_pickle(f'{data_dir}df_jobs_raw_language_detected.pkl')\n",
    "    \n",
    "    df_jobs.to_csv(f'{data_dir}df_jobs_raw_language_detected.csv', index=False)\n",
    "else:\n",
    "    print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-english job descriptions\n",
    "# df_jobs.drop(df_jobs.index[df_jobs['Language'] == str(language)], axis='index', inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_jobs) > 0 and isinstance(df_jobs, pd.DataFrame):\n",
    "    df_jobs.to_pickle(f'{data_dir}df_jobs_raw_language_detected.pkl')\n",
    "    \n",
    "    df_jobs.to_csv(f'{data_dir}df_jobs_raw_language_detected.csv', index=False)\n",
    "else:\n",
    "    print(f'ERORR: LENGTH OF DF = {len(df_jobs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_jobs = pd.read_pickle(f'{data_dir}df_jobs_raw_language_detected.pkl').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and count unique search keywords\n",
    "search_keywords = list(set(df_jobs['Search Keyword'].to_list()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(search_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descriptions = list(set(df_jobs['Job Description'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(job_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NLK\n",
    "nltk_path = f'{llm_path}/nltk'\n",
    "nltk.data.path.append(nltk_path)\n",
    "\n",
    "nltk.download('words', download_dir = nltk_path)\n",
    "nltk.download('punkt', download_dir = nltk_path)\n",
    "nltk.download('stopwords', download_dir = nltk_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job_description in job_descriptions:\n",
    "    print([doc for doc in sentencizer()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_sentences = []\n",
    "for job_description in job_descriptions:\n",
    "    job_sentences.extend(sent_tokenize(job_description))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_sentences[0].split('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spacy with nlp to sent tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study1_3.10",
   "language": "python",
   "name": "study1_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e64b55c31e662d3b8ca165241f15a246a93354fe580fc7a1249b2f351dbc5a06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
